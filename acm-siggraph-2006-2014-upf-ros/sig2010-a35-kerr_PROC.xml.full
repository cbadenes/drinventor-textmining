{
  "uri" : "sig2010-a35-kerr_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2010/a35-kerr_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Toward Evaluating Material Design Interface Paradigms for Novice Users",
    "published" : "2010",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/William B.-Kerr",
      "name" : "William B.",
      "surname" : "Kerr"
    }, {
      "uri" : "http://drinventor/Fabio-Pellacini",
      "name" : "Fabio",
      "surname" : "Pellacini"
    } ]
  },
  "bagOfWords" : [ "369c7203009bde22530935fb84de1891c5acb86b1003994a1d41cb27282afcb9", "mib", "10.1145", "1778765.1778772", "name", "identification", "possible", "toward", "evaluate", "Material", "Design", "Interface", "Paradigms", "Novice", "Users", "William", "B.", "Kerr", "Dartmouth", "College", "physical", "slider", "perceptual", "slider", "image", "navigation", "figure", "example", "workflow", "two", "novice", "subject", "editing", "material", "use", "three", "different", "interface", "material", "design", "goal", "can", "find", "fig.", "error", "compute", "from", "equation", "-lrb-", "-rrb-", "can", "find", "fig.", "material", "design", "process", "which", "artist", "specify", "reflectance", "property", "surface", "its", "diffuse", "color", "specular", "roughness", "we", "present", "user", "study", "evaluate", "relative", "benefit", "different", "material", "design", "interface", "focus", "novice", "user", "since", "stand", "gain", "most", "from", "intuitive", "interface", "specifically", "we", "investigate", "editing", "parameter", "analytic", "bidirectional", "distribution", "function", "-lrb-", "brdf", "-rrb-", "use", "three", "interface", "paradigm", "physical", "slider", "which", "user", "set", "parameter", "analytic", "brdf", "model", "diffuse", "albedo", "specular", "roughness", "perceptual", "slider", "which", "user", "set", "perceptually-inspired", "parameter", "diffuse", "luminance", "gloss", "contrast", "image", "navigation", "which", "material", "variation", "display", "array", "image", "thumbnail", "user", "make", "edit", "select", "they", "we", "investigate", "two", "design", "task", "precise", "adjustment", "artistic", "exploration", "we", "collect", "objective", "subjective", "datum", "find", "subject", "can", "perform", "equally", "well", "physical", "perceptual", "slider", "long", "interface", "respond", "interactively", "image", "navigation", "perform", "worse", "than", "other", "interface", "precise", "adjustment", "task", "excel", "aid", "artistic", "exploration", "we", "find", "give", "enough", "time", "novice", "can", "perform", "relatively", "complex", "material", "editing", "task", "little", "training", "most", "novice", "work", "similarly", "one", "another", "keyword", "material", "design", "interface", "user", "study", "e-mail", "wkerr@cs.dartmouth.edu", "e-mail", "fabio@cs.dartmouth.edu", "fabio", "Pellacini", "Dartmouth", "College", "physical", "slider", "perceptual", "slider", "image", "navigation", "introduction", "real-world", "material", "exhibit", "wide", "variety", "reflectance", "behavior", "from", "matte", "surface", "highly", "glossy", "finish", "opaque", "material", "bidirectional", "reflectance", "distribution", "function", "-lrb-", "brdf", "-rrb-", "-lsb-", "Nicodemus", "et", "al.", "1977", "-rsb-", "capture", "directionally-varying", "appearance", "real-world", "surface", "material", "design", "process", "which", "artist", "define", "property", "surface", "material", "color", "specular", "roughness", "etc.", "can", "difficult", "time", "consuming", "task", "since", "variety", "real-world", "material", "large", "many", "user", "interface", "have", "be", "propose", "simplify", "process", "paper", "represent", "first", "step", "toward", "quantitatively", "evaluate", "effectiveness", "user", "interface", "material", "design", "we", "focus", "novice", "user", "without", "previous", "experience", "material", "design", "since", "stand", "gain", "most", "from", "intuitive", "interface", "represent", "majority", "potential", "user", "computer", "graphic", "design", "application", "we", "specifically", "interested", "task", "editing", "parameter", "realistic", "material", "represent", "analytic", "brdf", "since", "simplest", "most", "commonly", "use", "model", "we", "present", "user", "study", "investigate", "relative", "effectiveness", "three", "interactive", "material", "design", "interface", "physical", "slider", "which", "ACM", "Reference", "Format", "Kerr", "W.", "Pellacini", "F.", "2010", "toward", "evaluate", "Material", "Design", "Interface", "Paradigms", "Novice", "Users", "ACM", "Trans", "graph", "29", "Article", "35", "-lrb-", "July", "2010", "-rrb-", "10", "page", "dous", "10.1145", "1778765.1778772", "http://doi.acm.org/10.1145/1778765.1778772", "copyright", "Notice", "permission", "make", "digital", "hard", "copy", "part", "all", "work", "personal", "classroom", "use", "grant", "without", "fee", "provide", "copy", "make", "distribute", "profit", "direct", "commercial", "advantage", "copy", "show", "notice", "fus", "rst", "page", "initial", "screen", "display", "along", "full", "citation", "copyright", "component", "work", "own", "other", "than", "ACM", "must", "honor", "abstract", "credit", "permit", "copy", "otherwise", "republish", "post", "server", "redistribute", "list", "use", "any", "component", "work", "other", "work", "require", "prior", "specific", "permission", "and/or", "fee", "permission", "may", "request", "from", "Publications", "Dept.", "ACM", "Inc.", "Penn", "Plaza", "Suite", "701", "New", "York", "NY", "10121-0701", "fax", "+1", "-lrb-212-rrb-Â 869-0481", "permissions@acm.org", "2010", "ACM", "0730-0301/2010", "07-art35", "10.00", "DOI", "10.1145", "1778765.1778772", "http://doi.acm.org/10.1145/1778765.1778772", "ACM", "transaction", "Graphics", "Vol", "29", "no.", "Article", "35", "publication", "date", "July", "2010", "35:2", "W.", "Kerr", "et", "al.", "user", "set", "parameter", "analytic", "brdf", "model", "diffuse", "albedo", "specular", "roughness", "perceptual", "slider", "which", "user", "set", "perceptually-inspired", "parameter", "diffuse", "luminance", "gloss", "contrast", "image", "navigation", "which", "material", "variation", "display", "array", "image", "thumbnail", "user", "make", "edit", "select", "they", "fig.", "show", "example", "output", "from", "we", "subject", "use", "each", "interface", "we", "simplify", "material", "design", "task", "so", "can", "accomplish", "novice", "effectively", "measure", "focus", "physically-based", "isotropic", "brdf", "real-world", "material", "respect", "CookTorrance", "Ward", "BRDF", "model", "-lsb-", "cook", "Torrance", "1981", "Ward", "1992", "-rsb-", "much", "previous", "work", "material", "design", "focus", "modeling", "editing", "achromatic", "reflectance", "so", "we", "investigate", "use", "material", "design", "interface", "without", "color", "we", "also", "investigate", "editing", "analytic", "brdf", "parameter", "presence", "spatial", "variation", "across", "surface", "editing", "spatially-varying", "pattern", "themselves", "we", "extend", "we", "methodology", "from", "-lsb-", "Kerr", "Pellacini", "2009", "-rsb-", "investigate", "how", "novice", "use", "interface", "make", "precise", "adjustment", "artistically", "explore", "broad", "material", "variation", "we", "study", "consist", "three", "part", "first", "six", "match", "trial", "subject", "ask", "match", "target", "brdf", "closely", "possible", "second", "three", "open", "trial", "subject", "use", "own", "creativity", "design", "brdf", "base", "suggestive", "image", "finally", "questionnaire", "subject", "give", "both", "quantitative", "qualitative", "feedback", "about", "interface", "twenty", "subject", "spend", "roughly", "one", "hour", "each", "three", "interface", "we", "perform", "analysis", "objective", "measurement", "subjective", "user", "feedback", "draw", "follow", "conclusion", "give", "enough", "time", "subject", "previous", "training", "can", "perform", "meaningful", "material", "design", "task", "when", "support", "interface", "subject", "perform", "well", "both", "slider", "interface", "interactivity", "benefit", "outweigh", "benefit", "from", "use", "perceptually-inspired", "parameter", "compare", "physical", "parameter", "image", "navigation", "interface", "perform", "significantly", "worse", "than", "slider", "interface", "match", "task", "precise", "adjustment", "within", "boundary", "we", "study", "performance", "scale", "well", "material", "complexity", "degree", "freedom", "however", "some", "user", "do", "poorly", "when", "multiple", "brdf", "interact", "spatially-varying", "way", "within", "boundary", "we", "study", "introduction", "color", "roughly", "double", "time", "take", "reach", "goal", "reduce", "quality", "result", "similar", "factor", "error", "space", "indicate", "chromaticity", "significant", "challenge", "material", "design", "while", "image", "navigation", "generally", "inferior", "slider", "interface", "support", "broad", "artistic", "exploration", "better", "than", "parameter", "adjustment", "any", "user", "study", "we", "observation", "only", "strictly", "apply", "within", "boundary", "test", "case", "however", "we", "believe", "trend", "general", "enough", "apply", "other", "closely-related", "material", "domain", "affect", "development", "future", "material", "design", "interface", "additionally", "we", "believe", "principle", "use", "design", "we", "study", "can", "employ", "evaluate", "additional", "material", "design", "task", "move", "toward", "comprehensive", "evaluation", "material", "design", "interface", "related", "work", "Analytic", "BRDF", "model", "various", "brdf", "representation", "we", "specifically", "interested", "editing", "analytic", "brdf", "mod", "el", "since", "give", "user", "ability", "define", "brdf", "use", "only", "small", "number", "parameter", "we", "choose", "study", "editing", "Cook-Torrance", "brdf", "-lsb-", "cook", "Torrance", "1981", "-rsb-", "since", "fit", "measure", "datum", "well", "-lsb-", "Ngan", "et", "al.", "2005", "-rsb-", "isotropic", "version", "Ward", "brdf", "-lsb-", "Ward", "1992", "-rsb-", "since", "still", "fit", "measure", "datum", "reasonably", "well", "-lsb-", "Ngan", "et", "al.", "2005", "-rsb-", "since", "perceptual", "parameterization", "have", "be", "investigate", "-lsb-", "Pellacini", "et", "al.", "2000", "-rsb-", "avoid", "confusing", "novice", "large", "number", "model", "we", "do", "include", "other", "brdf", "model", "commonly", "use", "represent", "realistic", "material", "-lsb-", "Blinn", "1977", "Lafortune", "et", "al.", "1997", "he", "et", "al.", "1991", "Ashikhmin", "Shirley", "2000", "-rsb-", "physical", "slider", "common", "practice", "material", "editing", "edit", "brdf", "modify", "directly", "parameter", "analytic", "model", "example", "user", "might", "input", "value", "diffuse", "albedo", "specular", "roughness", "off-the-shelf", "modeling", "animation", "software", "maya", "-lsb-", "Autodesk", "Inc", "2010", "-rsb-", "use", "type", "interface", "Perceptual", "Sliders", "since", "physical", "parameter", "only", "indirectly", "related", "perceive", "appearance", "material", "researcher", "have", "investigate", "perceptual", "parameterization", "where", "each", "parameter", "represent", "perceptually-meaningful", "dimension", "surface", "appearance", "diffuse", "luminance", "gloss", "contrast", "parameterization", "also", "scale", "linear", "change", "parameter", "yield", "linear", "change", "perceive", "appearance", "surface", "material", "Pellacini", "et", "al.", "-lsb-", "2000", "-rsb-", "develop", "perceptual", "parameterization", "Ward", "BRDF", "model", "through", "psychophysical", "experiment", "Westlund", "Meyer", "-lsb-", "2001", "-rsb-", "investigate", "correspondence", "between", "traditional", "appearance", "standard", "gloss", "sheen", "haze", "analytic", "material", "model", "will", "et", "al.", "-lsb-", "2009", "-rsb-", "develop", "method", "find", "perceptual", "embedding", "measure", "material", "datum", "method", "traverse", "embedding", "work", "we", "investigate", "whether", "manipulate", "perceptual", "parameter", "have", "benefit", "over", "manipulate", "physical", "one", "editing", "task", "since", "perceptual", "parameterization", "exist", "all", "brdf", "use", "study", "we", "develop", "perceptually-inspired", "parameterization", "base", "-lsb-", "Pellacini", "et", "al.", "2000", "-rsb-", "-lsb-", "Ngan", "et", "al.", "2006", "-rsb-", "Sec", "image", "Navigation", "image", "navigation", "user", "can", "view", "variation", "material", "browse", "array", "thumbnail", "image", "material", "edit", "make", "select", "desire", "image", "Marks", "et", "al.", "-lsb-", "1997", "-rsb-", "explore", "idea", "computer", "graphic", "suggest", "arrangement", "scheme", "display", "set", "image", "variation", "interest", "Adobe", "Photoshop", "-lsb-", "Adobe", "Systems", "Inc", "2009", "-rsb-", "use", "interface", "call", "variation", "show", "multiple", "image", "configuration", "result", "from", "photographic", "adjustment", "like", "hue", "saturation", "change", "Ngan", "et", "al.", "-lsb-", "2006", "-rsb-", "propose", "user", "interface", "specific", "brdf", "editing", "use", "perceptually-inspired", "image", "difference", "metric", "arrange", "possible", "brdf", "configuration", "perceptually-uniform", "spacing", "include", "vary", "BRDF", "model", "argue", "since", "novice", "do", "have", "deep", "understanding", "material", "appearance", "allow", "they", "choose", "render", "image", "directly", "might", "beneficial", "study", "we", "compare", "interface", "direct", "parameter", "setting", "other", "interface", "Colbert", "et", "al.", "-lsb-", "2006", "-rsb-", "suggest", "painting", "interface", "editing", "brdf", "highlight", "brush", "tool", "similarly", "-lsb-", "Pacanowski", "et", "al.", "2008", "-rsb-", "develop", "painting", "interface", "nonphotorealistic", "highlight", "we", "do", "include", "interface", "type", "study", "because", "utilize", "custom", "material", "model", "specific", "control", "scheme", "Poulin", "Fournier", "-lsb-", "1995", "-rsb-", "introduce", "idea", "optimize", "material", "parameter", "match", "paint", "color", "point", "surface", "geometry", "we", "exclude", "interface", "type", "because", "unclear", "how", "extend", "support", "texture", "variation", "robustly", "brdf", "can", "also", "define", "arbitrary", "curve", "over", "angular", "parameterization", "use", "-lsb-", "Lawrence", "et", "al.", "2006", "-rsb-", "spatial", "variation", "editing", "edit", "spatially-varying", "brdf", "considerably", "harder", "than", "editing", "single", "brdf", "three", "editing", "task", "normally", "perform", "spatially-varying", "brdf", "change", "spatial", "pattern", "-lrb-", "texture", "painting", "synthesis", "-rrb-", "select", "region", "similar", "appearance", "-lrb-", "e.g.", "use", "-lsb-", "Pellacini", "Lawrence", "2007", "-rsb-", "-rrb-", "alter", "brdf", "select", "region", "paper", "we", "focus", "interface", "editing", "parameter", "brdf", "leave", "study", "interface", "editing", "selection", "spatial", "pattern", "future", "work", "we", "represent", "spatially-varying", "brdf", "linear", "combination", "basis", "brdf", "spatially-varying", "weight", "-lsb-", "Lawrence", "et", "al.", "2006", "-rsb-", "where", "user", "edit", "parameter", "basis", "brdf", "we", "choose", "model", "since", "fit", "measure", "datum", "well", "appearance", "design", "study", "we", "follow", "approach", "we", "use", "-lsb-", "Kerr", "Pellacini", "2009", "-rsb-", "evaluation", "lighting", "design", "interface", "apply", "material", "editing", "domain", "Talton", "et", "al.", "-lsb-", "2009", "-rsb-", "study", "space", "many", "design", "task", "develop", "collaborative", "editing", "system", "map", "space", "desirable", "configuration", "base", "what", "previous", "user", "have", "produce", "brdf", "editing", "part", "system", "direct", "comparison", "various", "interface", "paradigm", "explore", "ACM", "transaction", "Graphics", "Vol", "29", "no.", "Article", "35", "publication", "date", "July", "2010", "toward", "evaluate", "Material", "Design", "Interface", "Paradigms", "Novice", "Users", "35:3", "Ward", "-lrb-", "color", "-rrb-", "Ward", "-lrb-", "gray", "-rrb-", "cook-torrance", "-lrb-", "gray", "-rrb-", "2-lobe", "Ward", "-lrb-", "gray", "-rrb-", "goal", "training", "-lrb-", "matching", "-rrb-", "trial", "-lrb-", "matching", "-rrb-", "trial", "-lrb-", "matching", "-rrb-", "trial", "limit", "limit", "minute", "limit", "minute", "limit", "minute", "figure", "start", "goal", "configuration", "training", "match", "trial", "material", "model", "list", "above", "Time", "limit", "list", "below", "-lrb-", "see", "Sec", "-rrb-", "study", "Overview", "Goal", "we", "seek", "evaluate", "relative", "effectiveness", "different", "interface", "paradigm", "material", "design", "context", "design", "realistic", "material", "focus", "novice", "user", "specifically", "-lrb-", "-rrb-", "we", "want", "measure", "how", "efficiently", "user", "can", "perform", "specific", "material", "adjustment", "-lrb-", "-rrb-", "we", "want", "understand", "which", "interface", "paradigm", "provide", "better", "artistic", "exploration", "possible", "material", "variation", "Novice", "Users", "we", "focus", "novice", "little", "prior", "knowledge", "material", "design", "since", "make", "up", "majority", "user", "who", "can", "take", "advantage", "intuitive", "interface", "we", "would", "like", "have", "many", "people", "possible", "capable", "use", "graphic", "tool", "all", "subject", "rate", "experience", "level", "material", "design", "either", "scale", "from", "can", "consider", "novice", "reduce", "Complexity", "since", "material", "design", "non-trivial", "process", "we", "require", "careful", "triage", "between", "completeness", "length", "one", "hand", "we", "want", "achieve", "complex-enough", "material", "editing", "task", "ensure", "meaningful", "measurement", "other", "we", "want", "avoid", "bias", "datum", "ensure", "subject", "can", "successfully", "complete", "require", "task", "without", "incur", "too", "much", "fatigue", "work", "novice", "make", "triage", "even", "more", "necessary", "we", "simplify", "material", "editing", "task", "focus", "editing", "parameter", "analytic", "brdf", "while", "we", "include", "different", "brdf", "model", "we", "do", "ask", "subject", "select", "between", "different", "model", "during", "trial", "we", "simplify", "implementation", "interface", "ensure", "can", "quickly", "learn", "while", "sufficiently", "complete", "capture", "main", "characteristic", "each", "paradigm", "Materials", "we", "design", "task", "subject", "edit", "material", "represent", "isotropic", "Ward", "-lsb-", "1992", "-rsb-", "cook-torrance", "-lsb-", "1981", "-rsb-", "brdf", "-lrb-", "sec", "-rrb-", "we", "investigate", "three", "variation", "model", "first", "we", "use", "achromatic", "material", "half", "trial", "color", "other", "half", "much", "previous", "work", "material", "design", "focus", "modeling", "editing", "achromatic", "reflectance", "we", "would", "like", "discover", "how", "important", "chromaticity", "design", "process", "second", "we", "include", "two", "trial", "where", "brdf", "have", "two", "specular", "lobe", "since", "some", "material", "brdf", "fit", "measure", "material", "better", "than", "single", "lobe", "one", "-lsb-", "Ngan", "et", "al.", "2005", "-rsb-", "Third", "determine", "whether", "presence", "spatial", "variation", "affect", "design", "task", "we", "investigate", "editing", "spatially-varying", "brdf", "represent", "linear", "combination", "two", "basis", "brdf", "spatially-varying", "weight", "where", "user", "edit", "parameter", "basis", "brdf", "we", "choose", "model", "since", "fit", "measure", "datum", "well", "-lsb-", "Lawrence", "et", "al.", "2006", "-rsb-", "example", "each", "material", "type", "can", "find", "fig.", "Lighting", "we", "study", "material", "light", "direct", "illumination", "from", "real-world", "environment", "map", "natural", "illumination", "consider", "ideal", "material", "perception", "when", "only", "single", "image", "available", "-lsb-", "Dror", "et", "al.", "2001", "Fleming", "et", "al.", "2001", "-rsb-", "we", "use", "Grace", "Cathedral", "environment", "map", "-lsb-", "Debevec", "1998", "-rsb-", "since", "-lsb-", "Ngan", "et", "al.", "2006", "-rsb-", "suggest", "choice", "illumination", "environment", "have", "little", "effect", "material", "distinction", "long", "natural", "recommend", "Grace", "Cathedral", "map", "we", "choose", "use", "direct", "illumination", "rather", "than", "global", "illumination", "since", "we", "want", "preserve", "interactivity", "high", "image", "fidelity", "during", "design", "task", "we", "use", "tone", "mapping", "equation", "image", "-lrb-", "intensity", "exposure", "-rrb-", "1/gamma", "gamma", "2.2", "exposure", "fix", "so", "goal", "trial", "clearly", "visible", "subject", "have", "control", "over", "exposure", "gamma", "geometry", "geometry", "we", "image", "consist", "sphere", "float", "space", "we", "use", "sphere", "avoid", "occlusion", "artifact", "glossy", "reflection", "cause", "compute", "direct", "illumination", "only", "Vangorp", "et", "al.", "-lsb-", "2007", "-rsb-", "suggest", "may", "shape", "better", "than", "sphere", "material", "discrimination", "sphere", "possess", "many", "desirable", "property", "we", "determine", "sphere", "shape", "best", "we", "purpose", "give", "we", "render", "limitation", "interface", "we", "compare", "three", "user", "interface", "physical", "slider", "perceptual", "slider", "image", "navigation", "implementation", "detail", "interface", "present", "Sec", "physical", "perceptual", "slider", "interface", "similar", "design", "manipulate", "one", "parameter", "time", "physical", "slider", "alter", "parameter", "analytic", "brdf", "model", "directly", "parameter", "related", "physical", "reflectance", "property", "diffuse", "energy", "specular", "roughness", "parameter", "though", "directly", "related", "material", "appearance", "perceptual", "slider", "alter", "perceptually-meaningful", "material", "parameter", "diffuse", "luminance", "gloss", "contrast", "parameter", "scale", "linearly", "related", "perceptual", "distance", "perceptual", "parameterization", "believe", "more", "natural", "editing", "purpose", "since", "directly", "relate", "how", "human", "perceive", "material", "image", "navigation", "user", "can", "view", "variation", "material", "browse", "array", "thumbnail", "image", "material", "edit", "make", "select", "desire", "image", "believe", "image", "navigation", "useful", "editing", "metaphor", "since", "novice", "can", "directly", "select", "render", "image", "rather", "than", "specify", "parameter", "value", "since", "can", "preview", "several", "variation", "combination", "multiple", "parameter", "simultaneously", "task", "we", "ask", "subject", "perform", "two", "type", "material", "design", "task", "during", "match", "trial", "ask", "match", "material", "object", "under", "fixed", "environmental", "lighting", "image", "same", "object", "lighting", "target", "material", "configuration", "match", "trial", "allow", "we", "quantitatively", "measure", "user", "performance", "while", "provide", "clear", "goal", "subject", "who", "have", "never", "experienced", "material", "design", "before", "provide", "context", "more", "subjective", "open", "trial", "where", "user", "give", "photograph", "several", "real-world", "object", "round", "target", "area", "remove", "ask", "creatively", "design", "material", "would", "look", "good", "assign", "object", "place", "target", "area", "trial", "allow", "we", "observe", "how", "user", "artistically", "explore", "space", "possible", "material", "configuration", "more", "natural", "harder", "measure", "task", "Ward", "-lrb-", "color", "-rrb-", "cook-torrance", "-lrb-", "color", "-rrb-", "textured", "Ward", "-lrb-", "color", "-rrb-", "-lrb-", "matching", "-rrb-", "trial", "-lrb-", "matching", "-rrb-", "trial", "-lrb-", "matching", "-rrb-", "trial", "limit", "minute", "limit", "minute", "limit", "minute", "ACM", "transaction", "Graphics", "Vol", "29", "no.", "Article", "35", "publication", "date", "July", "2010", "35:4", "W.", "Kerr", "et", "al.", "2-lobe", "Ward", "-lrb-", "gray", "-rrb-", "cook-torrance", "-lrb-", "color", "-rrb-", "textured", "Ward", "-lrb-", "color", "-rrb-", "goal", "-lrb-", "open", "-rrb-", "trial", "-lrb-", "open", "-rrb-", "trial", "-lrb-", "open", "-rrb-", "trial", "limit", "minute", "limit", "minute", "limit", "minute", "Figure", "goal", "open", "trial", "start", "configuration", "identical", "match", "trial", "experiment", "we", "ask", "subject", "complete", "number", "trial", "during", "which", "all", "action", "record", "further", "analysis", "each", "subject", "perform", "all", "trial", "use", "all", "interface", "trial", "vary", "number", "material", "parameter", "material", "model", "type", "number", "lobe", "presence", "color", "presence", "spatial", "variation", "task", "goal", "preparatory", "study", "we", "conduct", "formal", "informal", "preparatory", "user", "study", "15", "additional", "subject", "result", "which", "include", "paper", "different", "implementation", "various", "interface", "be", "test", "determine", "locally", "optimal", "set", "control", "remove", "any", "implementation", "error", "open", "matching", "goal", "use", "final", "study", "be", "test", "ensure", "time", "limit", "be", "appropriate", "task", "could", "complete", "trial", "we", "perform", "six", "matching", "trial", "three", "open", "trial", "progressively", "increase", "number", "degree", "freedom", "material", "model", "start", "configuration", "goal", "configuration", "time", "limit", "each", "trial", "summarize", "fig.", "Fig.", "match", "trial", "goal", "configuration", "be", "take", "from", "parametric", "fit", "present", "-lsb-", "Ngan", "et", "al.", "2005", "-rsb-", "measure", "material", "-lsb-", "Matusik", "et", "al.", "2003", "-rsb-", "grayscale", "trial", "diffuse", "specular", "coefficient", "metallic", "blue", "white", "bball", "be", "desaturate", "grayscale", "trial", "goal", "model", "hand", "after", "rendering", "acrylic", "violet", "since", "fit", "unavailable", "Color", "trial", "use", "fit", "blue", "bball", "ch-ball-green-metallic", "respectively", "trial", "use", "fit", "white-bball", "metallic", "gold", "weight", "texture", "we", "vary", "match", "trial", "material", "complexity", "observe", "possible", "change", "user", "workflow", "interface", "effectiveness", "under", "condition", "open", "trial", "we", "select", "target", "image", "differ", "from", "workspace", "lighting", "environment", "vary", "content", "encourage", "free-form", "artistic", "exploration", "we", "choose", "one", "grayscale", "two", "color", "material", "goal", "object", "vary", "material", "property", "object", "same", "goal", "image", "share", "some", "material", "property", "keep", "objective", "from", "be", "completely", "unspecified", "same", "initial", "goal", "material", "configuration", "use", "all", "subject", "all", "interface", "each", "trial", "have", "fixed", "time", "limit", "subject", "can", "end", "trial", "sooner", "satisfy", "current", "result", "end", "each", "match", "trial", "subject", "rate", "accuracy", "matching", "scale", "open", "trial", "subject", "use", "same", "scale", "rate", "how", "satisfied", "result", "questionnaire", "after", "perform", "all", "trial", "all", "interface", "subject", "complete", "questionnaire", "where", "rate", "each", "interface", "scale", "follow", "category", "-lrb-", "-rrb-", "natural", "way", "think", "about", "material", "editing", "-lrb-", "-rrb-", "preference", "match", "trial", "-lrb-", "-rrb-", "preference", "open", "trial", "-lrb-", "-rrb-", "overall", "preference", "subject", "also", "strictly", "rank", "interface", "each", "category", "immediately", "after", "finish", "trial", "each", "single", "interface", "subject", "ask", "leave", "free-form", "comment", "aspect", "each", "interface", "reproducibility", "we", "include", "copy", "questionnaire", "additional", "material", "procedure", "twenty", "subject", "participate", "study", "choose", "from", "different", "age", "educational", "group", "all", "subject", "have", "normal", "corrected-to-normal", "vision", "subject", "edit", "material", "about", "hour", "each", "ensure", "good", "statistical", "significance", "we", "test", "while", "keep", "fatigue", "low", "subject", "complete", "study", "three", "60-minute", "session", "one", "each", "interface", "we", "randomize", "order", "interface", "each", "subject", "before", "each", "session", "subject", "complete", "training", "phase", "become", "familiar", "specific", "interface", "we", "train", "each", "subject", "individually", "allow", "question", "accommodate", "each", "subject?s", "learn", "need", "instructor", "verify", "subject", "use", "each", "part", "interface", "answer", "subject", "question", "before", "proceed", "experiment", "subject", "use", "interface", "until", "he", "she", "feel", "comfortable", "during", "both", "guide", "free", "portion", "training", "single", "sample", "goal", "show", "-lrb-", "fig.", "-rrb-", "once", "trial", "begin", "all", "user", "interface", "action", "record", "study", "conduct", "controlled", "lighting", "environment", "negligible", "ambient", "lighting", "simulate", "typical", "working", "condition", "artist", "maximize", "visibility", "screen", "we", "use", "24-inch", "Dell", "2407WFPb", "lcd", "display", "1280", "800", "resolution", "distance", "approximately", "foot", "from", "subject", "-lrb-", "monitor", "native", "resolution", "1900", "1200", "-rrb-", "all", "render", "image", "256x256", "pixel", "screen", "cover", "area", "square", "inch", "we", "use", "Intel", "2.8", "Ghz", "Core2", "Quad", "Q9550", "PC", "gb", "RAM", "NVidia", "GeForce", "9800", "gt", "graphic", "card", "Interface", "Implementation", "section", "we", "discuss", "we", "implementation", "user", "interface", "include", "study", "reproducibility", "we", "include", "video", "supplemental", "material", "show", "each", "interface", "detail", "rendering", "we", "use", "real-time", "render", "algorithm", "-lsb-", "BenArtzi", "et", "al.", "2006", "-rsb-", "preview", "brdf", "edit", "under", "direct", "natural", "illumination", "we", "implementation", "render", "45f", "p", "256", "256", "pixel", "image", "sphere", "use", "study", "we", "consider", "add", "global", "illumination", "-lsb-", "Ben-Artzi", "et", "al.", "2008", "-rsb-", "decide", "potential", "artifact", "result", "from", "approximate", "brdf", "lower", "frequency", "might", "effect", "we", "measurement", "algorithm", "we", "use", "doesn?t", "allow", "roughness", "fresnel", "term", "CookTorrance", "BRDF", "model", "simultaneously", "modify", "take", "approximately", "0.6", "seconds", "switch", "between", "parameter", "we", "implementation", "brdf", "model", "we", "implementation", "we", "parameterize", "isotropic", "Ward", "BRDF", "ACM", "transaction", "Graphics", "Vol", "29", "no.", "Article", "35", "publication", "date", "July", "2010", "toward", "evaluate", "Material", "Design", "Interface", "Paradigms", "Novice", "Users", "35:5", "Figure", "Study", "interface", "layout", "-lrb-", "tan", "-rrb-", "??", "cos", "cos", "where", "diffuse", "albedo", "energy", "specular", "component", "surface", "roughness", "angle", "between", "surface", "normal", "incoming", "outgoing", "halfangle", "respectively", "we", "parameterize", "Cook-Torrance", "BRDF", "ct", "follow", "-lsb-", "Ngan", "et", "al.", "2005", "-rsb-", "dgf", "ct", "cos", "cos", "-lrb-", "-rrb-", "-lrb-", "cos", "-rrb-", "-lrb-", "tan", "-rrb-", "cos", "cos", "cos", "cos", "cos", "min", "cos", "cos", "where", "diffuse", "albedo", "energy", "specular", "component", "surface", "roughness", "fresnel", "reflectance", "direction", "orthogonal", "surface", "angle", "between", "outgoing", "half-vector", "direction", "some", "trial", "use", "brdf", "ww", "Ward", "lobe", "define", "-lrb-", "tan", "-rrb-", "-lrb-", "tan", "-rrb-", "ww", "s1", "??", "s2", "??", "where", "cos", "cos", "other", "select", "trial", "we", "use", "spatially-varying", "material", "spatial", "variation", "model", "weighted", "sum", "two", "Ward", "brdf", "sum", "w1", "w2", "where", "weight", "spatially-varying", "sum", "one", "all", "surface", "point", "-lsb-", "Lawrence", "et", "al.", "2006", "-rsb-", "Universal", "Interface", "Features", "all", "interface", "use", "same", "screen", "layout", "consist", "workspace", "window", "goal", "window", "rating", "button", "-lrb-", "fig.", "-rrb-", "undo", "key", "allow", "user", "walk", "back", "through", "unlimited", "number", "edit", "compensate", "fact", "material", "create", "use", "system", "may", "conserve", "energy", "warning", "indicator", "appear", "upper", "right", "corner", "user?s", "image", "when", "brdf", "energy", "conserving", "physical", "slider", "we", "use", "slider", "interface", "means", "which", "user", "set", "parameter", "brdf", "model", "e.g.", "diffuse", "albedo", "specular", "energy", "roughness", "fresnel", "term", "each", "user", "control", "parameter", "list", "slider", "bar", "next", "parameter", "can", "change", "click", "anywhere", "bar", "gradual", "change", "can", "see", "drag", "slider", "continuously", "across", "bar", "set", "model", "parameter", "directly", "would", "require", "specify", "red", "green", "blue", "coefficient", "would", "ignore", "common", "color", "editing", "practice", "artificially", "handicap", "interface", "we", "use", "CIELAB", "luminance", "-lrb-", "-rrb-", "achromatic", "intensity", "saturation", "hue", "chromaticity", "-lsb-", "Fairchild", "1998", "-rsb-", "we", "use", "hue", "saturation", "since", "default", "maya", "-lsb-", "Autodesk", "Inc", "2010", "-rsb-", "Perceptual", "Sliders", "perceptual", "parameterization", "differ", "from", "physical", "one", "both", "effect", "scale", "paper", "we", "choose", "perceptually-inspired", "parameter", "base", "-lsb-", "Pellacini", "et", "al.", "2000", "Westlund", "Meyer", "2001", "-rsb-", "furthermore", "since", "all", "perceptual", "parameterization", "derive", "from", "achromatic", "datum", "we", "follow", "-lsb-", "Wills", "et", "al.", "2009", "Pellacini", "et", "al.", "2000", "-rsb-", "derive", "parameter", "grayscale", "diffuse", "specular", "component", "add", "hue", "saturation", "they", "we", "use", "same", "saturation", "hue", "control", "physical", "slider", "Slider", "control", "work", "same", "way", "physical", "slider", "modify", "perceptually-inspired", "parameter", "determine", "correct", "scaling", "each", "parameter", "axis", "brdf", "model?s", "configuration", "space", "we", "use", "image-based", "brdf", "difference", "metric", "from", "-lsb-", "Ngan", "et", "al.", "2006", "-rsb-", "since", "psychophysical", "datum", "have", "be", "publish", "range", "brdf", "parameter", "we", "investigate", "let", "-lrb-", "-rrb-", "image", "correspond", "brdf", "we", "can", "approximately", "compute", "perceptual", "distance", "between", "brdf", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "p?pixels", "c?r", "we", "scale", "we", "perceptually-inspired", "parameter", "equal", "step", "parameter", "yield", "step", "accord", "distance", "metric", "we", "include", "comparison", "metric", "we", "parameterization", "supplemental", "document", "all", "parameterization", "follow", "represent", "achromatically", "accord", "CIELAB", "luminance", "range", "-lsb-", "-rsb-", "Ward", "brdf", "we", "use", "parameterization", "from", "-lsb-", "Pellacini", "et", "al.", "2000", "-rsb-", "modify", "parameter", "1/4", "where", "diffuse", "luminance", "gloss", "contrast", "gloss", "distinctness", "we", "raise", "power", "1/4", "because", "more", "closely", "match", "scale", "accord", "equation", "-lrb-", "-rrb-", "which", "valid", "larger", "range", "than", "original", "experiment", "cover", "-lsb-", "Pellacini", "et", "al.", "2000", "-rsb-", "trial", "use", "textured", "Ward", "simply", "have", "two", "instance", "perceptually", "inspire", "Ward", "parameter", "Cook-Torrance", "brdf", "we", "use", "follow", "parameterization", "1/4", "-lsb-", "-lrb-", "-rrb-", "-rsb-", "-lsb-", "-lrb-", "-rrb-", "-rsb-", "where", "diffuse", "luminance", "gloss", "contrast", "gloss", "distinctness", "gloss", "sheen", "0.02", "minimum", "allow", "value", "when", "-lsb-", "-rsb-", "Cook-Torrance", "parameter", "similar", "Ward", "counterpart", "add", "set", "contrast", "specular", "component", "grazing", "angle", "while", "preserve", "its", "contrast", "non-grazing", "angle", "Ward", "brdf", "two", "lobe", "we", "use", "follow", "parameterization", "s1", "s2", "ACM", "transaction", "Graphics", "Vol", "29", "no.", "Article", "35", "publication", "date", "July", "2010", "35:6", "W.", "Kerr", "et", "al.", "Figure", "image", "navigation", "2d", "layout", "s1", "-lrb-", "s1", "s2", "-rrb-", "1/4", "1Â 1/4", "1/4", "1/4", "1/4", "-lrb-", "-rrb-", "-lrb-", "max", "-rrb-", "where", "diffuse", "luminance", "gloss", "contrast", "lobe", "blend", "parameter", "overall", "gloss", "distinctness", "haze", "parameter", "max", "maximum", "possible", "value", "normalization", "image", "Navigation", "we", "base", "we", "implementation", "image", "navigation", "-lsb-", "Ngan", "et", "al.", "2006", "-rsb-", "interface", "consist", "series", "tab", "reveal", "different", "image", "array", "some", "tab", "show", "variation", "material", "model", "parameter", "along", "two", "axis", "while", "other", "serve", "color", "picker", "diffuse", "specualr", "coefficient", "parameter", "image", "space", "accord", "image", "difference", "metric", "equation", "-lrb-", "-rrb-", "spacing", "size", "determine", "user-controlled", "slider", "-lsb-", "Ngan", "et", "al.", "2006", "-rsb-", "we", "limit", "interface", "display", "only", "two", "parameter", "simultaneously", "ensure", "thumbnail", "large", "enough", "perform", "accurate", "selection", "fig.", "show", "what", "we", "two-parameter", "layout", "look", "like", "use", "image", "navigation", "we", "implement", "system", "which", "all", "model", "parameter", "can", "assign", "either", "horizontal", "vertical", "axis", "from", "current", "configuration", "two", "step", "either", "direction", "either", "parameter", "axis", "show", "result", "five", "five", "image", "array", "25", "image", "represent", "different", "combination", "two", "parameter", "we", "also", "give", "user", "preset", "configuration", "helpful", "combination", "parameter", "reduce", "confusion", "-lrb-", "e.g.", "diffuse", "versus", "specular", "brightness", "diffuse", "color", "picker", "-rrb-", "since", "we", "perceptuallyinspired", "parameterization", "scale", "similarly", "difference", "metric", "-lsb-", "Ngan", "et", "al.", "2006", "-rsb-", "we", "space", "image", "equal", "step", "parameter", "space", "may", "cause", "space", "display", "2d", "image", "scale", "differently", "horizontal", "than", "vertical", "error", "space", "even", "though", "uniform", "parameter", "space", "we", "don?t", "find", "problem", "we", "do", "allow", "slider", "determine", "size", "step", "because", "real-time", "feedback", "we", "feel", "would", "like", "take", "perceptual", "slider", "interface", "simply", "give", "multiple", "preview", "time", "give", "button", "increase", "decrease", "step", "size", "log", "scale", "we", "keep", "image", "navigation", "perceptual", "slider", "implementation", "respective", "interface", "metaphor", "while", "give", "image", "navigation", "power", "make", "small", "large", "edit", "rendering", "time", "thumbnail", "depend", "material", "configuration", "normally", "0.25", "seconds", "exception", "array", "where", "both", "gloss", "distinctness", "sheen", "vary", "simultaneously", "where", "2.5", "seconds", "-lrb-", "see", "previous", "section", "-rrb-", "we", "account", "we", "analysis", "Time", "Completion", "Final", "Error", "400", "60", "time", "error", "trial", "trial", "physical", "slider", "perceptual", "slider", "image", "navigation", "figure", "leave", "average", "time", "completion", "all", "trial", "over", "all", "subject", "-lrb-", "seconds", "-rrb-", "right", "average", "final", "error", "match", "trial", "over", "all", "subject", "error", "value", "from", "equation", "-lrb-", "-rrb-", "normalization", "analysis", "we", "present", "analysis", "we", "datum", "two", "part", "first", "we", "analyse", "output", "render", "system", "subject", "proceed", "through", "each", "trial", "second", "we", "analyse", "feedback", "from", "user", "end", "each", "trial", "questionnaire", "unless", "state", "otherwise", "test", "statistical", "significance", "compute", "repeat", "measure", "analysis", "variance", "-lrb-", "anova", "-rrb-", "-lsb-", "Stevens", "1996", "-rsb-", "handle", "within-subject", "factor", "create", "correlation", "which", "invalidate", "assumption", "independence", "standard", "one-way", "ANOVA", "value", "below", "0.1", "indicate", "90", "confidence", "two", "population", "mean", "differ", "give", "measure", "sample", "all", "figure", "error", "bar", "represent", "standard", "error", "Time", "Completion", "we", "investigate", "work", "speed", "user", "each", "interface", "generally", "subject", "able", "complete", "each", "trial", "within", "allotted", "time", "limit", "one", "more", "interface", "fig.", "we", "show", "mean", "time", "completion", "each", "match", "trial", "over", "all", "subject", "Time", "completion", "image", "navigation", "almost", "always", "significantly", "higher", "than", "either", "physical", "perceptual", "slider", "match", "trial", "-lrb-", "0.051", "-rrb-", "except", "trial", "we", "believe", "trial", "differ", "because", "many", "subject", "run", "out", "time", "give", "up", "early", "image", "navigation", "reduce", "its", "mean", "time", "result", "match", "lower", "quality", "we", "conclude", "image", "navigation", "must", "slower", "work", "trial", "we", "reach", "limit", "subject", "patience", "time", "completion", "physical", "perceptual", "slider", "show", "significant", "difference", "trial", "2-6", "physical", "slider", "average", "20", "seconds", "faster", "than", "perceptual", "slider", "trial", "-lrb-", "0.053", "-rrb-", "open", "trial", "meaning", "time", "completion", "less", "define", "since", "standard", "judgement", "use", "subject", "can", "vary", "from", "trial", "trial", "even", "interface", "interface", "only", "statistically", "significant", "difference", "-lrb-", "0.1", "-rrb-", "be", "between", "perceptual", "slider", "-lrb-", "69.0", "-rrb-", "image", "navigation", "-lrb-", "107.5", "-rrb-", "trial", "-lrb-", "0.039", "-rrb-", "physical", "slider", "-lrb-", "113.5", ",201.9", "-rrb-", "image", "navigation", "-lrb-", "150.9", ",179.3", "-rrb-", "trial", "-lrb-", "0.080", "-rrb-", "-lrb-", "0.048", "-rrb-", "respectively", "trial", "grayscale", "trial", "color", "use", "same", "brdf", "model", "do", "trial", "average", "factor", "time", "completion", "between", "grayscale", "trial", "color", "trial", "1.886", "match", "error", "evaluate", "user", "performance", "match", "trial", "we", "compute", "error", "between", "subject?s", "brdf", "goal", "brdf", "use", "image-based", "difference", "metric", "equation", "-lrb-", "-rrb-", "-lsb-", "Ngan", "et", "al.", "2006", "-rsb-", "metric", "have", "be", "show", "capture", "perceive", "difference", "brdf", "fig.", "show", "error", "over", "time", "one", "subject", "perform", "same", "trial", "all", "interface", "when", "subject", "successful", "error", "decrease", "toward", "correct", "solution", "converge", "some", "low", "error", "value", "convergence", "monotonic", "because", "user", "explore", "configuration", "space", "order", "reach", "desire", "goal", "accompany", "supplemental", "material", "paper", "we", "include", "error", "graph", "all", "subject", "all", "trial", "together", "render", "image", "material", "configuration", "fixed", "time", "interval", "summarize", "overall", "performance", "each", "interface", "we", "analyse", "final", "image", "error", "each", "match", "trial", "average", "over", "all", "subject", "-lrb-", "fig.", "-rrb-", "both", "physical", "perceptual", "slider", "outperform", "image", "navigation", "all", "trial", "-lrb-", "0.064", "-rrb-", "except", "trial", "where", "image", "navigation", "have", "roughly", "same", "error", "perceptual", "slider", "however", "take", "longer", "amount", "time", "complete", "trial", "image", "navigation", "-lrb-", "0.026", "-rrb-", "error", "trial", "especially", "high", "image", "navigation", "could", "part", "due", "render", "limitation", "specific", "image", "navigation", "Cook-Torrance", "brdf", "-lrb-", "sec", "-rrb-", "however", "anomaly", "can", "see", "trial", "which", "also", "use", "Cook-Torrance", "model", "goal", "trial", "happen", "particularly", "bright", "error", "discrepancy", "pronounced", "when", "error", "compute", "clamp", "intensity", "value", "we", "conclude", "failure", "case", "reasonably", "alignment", "rest", "datum", "when", "take", "account", "surprisingly", "significant", "difference", "error", "between", "perceptual", "physical", "slider", "except", "trial", "where", "physical", "slider", "outperform", "perceptual", "slider", "-lrb-", "0.064", "-rrb-", "trial", "again", "exhibit", "difference", "we", "can", "identify", "conclusively", "other", "CookTorrance", "trial", "do", "show", "difference", "between", "physical", "perceptual", "slider", "nor", "do", "other", "grayscale", "trial", "time", "completion", "we", "compare", "grayscale", "trial", "color", "trial", "average", "factor", "error", "between", "grayscale", "trial", "color", "trial", "2.167", "convergence", "illustrate", "convergence", "behavior", "different", "interface", "we", "average", "image", "error", "across", "all", "subject", "over", "time", "fig.", "average", "statistically", "valid", "we", "find", "give", "revealing", "visual", "summary", "overall", "behavior", "can", "see", "graph", "physical", "perceptual", "slider", "tend", "converge", "more", "quickly", "than", "image", "navigation", "lower", "error", "we", "also", "see", "convergence", "behavior", "physical", "perceptual", "slider", "similar", "though", "trial", "seem", "show", "better", "convergence", "phy", "ical", "slider", "finally", "we", "note", "trial", "show", "particularly", "poor", "convergence", "image", "navigation", "trial", "spatiallyvarying", "brdf", "many", "subject", "give", "up", "run", "out", "time", "use", "image", "navigation", "we", "also", "see", "slower", "poorer", "convergence", "slider", "interface", "trial", "again", "we", "can", "identify", "conclusively", "what", "cause", "difference", "trial", "subjective", "image", "Quality", "end", "each", "trial", "subject", "rate", "work", "scale", "be", "worst", "be", "best", "match", "trial", "rate", "term", "how", "close", "workspace", "goal", "image", "match", "open", "trial", "rate", "term", "how", "satisfied", "subject", "result", "fig.", "show", "average", "rating", "each", "trial", "subjective", "image", "quality", "correlate", "computed", "error", "final", "image", "linear", "correlation", "coefficient", "0.5895", "match", "trial", "subject", "average", "rate", "work", "better", "when", "use", "slider", "than", "image", "navigation", "all", "trial", "-lrb-", "0.058", "-rrb-", "only", "do", "subject", "perform", "objectively", "better", "use", "slider", "interface", "compare", "image", "navigation", "measure", "error", "perceive", "themselves", "do", "better", "well", "rating", "slider", "interface", "compare", "one", "another", "contain", "significant", "difference", "except", "trial", "-lrb-", "0.042", "-rrb-", "computed", "error", "open", "trial", "significant", "difference", "image", "rating", "between", "any", "three", "interface", "except", "physical", "slider", "have", "slightly", "higher", "average", "rating", "than", "image", "navigation", "trial", "-lrb-", "0.015", "-rrb-", "Interface", "Rankings", "rating", "subject", "rate", "rank", "each", "interface", "category", "where", "rating", "can", "have", "tie", "ranking", "force", "choice", "-lrb-", "see", "Sec", "-rrb-", "average", "rating", "stack", "fre", "quency", "ranking", "show", "Fig.", "evaluate", "statistical", "significance", "rank", "we", "use", "Friedman", "test", "-lsb-", "Friedman", "1937", "-rsb-", "nonparametric", "test", "take", "account", "within-subject", "effect", "low", "p-value", "indicate", "high", "confidence", "subject", "have", "make", "significant", "distinction", "between", "two", "interface", "all", "category", "except", "preference", "open", "trial", "slider", "interface", "outrank", "image", "navigation", "-lrb-", "0.074", "perceptual", "vs.", "image", "navigation", "natural", "category", "0.002", "otherwise", "-rrb-", "we", "find", "statistical", "difference", "between", "rank", "two", "slider", "interface", "roughly", "half", "subject", "rank", "physical", "slider", "higher", "than", "perceptual", "overall", "preference", "vice", "versa", "we", "find", "similar", "trend", "interface", "rating", "slider", "interface", "average", "roughly", "equivalent", "all", "category", "when", "compare", "image", "navigation", "slider", "interface", "except", "open", "trial", "preference", "image", "navigation", "rate", "much", "lower", "all", "category", "-lrb-", "0.002", "-rrb-", "complexity", "we", "have", "show", "interface", "use", "perform", "material", "editing", "influence", "performance", "complexity", "material", "be", "edit", "have", "effect", "how", "difficult", "task", "perform", "relative", "performance", "interface", "remain", "unchanged", "difficulty", "seem", "scale", "linearly", "average", "number", "user", "controlled", "parameter", "material", "model", "regression", "average", "time", "completion", "suggest", "linear", "relationship", "-lrb-", "0.919", "-rrb-", "error", "have", "similar", "trend", "physical", "-lrb-", "0.996", "-rrb-", "perceptual", "-lrb-", "0.880", "-rrb-", "slider", "much", "image", "navigation", "-lrb-", "0.499", "-rrb-", "unclear", "we", "increase", "complexity", "further", "novice", "would", "still", "able", "accomplish", "task", "trial", "appear", "indicate", "point", "which", "many", "subject", "give", "up", "we", "datum", "do", "indicate", "any", "significant", "trend", "material", "editing", "between", "use", "Ward", "CookTorrance", "BRDF", "model", "Cook-Torrance", "BRDF", "trial", "appear", "more", "challenging", "than", "Ward", "BRDF", "trial", "Cook-Torrance", "BRDF", "trial", "appear", "less", "challenging", "than", "Ward", "BRDF", "trial", "we", "make", "claim", "usefulness", "one", "model", "over", "another", "we", "study", "design", "give", "subject", "choice", "between", "two", "ACM", "transaction", "Graphics", "Vol", "29", "no.", "Article", "35", "publication", "date", "July", "2010", "toward", "evaluate", "Material", "Design", "Interface", "Paradigms", "Novice", "Users", "35:7", "trial", "Subject", "Trial", "all", "subject", "250", "90", "120", "error", "error", "error", "time", "360", "time", "180", "trial", "Subject", "Trial", "all", "subject", "140Â 140Â 150", "error", "error", "error", "time", "480", "time", "360", "figure", "leave", "example", "graph", "error", "over", "time", "-lrb-", "seconds", "-rrb-", "individual", "trial", "show", "fig.", "right", "illustration", "error", "over", "time", "-lrb-", "seconds", "-rrb-", "match", "trial", "average", "over", "all", "subject", "error", "value", "from", "equation", "-lrb-", "-rrb-", "normalization", "trial", "all", "subject", "trial", "all", "subject", "physical", "80", "slider", "perceptual", "slider", "error", "image", "navigation", "time", "180", "time", "300", "trial", "all", "subject", "trial", "all", "subject", "100", "error", "20", "time", "360", "time", "480", "physical", "slider", "perceptual", "slider", "image", "navigation", "rating", "matching", "trial", "open", "trial", "figure", "average", "subjective", "image", "quality", "rating", "over", "all", "subject", "ACM", "transaction", "Graphics", "Vol", "29", "no.", "Article", "35", "publication", "date", "July", "2010", "35:8", "W.", "Kerr", "et", "al.", "Interface", "rating", "Interface", "Rankings", "20", "physical", "slider", "perceptual", "slider", "image", "navigation", "figure", "leave", "average", "interface", "rating", "from", "questionnaire", "over", "all", "subject", "Rating", "imply", "best", "right", "sum", "interface", "ranking", "over", "all", "subject", "Rank", "imply", "best", "Workflow", "observation", "we", "now", "discuss", "common", "trend", "way", "we", "subject", "use", "different", "interface", "edit", "material", "fig.", "we", "show", "work", "do", "two", "different", "subject", "correspond", "error", "graph", "can", "find", "fig.", "image", "error", "graph", "from", "all", "subject", "all", "trial", "can", "find", "supplemental", "material", "well", "select", "video", "workflow", "blocking", "refinement", "subject", "do", "fix", "each", "parameter", "value", "independently", "permanently", "make", "rough", "adjustment", "move", "configuration", "good", "local", "space", "hierarchically", "refine", "smaller", "smaller", "space", "until", "precise", "configuration", "reach", "mean", "parameter", "revisit", "change", "many", "time", "during", "course", "editing", "session", "behavior", "universal", "across", "all", "subject", "inability", "configure", "image", "Navigation", "we", "notice", "majority", "time", "spend", "when", "use", "image", "navigation", "spend", "change", "configuration", "material", "subject", "appear", "have", "trouble", "set", "up", "2d", "navigation", "array", "image", "only", "do", "have", "figure", "out", "which", "axis", "look", "must", "also", "determine", "scale", "granularity", "those", "axis", "we", "observe", "most", "we", "subject", "be", "confuse", "despite", "have", "preset", "configuration", "subject", "comment", "feel", "limit", "layout", "because", "could", "find", "combination", "need", "find", "match", "bit", "confine", "tool", "feel", "like", "could", "control", "my", "work", "much", "-lsb-", "image", "navigation", "-rsb-", "way", "you", "know", "what", "change", "clear", "how", "exactly", "get", "slider", "approach", "part", "little", "easier", "when", "use", "either", "physical", "perceptual", "slider", "subject", "make", "change", "far", "more", "often", "can", "see", "Sec", "lead", "faster", "better", "convergence", "goal", "additionally", "only", "do", "image", "navigation", "yield", "change", "less", "often", "those", "change", "be", "undo", "more", "often", "undo", "use", "roughly", "twice", "often", "image", "navigation", "than", "slider", "interface", "-lrb-", "0.051", "-rrb-", "physical", "perceptual", "slider", "share", "roughly", "same", "undo", "usage", "image", "Navigation", "Sliders", "when", "use", "image", "navigation", "almost", "all", "subject", "display", "behavior", "use", "only", "one", "axis", "time", "effectively", "reduce", "slider", "interface", "discrete", "configuration", "visible", "time", "while", "most", "occurrence", "behavior", "be", "interleave", "use", "2d", "array", "color", "picker", "some", "subject", "would", "go", "entire", "trial", "use", "only", "technique", "lead", "we", "believe", "many", "situation", "where", "user", "think", "independent", "parameter", "space", "Sliders", "Equalized", "Interactivity", "universally", "subject", "rarely", "snap", "slider", "particular", "value", "almost", "always", "drag", "they", "see", "material", "workspace", "change", "gradually", "suggest", "optimal", "workflow", "novice", "smoothly", "vary", "appearance", "until", "image", "look", "like", "what", "look", "do", "seem", "less", "confusing", "than", "see", "several", "image", "side-byside", "also", "suggest", "subject", "anticipate", "precisely", "what", "value", "parameter", "should", "make", "many", "peceptual", "scaling", "perceptual", "parameterization", "irrelevant", "when", "interactivity", "available", "we", "investigate", "behavior", "disable", "ability", "drag", "slider", "interface", "leave", "only", "option", "click", "specific", "location", "slider", "run", "five", "additional", "subject", "through", "otherwise", "unchanged", "study", "situation", "all", "subject", "essentially", "mimic", "drag", "action", "repeatedly", "clike", "small", "interval", "along", "bar", "average", "number", "click", "physical", "perceptual", "slider", "roughly", "equal", "except", "trial", "where", "perceptual", "slider", "average", "roughly", "1/3", "more", "click", "than", "physical", "slider", "-lrb-", "0.034", "-rrb-", "we", "believe", "interactivity", "nullify", "difference", "between", "two", "interface", "novice", "prefer", "nudge", "control", "until", "image", "look", "right", "rather", "than", "purposefully", "set", "value", "Material", "Properties", "after", "use", "each", "interface", "subject", "be", "ask", "what", "think", "most", "least", "difficult", "aspect", "design", "process", "question", "open", "interpretation", "we", "do", "get", "several", "comment", "about", "specific", "parameter", "property", "material", "model", "we", "categorize", "comment", "adjustment", "color", "relative", "diffuse", "specular", "intensity", "highlight", "shaping", "-lrb-", "specular", "roughness", "fresnel", "effect", "-rrb-", "number", "time", "each", "category", "be", "mention", "-lrb-", "sum", "all", "three", "questionnaire", "per", "subject", "-rrb-", "list", "below", "color", "23", "most", "difficult", "least", "difficult", "relative", "intensity", "most", "difficult", "least", "difficult", "highlight", "shaping", "most", "difficult", "13", "least", "difficult", "we", "draw", "two", "piece", "information", "from", "datum", "first", "because", "color", "mention", "most", "often", "user", "must", "feel", "important", "factor", "overall", "material", "appearance", "second", "majority", "subject", "feel", "color", "most", "difficult", "part", "design", "process", "surprising", "give", "most", "work", "develop", "perceptual", "parameterization", "material", "have", "be", "do", "grayscale", "exploration", "open", "trial", "subject", "perform", "exploratory", "task", "require", "less", "fine", "tuning", "many", "subject", "comment", "directly", "be", "explore", "wide", "space", "rather", "than", "refining", "example", "one", "subject", "comment", "open", "trial", "have", "I", "look", "all", "over", "place", "cool", "option", "where", "matching", "tend", "make", "smaller", "change", "another", "comment", "my", "workflow", "completely", "random", "experimental", "when", "do", "open", "trial", "we", "observe", "performance", "image", "navigation", "interface", "compare", "slider", "improve", "greatly", "from", "match", "open", "trial", "user", "explain", "comment", "use", "-lsb-", "image", "navigation", "-rsb-", "much", "like", "other", "one", "match", "open", "trial", "lot", "easier", "see", "something", "good", "here", "-lsb-", "image", "navigation", "-rsb-", "matching", "very", "difficult", "have", "try", "many", "different", "thing", "open", "trial", "be", "enjoyable", "could", "pick", "from", "option", "-lsb-", "preset", "-rsb-", "button", "bring", "up", "-lsb-", "image", "navigation", "-rsb-", "open", "one", "be", "easier", "because", "get", "better", "view", "what", "want", "we", "conclude", "give", "its", "problem", "precise", "adjustment", "image", "navigation", "must", "better", "pure", "exploration", "lack", "need", "control", "complete", "solution", "material", "design", "otherwise", "would", "able", "compete", "so", "closely", "slider", "open", "trial", "ACM", "transaction", "Graphics", "Vol", "29", "no.", "Article", "35", "publication", "date", "July", "2010", "toward", "evaluate", "Material", "Design", "Interface", "Paradigms", "Novice", "Users", "35:9", "discussion", "conclusion", "we", "now", "discuss", "result", "we", "study", "we", "remind", "reader", "strictly", "speak", "we", "observation", "only", "apply", "within", "boundary", "test", "case", "all", "user", "study", "same", "time", "we", "belief", "trend", "observe", "study", "should", "apply", "other", "similar", "appearance", "design", "task", "novice", "novice", "can", "edit", "Materials", "we", "have", "find", "novice", "capable", "design", "editing", "realistic", "material", "when", "interface", "support", "they", "novice", "can", "perform", "relatively", "complex", "task", "efficient", "way", "suggest", "future", "work", "material", "design", "interface", "tool", "novice", "would", "fruitful", "physical", "perceptual", "slider", "we", "find", "subject", "can", "perform", "material", "editing", "equivalently", "well", "whether", "use", "physical", "parameter", "perceptually-inspired", "parameter", "provide", "we", "implementation", "additionally", "subject", "pool", "split", "half", "which", "prefer", "we", "conclude", "interactivity", "more", "important", "than", "whatever", "advantage", "perceptually-inspired", "parameter", "we", "give", "we", "subject", "yield", "image", "Navigation", "vs.", "Sliders", "we", "most", "prominent", "result", "poor", "performance", "image", "navigation", "interface", "compare", "individual", "parameter", "adjustment", "via", "slider", "because", "image", "navigation", "can", "show", "enough", "parameter", "combination", "simultaneously", "due", "limited", "screen", "real", "estate", "perhaps", "parameterbased", "organization", "use", "-lsb-", "Ngan", "et", "al.", "2006", "-rsb-", "optimal", "so", "optimal", "layout", "remain", "undiscovered", "Material", "Complexity", "we", "find", "color", "significant", "challenge", "material", "editing", "take", "almost", "twice", "long", "subject", "match", "colored", "material", "than", "grayscale", "error", "significantly", "higher", "subject", "also", "tell", "we", "color", "often", "most", "diffi", "cult", "part", "design", "process", "we", "believe", "need", "investigation", "method", "perceptual", "color", "manipulation", "material", "under", "color", "lighting", "note", "editing", "color", "material", "editing", "very", "different", "from", "set", "color", "image", "editing", "we", "find", "difficulty", "trial", "measure", "time", "completion", "error", "linear", "number", "material", "parameter", "give", "user", "slider", "interface", "when", "editing", "material", "more", "than", "one", "lobe", "subject", "could", "accomplish", "task", "give", "enough", "time", "we", "find", "spatially-varying", "material", "more", "challenging", "than", "other", "type", "material", "study", "result", "higher", "final", "error", "finally", "we", "discover", "significant", "difference", "between", "editing", "Ward", "Cook-Torrance", "brdf", "common", "Workflow", "we", "subject", "exhibit", "common", "workflow", "pattern", "we", "notice", "subject", "generally", "employ", "block-and-refine", "workflow", "move", "from", "large", "edit", "small", "edit", "slider", "interface", "subject", "do", "set", "parameter", "directly", "prefer", "smoothly", "change", "they", "until", "look", "right", "interactivity", "important", "reduce", "effect", "parameterization", "type", "exploration", "advantage", "slider", "interface", "over", "image", "navigation", "less", "obvious", "open", "trial", "take", "account", "control", "problem", "image", "navigation", "imply", "navigation", "better", "metaphor", "support", "exploration", "broad", "material", "variation", "Limitations", "main", "limitation", "work", "scope", "material", "editing", "task", "we", "investigate", "first", "we", "have", "only", "study", "subset", "possible", "brdf", "model", "second", "we", "do", "explicitly", "investigate", "whether", "novice", "can", "effectively", "pick", "material", "model", "from", "list", "available", "option", "Third", "we", "do", "investigate", "creation", "spatial", "pattern", "although", "we", "believe", "task", "well", "beyond", "capability", "novice", "user", "fourth", "we", "forego", "study", "interface", "painting", "because", "material", "representation", "restriction", "Summary", "paper", "present", "first", "step", "toward", "quantitatively", "evaluate", "use", "effectiveness", "user", "interface", "material", "design", "focus", "novice", "user", "we", "find", "novice", "can", "edit", "material", "equally", "well", "slider", "control", "either", "physical", "perceptually-inspired", "parameter", "long", "interactivity", "available", "image", "navigation", "can", "help", "user", "find", "important", "material", "configuration", "when", "artistically", "explore", "possibility", "perform", "slower", "less", "accuracy", "when", "precise", "adjustment", "necessary", "novice", "tend", "work", "similarly", "one", "another", "make", "large", "edit", "first", "systematically", "readjust", "each", "parameter", "smaller", "step", "until", "converge", "final", "solution", "prefer", "drag", "slider", "see", "change", "happen", "smoothly", "rather", "than", "snap", "value", "directly", "imply", "continuous", "traversal", "configuration", "space", "more", "appropriate", "novice", "than", "require", "they", "input", "parameter", "value", "directly", "many", "opportunity", "future", "work", "area", "we", "only", "study", "small", "subset", "interface", "model", "material", "design", "development", "method", "compare", "interface", "operate", "different", "material", "model", "would", "useful", "long", "term", "study", "expert", "user", "interact", "material", "design", "interface", "complex", "scene", "long", "render", "time", "would", "also", "interest", "acknowledgement", "we", "would", "like", "thank", "Jonathan", "Denning", "Lori", "Lorigo", "help", "prepare", "paper", "work", "support", "nsf", "-lrb-", "cns-070820", "ccf-0746117", "-rrb-", "Intel", "Sloan", "Foundation", "ACM", "transaction", "Graphics", "Vol", "29", "no.", "Article", "35", "publication", "date", "July", "2010", "35:10", "W.", "Kerr", "et", "al.", "reference", "dobe", "ystem", "nc", "2009", "Photoshop", "CS", "SHIKHMIN", "M.", "HIRLEY", "P.", "S.", "2000", "anisotropic", "phong", "brdf", "model", "Journal", "Graphics", "Tools", "25", "32", "utodesk", "nc", "2010", "maya", "2010", "en", "rtzus", "a.", "VERBECK", "R.", "AMAMOORTHI", "R.", "2006", "real-time", "brdf", "editing", "complex", "lighting", "ACM", "transaction", "Graphics", "25", "-lrb-", "July", "-rrb-", "945", "954", "en", "rtzus", "a.", "GAN", "K.", "AMAMOORTHI", "R.", "URAND", "F.", "2008", "precomputed", "polynomial", "representation", "interactive", "brdf", "editing", "global", "illumination", "ACM", "transaction", "Graphics", "27", "-lrb-", "apr.", "-rrb-", "13:1", "13:13", "linn", "J.", "F.", "1977", "model", "light", "reflection", "computer", "synthesize", "picture", "Computer", "Graphics", "-lrb-", "Proceedings", "SIGGRAPH", "77", "-rrb-", "192", "198", "OLBERT", "M.", "attanaik", "S.", "RIVANEK", "J.", "2006", "BRDFshop", "create", "physically", "correct", "bidirectional", "reflectance", "distribution", "function", "IEEE", "Comput", "graph", "appl", "26", "30", "36", "ook", "R.", "L.", "orrance", "K.", "E.", "1981", "reflectance", "model", "computer", "graphic", "SIGGRAPH", "81", "Proceedings", "8th", "annual", "conference", "computer", "graphic", "interactive", "technique", "ACM", "New", "York", "NY", "USA", "307", "316", "ebevec", "P.", "1998", "render", "synthetic", "object", "real", "scene", "bridge", "traditional", "image-based", "graphic", "global", "illumination", "high", "dynamic", "range", "photography", "Proceedings", "SIGGRAPH", "98", "Computer", "Graphics", "Proceedings", "annual", "Conference", "Series", "189", "198", "ror", "R.", "O.", "DELSON", "E.", "H.", "ILLSKY", "A.", "S.", "2001", "recognition", "surface", "reflectance", "property", "from", "single", "image", "under", "unknown", "real-world", "illumination", "Proceedings", "Workshop", "Identifying", "Objects", "across", "Variations", "Lighting", "IEEE", "conference", "computer", "Vision", "Pattern", "recognition", "-lrb-", "cvpr", "-rrb-", "airchild", "M.", "D.", "1998", "Color", "appearance", "model", "AddisonWesley", "Reading", "MA", "leming", "R.", "W.", "ROR", "R.", "O.", "DELSON", "E.", "H.", "2001", "how", "do", "human", "determine", "reflectance", "property", "under", "unknown", "illumination", "Proceedings", "Workshop", "Identifying", "Objects", "across", "Variations", "Lighting", "IEEE", "conference", "computer", "Vision", "Pattern", "recognition", "-lrb-", "cvpr", "-rrb-", "RIEDMAN", "M.", "1937", "use", "rank", "avoid", "assumption", "normality", "implicit", "analysis", "variance", "Journal", "american", "Statistical", "Association", "32", "200", "675", "701", "X.", "D.", "orrance", "K.", "E.", "ILLION", "F.", "X.", "REEN", "BERG", "D.", "P.", "1991", "comprehensive", "physical", "model", "light", "reflection", "Computer", "Graphics", "-lrb-", "Proceedings", "SIGGRAPH", "91", "-rrb-", "175", "186", "ERR", "W.", "B.", "ellacinus", "F.", "2009", "toward", "evaluate", "lighting", "design", "interface", "paradigm", "novice", "user", "ACM", "transaction", "Graphics", "28", "-lrb-", "July", "-rrb-", "26:1", "26:9", "afortune", "E.", "P.", "F.", "oo", "s.-c.", "orrance", "K.", "E.", "REENBERG", "D.", "P.", "1997", "non-linear", "approximation", "reflectance", "function", "Proceedings", "SIGGRAPH", "97", "Computer", "Graphics", "Proceedings", "annual", "Conference", "Series", "117", "126", "awrence", "J.", "EN", "rtzus", "a.", "ORO", "C.", "atusik", "W.", "fister", "H.", "AMAMOORTHI", "R.", "usinkiewicz", "S.", "2006", "inverse", "shade", "tree", "non-parametric", "material", "representation", "editing", "ACM", "transaction", "graphic", "-lrb-", "Proc", "SIGGRAPH", "-rrb-", "25", "-lrb-", "July", "-rrb-", "735", "745", "ark", "J.", "NDALMAN", "B.", "EARDSLEY", "P.", "A.", "reeman", "W.", "IBSON", "S.", "ODGINS", "J.", "K.", "ang", "T.", "IRTICH", "B.", "FIS", "TER", "H.", "UML", "W.", "YALL", "K.", "eim", "J.", "HIEBER", "S.", "1997", "design", "gallery", "general", "approach", "set", "parameter", "computer", "graphic", "animation", "Proceedings", "SIGGRAPH", "97", "389", "400", "atusik", "W.", "fister", "H.", "RAND", "M.", "ILLAN", "L.", "2003", "data-driven", "reflectance", "model", "ACM", "transaction", "Graphics", "22", "-lrb-", "July", "-rrb-", "759", "769", "GAN", "A.", "URAND", "F.", "atusik", "W.", "2005", "experimental", "analysis", "brdf", "model", "render", "technique", "2005", "16th", "eurographic", "Workshop", "Rendering", "117", "126", "GAN", "A.", "URAND", "F.", "atusik", "W.", "2006", "image-driven", "navigation", "analytical", "brdf", "model", "Eurographics", "Symposium", "Rendering", "2006", "399", "408", "icodemus", "F.", "E.", "ICHMOND", "J.", "C.", "SIA", "J.", "J.", "INSBERG", "I.", "W.", "IMPERIS", "T.", "1977", "geometrical", "consideration", "Nomenclature", "Reflectance", "National", "Bureau", "Standards", "-lrb-", "US", "-rrb-", "monograph", "160", "acanowskus", "R.", "RANIER", "X.", "CHLICK", "C.", "oulin", "P.", "2008", "sketch", "paint-based", "interface", "highlight", "modeling", "Eurographics", "Workshop", "sketch-based", "interface", "model", "2008", "17", "23", "ellacinus", "F.", "awrence", "J.", "2007", "Appwand", "editing", "measure", "material", "use", "appearance-driven", "optimization", "ACM", "transaction", "Graphics", "26", "54:1", "54:9", "ellacinus", "F.", "erwerda", "J.", "A.", "REENBERG", "D.", "P.", "2000", "toward", "psychophysically-based", "light", "reflection", "model", "image", "synthesis", "Proceedings", "ACM", "SIGGRAPH", "2000", "Computer", "Graphics", "Proceedings", "annual", "Conference", "Series", "55", "64", "oulin", "P.", "ournier", "a.", "1995", "painting", "surface", "charactristic", "Eurographics", "Rendering", "Workshop", "160", "169", "teven", "J.", "P.", "1996", "Applied", "Multivariate", "Statistics", "Social", "Sciences", "third", "ed", "Lawrence", "Erlbaum", "Associates", "Inc.", "ALTON", "J.", "O.", "IBSON", "D.", "ang", "L.", "ANRAHAN", "P.", "OLTUN", "V.", "2009", "exploratory", "modeling", "collaborative", "design", "space", "SIGGRAPH", "Asia", "09", "ACM", "SIGGRAPH", "Asia", "2009", "papers", "ACM", "New", "York", "NY", "USA", "10", "angorp", "P.", "AURIJSSEN", "J.", "utr", "P.", "2007", "influence", "shape", "perception", "material", "reflectance", "ACM", "transaction", "Graphics", "26", "77:1", "77:9", "ARD", "G.", "J.", "1992", "measure", "modeling", "anisotropic", "reflection", "SIGGRAPH", "92", "Proceedings", "19th", "annual", "conference", "computer", "graphic", "interactive", "technique", "ACM", "New", "York", "NY", "USA", "265", "272", "ESTLUND", "H.", "B.", "eyer", "G.", "W.", "2001", "apply", "appearance", "standard", "light", "reflection", "model", "Proceedings", "ACM", "SIGGRAPH", "2001", "Computer", "Graphics", "Proceedings", "annual", "Conference", "Series", "501", "510", "ill", "J.", "GARWAL", "S.", "RIEGMAN", "D.", "ELONGIE", "S.", "2009", "toward", "perceptual", "space", "gloss", "ACM", "transaction", "Graphics", "28", "-lrb-", "Aug.", "-rrb-", "103:1", "103:15", "ACM", "transaction", "Graphics", "Vol", "29", "no.", "Article", "35", "publication", "date", "July", "2010" ],
  "content" : "\n  \n    369c7203009bde22530935fb84de1891c5acb86b1003994a1d41cb27282afcb9\n    mib\n    10.1145/1778765.1778772\n    Name identification was not possible. \n  \n  \n    \n      \n        Toward Evaluating Material Design Interface Paradigms for Novice Users\n      \n      William B. Kerr ? Dartmouth College physical sliders perceptual sliders image navigation\n      \n        \n        \n        \n        Figure 1: Example workflow of two novice subjects editing materials using three different interfaces for material design. Goals can be found in Fig. 2 . Errors computed from equation (4) can be found in Fig. 7 .\n      \n       Material design is the process by which artists specify the reflectance properties of a surface, such as its diffuse color and specular roughness. We present a user study to evaluate the relative benefits of different material design interfaces, focusing on novice users since they stand to gain the most from intuitive interfaces. Specifically, we investigate the editing of the parameters of analytic bidirectional distribution functions (BRDFs) using three interface paradigms: physical sliders by which users set the parameters of analytic BRDF models, such as diffuse albedo and specular roughness; perceptual sliders by which users set perceptually-inspired parameters, such as diffuse luminance and gloss contrast; and image navigation by which material variations are displayed in arrays of image thumbnails and users make edits by selecting them. We investigate two design tasks: precise adjustment and artistic exploration. We collect objective and subjective data, finding that subjects can perform equally well with physical and perceptual sliders as long as the interface responds interactively. Image navigation performs worse than the other interfaces on precise adjustment tasks, but excels at aiding in artistic exploration. We find that given enough time, novices can perform relatively complex material editing tasks with little training, and most novices work similarly to one another. Keywords: material design interfaces, user study\n      ? e-mail: wkerr@cs.dartmouth.edu ? e-mail: fabio@cs.dartmouth.edu\n      Fabio Pellacini ? Dartmouth College physical sliders perceptual sliders image navigation\n      \n        \n        \n        \n      \n    \n    \n      \n        1 Introduction\n      \n      Real-world materials exhibit a wide variety of reflectance behaviors, from matte surfaces to highly glossy finishes. For opaque materials, the bidirectional reflectance distribution function (BRDF) [Nicodemus et al. 1977] captures the directionally-varying appearance of real-world surfaces. Material design is the process by which artists define properties of surface materials, such as their color, specular roughness, etc. This can be a difficult and time consuming task, since the variety of real-world materials is large. Many user interfaces have been proposed to simplify the process. This paper represents a first step toward quantitatively evaluating the effectiveness of user interfaces for material design. We focus on novice users without previous experience in material design since they stand to gain the most from intuitive interfaces and represent the majority of potential users of computer graphics design applications. We are specifically interested in the task of editing the parameters of realistic materials represented as analytic BRDFs, since they are the simplest and most commonly used models. We present a user study investigating the relative effectiveness of three interactive material design interfaces: physical sliders, by which\n      \n        ACM Reference Format\n      \n      Kerr, W., Pellacini, F. 2010. Toward Evaluating Material Design Interface Paradigms for Novice Users. ACM Trans. Graph. 29, 4, Article 35 (July 2010), 10 pages. DOI = 10.1145/1778765.1778772 http://doi.acm.org/10.1145/1778765.1778772.\n      \n        Copyright Notice\n      \n      Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or direct commercial advantage and that copies show this notice on the fi rst page or initial screen of a display along with the full citation. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers, to redistribute to lists, or to use any component of this work in other works requires prior specific permission and/or a fee. Permissions may be requested from Publications Dept., ACM, Inc., 2 Penn Plaza, Suite 701, New York, NY 10121-0701, fax +1 (212) 869-0481, or permissions@acm.org . ? 2010 ACM 0730-0301/2010/07-ART35 $10.00 DOI 10.1145/1778765.1778772 http://doi.acm.org/10.1145/1778765.1778772\n      ACM Transactions on Graphics, Vol. 29, No. 4, Article 35, Publication date: July 2010.\n      35:2 ? W. Kerr et al.\n      users set the parameters of analytic BRDF models, such as diffuse albedo and specular roughness; perceptual sliders by which users set perceptually-inspired parameters, such as diffuse luminance and gloss contrast; and image navigation by which material variations are displayed in arrays of image thumbnails and users make edits by selecting them. Fig. 1 shows examples of output from our subjects using each of these interfaces. We simplify material design tasks so that they can be accomplished by novices and effectively measured, focusing on physically-based isotropic BRDFs of real-world materials respected by the CookTorrance and Ward BRDF models [Cook and Torrance 1981; Ward 1992]. Much previous work in material design focuses on the modeling and editing of achromatic reflectance, so we investigate the use of material design interfaces with and without color. We also investigate the editing of analytic BRDF parameters in the presence of spatial variation across a surface, but not the editing of the spatially-varying patterns themselves. We extend our methodology from [Kerr and Pellacini 2009] to investigate how novices use these interfaces to make precise adjustments and artistically explore broad material variations. Our study consists of three parts. First, in six matching trials, subjects are asked to match a target BRDF as closely as possible. Second, in three open trials, subjects use their own creativity to design a BRDF based on a suggestive image. Finally, in questionnaires, subjects give both quantitative and qualitative feedback about the interfaces. Twenty subjects spend roughly one hour with each of the three interfaces. We perform an analysis of objective measurements and subjective user feedback and draw the following conclusions: 1. Given enough time, subjects with no previous training can perform meaningful material design tasks, when supported by the interface. 2. Subjects perform well with both slider interfaces, with interactivity benefits outweighing benefits from using perceptually-inspired parameters compared to physical parameters. 3. The image navigation interface performs significantly worse than slider interfaces for matching tasks and precise adjustments. 4. Within the boundaries of our study, performance scales well with material complexity in degrees of freedom. However, some users do poorly when multiple BRDFs interact in a spatially-varying way. 5. Within the boundaries of our study, the introduction of color roughly doubles the time it takes to reach a goal, and reduces the quality of the result by a similar factor in the error space. This indicates that chromaticity is a significant challenge in material design. 6. While image navigation is generally inferior to the slider interfaces, it supports broad artistic exploration better than parameter adjustment. As with any user study, our observations only strictly apply within the boundary of the tested cases. However, we believe that these trends are general enough to apply to other closely-related material domains, affecting the development of future material design interfaces. Additionally, we believe that the principles used to design our study can be employed to evaluate additional material design tasks in moving toward a comprehensive evaluation of material design interfaces.\n      \n        2 Related Work\n        Analytic BRDF Models. Of the various BRDF representations, we are specifically interested in the editing of analytic BRDF mod els since they give users the ability to define a BRDF using only a small number of parameters. We choose to study the editing of Cook-Torrance BRDFs [Cook and Torrance 1981], since they fit measured data well [Ngan et al. 2005], and the isotropic version of the Ward BRDFs [Ward 1992], since they still fit measured data reasonably well [Ngan et al. 2005] and since a perceptual parameterization has been investigated [Pellacini et al. 2000]. To avoid confusing novices with a large number of models, we do not include other BRDF models that are commonly used to represent realistic materials, such as [Blinn 1977; Lafortune et al. 1997; He et al. 1991; Ashikhmin and Shirley 2000]. Physical Sliders. A common practice in material editing is to edit a BRDF by modifying directly the parameters of the analytic model. For example, a user might input values for diffuse albedo and specular roughness. Off-the-shelf modeling and animation software such as Maya [Autodesk Inc 2010] use this type of interface. Perceptual Sliders. Since physical parameters are only indirectly related to the perceived appearance of a material, researchers have investigated perceptual parameterizations where each parameter represents a perceptually-meaningful dimension of surface appearance, such as diffuse luminance or gloss contrast. These parameterizations are also scaled such that linear changes in the parameters yield linear changes in the perceived appearance of the surface material. Pellacini et al. [2000] develop a perceptual parameterization of the Ward BRDF model through psychophysical experiments. Westlund and Meyer [2001] investigate correspondences between traditional appearance standards such as gloss, sheen, and haze and analytic material models. Wills et al. [2009] develop a method for finding perceptual embeddings of measured material data and a method for traversing that embedding. In this work, we investigate whether manipulating perceptual parameters has benefits over manipulating physical ones in editing tasks. Since no perceptual parameterizations exist for all BRDFs used in this study, we develop perceptually-inspired parameterizations based on [Pellacini et al. 2000] and [Ngan et al. 2006] in Sec. 5. Image Navigation. With image navigation, a user can view variations of materials by browsing arrays of thumbnail images. Material edits are made by selecting a desired image. Marks et al. [1997] explore this idea for computer graphics and suggest arrangement schemes for displaying sets of images with variations of interest. Adobe Photoshop [Adobe Systems Inc 2009] uses an interface called ?variations? to show multiple image configurations resulting from photographic adjustments like hue and saturation changes. Ngan et al. [2006] propose a user interface specific to BRDF editing that uses a perceptually-inspired image difference metric to arrange possible BRDF configurations with perceptually-uniform spacing, including varying BRDF models. It is argued that since novices do not have a deep understanding of material appearance, allowing them to choose rendered images directly might be beneficial. In this study, we compare this interface to direct parameter setting. Other Interfaces. Colbert et al. [2006] suggest a painting interface for editing BRDF highlights with brush tools. Similarly, [Pacanowski et al. 2008] develop a painting interface for nonphotorealistic highlights. We do not include such interface types in this study because they utilize custom material models specific to the control scheme. Poulin and Fournier [1995] introduce the idea of optimizing material parameters to match painted color points on surface geometry. We exclude this interface type because it is unclear how to extend it to support texture variations robustly. BRDFs can also be defined by arbitrary curves over an angular parameterization, as used in [Lawrence et al. 2006]. Spatial Variation Editing. Editing spatially-varying BRDFs is considerably harder than editing single BRDFs. Three editing tasks are normally performed on spatially-varying BRDFs: changing the spatial patterns (by texture painting or synthesis), selecting regions of similar appearance (e.g. using [Pellacini and Lawrence 2007]) and altering the BRDFs of the selected regions. In this paper, we focus on interfaces for editing the parameters of BRDFs, leaving the study of interfaces for editing and selection of spatial patterns to future work. We represent spatially-varying BRDFs as linear combinations of basis BRDFs with spatially-varying weights [Lawrence et al. 2006], where users edit the parameters of the basis BRDFs. We choose this model since it fits measured data well. Appearance Design Study. We follow the approach we used in [Kerr and Pellacini 2009] for the evaluation of lighting design interfaces and apply it to the material editing domain. Talton et al. [2009] study the space of many design tasks by developing a collaborative editing system that maps the space of desirable configurations based on what previous users have produced. BRDF editing was part of this system, but a direct comparison of various interface paradigms was not explored.\n        ACM Transactions on Graphics, Vol. 29, No. 4, Article 35, Publication date: July 2010.\n        Toward Evaluating Material Design Interface Paradigms for Novice Users ? 35:3\n        Ward (color) Ward (gray) Cook-Torrance (gray) 2-lobe Ward (gray)\n        start goal\n        \n          \n        \n        training (matching) trial 1 (matching) trial 2 (matching) trial 3 no limit limit: 3 minutes limit: 3 minutes limit: 5 minutes\n        \n          Figure 2: Starting and goal configurations for training and matching trials. Material models are listed above. Time limits are listed below (see Sec. 4).\n        \n      \n      \n        3 Study Overview\n        Goal. We seek to evaluate the relative effectiveness of different interface paradigms for material design in the context of designing realistic materials with a focus on novice users. Specifically, (1) we want to measure how efficiently these users can perform specific material adjustments and (2) we want to understand which interface paradigms provide better artistic exploration of possible material variations. Novice Users. We focus on novices with little or no prior knowledge of material design since they make up the majority of users who can take advantage of intuitive interfaces. We would like to have as many people as possible capable of using graphics tools. All subjects rated their experience level with material design as either 1 or 2 on a scale from 1 to 5, and can be considered novices. Reducing Complexity. Since material design is a non-trivial process, we require a careful triage between completeness and length. On the one hand, we want to achieve complex-enough material editing tasks to ensure meaningful measurements. On the other, we want to avoid bias in the data by ensuring subjects can successfully complete the required tasks without incurring too much fatigue. Working with novices makes this triage even more necessary. We simplify the material editing task by focusing on editing the parameters of analytic BRDFs, and while we include different BRDF models, we do not ask subjects to select between different  models during trials. We simplify implementation of interfaces to ensure that they can be quickly learned while sufficiently complete to capture the main characteristics of each paradigm. Materials. In our design tasks, subjects edit materials represented as isotropic Ward [1992] and Cook-Torrance [1981] BRDFs (Sec. 2). We investigate three variations of these models. First, we use achromatic materials for half of the trials and color for the other half. Much previous work in material design focuses on the modeling and editing of achromatic reflectance, and we would like to discover how important chromaticity is in the design process. Second, we include two trials where BRDFs have two specular lobes, since, for some materials, such BRDFs fit measured materials better than single lobe ones [Ngan et al. 2005]. Third, to determine whether the presence of spatial variation affects the design tasks, we investigate the editing of spatially-varying BRDFs represented as linear combinations of two basis BRDFs with spatially-varying weights, where users edit the parameters of the basis BRDFs. We choose this model since it fits measured data well [Lawrence et al. 2006]. Examples of each material type can be found in Fig. 2 . Lighting. In our study, materials are lit by direct illumination from a real-world environment map. Natural illumination is considered ideal for material perception when only a single image is available [Dror et al. 2001; Fleming et al. 2001]. We use the Grace Cathedral environment map [Debevec 1998] since [Ngan et al. 2006] suggest that the choice of illumination environment has little effect on material distinction as long as it is natural, and recommend the Grace Cathedral map. We choose to use direct illumination, rather than global illumination, since we want to preserve interactivity and high image fidelity during the design task. We use the tone mapping equation Image = (Intensity ? 2 exposure ) 1/gamma with a gamma of 2.2. Exposure is fixed so that the goal for a trial is clearly visible. Subjects have no control over exposure or gamma. Geometry. The geometry in our images consists of a sphere floating in space. We use a sphere to avoid occlusion artifacts in glossy reflections caused by computing direct illumination only. Vangorp et al. [2007] suggest there may be shapes better than spheres for material discrimination, but that spheres possess many desirable properties. We determine that a sphere shape is the best for our purposes given our rendering limitations. Interfaces. We compare three user interfaces: physical sliders, perceptual sliders, and image navigation. Implementation details of these interfaces are presented in Sec. 5. Physical and perceptual slider interfaces are similar in that they are designed to manipulate one parameter at a time. Physical sliders alter the parameters of analytic BRDF models directly; these parameters are related to physical reflectance properties such as diffuse energy and specular roughness. Such parameters, though, are not directly related to material appearance. Perceptual sliders alter perceptually-meaningful material parameters, such as diffuse luminance and gloss contrast. These parameters are scaled to be linearly related to perceptual distances. Perceptual parameterizations are believed to be more natural for editing purposes since they are directly related to how humans perceive materials. With image navigation, a user can view variations of materials by browsing arrays of thumbnail images. Material edits are made by selecting a desired image. It is believed that image navigation is a useful editing metaphor since novices can directly select rendered images, rather than specifying parameter values, and since they can preview several variations and combinations of multiple parameters simultaneously. Tasks. We ask subjects to perform two types of material design tasks. During matching trials, they are asked to match a material of an object under fixed environmental lighting to an image of the same object and lighting with a target material configuration. Matching trials allow us to quantitatively measure users? performance, while providing a clear goal for subjects who have never experienced material design before. This provides context for the more subjective open trials, where users are given a photograph of several real-world objects with a round target area removed and asked to creatively design a material that would look good if assigned to an object placed in the target area. These trials allow us to observe how users artistically explore the space of possible material configurations, a more natural but harder to measure task.\n        Ward (color) Cook-Torrance (color) Textured Ward (color)\n        (matching) trial 4 (matching) trial 5 (matching) trial 6 limit: 6 minutes limit: 6 minutes limit: 8 minutes\n        ACM Transactions on Graphics, Vol. 29, No. 4, Article 35, Publication date: July 2010.\n        35:4 ? W. Kerr et al.\n        2-lobe Ward (gray) Cook-Torrance (color) Textured Ward (color)\n        goal\n        \n          \n        \n        (open) trial 7 (open) trial 8 (open) trial 9 limit: 5 minutes limit: 6 minutes limit: 8 minutes\n        \n          Figure 3: Goals for open trials. Starting configurations are identical to matching trials 3, 5, and 6.\n        \n      \n      \n        4 Experiment\n        We ask subjects to complete a number of trials, during which all actions are recorded for further analysis. Each subject performs all trials using all interfaces. These trials vary in the number of material parameters, material model type, number of lobes, presence of color, presence of spatial variation, and task goal. Preparatory Studies. We conducted formal and informal preparatory user studies on 15 additional subjects, the results of which are not included in this paper. Different implementations of the various interfaces were tested to determine a locally optimal set of controls and to remove any implementation errors. The open and matching goals used in the final study were tested to ensure that time limits were appropriate and that the tasks could be completed. Trials. We perform six matching trials and three open trials with a progressively increasing number of degrees of freedom in the material model. Starting configuration, goal configuration, and time limit for each trial are summarized in Fig. 2 and Fig. 3 . For matching trials, goal configurations were taken from parametric fits presented in [Ngan et al. 2005] to measured materials in [Matusik et al. 2003]. For grayscale trials 1 and 2, the diffuse and specular coefficients of ?metallic blue? and ?white bball? were desaturated. For grayscale trial 3, the goal was modeled by hand after a rendering of ?acrylic violet?, since a fit was unavailable. Color trials 4 and 5 use fits for ?blue bball? and ?ch-ball-green-metallic? respectively. Trial 6 uses fits for ?white-bball? and ?metallic gold? weighted by a texture. We vary matching trials in material complexity to observe possible changes in users? workflow and interfaces? effectiveness under these conditions. For open trials, we select target images that differ from the workspace lighting environment and vary in content to encourage free-form artistic exploration. We choose one grayscale and two colored material goals with objects of varying material properties. Objects in the same goal image share some material properties to keep the objective from being completely unspecified. The same initial and goal material configurations are used for all subjects and all interfaces. Each trial has a fixed time limit, and subjects can end the trial sooner if satisfied with the current result. At the end of each matching trial, subjects rate the accuracy of the matching on a scale of 1 to 5. For open trials, subjects use the same scale to rate how satisfied they are with their result. Questionnaire. After performing all trials with all interfaces, subjects complete a questionnaire where they rate each interface on a scale of 1 to 5 in the following categories: (1) natural way to think about material editing, (2) preference in matching trials, (3) preference in open trials, and (4) overall preference. Subjects also strictly rank interfaces in each of these categories. Immediately after finishing trials for each single interface, subjects are asked to leave free-form comments on aspects of each interface. For reproducibility, we include copies of the questionnaires as additional material. Procedure. Twenty subjects participated in the study, chosen from different age and educational groups. All subjects had normal or corrected-to-normal vision. Subjects edit materials for about 3 hours each to ensure good statistical significance of our tests, while keeping fatigue low. Subjects complete the study in three 60-minutes sessions, one for each interface. We randomize the order of the interfaces for each subject. Before each session, subjects complete a training phase to become familiar with the specific interface. We train each subject individually to allow questions, accommodating each subject?s learning needs. The instructor verifies that the subject uses each part of the interface, and answers the subjects? questions. Before proceeding to the experiment, the subject uses the interface until he or she feels comfortable. During both the guided and free portions of the training, a single sample goal was shown ( Fig. 2 ). Once trials begin, all user interface actions are recorded. The study is conducted in a controlled lighting environment with negligible ambient lighting, to simulate typical working conditions of artists and maximize visibility of the screen. We use a 24-inch Dell 2407WFPb LCD display at 1280?800 resolution at a distance of approximately 1 foot from the subject (monitor native resolution: 1900 ? 1200). All rendered images are 256x256 pixels on screen covering an area of 4 square inches. We used an Intel 2.8 Ghz Core2 Quad Q9550 PC with 4 GB of RAM and an NVidia GeForce 9800 GT graphics card.\n      \n      \n        5 Interface Implementation\n        In this section we discuss our implementations of the user interfaces included in the study. For reproducibility, we include a video as  supplemental material that shows each interface in detail. Rendering. We use the real-time rendering algorithm of [BenArtzi et al. 2006] to preview BRDF edits under direct natural illumination. Our implementation renders 45f ps on the 256 x 256 pixel images of a sphere used in the study. We considered adding global illumination as in [Ben-Artzi et al. 2008], but decided that the potential artifacts resulting from approximating the BRDF at a lower frequency might effect our measurements. The algorithm we use doesn?t allow the roughness and Fresnel terms of the CookTorrance BRDF model to be simultaneously modified. It takes approximately 0.6 seconds to switch between these parameters in our implementation. BRDF models. In our implementation, we parameterize the isotropic Ward BRDF ? w as\n        ACM Transactions on Graphics, Vol. 29, No. 4, Article 35, Publication date: July 2010.\n        Toward Evaluating Material Design Interface Paradigms for Novice Users ? 35:5\n        \n          \n          Figure 4: Study interface layout.\n        \n        \n          1\n          ? d e (? tan 2 ? h /? 2 ) ? w = + ? s ? ? 4?? 2 cos ? i cos ? o\n        \n        where ? d is the diffuse albedo, ? s is the energy of the specular component, ? is the surface roughness and ? i , ? o , ? h are the angles between the surface normal and the incoming, outgoing and halfangle respectively. We parameterize the Cook-Torrance BRDF ? ct following [Ngan et al. 2005] as\n        \n          2\n          ? d ? s DGF ? ct = + ? ? cos ? i cos ? o\n        \n        with F = F 0 + (1 ? F 0 )(1 ? cos ? b ) 5 , e ?(tan ? h /m) 2 D = , m 2 cos 4 ? h 2 cos ? h cos ? i 2 cos ? h cos ? o G = min 1, , , cos ? b cos ? b where ? d is the diffuse albedo, ? s is the energy of the specular component, ? is the surface roughness, F 0 is the Fresnel reflectance for a direction orthogonal to the surface, and ? b is the angle between the outgoing and half-vector direction. Some trials use BRDFs ? ww with 2 Ward lobes defined by\n        \n          3\n          ? d e (?tan 2 ?/? 1 2 ) e (?tan 2 ?/? 2 2 ) ? ww = ? + ? ? s1 4?? 1 2 + ? s2 4?? 2 2 ?\n        \n        where ? = 1/ cos ? i cos ? o . In other selected trials, we use a spatially-varying material. This spatial variation is modeled as a weighted sum of two Ward BRDFs ? sum = w 1 ? w1 + w 2 ? w2 , where the weights w 1 and w 2 are spatially-varying and sum to one at all surface points [Lawrence et al. 2006]. Universal Interface Features. All interfaces use the same screen layout consisting of a workspace window, a goal window, and rating buttons ( Fig. 4 ). An undo key allows the user to walk back through an unlimited number of edits. To compensate for the fact that materials created using this system may not conserve energy, a warning indicator appears in the upper right corner of the user?s image when the BRDF is not energy conserving. Physical Sliders. We use a slider interface as the means by which a user sets the parameters of the BRDF model, e.g. the diffuse albedo ? d , specular energy ? s , roughness ?, m and Fresnel term F 0 . Each user controlled parameter is listed with a slider bar next to it. The parameter can be changed by clicking anywhere on the bar, and gradual changes can be seen by dragging the slider continuously across the bar. Setting model parameters directly would require specifying the red, green and blue coefficients of ? d and ? s . This would ignore common color editing practices, artificially handicapping the interface. We use CIELAB luminance (L) for achromatic intensity, and saturation and hue for chromaticity [Fairchild 1998]. We use hue and saturation since they are the default in Maya [Autodesk Inc 2010]. Perceptual Sliders. Perceptual parameterizations differ from physical ones in both effect and scale. In this paper, we choose perceptually-inspired parameters based on [Pellacini et al. 2000; Westlund and Meyer 2001]. Furthermore, since all perceptual parameterizations are derived from achromatic data, we follow [Wills et al. 2009; Pellacini et al. 2000] and derive parameters for grayscale diffuse and specular components, and then add hue and saturation to them. We use the same saturation and hue controls as with physical sliders. Slider controls work the same way as with physical sliders, but modify the perceptually-inspired parameters. To determine the correct scaling of each parameter axis in BRDF model?s configuration space, we use the image-based BRDF difference metric from [Ngan et al. 2006] since psychophysical data has not been published for the range of BRDF parameters we investigate. Letting I(?) be the image corresponding to BRDFs ?, we can approximately compute the perceptual distance, d, between BRDFs ? 1 and ? 2 as 2\n        \n          4\n          d 2 (? 1 , ? 2 ) = 3 I p,c (? 1 ) ? 3 I p,c (? 2 ) p?pixels c?r,g,b\n        \n        We scale our perceptually-inspired parameters such that equal steps of the parameter yield steps according in the distance metric. We include a comparison of this metric to our parameterizations as a supplemental document. For all parameterizations that follow, ? d and ? s are represented achromatically according to CIELAB luminance in the range [0, 1]. For Ward BRDFs, we use the parameterization from [Pellacini et al. 2000] with a modified d parameter: L = ? d\n        \n          5\n          c = 3 ? s + ? d /2 ? 3 ? d /2 d = 1 ? ? 1/4\n        \n        where L is the diffuse luminance, c is the gloss contrast, and d is the gloss distinctness. We raise ? to a power of 1/4 because it more closely matches scaling according to equation (4) which is valid for a larger range of ? than the original experiment covered in [Pellacini et al. 2000]. The trials using textured Ward simply have two instances of the perceptually inspired Ward parameters. For Cook-Torrance BRDFs, we use the following parameterization: L = ? d\n        \n          6\n          c = 3 ? s F 0 + ? d /2 ? 3 ? d /2\n        \n        \n          6\n          d = 1 ? m 1/4 s = 3 [(1 ? F 0 ) ]/[(1 ? )F 0 ]\n        \n        where L is the diffuse luminance, c is the gloss contrast, d is the gloss distinctness, s is the gloss sheen and = 0.02 is the minimum  allowed value of F 0 when s ? [0, 1]. Cook-Torrance parameters L, c, and d are similar to their Ward counterparts; with added s to set the contrast of the specular component at grazing angles while preserving its contrast at non-grazing angles. For Ward BRDFs with two lobes, we use the following parameterization: L = ? d c = 3 ? s1 + ? s2 + ? d /2 ? 3 ? d /2\n        ACM Transactions on Graphics, Vol. 29, No. 4, Article 35, Publication date: July 2010.\n        35:6 ? W. Kerr et al.\n        \n          \n          Figure 5: Image navigation 2D layout.\n        \n        \n          7\n          b = ? s1 /(? s1 + ? s2 ) 1/4 d = 1 ? ? 1 1/4 1/4 1/4 1/4 h = (? 2 ? ? 1 )/(? max ? ? 1 )\n        \n        where L is the diffuse luminance, c is the gloss contrast, b is a lobe blending parameter, d is the overall gloss distinctness, h is a haze parameter and ? max is the maximum possible ? value for normalization. Image Navigation. We base our implementation of image navigation on [Ngan et al. 2006]. Their interface consists of a series of tabs that reveal different image arrays. Some tabs show variations of material model parameters along two axes, while others serve as color pickers for the diffuse and specualr coefficient parameters. Images are spaced according to the image difference metric in equation (4), and the spacing size is determined by a user-controlled slider. As in [Ngan et al. 2006], we limit the interface to display only two parameters simultaneously to ensure that thumbnails are large enough to perform accurate selection. Fig. 5 shows what our two-parameter layout looks like using image navigation. We implement a system by which all model parameters can be assigned to either a horizontal or vertical axis. From the current configuration, two steps in either direction for either parameter axes are shown. This results in a five by five image array of 25 images representing different combinations of two parameters. We also give the user preset configurations that are helpful combinations of parameters to reduce confusion (e.g. diffuse versus specular brightness or a diffuse color picker). Since our perceptuallyinspired parameterizations scale similarly to the difference metric in [Ngan et al. 2006], we space images by equal steps in that parameter space. This may cause the space displayed in a 2D image to be scaled differently on the horizontal than the vertical in error space even though they are uniform in parameter space, but we don?t find it to be a problem. We do not allow a slider to determine the size of these steps, because with real-time feedback we feel this would be like taking the perceptual sliders interface and simply giving multiple previews at a time. By giving buttons that increase and decrease the step sizes on a log scale, we keep image navigation and perceptual sliders implementations to their respective interface metaphors, while giving image navigation the power to make small and large edits. Rendering time for the thumbnails depends on the material configuration, but is normally 0.25 seconds with the exception of arrays where both gloss distinctness and sheen vary simultaneously where it is 2.5 seconds (see previous section). We account for this in our analysis.\n        Time to Completion Final Error 400 60 time error 0 0 1 2 3 4 5 6 1 2 3 4 5 6 trial trial ? physical sliders ? perceptual sliders ? image navigation\n        \n          Figure 6: Left: average time to completion for all trials over all subjects (in seconds). Right: average final error for matching trials over all subjects. Error values are from equation (4), no normalization.\n        \n      \n      \n        6 Analysis\n        We present an analysis of our data in two parts. First, we analyse the output of the rendering system as subjects proceed through each trial. Second, we analyse the feedback from users at the end of each trial and in the questionnaires. Unless stated otherwise, tests for statistical significance are computed with repeated measures analysis of variance (ANOVA) [Stevens 1996]. This handles within-subject factors that create correlations which invalidate the assumption of independence in standard one-way ANOVA. A p value below 0.1 indicates a 90% confidence that the two population means differ given the measure of the sample. In all figures, error bars represent standard error. Time to Completion. We investigate the work speed of users with each interface. Generally, subjects are able to complete each trial within the allotted time limit with one or more interfaces. In Fig. 6 , we show the mean time to completion for each matching trial over all subjects. Time to completion for image navigation is almost always significantly higher than either physical or perceptual sliders on matching trials (p ? 0.051), excepting trial 6. We believe trial 6 differs because many subjects ran out of time or gave up early with image navigation, reducing its mean time and resulting in matches of lower quality. We conclude that image navigation must be slower to work with on trial 6, and that we are reaching the limit of subjects? patience. The time to completion for physical and perceptual sliders shows no significant difference on trials 2-6, but physical sliders average 20 seconds faster than perceptual sliders on trial 1 (p = 0.053). In open trials, the meaning of time to completion is less defined since the standard of judgement used by the subject can vary from trial to trial or even interface to interface. The only statistically significant differences (p < 0.1) were between perceptual sliders (69.0s) and image navigation (107.5s) on trial 7 (p = 0.039), and physical sliders (113.5s,201.9s) and image navigation (150.9s,179.3s) on trials 8 (p = 0.080) and 9 (p = 0.048) respectively. Trial 1 in grayscale and trial 4 in color use the same BRDF model, as do trials 2 and 5. The average factor of time to completion between grayscale trials and color trials is 1.886. Matching Error. To evaluate user performance in matching trials, we compute the error between the subject?s BRDF and the goal BRDF using the image-based difference metric in equation (4) [Ngan et al. 2006]. This metric has been shown to capture perceived differences in BRDFs. Fig. 7 shows the error over time for one subject performing the same trial with all interfaces. When subjects are successful, error decreases toward the correct solution, converging on some low error value. This convergence is not monotonic, because users explore the configuration space in order to reach the desired goal. In the accompanying supplemental material for this paper we include error graphs for all subjects on all trials together with rendered images of their material configurations at fixed time intervals. To summarize the overall performance of each interface we analyse the final image error for each matching trial averaged over all subjects ( Fig. 6 ). Both physical and perceptual sliders outperform image navigation on all trials (p < 0.064) except for trial 4, where image navigation has roughly the same error as perceptual sliders. However, it took a longer amount of time to complete this trial with image navigation (p ? 0.026). The error on trial 2 is especially high for image navigation. This could in part be due to the rendering limitation specific to image navigation on Cook-Torrance BRDFs (Sec. 5). However, this anomaly cannot be seen in trial 5, which also uses the Cook-Torrance model. The goal in trial 2 happens to be particularly bright, and this error discrepancy is not as pronounced when error is computed with clamped intensity values. We conclude that these failure cases are reasonably in alignment with the rest of the data when taking this into account. Surprisingly, there is no significant difference in errors between perceptual and physical sliders except on trial 2 where physical sliders outperform perceptual sliders (p = 0.064). This trial again exhibits a difference that we cannot identify conclusively. The other CookTorrance trial does not show such a difference between physical and perceptual sliders, nor do the other grayscale trials. As with the time to completion, we compare grayscale trials 1 and 2 to color trials 4 and 5. The average factor in error between grayscale trials and color trials is 2.167. Convergence. To illustrate the convergence behavior of different interfaces we average the image error across all subjects over time in Fig. 7 . This average is not statistically valid, but we find that it gives a revealing visual summary of overall behavior. As can be seen in the graphs, physical and perceptual sliders tend to converge more quickly than image navigation, and with lower error. We also see that convergence behavior of physical and perceptual sliders are similar, though trial 2 seems to show better convergence with phys- ical sliders. Finally, we note that trials 2 and 6 show particularly poor convergence for image navigation. In trial 6 with a spatiallyvarying BRDF, many subjects give up or run out of time using image navigation. We also see slower and poorer convergence with the slider interfaces on this trial. Again, we cannot identify conclusively what causes the differences in trial 2. Subjective Image Quality. At the end of each trial, subjects rate their work on a scale of 1 to 5, with 1 being the worst and 5 being the best. Matching trials are rated in terms of how close the workspace and goal images match. Open trials are rated in terms of how satisfied the subject is with their result. Fig. 8 shows the average ratings for each trial. This subjective image quality correlates with the computed error of the final image with a linear correlation coefficient of ?0.5895. In matching trials, subjects on average rate their work better when using sliders than with image navigation on all trials (p ? 0.058). Not only do subjects perform objectively better using slider interfaces compared to image navigation as measured by error, they perceive themselves as doing better as well. Ratings for the slider interfaces compared to one another contain no significant differences, except on trial 2 (p = 0.042), as with the computed error. In open trials, there is no significant difference in the image ratings between any of the three interfaces, except for physical sliders having a slightly higher average rating than image navigation on trial 7 (p = 0.015). Interface Rankings and Ratings. Subjects rate and rank each interface in 4 categories where ratings can have ties, but rankings are forced choice (see Sec. 4). Average ratings and stacked fre- quencies of rankings are shown in Fig. 9 . For evaluating statistical significance of ranks we use the Friedman test [Friedman 1937], a nonparametric test that takes into account within-subject effects. A low p-value indicates high confidence that subjects have made a significant distinction between two interfaces. In all categories except preference on open trials, slider interfaces outrank image navigation (p = 0.074 on perceptual vs. image navigation in the natural category, p ? 0.002 otherwise). We find no statistical difference between ranks for the two slider interfaces. Roughly half of subjects rank physical sliders higher than perceptual in overall preference, and vice versa. We find similar trends in the interface ratings. The slider interfaces average to roughly equivalent in all categories. When comparing image navigation to slider interfaces, except for open trial preference, image navigation is rated much lower in all categories (p ? 0.002). Complexity. We have shown that the interface used to perform material editing influences performance. The complexity of the material being edited has an effect on how difficult the task is to perform, but the relative performance of the interfaces remains unchanged. Difficulty seems to scale linearly on average with the number of user controlled parameters in the material model. Regression on average time to completion suggests a linear relationship (r 2 ? 0.919). Error has a similar trend with physical (r 2 = 0.996) and perceptual (r 2 = 0.880) sliders, but not as much with image navigation (r 2 = 0.499). It is unclear if we increased complexity further, that novices would still be able to accomplish the task. Trial 6 appears to indicate that there is a point at which many subjects will give up. Our data does not indicate any significant trends in material editing between using the Ward or CookTorrance BRDF model. The Cook-Torrance BRDF in trial 2 appears to be more challenging than the Ward BRDF in trial 1, but the Cook-Torrance BRDF in trial 5 appears to be less challenging than the Ward BRDF in trial 4. We make no claims as to the usefulness of one model over another, as our study is not designed to give subjects a choice between the two.\n        ACM Transactions on Graphics, Vol. 29, No. 4, Article 35, Publication date: July 2010.\n        Toward Evaluating Material Design Interface Paradigms for Novice Users ? 35:7\n        Trial 5, 1 Subject Trial 1, All Subjects 250 90 120 error error error 0 0 0 0 time 360 0 time 180 0 Trial 6, 1 Subject Trial 4, All Subjects 140 140 150 error error error 0 0 0 0 time 480 0 time 360 0\n        \n          Figure 7: Left: example graphs of error over time (in seconds) for the individual trials shown in Fig. 1 . Right: illustration of the error over time (in seconds) for matching trials averaged over all subjects. Error values are from equation (4), no normalization.\n        \n        Trial 2, All Subjects Trial 3, All Subjects ? physical 80 sliders ? perceptual sliders error ? image navigation 0 time 180 0 time 300 Trial 5, All Subjects Trial 6, All Subjects 100 error 20 0 time 360 0 time 480\n        ? physical sliders ? perceptual sliders ? image navigation 5 rating 1 1 2 3 4 5 6 7 8 9 matching trials open trials\n        \n          Figure 8: Average of subjective image quality ratings over all subjects.\n        \n        ACM Transactions on Graphics, Vol. 29, No. 4, Article 35, Publication date: July 2010.\n        35:8 ? W. Kerr et al.\n        Interface Ratings Interface Rankings 5 20 3 2 1 0 1 ? physical sliders ? perceptual sliders ? image navigation\n        \n          Figure 9: Left: Average interface ratings from questionnaire over all subjects. Rating 5 implies best. Right: Sum of interface rankings over all subjects. Rank 1 implies best.\n        \n      \n      \n        7 Workflow Observations\n        We now discuss common trends in the way our subjects use the different interfaces to edit materials. In Fig. 1 we show work done by two different subjects. Corresponding error graphs can be found in Fig. 7 . Images and error graphs from all subjects and all trials can be found in the supplemental material, as well as selected videos of workflow. Blocking and Refinement. Subjects do not fix each parameter value independently and permanently. They make rough adjustments to move the configuration into a good local space and hierarchically refine into smaller and smaller spaces until the precise configuration is reached. This means that parameters are revisited and changed many times during the course of an editing session. Such behavior is universal across all subjects. Inability to Configure Image Navigation. We notice that the majority of the time spent when using image navigation is not spent changing the configuration of the material. Subjects appear to have trouble setting up the 2D navigation array of images. Not only do they have to figure out which axes to look at, they must also determine the scale and granularity of those axes. We observed that most of our subjects were confused by this, despite having preset configurations. Subjects comment ?I felt limited by the layout because I could not find the combination I needed to find a match. I was a bit confined by the tools and felt like I could not control my work as much;? and ?[with image navigation] in a way, you know what to change, but not clear how exactly to get there. In the slider approach, that part was a little easier.? When using either physical or perceptual sliders, subjects made changes far more often. As can be seen in Sec. 6, this led to faster and better convergence on a goal. Additionally, not only did image navigation yield changes less often, those changes were undone more often. Undo is used roughly twice as often with image navigation than with the slider interfaces (p ? 0.051). Physical and perceptual sliders share roughly the same undo usage. Image Navigation as Sliders. When using image navigation, almost all subjects displayed behavior of using only one axis at a time, effectively reducing it to a slider interface with 5 discrete configurations visible at a time. While most occurrences of this behavior were interleaved with use of the 2D array or the color pickers, some subjects would go entire trials using only this technique. This leads us to believe that there are many situations where users think in independent parameter space. Sliders Equalized by Interactivity. Universally, subjects rarely snap sliders to a particular value. They almost always drag them to see the material in their workspace change gradually. This suggests that the optimal workflow for novices is to smoothly vary appearance until the image looks like what they are looking for. Doing this seems to be less confusing than seeing several images side-byside. It also suggests that subjects are not anticipating precisely what value a parameter should be, making many of the peceptual scalings in perceptual parameterizations irrelevant when interactivity is available. We investigate this behavior by disabling the ability to drag in the slider interfaces, leaving only the option to click a specific location on the slider, and running five additional subjects through the otherwise unchanged study. In this situation, all subjects essentially mimicked a dragging action by repeatedly cliking at small intervals along the bar. The average number of clicks for physical and perceptual sliders was roughly equal, except on trial 3 where perceptual sliders averaged roughly 1/3 more clicks than physical sliders (p = 0.034). We believe that interactivity nullifies the differences between these two interfaces and that novices prefer nudging controls until an image looks right, rather than purposefully setting values. Material Properties. After using each interface, subjects were asked what they thought the most and least difficult aspect of the design process was. This question was open for interpretation, but we did get several comments about specific parameters and properties of the material models. We categorize these comments into the adjustment of color, relative diffuse and specular intensities, and highlight shaping (specular roughness and fresnel effects). The number of times each of these categories were mentioned (sum of all three questionnaires per subject) are listed below: 1. Color: 23 most difficult, 8 least difficult 2. Relative intensities: 2 most difficult, 7 least difficult 3. Highlight shaping: 5 most difficult, 13 least difficult We draw two pieces of information from this data. First, because color is mentioned most often, users must feel it is an important factor in the overall material appearance. Second, a majority of subjects felt that color was the most difficult part of the design process. This is surprising given that most work in developing perceptual parameterizations of materials has been done in grayscale. Exploration. In open trials subjects perform an exploratory task that requires less fine tuning. Many subjects commented directly that they were exploring in a wide space rather than refining. For example, one subject commented ?the open trials had me looking all over the place for cool options, where the matching I tended to make smaller changes.? Another commented ?my workflow was completely random and experimental when doing open trials.? We observe that the performance of the image navigation interface compared to sliders improves greatly from matching to open trials. Users explain in comments, ?I used [image navigation] much like the other ones for matching, but for open trials it was a lot easier to see something good here;? ?[with image navigation] matching was very difficult. I had to try many different things. The open trials were enjoyable. I could pick from the options the [preset] buttons brought up;? and ?[with image navigation] the open ones were easier because I got a better view of what I wanted.? We conclude that given its problems with precise adjustment, image navigation must be better at pure exploration, but lacks the needed control for a complete solution to material design. Otherwise, it would not be able to compete so closely with sliders in these open trials.\n        ACM Transactions on Graphics, Vol. 29, No. 4, Article 35, Publication date: July 2010.\n        Toward Evaluating Material Design Interface Paradigms for Novice Users ? 35:9\n      \n      \n        8 Discussion and Conclusions\n        We now discuss the results of our study. We remind the reader that strictly speaking, our observations only apply within the boundary of the tested cases, as with all user studies. At the same time, it is our belief that the trends observed in this study should apply to other similar appearance design tasks for novices. Novices Can Edit Materials. We have found that novices are capable of designing and editing realistic materials. When an interface supports them, novices can perform relatively complex tasks in an efficient way. This suggests that future work on material design interfaces and tools for novices would be fruitful. Physical and Perceptual Sliders. We found that subjects can perform material editing equivalently well whether they use physical parameters or the perceptually-inspired parameters provided by our implementation. Additionally, the subject pool is split in half as to which is preferred. We conclude that interactivity is more important than whatever advantages the perceptually-inspired parameters we gave our subjects yield. Image Navigation vs. Sliders. Our most prominent result is the poor performance of the image navigation interface compared to individual parameter adjustment via sliders. This is because image navigation cannot show enough parameter combinations simultaneously due to the limited screen real estate. Perhaps the parameterbased organization used in [Ngan et al. 2006] is not optimal, but if so, the optimal layout remains undiscovered. Material Complexity. We find color to be a significant challenge in material editing. It takes almost twice as long for subjects to match colored materials than grayscale, and the error is significantly higher. Subjects also tell us that color is often the most diffi cult part of the design process. We believe that there is need for an investigation of methods for perceptual color manipulation of materials under colored lighting. Note that editing color in material editing is very different from setting color in image editing. We find the difficulty of trials, measured by time to completion and error, to be linear in the number of material parameters given to the users for the slider interfaces. When editing materials with more than one lobe, subjects could accomplish the task given enough time. We found spatially-varying materials to be more challenging than the other types of materials studied, resulting in higher final error. Finally, we discovered no significant difference between editing Ward or Cook-Torrance BRDFs. Common Workflow. Our subjects exhibit common workflow patterns. We notice that subjects generally employ a block-and-refine workflow, moving from large edits to small edits. In slider interfaces, subjects do not set parameters directly, but prefer to smoothly change them until they look right. This interactivity is important, and reduces the effect of the parameterization type. Exploration. The advantage of slider interfaces over image navigation is less obvious in open trials. Taking into account the control problems of image navigation, this implies that navigation is a better metaphor to support exploration of broad material variations. Limitations. The main limitation of this work is the scope of material editing tasks we investigate. First, we have only studied a subset of possible BRDF models. Second, we did not explicitly investigate whether novices can effectively pick a material model from a list of available options. Third, we did not investigate the creation of spatial patterns, although we believe that this task is well beyond the capability of novice users. Fourth, we forego the study of interfaces such as painting because of material representation restrictions.\n      \n      \n        9 Summary\n        This paper presents a first step toward quantitatively evaluating the use and effectiveness of user interfaces for material design, with a focus on novice users. We find that novices can edit materials equally well with sliders that control either physical or perceptually-inspired parameters as long as interactivity is available. Image navigation can help users find important material configurations when artistically exploring possibilities, but performs slower and with less accuracy when precise adjustments are necessary. Novices tend to work similarly to one another, making large edits first and then systematically readjusting each parameter by smaller steps until converging on a final solution. They prefer to drag sliders to see changes happen smoothly rather than snapping values directly, implying that a continuous traversal of the configuration space is more appropriate for novices than requiring them to input parameter values directly. There are many opportunities for future work in this area. We only study a small subset of interfaces and models for material design, and the development of a method to compare interfaces that operate on different material models would be useful. Long term studies of expert users interacting with material design interfaces on complex scenes with long rendering times would also be of interest.\n      \n      \n        Acknowledgements\n        We would like to thank Jonathan Denning and Lori Lorigo for their help in preparing this paper. This work was supported by NSF (CNS-070820, CCF-0746117), Intel, and the Sloan Foundation.\n        ACM Transactions on Graphics, Vol. 29, No. 4, Article 35, Publication date: July 2010.\n        35:10 ? W. Kerr et al.\n      \n      \n        References\n        \n          A DOBE S YSTEMS I NC , 2009. Photoshop CS 4.\n          A SHIKHMIN , M., AND S HIRLEY , P. S. 2000. An anisotropic phong brdf model. Journal of Graphics Tools 5, 2, 25?32.\n          A UTODESK I NC , 2010. Maya 2010.\n          B EN -A RTZI , A., O VERBECK , R., AND R AMAMOORTHI , R. 2006. Real-time BRDF editing in complex lighting. ACM Transactions on Graphics 25, 3 (July), 945?954.\n          B EN -A RTZI , A., E GAN , K., R AMAMOORTHI , R., AND D URAND , F. 2008. A precomputed polynomial representation for interactive BRDF editing with global illumination. ACM Transactions on Graphics 27, 2 (Apr.), 13:1?13:13.\n          B LINN , J. F. 1977. Models of light reflection for computer synthesized pictures. In Computer Graphics (Proceedings of SIGGRAPH 77), 192?198.\n          C OLBERT , M., P ATTANAIK , S., AND K RIVANEK , J. 2006. BRDFshop: Creating physically correct bidirectional reflectance distribution functions. IEEE Comput. Graph. Appl. 26, 1, 30?36.\n          C OOK , R. L., AND T ORRANCE , K. E. 1981. A reflectance model for computer graphics. In SIGGRAPH ?81: Proceedings of the 8th Annual Conference on Computer Graphics and Interactive Techniques, ACM, New York, NY, USA, 307?316.\n          D EBEVEC , P. 1998. Rendering synthetic objects into real scenes: Bridging traditional and image-based graphics with global illumination and high dynamic range photography. In Proceedings of SIGGRAPH 98, Computer Graphics Proceedings, Annual Conference Series, 189?198.\n          D ROR , R. O., A DELSON , E. H., AND W ILLSKY , A. S. 2001. Recognition of surface reflectance properties from a single image under unknown real-world illumination. In Proceedings of the Workshop on Identifying Objects Across Variations in Lighting at the IEEE Conference on Computer Vision and Pattern Recognition (CVPR).\n          F AIRCHILD , M. D. 1998. Color Appearance Models. AddisonWesley, Reading, MA.\n          F LEMING , R. W., D ROR , R. O., AND A DELSON , E. H. 2001. How do humans determine reflectance properties under unknown illumination? In Proceedings of the Workshop on Identifying Objects Across Variations in Lighting at the IEEE Conference on Computer Vision and Pattern Recognition (CVPR).\n          F RIEDMAN , M. 1937. The use of ranks to avoid the assumption of normality implicit in the analysis of variance. Journal of the American Statistical Association 32, 200, 675?701.\n          H E , X. D., T ORRANCE , K. E., S ILLION , F. X., AND G REEN BERG , D. P. 1991. A comprehensive physical model for light reflection. In Computer Graphics (Proceedings of SIGGRAPH 91), 175?186.\n          K ERR , W. B., AND P ELLACINI , F. 2009. Toward evaluating lighting design interface paradigms for novice users. ACM Transactions on Graphics 28, 3 (July), 26:1?26:9.\n          L AFORTUNE , E. P. F., F OO , S.-C., T ORRANCE , K. E., AND G REENBERG , D. P. 1997. Non-linear approximation of reflectance functions. In Proceedings of SIGGRAPH 97, Computer Graphics Proceedings, Annual Conference Series, 117?126.\n          L AWRENCE , J., B EN -A RTZI , A., D E C ORO , C., M ATUSIK , W., P FISTER , H., R AMAMOORTHI , R., AND R USINKIEWICZ , S.\n          2006. Inverse shade trees for non-parametric material representation and editing. ACM Transactions on Graphics (Proc. SIGGRAPH) 25, 3 (July), 735?745.\n          M ARKS , J., A NDALMAN , B., B EARDSLEY , P. A., F REEMAN , W., G IBSON , S., H ODGINS , J. K., K ANG , T., M IRTICH , B., P FIS TER , H., R UML , W., R YALL , K., S EIMS , J., AND S HIEBER , S. 1997. Design galleries: A general approach to setting parameters for computer graphics and animation. In Proceedings of SIGGRAPH ?97, 389?400.\n          M ATUSIK , W., P FISTER , H., B RAND , M., AND M C M ILLAN , L. 2003. A data-driven reflectance model. ACM Transactions on Graphics 22, 3 (July), 759?769.\n          N GAN , A., D URAND , F., AND M ATUSIK , W. 2005. Experimental analysis of BRDF models. In Rendering Techniques 2005: 16th Eurographics Workshop on Rendering, 117?126.\n          N GAN , A., D URAND , F., AND M ATUSIK , W. 2006. Image-driven navigation of analytical BRDF models. In Eurographics Symposium on Rendering 2006, 399?408.\n          N ICODEMUS , F. E., R ICHMOND , J. C., H SIA , J. J., G INSBERG , I. W., AND L IMPERIS , T. 1977. Geometrical Considerations and Nomenclature for Reflectance. National Bureau of Standards (US) Monograph 160.\n          P ACANOWSKI , R., G RANIER , X., S CHLICK , C., AND P OULIN , P. 2008. Sketch and paint-based interface for highlight modeling. In Eurographics Workshop on Sketch-based Interfaces and Modeling 2008, 17?23.\n          P ELLACINI , F., AND L AWRENCE , J. 2007. Appwand: Editing measured materials using appearance-driven optimization. ACM Transactions on Graphics 26, 3, 54:1?54:9.\n          P ELLACINI , F., F ERWERDA , J. A., AND G REENBERG , D. P. 2000. Toward a psychophysically-based light reflection model for image synthesis. In Proceedings of ACM SIGGRAPH 2000, Computer Graphics Proceedings, Annual Conference Series, 55? 64.\n          P OULIN , P., AND F OURNIER , A. 1995. Painting surface charactristics. In Eurographics Rendering Workshop, 160?169.\n          S TEVENS , J. P. 1996. Applied Multivariate Statistics for the Social Sciences, third ed. Lawrence Erlbaum Associates Inc.\n          T ALTON , J. O., G IBSON , D., Y ANG , L., H ANRAHAN , P., AND K OLTUN , V. 2009. Exploratory modeling with collaborative design spaces. In SIGGRAPH Asia ?09: ACM SIGGRAPH Asia 2009 papers, ACM, New York, NY, USA, 1?10.\n          V ANGORP , P., L AURIJSSEN , J., AND D UTR ? , P. 2007. The influence of shape on the perception of material reflectance. ACM Transactions on Graphics 26, 3, 77:1?77:9.\n          W ARD , G. J. 1992. Measuring and modeling anisotropic reflection. In SIGGRAPH ?92: Proceedings of the 19th Annual Conference on Computer Graphics and Interactive Techniques, ACM, New York, NY, USA, 265?272.\n          W ESTLUND , H. B., AND M EYER , G. W. 2001. Applying appearance standards to light reflection models. In Proceedings of ACM SIGGRAPH 2001, Computer Graphics Proceedings, Annual Conference Series, 501?510.\n          W ILLS , J., A GARWAL , S., K RIEGMAN , D., AND B ELONGIE , S. 2009. Toward a perceptual space for gloss. ACM Transactions on Graphics 28, 4 (Aug.), 103:1?103:15.\n        \n        ACM Transactions on Graphics, Vol. 29, No. 4, Article 35, Publication date: July 2010.\n      \n    \n  ",
  "resources" : [ ]
}