{
  "uri" : "sig2008a-a108-tan_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2008a/a108-tan_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Single Image Tree Modeling",
    "published" : "2008",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Ping-Tan",
      "name" : "Ping",
      "surname" : "Tan"
    }, {
      "uri" : "http://drinventor/Tian-Fang",
      "name" : "Tian",
      "surname" : "Fang"
    }, {
      "uri" : "http://drinventor/Jianxiong-Xiao",
      "name" : "Jianxiong",
      "surname" : "Xiao"
    }, {
      "uri" : "http://drinventor/Peng-Zhao",
      "name" : "Peng",
      "surname" : "Zhao"
    }, {
      "uri" : "http://drinventor/Long-Quan",
      "name" : "Long",
      "surname" : "Quan"
    } ]
  },
  "bagOfWords" : [ "we", "demonstrate", "we", "method", "variety", "example", "stroke", "we", "system", "first", "generate", "whole", "tree", "branch", "structure", "non-parametric", "synthesis", "complete", "tree", "model", "leaf", "we", "system", "remarkably", "simple", "generate", "visually", "convincing", "result", "make", "modeling", "large", "scale", "vegetation", "affordable", "although", "some", "well", "develop", "tool", "-lsb-", "Li", "et", "al.", "2004", "Rother", "et", "al.", "2004", "-rsb-", "segmentation", "multiple", "image", "tedious", "time", "consuming", "-lsb-", "Xu", "et", "al.", "2007", "-rsb-", "produce", "very", "good", "tree", "model", "from", "set", "3d", "point", "cap", "ture", "scanner", "1.2", "we", "approach", "give", "single", "image", "tree", "we", "draw", "stroke", "image", "create", "tree", "model", "we", "draw", "crown", "stroke", "mark", "up", "leaf", "region", "image", "branch", "visible", "image", "automatically", "trace", "out", "around", "draw", "branch", "stroke", "minimize", "user", "intervention", "achieve", "highest", "realism", "few", "other", "branch", "stroke", "could", "add", "complete", "visible", "branch", "when", "necessary", "too", "few", "visible", "branch", "exist", "image", "tree", "could", "also", "grow", "accord", "some", "predefine", "subtree", "pattern", "once", "branch", "ready", "leave", "can", "generate", "easily", "accord", "branch", "structure", "image", "information", "one", "example", "can", "see", "Figure", "input", "single", "image", "show", "-lrb-", "-rrb-", "two", "stroke", "draw", "user", "-lrb-", "-rrb-", "we", "method", "first", "grow", "branch", "structure", "illustrate", "-lrb-", "-rrb-", "complete", "tree", "leaf", "-lrb-", "-rrb-", "rather", "than", "apply", "parametric", "rule", "branch", "generation", "we", "use", "local", "branch", "shape", "synthesize", "new", "branch", "different", "from", "previous", "imagebased", "method", "we", "design", "we", "system", "work", "single", "input", "image", "contrast", "we", "use", "image", "guide", "non-parametric", "tree", "grow", "i.e.", "growth", "should", "lead", "result", "close", "image", "different", "from", "pure", "sketch", "-lsb-", "Okabe", "et", "al.", "2005", "-rsb-", "we", "only", "draw", "few", "stroke", "image", "statistics", "underline", "stroke", "allow", "we", "recover", "more", "tree", "structure", "we", "method", "do", "depend", "high", "quality", "segmentation", "we", "system", "user", "draw", "few", "stroke", "mark", "out", "foliage", "visible", "branch", "take", "advantage", "tree", "prior", "facilitate", "segmentation", "user", "interface", "user", "draw", "stroke", "image", "move", "mouse", "cursor", "hold", "button", "-lrb-", "leave", "button", "crown", "right", "button", "branch", "-rrb-", "similar", "uus", "design", "-lsb-", "Li", "et", "al.", "2004", "-rsb-", "image", "segmentation", "simplicity", "we", "always", "use", "one", "stroke", "mark", "crown", "foliage", "region", "automatically", "extract", "method", "describe", "follow", "paragraph", "accord", "stroke", "user", "draw", "stroke", "mark", "out", "branch", "after", "each", "branch", "stroke", "trace", "algorithm", "trigg", "follow", "visible", "branch", "close", "stroke", "unlike", "pure", "sketch", "system", "-lsb-", "Okabe", "et", "al.", "2005", "-rsb-", "we", "have", "image", "information", "underlie", "draw", "stroke", "allow", "extremely", "simple", "sketch", "Figure", "show", "example", "which", "we", "need", "only", "two", "stroke", "first", "crown", "stroke", "red", "second", "branch", "stroke", "blue", "foliage", "extraction", "foliage", "extract", "from", "closed", "region", "first", "crown", "stroke", "which", "roughly", "follow", "crown", "boundary", "GrabCut", "-lsb-", "Rother", "et", "al.", "2004", "-rsb-", "extract", "object", "inside", "bound", "rectangle", "analyze", "different", "appearance", "inside", "outside", "rectangle", "extraction", "we", "simply", "compute", "gaussian", "mixture", "model", "-lrb-", "gmm", "-rrb-", "pixel", "rgb", "value", "region", "close", "crown", "stroke", "we", "employ", "mixture", "10", "gaussian", "large", "variation", "color", "due", "background", "we", "take", "four", "most", "green", "red", "gaussian", "component", "leaf", "cluster", "remain", "six", "component", "consider", "background", "cluster", "here", "-lrb-", "-rrb-", "pdf", "function", "GMM", "distribution", "indicate", "rgb", "value", "pixel", "GMM", "parameter", "each", "pixel", "we", "compute", "label", "via", "graph", "cut", "where", "represent", "leaf", "pixel", "represent", "background", "pixel", "Gibbs", "energy", "following", "form", "define", "over", "enclosed", "region", "crown", "stroke", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "where", "set", "all", "4-neighbor", "pixel", "pair", "-lrb-", "-rrb-", "??", "logg", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "logg", "-lrb-", "-rrb-", "datum", "term", "-lrb-", "-rrb-", "smooth", "term", "graph-cut", "algorithm", "-lsb-", "Kolmogorov", "Zabih", "2002", "-rsb-", "apply", "minimize", "Gibbs", "energy", "assign", "each", "constant", "indicate", "strength", "smoothness", "set", "60", "we", "implementation", "before", "extraction", "we", "usually", "expand", "enclosed", "region", "morphology", "expansion", "10", "time", "allow", "more", "freedom", "user?s", "sketch", "figure", "show", "result", "foliage", "extraction", "from", "input", "image", "stroke", "Figure", "should", "notice", "we", "do", "require", "very", "accurate", "segmentation", "which", "important", "advantage", "we", "method", "trace", "trigg", "after", "each", "branch", "stroke", "draw", "we", "apply", "method", "inspire", "lazy", "snapping", "-lsb-", "Li", "et", "al.", "2004", "-rsb-", "pixel", "branch", "stroke", "use", "sample", "compute", "appearance", "model", "branch", "all", "other", "pixel", "sample", "compute", "non-branch", "appearance", "again", "GMM", "model", "use", "appearance", "model", "since", "branch", "stroke", "could", "cover", "leaf", "pixel", "-lrb-", "e.g.", "first", "example", "Figure", "-rrb-", "we", "discard", "gaussian", "component", "branch", "gmm", "too", "close", "some", "component", "foliage", "gmm", "-lrb-", "-rrb-", "branch", "appearance", "model", "denote", "-lrb-", "-rrb-", "appearance", "model", "non-branch", "pixel", "-lrb-", "-rrb-", "pixel", "form", "cluster", "we", "discard", "cluster", "nonbranch", "pixel", "along", "line", "segment", "connect", "cluster", "center", "circle", "center", "-lrb-", "via", "maximum", "likelihood", "estimation", "-rrb-", "circle", "center", "move", "remain", "cluster", "center", "continue", "trace", "case", "multiple", "cluster", "leave", "circle", "process", "breadth", "first", "manner", "branch", "skeleton", "detect", "connect", "all", "circle", "center", "during", "trace", "skeleton", "overlay", "image", "skeleton", "simplify", "discard", "redundant", "joint", "which", "fork", "branch", "direction", "do", "change", "drastically", "-lrb-", "30", "-rrb-", "joint", "we", "implementation", "circle", "radius", "fix", "50", "pixel", "all", "example", "-lrb-", "image", "resolution", "about", "1500", "pixel", "-rrb-", "tree", "root", "branch", "thickness", "also", "compute", "vary", "circle", "radius", "find", "largest", "circle", "whose", "pixel", "all", "branch", "pixel", "thickness", "computation", "unreliable", "small", "twig", "we", "simply", "set", "branch", "radius", "75", "its", "parent", "although", "better", "botanical", "rule", "can", "use", "accord", "-lsb-", "Weber", "Penn", "1995", "-rsb-", "show", "Figure", "-lrb-", "-rrb-", "branch", "segment", "indicate", "green", "line", "correctly", "detect", "although", "draw", "stroke", "do", "pass", "through", "branch", "system", "retrieve", "connect", "circle", "center", "sequence", "show", "-lrb-", "-rrb-", "initial", "result", "contain", "many", "fragment", "line", "segment", "which", "undesirable", "non-parametric", "synthesis", "section", "3.1", "final", "branch", "after", "discard", "some", "redundant", "joint", "show", "-lrb-", "-rrb-", "once", "branch", "recover", "leave", "can", "generate", "along", "branch", "complete", "tree", "once", "visible", "branch", "foliage", "region", "extract", "from", "image", "we", "develop", "tree", "grow", "engine", "automatically", "generate", "whole", "tree", "branch", "3d", "space", "follow", "give", "image", "we", "only", "seek", "plausible", "solution", "possible", "tree", "prior", "inherent", "self-similar", "structural", "pattern", "tree", "similar", "-lrb-", "-rrb-", "type", "branch", "replacement", "-lrb-", "-rrb-", "type", "ii", "branch", "replacement", "engine", "creation", "library", "elementary", "subtree", "from", "visible", "branch", "initialization", "conversion", "2d", "branch", "3d", "visible", "branch", "interactively", "trace", "section", "define", "image", "plane", "we", "first", "convert", "branch", "from", "2d", "3d", "before", "grow", "from", "single", "image", "enough", "information", "accurately", "reconstruct", "branch", "position", "3d", "space", "we", "assume", "orthographic", "camera", "model", "relate", "3d", "branch", "position", "image", "coordinate", "creation", "library", "we", "build", "library", "elementary", "subtree", "library", "subtree", "build", "from", "recover", "visible", "branch", "take", "all", "its", "subtree", "too", "few", "subtree", "-lrb-", "first", "example", "Figure", "-rrb-", "we", "add", "predefined", "subtree", "library", "Figure", "show", "predefined", "subtree", "we", "implement", "system", "obviously", "predefined", "library", "can", "further", "enriched", "handle", "larger", "variety", "tree", "remarkable", "we", "produce", "all", "we", "result", "only", "most", "subtree", "current", "implementation", "non-parametric", "synthesis", "start", "from", "3d", "visible", "branch", "library", "we", "take", "non-parametric", "approach", "grow", "tree", "synthesis", "process", "simply", "iteratively", "replace", "exist", "branch", "library", "subtree", "Figure", "show", "single", "step", "non-parametric", "branch", "growth", "two", "type", "branch", "replacement", "we", "system", "type", "replacement", "new", "branch", "grow", "end", "its", "support", "branch", "-lrb-", "i.e.", "show", "red", "segment", "subtree", "-rrb-", "selection", "branch", "replace", "library", "subtree", "drive", "minimize", "cost", "function", "define", "section", "3.2", "each", "time", "result", "synthesis", "prune", "extract", "foliage", "silhouette", "we", "empirically", "run", "follow", "three", "step", "iteratively", "about", "100", "time", "each", "tree", "selection", "branch", "replace", "we", "go", "through", "small", "set", "exist", "branch", "take", "one", "whose", "replacement", "give", "lowest", "cost", "function", "define", "section", "3.2", "create", "set", "exist", "branch", "we", "choose", "branch", "larger", "radius", "older", "generation", "we", "sort", "all", "exist", "branch", "accord", "radius", "branch", "select", "sequentially", "from", "sort", "array", "each", "branch", "select", "probability", "which", "inversely", "proportional", "its", "generation", "selection", "replace", "library", "subtree", "select", "branch", "replace", "we", "search", "all", "available", "library", "subtree", "-lrb-", "most", "-rrb-", "find", "one", "give", "lowest", "cost", "function", "define", "section", "3.2", "except", "subtree", "generate", "from", "visible", "branch", "user", "can", "add", "predefined", "subtree", "type", "type", "ii", "both", "subtree", "rotate", "around", "its", "support", "branch", "scale", "before", "use", "replace", "some", "exist", "branch", "rotation", "angle", "subtree", "around", "its", "support", "branch", "search", "among", "12", "quantize", "level", "360", "degree", "give", "lowest", "cost", "scaling", "factor", "subtree", "determine", "its", "support", "branch", "same", "length", "replace", "branch", "Branch", "pruning", "after", "replacement", "result", "branch", "prune", "base", "detect", "foliage", "region", "exist", "branch", "any", "branch", "go", "beyond", "foliage", "region", "remove", "so", "new", "branch", "too", "close", "some", "exist", "branch", "3.2", "data-driven", "attractor", "growth", "engine", "drive", "datum", "produce", "realistic", "result", "input", "image", "information", "2d", "only", "weakly", "control", "growth", "desire", "tree", "volume", "hence", "we", "introduce", "some", "3d", "point", "base", "heuristic", "control", "growth", "better", "image", "attractor", "make", "result", "after", "grow", "similar", "image", "we", "define", "set", "image", "attractor", "-lcb-", "-rcb-", "sample", "evenly", "foliage", "region", "fix", "interval", "illustrate", "yellow", "point", "Figure", "-lrb-", "-rrb-", "growth", "drive", "minimize", "cost", "define", "2d", "-lrb-", "-rrb-", "dist", "-lrb-", "-rrb-", "where", "dist", "-lrb-", "-rrb-", "distance", "attractor", "projection", "tree", "onto", "image", "compute", "dist", "-lrb-", "-rrb-", "we", "also", "sample", "set", "point", "-lcb-", "-rcb-", "along", "image", "projection", "tree", "blue", "point", "Figure", "-lrb-", "-rrb-", "extrapolate", "3d", "attractor", "image", "drive", "growth", "could", "lead", "unbalanced", "tree", "where", "only", "front", "branch", "generate", "similar", "problem", "exist", "previous", "sketch", "system", "like", "-lsb-", "Okabe", "et", "al.", "2005", "-rsb-", "alleviate", "problem", "tree", "rotate", "90", "degree", "around", "its", "main", "trunk", "merge", "original", "one", "-lsb-", "Okabe", "et", "al.", "2005", "-rsb-", "method", "solve", "problem", "cost", "create", "inconsistent", "visible", "branch", "image", "3d", "point", "generate", "two", "step", "first", "take", "set", "branch", "joint", "current", "tree", "rotate", "joint", "90", "degree", "around", "main", "trunk", "again", "tree", "sample", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "we", "current", "implementation", "growth", "drive", "alternate", "image", "attractor", "3d", "point", "attractor", "Figure", "illustrate", "effectiveness", "alternate", "strategy", "pure", "image", "drive", "growth", "yield", "good", "result", "when", "view", "from", "same", "direction", "input", "image", "-lrb-", "-rrb-", "while", "unnatural", "result", "-lrb-", "-rrb-", "view", "from", "orthogonal", "viewpoint", "alternate", "image", "drive", "growth", "3d", "point", "drive", "growth", "better", "result", "can", "obtain", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "each", "replacement", "iteration", "we", "only", "add", "more", "branch", "tree", "exist", "branch", "discard", "so", "distance", "computation", "previous", "iteration", "can", "reuse", "speedup", "purpose", "each", "attractor", "-lrb-", "matter", "image", "point", "3d", "point", "-rrb-", "we", "record", "its", "distance", "tree", "n?th", "iteration", "th", "iteration", "we", "compute", "distance", "between", "newly", "create", "branch", "illustrate", "Figure", "-lrb-", "-rrb-", "leaf", "tree", "automatically", "synthesize", "from", "recover", "branch", "structure", "texture", "input", "image", "each", "leaf", "represent", "flat", "rectangle", "size", "1/10", "main", "trunk", "radius", "each", "branch", "generate", "from", "range", "50", "200", "leave", "proportional", "length", "arrangement", "leaf", "around", "branch", "randomize", "we", "keep", "only", "those", "leaf", "project", "inside", "foliage", "region", "input", "image", "leaf", "texture", "accord", "project", "position", "input", "image", "generic", "leaf", "shape", "leaf", "size", "density", "arrangement", "leaf", "along", "branch", "all", "parameterize", "we", "current", "implementation", "default", "value", "use", "throughout", "all", "example", "paper", "we", "test", "we", "algorithm", "several", "different", "example", "demonstrate", "its", "effectiveness", "typical", "example", "cherry", "tree", "download", "from", "www.flickr.com", "show", "Figure", "its", "foliage", "region", "show", "figure", "its", "branch", "trace", "procedure", "illustrate", "Figure", "complete", "branch", "structure", "generate", "growth", "engine", "show", "Figure", "-lrb-", "-rrb-", "complete", "cherry", "tree", "model", "render", "Figure", "-lrb-", "-rrb-", "example", "we", "draw", "two", "stroke", "use", "both", "subtree", "visible", "branch", "predefined", "subtree", "type", "branch", "trace", "realtime", "which", "provide", "rapid", "feedback", "user", "decide", "whether", "additional", "branch", "stroke", "need", "however", "branch", "grow", "typically", "take", "about", "20", "minute", "pc", "2.4", "cpu", "population", "tree", "leaf", "take", "another", "10", "minute", "more", "example", "show", "figure", "sycamore", "tree", "first", "row", "take", "only", "two", "stroke", "trace", "do", "add", "any", "more", "branch", "its", "branch", "structure", "entirely", "synthesize", "from", "library", "predefined", "subtree", "type", "ii", "oak", "tree", "second", "row", "take", "three", "stroke", "part", "its", "visible", "branch", "trace", "automatically", "one", "miss", "due", "dense", "foliage", "add", "second", "branch", "stroke", "second", "cherry", "tree", "take", "stroke", "branch", "trace", "more", "challenging", "oak", "tree", "cherry", "tree", "both", "download", "from", "www.flickr.com", "simplicity", "we", "method", "make", "modeling", "affordable", "wood", "well", "casually", "capture", "image", "show", "Figure", "we", "able", "get", "all", "four", "tree", "model", "from", "total", "16", "stroke", "input", "image", "relative", "position", "tree", "3d", "set", "manually", "more", "systematic", "usage", "method", "urban", "environment", "show", "Figure", "Trees", "along", "street", "can", "only", "capture", "from", "close", "viewpoint", "due", "space", "constraint", "which", "make", "previous", "image-based", "tree", "modeling", "method", "less", "applicable", "here", "we", "model", "each", "tree", "from", "single", "image", "align", "all", "tree", "manually", "3d", "space", "Figure", "tree", "model", "stroke", "from", "leave", "right", "all", "tree", "grow", "predefined", "subtree", "type", "we", "have", "describe", "simple", "effective", "system", "construct", "realistic", "tree", "model", "from", "single", "image", "we", "system", "design", "minimize", "user", "interaction", "result", "system", "simple", "practical", "amateur", "user", "only", "need", "sketch", "few", "stroke", "single", "input", "image", "some", "direction", "future", "work", "example", "we", "could", "fill", "gap", "between", "single", "image", "base", "method", "previous", "multi-views", "method", "improve", "3d", "shape", "while", "keep", "modeling", "simplicity", "we", "could", "also", "improve", "system", "runtime", "efficiency", "realtime", "describe", "system", "could", "upgrade", "full-automatic", "automatic", "tree", "detection", "visible", "branch", "trace", "algorithm", "available", "we", "thank", "Marcus", "Lundberg", "Sean", "Pecor", "Jason", "Ramsay", "permission", "use", "picture", "paper", "ping", "Tan", "support", "Singapore", "FRC", "Grant", "r-263-000-477-112", "work", "also", "support", "Hong", "Kong", "RGC", "Grants", "618908", "619107", "619006", "rgc/nsfc", "n-hkust602", "05", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "eche", "artinez", "a.", "artin", "i.", "rettaki", "G.", "2004", "volumetric", "reconstruction", "interactive", "rendering", "tree", "from", "photograph", "SIGGRAPH", "2004", "other", "C.", "OLMOGOROV", "V.", "lake", "a.", "2004", "grabcut", "interactive", "foreground", "extraction", "use", "iterated", "graph", "cut", "SIGGRAPH", "2004", "309", "314", "hlyakhter", "i.", "ozenoer", "M.", "ORSEY", "J.", "eller", "S.", "2001", "reconstruct", "3d", "tree", "model", "from", "instrumented", "photograph", "IEEE", "Comput", "21", "53", "61", "P.", "ENG", "G.", "ang", "J.", "ang", "S.", "B.", "UAN", "L.", "2007", "image-based", "tree", "modeling", "SIGGRAPH", "2007", "87", "eber", "J.", "enn", "J.", "1995", "creation", "rendering", "realistic", "tree", "SIGGRAPH", "1995", "119", "128", "H.", "OSSETT", "N.", "hen", "B.", "2007", "knowledge", "heuristic-based", "modeling", "laser-scanned", "tree", "ACM", "Trans", "26", "19" ],
  "content" : "We demonstrate our method on a variety of examples. strokes, our system first generates the whole tree branching structure by non-parametric synthesis, then complete tree model with leaves. Our system is remarkably simple and generates visually convincing results. It makes the modeling of large scale vegetation affordable. Although there are some well developed tools [Li et al. 2004; Rother et al. 2004], such a segmentation of multiple images is tedious and time consuming . [Xu et al. 2007] produced very good tree models from a set of 3D points cap- tured by scanner. 1.2 Our approach Given a single image of a tree, we draw strokes on the image to create a tree model. We start to draw a crown stroke to mark up the leaf region in the image. Branches visible in the image are automatically traced out around drawn branch strokes to minimize the user intervention and achieve the highest realism. A few other branch strokes could be added to complete visible branches when necessary. If too few visible branches exist in the image, the tree could also grow according to some predefined subtree patterns. Once branches are ready, leaves can be generated easily according to the branch structure and image information. One example can be seen in Figure 1 . The input single image is shown in (a), with two strokes drawn by the user as (b). Our method first grows a branch structure illustrated in (c) then complete the tree with leaves as in (d). Rather than applying parametric rules for branch generation, we use the local branch shapes to synthesize new branches. Different from previous imagebased methods, we design our system to work with a single input image. In contrast, we use the image as a guide for non-parametric tree growing, i.e. the growth should lead to a result close to the image. Different from a pure sketching [Okabe et al. 2005], we only draw a few strokes. The image statistics underlined by the strokes allows us to recover more tree structures. Our method does not depend on high quality segmentation. In our system, the user draws a few strokes to mark out foliage and visible branches by taking advantage of the tree prior to facilitate segmentation. User interface The user draw strokes on the image by moving the mouse cursor and holding a button. (Left button for the crown and right button for branches.) Similar UI is designed in [Li et al. 2004] for image segmentation. For simplicity, we always use one stroke to mark the crown. The foliage region is automatically extracted by the method described in the following paragraph according to this stroke. The user then draw strokes to mark out branches. After each branch stroke, a tracing algorithm is trigged to follow the visible branches close to the stroke. Unlike a pure sketching system [Okabe et al. 2005], we have the image information underlying the drawn strokes that allows extremely simple sketching. Figure 1 shows an example in which we need only two strokes: the first crown stroke in red and the second branch stroke in blue. Foliage extraction Foliage is extracted from the closed region by the first crown stroke, which roughly follows the crown boundary. ?GrabCut? [Rother et al. 2004] extracts object inside a bounding rectangle by analyzing the different appearance inside and outside of the rectangle. For extraction, we simply compute a Gaussian mixture model (GMM) for the pixel RGB values in the region closed by the crown stroke. We employ a mixture of 10 Gaussians for large variation of colors due to the background. Then we take the four most green or red Gaussian components as leaf clusters. And the remaining six components are considered as background clusters. Here, G(?, ?) is the pdf function of GMM distribution, I x indicates the RGB values at pixel x, ? F , ? B are GMM parameters. At each pixel x, we compute a 0 ? 1 label ? x via graph cut, where ? x = 0 represents leaf pixels and ? x = 1 represents background pixels. A Gibbs energy of the following form is defined over the enclosed region of crown stroke F B E d (? x , ? , ? ) + E s (? x , ? y ), x (x,y)?N where N is the set of all 4-neighbor pixel pairs, F B B F E d (? x , ? , ? ) = ?? x logG(I x , ? ) ? (1 ? ? x )logG(I x , ? ) is the data term, and E s (? x , ? y ) = ?/|I x 0 ? I y | ? ? x x = = ? ? y y is the smooth term. Graph-cut algorithm [Kolmogorov and Zabih 2002] is applied to minimize this Gibbs energy by assigning a 0 or 1 for each ? x . The constant ? indicating the strength of smoothness is set to 60 in our implementation. Before the extraction, we usually expand the enclosed region by morphology expansion 10 times to allow more freedom for the user?s sketching. Figure 2 shows the result of the foliage extraction from the input image and the stroke in Figure 1 . It is should be noticed that we do not require a very accurate segmentation, which is an important advantage of our method. This tracing is trigged after each branch stroke is drawn. We apply a method inspired by the ?Lazy Snapping? [Li et al. 2004]. Pixels on the branch stroke are used as samples to compute an appearance model for the branch. All the other pixels are samples to compute the non-branch appearance. Again, a GMM model is used for the appearance model. Since the branch stroke could cover leaf pixels (e.g. in the first example in Figure 7 ), we discard the Gaussian component in the branch GMM if it is too close to some component in the foliage GMM G(I x , ? F ). The branch appearance model is denoted as G(I x , ? T ). The appearance model for non-branch pixels is G(I x , ? N ). And these pixels form clusters. We discard a cluster if there are nonbranch pixels along the line segment connecting the cluster center and circle center (via the maximum likelihood estimation). The circle center will move to the remaining cluster center to continue tracing. In the case of multiple clusters left on the circle, they are processed in a breadth first manner. The branch skeleton is detected by connecting all these circle centers during tracing. This skeleton is overlayed in the image. This skeleton is then simplified by discarding redundant joints, which is not a fork and the branch direction does not change drastically (< 30 o ) at that joint. In our implementation, the circle radius is fixed as 50 pixels for all examples (image resolution at about 1500 pixels). At the tree root, the branch thickness is also computed by varying the circle radius to find a largest circle whose pixels are all branch pixels. This thickness computation is unreliable at small twigs. We simply set branch radius to 75% of its parent, although better botanical rules can be used according to [Weber and Penn 1995]. As shown in Figure 3 (a), the branch segment indicated by the green line is correctly detected, although the drawn stroke does not pass through it. A branch system is retrieved by connecting circle centers in sequence as shown in (b). This initial result contains many fragment line segments, which is undesirable for the non-parametric synthesis in Section 3.1. The final branch after discarding some redundant joints is shown in (c). Once branches are recovered, leaves can be generated along branches to complete the tree. Once visible branches and foliage region are extracted from the image, we develop a tree grow engine to automatically generate the whole tree branch in 3D space by following the given image. We only seek a plausible solution that is possible with the tree priors and the inherent self-similar structural patterns of the tree. Similar\n        (a) Type I branch replacement (b) Type II branch replacement The engine starts with the creation of a library of elementary subtrees from the visible branches. Initialization ? Conversion of 2D branches into 3D: Visible branches interactively traced in Section 2 are defined in the image plane. We first convert these branches from 2D to 3D before growing. From a single image, there is no enough information to accurately reconstruct the branch position in 3D space. We assume an orthographic camera model to relate 3D branch position and image coordinate. ? Creation of the library: We then built a library of elementary subtrees. These library subtrees are built from the recovered visible branches by taking all its subtrees. If there is too few subtrees (as the first example in Figure 7 ), we add predefined subtrees in the library. Figure 4 shows the predefined subtrees in our implemented system. Obviously, this predefined library can be further enriched to handle larger varieties of trees. It is remarkable that we produced all of our results with only at most 8 subtrees in the current implementation. Non-parametric synthesis Starting from the 3D visible branch and a library, we take a non-parametric approach to grow tree. The synthesis process simply iteratively replaces an existing branch by a library subtree. Figure 4 shows a single step of the non-parametric branch growth. There are two types of branch replacement in our system. In type I replacement, new branches grow at the end of its ?supporting branch? (i.e. shown as the red segment in a subtree). The selection of the branch to be replaced and the library subtree is driven by minimizing the cost function defined in Section 3.2. Each time, the resulting synthesis is pruned by the extracted foliage silhouette. We empirically run the following three steps iteratively about 100 times for each tree. ? Selection of a branch to be replaced: We go through a small set of existing branches and take the one whose replacement gives the lowest cost function defined in Section 3.2. To create this set of existing branches, we choose branches with larger radius and older generation. We sort all existing branches according to their radius. Then branches are selected sequentially from the sorted array. Each branch is selected with a probability, which is inversely proportional to its generation. ? Selection of a replacing library subtree: For the selected branch to be replaced, we search all the available library subtrees (at most 8) to find that one giving the lowest cost of the function defined in Section 3.2. Except for the subtrees generated from visible branches, the user can add predefined subtrees: type I, type II or both. A subtree is rotated around its ?supporting branch? and scaled before it is used to replace some existing branch. ? The rotation angle of the subtree around its ?supporting branch? is searched among 12 quantized levels of 360 degrees that gives the lowest cost. ? The scaling factor of the subtree is determined such that its ?supporting branch? is of the same length as the replaced branch. ? Branch pruning: After replacement, the resulting branches are pruned based on the detected foliage region and the existing branches. Any branch going beyond the foliage region is removed, so are the new branches if they are too close to some existing branches. 3.2 Data-driven attractors The growth engine is driven by the data to produce realistic result. The input image information is 2D and only weakly controls the growth in the desired tree volume. Hence, we introduce some 3D points based on heuristics to control the growth better. Image attractors To make the result after growing similar to image, We define a set of image attractors s i , i = {1, 2, ? ? ? N } that are sampled evenly in the foliage region with a fixed interval as illustrated by the yellow points in Figure 5 (a). The growth is then driven by minimizing a cost defined as E 2D (T ) = i dist(s i , T ), where dist(s i , T ) is the distance of an attractor s i to the projection of tree T onto the image. To compute dist(s i , T ), we also sample a set of points p i , i = {1, 2, ? ? ? M } along the image projection of the tree T , as the blue points in Figure 5 (a). Extrapolated 3D attractors The image driven growth could lead to an unbalanced tree, where only front branches are generated. Similar problem exists in previous sketching systems like [Okabe et al. 2005]. To alleviate this problem the tree is rotated 90 degrees around its main trunk and merged with the original one in [Okabe et al. 2005]. This method solves the problem at the cost of creating inconsistent visible branches with the image. These 3D points are generated by two steps. First, take the set of branch joints of the current tree. Then, rotate these joints 90 degree around the main trunk. Again the tree T is sampled as a\n          (a) (b) (a)\n          (b) (c)\n          (d) In our current implementation, the growth is driven by alternating the image attractors and the 3D point attractors. Figure 6 illustrates the effectiveness of this alternating strategy. The pure image driven growth yields good results when viewed from the same direction as the input image as in (a), while unnatural results (b) viewed from an orthogonal viewpoint. By alternating the image driven growth and 3D point driven growth, a better result can be obtained in (c) and (d). In each replacement iteration, we only add more branches to the tree and no existing branch is discarded. So the distance computation in previous iteration can be reused for speedup purpose. For each attractor s (no matter image point or 3D point), we record its distance to the tree T n at the n?th iteration as d s n . At the n + 1?th iteration, we compute the distance between s and newly created branches as d ? s . This is illustrated in Figure 5 (b). The leaves of the tree are automatically synthesized from the recovered branch structure and textured with the input image. Each leaf is represented by a flat rectangle with the size of 1/10 of the main trunk radius. Each branch generates from a range of 50 to 200 leaves proportional to it length. The arrangement of the leaves around the branch is randomized. We keep only those leaves that are projected inside the foliage region in the input image. Leaves are textured according to their projected position on the input image. The generic leaf shape, leaf size, density and arrangement of leaves along a branch are all parameterized in our current implementation. But the default values are used throughout all examples of this paper. We test our algorithm with several different examples to demonstrate its effectiveness. A typical example for a cherry tree downloaded from www.flickr.com is shown in Figure 1 . Its foliage region is shown in Figure 2 and its branch tracing procedure is illustrated in Figure 3 . The complete branching structure generated by growth engine is shown in Figure 1 (c). The complete cherry tree model is then rendered as in Figure 1 (d). For this example, we draw two strokes, and used both subtrees of visible branches and predefined subtrees of type I. The branch tracing is realtime, which provides rapid feedback to the user to decide whether additional branch strokes are needed. However, the branch growing typically takes about 20 minutes on a PC with 2.4G CPU. The population of the tree with leaves takes another 10 minutes. More examples are shown in Figure 7 . For the sycamore tree in the first row, it takes only two strokes. The tracing does not add any more branches. Its branching structure is entirely synthesized from the library of predefined subtrees of type II. For the oak tree in the second row, it takes three strokes. Part of its visible branches are traced automatically, but one is missing due to the dense foliage and is added by a second branch stroke. For the second cherry tree, it takes 3 strokes for the branches as the tracing is more challenging. The oak tree and cherry tree are both downloaded from www.flickr.com. The simplicity of our method makes the modeling affordable for woods as well. By casually capturing the image shown in Figure 9, we are able to get all four trees models from a total of 16 strokes in the input image. The relative positions of trees in 3D is set manually. A more systematic usage of the method in urban environment is shown in Figure 8 . Trees along a street can only be captured from close viewpoints due to space constraint, which makes previous image-based tree modeling methods less applicable. Here, we model each tree from a single image then align all trees manually in 3D space. In Figure 8 , the trees are modeled with 2, 2, 5, 3, 3, 2, 2 strokes from left to right. All trees are grown with predefined subtrees of type I. We have described a simple and effective system for constructing realistic tree models from a single image. Our system was designed to minimize user interaction. The resulting system is simple and practical in that an amateur user only needs to sketch a few strokes in the single input image. There are some directions for future works. For example, we could fill the gap between this single image based method and previous multi-views methods to improve the 3D shape while keeping the modeling simplicity. We could also improve the system in runtime efficiency to realtime. The described system could be upgraded to full-automatic if automatic tree detection and visible branch tracing algorithm are available. We thank Marcus Lundberg, Sean Pecor and Jason Ramsay, for their permission to use their pictures in this paper. Ping Tan is supported by Singapore FRC Grant R-263-000-477-112. This work is also supported by Hong Kong RGC Grants 618908, 619107, 619006 and RGC/NSFC N-HKUST602/05. (c)\n        (d) R ECHE -M ARTINEZ , A., M ARTIN , I., AND D RETTAKIS , G. 2004. Volumetric reconstruction and interactive rendering of trees from photographs. SIGGRAPH 2004. R OTHER , C., K OLMOGOROV , V., AND B LAKE , A. 2004. ?grabcut?: interactive foreground extraction using iterated graph cuts. In SIGGRAPH 2004, 309?314. S HLYAKHTER , I., R OZENOER , M., D ORSEY , J., AND T ELLER , S. 2001. Reconstructing 3d tree models from instrumented photographs. IEEE Comput. 21, 3, 53?61. T AN , P., Z ENG , G., W ANG , J., K ANG , S. B., AND Q UAN , L. 2007. Image-based tree modeling. In SIGGRAPH 2007, 87. W EBER , J., AND P ENN , J. 1995. Creation and rendering of realistic trees. In SIGGRAPH 1995, 119?128. X U , H., G OSSETT , N., AND C HEN , B. 2007. Knowledge and heuristic-based modeling of laser-scanned trees. ACM Trans. 26, 4, 19.",
  "resources" : [ ]
}