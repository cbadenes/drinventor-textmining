{
  "uri" : "sig2013a-a169-neissner_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2013a/a169-neissner_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Real-time 3D Reconstruction at Scale using Voxel Hashing",
    "published" : null,
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ ]
  },
  "bagOfWords" : [ "while", "3d", "reconstruction", "established", "field", "computer", "vision", "graphic", "now", "gain", "newfound", "momentum", "due", "wide", "availability", "depth", "camera", "-lrb-", "Microsoft", "Kinect", "Asus", "Xtion", "-rrb-", "since", "device", "output", "live", "noisy", "depth", "map", "particular", "focus", "recent", "work", "online", "surface", "reconstruction", "use", "consumer", "depth", "camera", "ability", "obtain", "reconstruction", "real-time", "open", "up", "various", "interactive", "application", "include", "augmented", "reality", "-lrb-", "ar", "-rrb-", "where", "real-world", "geometry", "can", "fuse", "3d", "graphic", "render", "live", "user", "autonomous", "guidance", "robot", "reconstruct", "respond", "rapidly", "environment", "even", "provide", "immediate", "feedback", "user", "during", "3d", "scanning", "online", "reconstruction", "require", "incremental", "fusion", "many", "overlap", "depth", "map", "single", "3d", "representation", "continuously", "refine", "challenging", "particularly", "when", "real-time", "performance", "require", "without", "trading", "fine-quality", "reconstruction", "spatial", "scale", "many", "state-of-the-art", "online", "technique", "therefore", "employ", "different", "type", "underlie", "datum", "structure", "accelerate", "use", "graphic", "hardware", "however", "have", "particular", "trade-off", "term", "reconstruction", "speed", "scale", "quality", "point-based", "method", "-lrb-", "e.g.", "-lsb-", "Rusinkiewicz", "et", "al.", "2002", "Weise", "et", "al.", "2009", "-rsb-", "-rrb-", "use", "simple", "unstructured", "representation", "closely", "map", "range", "depth", "sensor", "input", "lack", "ability", "directly", "reconstruct", "connected", "surface", "high-quality", "online", "scanning", "small", "object", "have", "be", "demonstrate", "-lsb-", "Weise", "et", "al.", "2009", "-rsb-", "largerscale", "reconstruction", "clearly", "trade", "quality", "and/or", "speed", "-lsb-", "Henry", "et", "al.", "2012", "St?ckler", "Behnke", "2012", "-rsb-", "height-map", "base", "representation", "-lsb-", "pollefey", "et", "al.", "2008", "Gallup", "et", "al.", "2010", "-rsb-", "support", "efficient", "compression", "connected", "surface", "datum", "can", "scale", "efficiently", "larger", "scene", "fail", "reconstruct", "complex", "3d", "structure", "active", "sensor", "implicit", "volumetric", "approach", "particular", "method", "Curless", "Levoy", "-lsb-", "1996", "-rsb-", "have", "demonstrate", "compelling", "result", "-lsb-", "Curless", "Levoy", "1996", "Levoy", "et", "al.", "2000", "Zhou", "Koltun", "2013", "-rsb-", "even", "real-time", "rate", "-lsb-", "Izadi", "et", "al.", "2011", "Newcombe", "et", "al.", "2011", "-rsb-", "however", "rely", "memory", "inefficient", "regular", "voxel", "grid", "turn", "restrict", "scale", "have", "lead", "either", "move", "volume", "variant", "-lsb-", "Roth", "Vona", "2012", "Whelan", "et", "al.", "2012", "-rsb-", "which", "stream", "voxel", "datum", "out-of-core", "sensor", "move", "still", "constrain", "size", "active", "volume", "hierarchical", "datum", "structure", "subdivide", "space", "more", "effectively", "do", "parallelize", "efficiently", "give", "add", "computational", "complexity", "-lsb-", "Zeng", "et", "al.", "2012", "Chen", "et", "al.", "2013", "-rsb-", "we", "contribute", "new", "real-time", "surface", "reconstruction", "system", "which", "support", "fine-quality", "reconstruction", "scale", "we", "approach", "carry", "benefit", "volumetric", "approach", "do", "require", "either", "memory", "constrain", "voxel", "grid", "computational", "overhead", "hierarchical", "datum", "structure", "we", "method", "base", "simple", "memory", "speed", "efficient", "spatial", "hash", "technique", "compress", "space", "allow", "real-time", "fusion", "reference", "implicit", "surface", "datum", "without", "need", "hierarchical", "datum", "structure", "surface", "datum", "only", "store", "densely", "cell", "where", "measurement", "observe", "additionally", "datum", "can", "stream", "efficiently", "out", "hash", "table", "allow", "further", "scalability", "during", "sensor", "motion", "while", "type", "efficient", "spatial", "hash", "technique", "have", "be", "propose", "variety", "render", "collision", "detection", "task", "-lsb-", "Teschner", "et", "al.", "2003", "Lefebvre", "Hoppe", "2006", "Bastos", "Celes", "2008", "Alcantara", "et", "al.", "2009", "Pan", "Manocha", "2011", "Garc?a", "et", "al.", "2011", "-rsb-", "we", "describe", "use", "datum", "structure", "surface", "reconstruction", "where", "underlie", "datum", "need", "continuously", "update", "we", "show", "interactive", "reconstruction", "variety", "scene", "reconstruct", "both", "fine-grained", "large-scale", "environment", "we", "illustrate", "how", "all", "part", "we", "pipeline", "from", "depth", "map", "pre-processing", "sensor", "pose", "estimation", "depth", "map", "fusion", "surface", "rendering", "perform", "real-time", "rate", "commodity", "graphic", "hardware", "we", "conclude", "comparison", "current", "state-of-the-art", "system", "illustrate", "improved", "performance", "reconstruction", "quality", "over", "three", "decade", "research", "3d", "reconstruction", "section", "we", "review", "relevant", "system", "focus", "online", "reconstruction", "method", "active", "sensor", "unlike", "system", "focus", "reconstruction", "from", "complete", "set", "3d", "point", "-lsb-", "Hoppe", "et", "al.", "1992", "Kazhdan", "et", "al.", "2006", "-rsb-", "online", "method", "require", "incremental", "fusion", "many", "overlap", "depth", "map", "single", "3d", "representation", "continuously", "refine", "typically", "method", "first", "register", "align", "sequential", "depth", "map", "use", "variant", "Iterative", "Closest", "point", "-lrb-", "icp", "-rrb-", "algorithm", "-lsb-", "besl", "McKay", "1992", "Chen", "Medioni", "1992", "-rsb-", "Parametric", "method", "-lsb-", "Chen", "Medioni", "1992", "Higuchi", "et", "al.", "1995", "-rsb-", "simply", "average", "overlap", "sample", "connect", "point", "assume", "simple", "surface", "topology", "-lrb-", "cylinder", "sphere", "-rrb-", "locally", "fit", "polygon", "extension", "mesh", "zippering", "-lsb-", "Turk", "Levoy", "1994", "-rsb-", "select", "one", "depth", "map", "per", "surface", "region", "remove", "redundant", "triangle", "overlap", "region", "stitch", "mesh", "method", "handle", "some", "denoising", "local", "averaging", "point", "fragile", "presence", "outlier", "area", "high", "curvature", "challenge", "associate", "work", "directly", "polygon", "mesh", "have", "lead", "many", "other", "reconstruction", "method", "point-based", "method", "perform", "reconstruction", "merge", "overlap", "point", "avoid", "infer", "connectivity", "render", "final", "model", "perform", "use", "point-based", "rendering", "technique", "-lsb-", "Gross", "Pfister", "2007", "-rsb-", "give", "output", "from", "most", "depth", "sensor", "3d", "point", "sample", "natural", "reconstruction", "method", "work", "directly", "datum", "example", "include", "in-hand", "scanning", "system", "-lsb-", "Rusinkiewicz", "et", "al.", "2002", "Weise", "et", "al.", "2009", "-rsb-", "which", "support", "reconstruction", "only", "single", "small", "object", "small", "scale", "high-quality", "-lsb-", "Weise", "et", "al.", "2009", "-rsb-", "reconstruction", "have", "be", "achieve", "larger", "scene", "have", "be", "reconstruct", "trade", "real-time", "speed", "quality", "-lsb-", "Henry", "et", "al.", "2012", "St?ckler", "Behnke", "2012", "-rsb-", "method", "lack", "ability", "directly", "model", "connected", "surface", "require", "additional", "expensive", "often", "offline", "step", "construct", "surface", "e.g.", "use", "volumetric", "datum", "structure", "-lsb-", "Rusinkiewicz", "et", "al.", "2002", "-rsb-", "height-map", "base", "representation", "explore", "use", "more", "compact", "2.5", "continuous", "surface", "representation", "reconstruction", "-lsb-", "Pollefeys", "et", "al.", "2008", "Gallup", "et", "al.", "2010", "-rsb-", "technique", "particularly", "useful", "modeling", "large", "building", "floor", "wall", "since", "appear", "clear", "discontinuity", "height-map", "multilayered", "height-map", "have", "be", "explore", "support", "reconstruction", "more", "complex", "3d", "shape", "balcony", "doorway", "arch", "-lsb-", "Gallup", "et", "al.", "2010", "-rsb-", "while", "method", "support", "more", "efficient", "compression", "surface", "datum", "2.5", "representation", "fail", "reconstruct", "many", "type", "complex", "3d", "structure", "alternative", "method", "use", "fully", "volumetric", "datum", "structure", "implicitly", "store", "sample", "continuous", "function", "-lsb-", "Hilton", "et", "al.", "1996", "Curless", "Levoy", "1996", "Wheeler", "et", "al.", "1998", "-rsb-", "method", "depth", "map", "convert", "sign", "distance", "field", "cumulatively", "average", "regular", "voxel", "grid", "final", "surface", "extract", "zero-level", "set", "implicit", "function", "use", "isosurface", "polygonisation", "-lrb-", "e.g.", "-lsb-", "Lorensen", "Cline", "1987", "-rsb-", "-rrb-", "raycasting", "well-known", "example", "method", "Curless", "Levoy", "-lsb-", "1996", "-rsb-", "which", "active", "triangulation-based", "sensor", "laser", "range", "scanner", "structured", "light", "camera", "can", "generate", "very", "high", "quality", "result", "-lsb-", "Curless", "Levoy", "1996", "Levoy", "et", "al.", "2000", "Zhou", "Koltun", "2013", "-rsb-", "kinectfusion", "-lsb-", "Newcombe", "et", "al.", "2011", "Izadi", "et", "al.", "2011", "-rsb-", "recently", "adopt", "volumetric", "method", "demonstrate", "compelling", "real-time", "reconstruction", "use", "commodity", "GPU", "while", "show", "high", "quality", "reconstruction", "method", "particularly", "give", "computational", "cost", "approach", "suffer", "from", "one", "major", "limitation", "use", "regular", "voxel", "grid", "impose", "large", "memory", "footprint", "represent", "both", "empty", "space", "surface", "densely", "thus", "fail", "reconstruct", "larger", "scene", "without", "compromise", "quality", "scaling-up", "Volumetric", "fusion", "recent", "work", "begin", "address", "spatial", "limitation", "volumetric", "method", "different", "way", "-lsb-", "Keller", "et", "al.", "2013", "-rsb-", "use", "point-based", "representation", "capture", "quality", "volumetric", "fusion", "remove", "need", "spatial", "datum", "structure", "while", "demonstrate", "compelling", "scalable", "real-time", "reconstruction", "quality", "on-par", "true", "volumetric", "method", "move", "volume", "method", "-lsb-", "Roth", "Vona", "2012", "Whelan", "et", "al.", "2012", "-rsb-", "extend", "gpu-based", "pipeline", "kinectfusion", "while", "still", "operate", "very", "restricted", "regular", "grid", "method", "stream", "out", "voxel", "from", "GPU", "base", "camera", "motion", "free", "space", "new", "datum", "store", "method", "streaming", "one-way", "lossy", "surface", "datum", "compress", "mesh", "once", "move", "host", "can", "stream", "back", "GPU", "while", "offer", "simple", "approach", "scalability", "core", "system", "still", "use", "regular", "grid", "structure", "which", "mean", "active", "volume", "must", "remain", "small", "ensure", "fine-quality", "reconstruction", "limit", "reconstruction", "scene", "close-by", "geometric", "structure", "can", "utilize", "full", "range", "datum", "active", "sensor", "Kinect", "limit", "regular", "grid", "have", "lead", "researcher", "investigate", "more", "efficient", "volumetric", "datum", "structure", "well", "study", "topic", "volume", "render", "literature", "efficient", "method", "base", "sparse", "voxel", "octree", "-lsb-", "laine", "Karras", "2011", "K?mpe", "et", "al.", "2013", "-rsb-", "simpler", "multi-level", "hierarchy", "adaptive", "datum", "structure", "-lsb-", "Kraus", "Ertl", "2002", "Lefebvre", "et", "al.", "2005", "Bastos", "Celes", "2008", "Reichl", "et", "al.", "2012", "-rsb-", "out-of-core", "streaming", "architecture", "large", "dataset", "-lsb-", "Hadwiger", "et", "al.", "2012", "Crassin", "et", "al.", "2009", "-rsb-", "approach", "have", "begin", "explore", "context", "online", "reconstruction", "where", "need", "support", "real-time", "update", "underlie", "datum", "add", "fundamentally", "new", "challenge", "example", "-lsb-", "Zhou", "et", "al.", "2011", "-rsb-", "demonstrate", "gpu-based", "octree", "which", "can", "perform", "Poisson", "surface", "reconstruction", "300k", "vertex", "interactive", "rate", "-lsb-", "Zeng", "et", "al.", "2012", "-rsb-", "implement", "9to", "10-level", "octree", "GPU", "which", "extend", "KinectFusion", "pipeline", "larger", "8m", "8m", "2m", "indoor", "office", "space", "method", "however", "require", "complex", "octree", "structure", "implement", "additional", "computational", "complexity", "pointer", "overhead", "only", "limited", "gain", "scale", "octree", "resolution", "each", "dimension", "increase", "factor", "two", "each", "subdivision", "level", "result", "need", "deep", "tree", "structure", "efficient", "subdivision", "which", "conversely", "impact", "performance", "particular", "gpus", "where", "tree", "traversal", "lead", "thread", "divergence", "render", "literature", "have", "propose", "many", "alternative", "hierarchical", "datum", "structure", "-lsb-", "Lefebvre", "et", "al.", "2005", "Kraus", "Ertl", "2002", "Laine", "Karras", "2011", "K?mpe", "et", "al.", "2013", "Reichl", "et", "al.", "2012", "-rsb-", "-lsb-", "Chen", "et", "al.", "2013", "-rsb-", "hierarchy", "-lsb-", "Lefebvre", "et", "al.", "2005", "-rsb-", "adopt", "3d", "reconstruction", "scale", "optimal", "tree", "depth", "branch", "factor", "be", "empirically", "derive", "-lrb-", "show", "large", "branch", "factor", "shallow", "tree", "optimize", "GPU", "performance", "-rrb-", "while", "avoid", "use", "octree", "system", "still", "carry", "computational", "overhead", "realize", "hierarchical", "datum", "structure", "GPU", "lead", "performance", "only", "real-time", "specific", "scene", "very", "high-end", "graphic", "hardware" ],
  "content" : "While 3D reconstruction is an established field in computer vision and graphics, it is now gaining newfound momentum due to the wide availability of depth cameras (such as the Microsoft Kinect and Asus Xtion). Since these devices output live but noisy depth maps, a particular focus of recent work is online surface reconstruction using such consumer depth cameras. The ability to obtain reconstructions in real-time opens up various interactive applications including: augmented reality (AR) where real-world geometry can be fused with 3D graphics and rendered live to the user; autonomous guidance for robots to reconstruct and respond rapidly to their environment; or even to provide immediate feedback to users during 3D scanning. Online reconstruction requires incremental fusion of many overlapping depth maps into a single 3D representation that is continuously refined. This is challenging particularly when real-time performance is required without trading fine-quality reconstructions and spatial scale. Many state-of-the-art online techniques therefore employ different types of underlying data structures accelerated using graphics hardware. These however have particular trade-offs in terms of reconstruction speed, scale, and quality. Point-based methods (e.g., [Rusinkiewicz et al. 2002; Weise et al. 2009]) use simple unstructured representations that closely map to range and depth sensor input, but lack the ability to directly reconstruct connected surfaces. High-quality online scanning of small objects has been demonstrated [Weise et al. 2009], but largerscale reconstructions clearly trade quality and/or speed [Henry et al. 2012; St?ckler and Behnke 2012]. Height-map based representations [Pollefeys et al. 2008; Gallup et al. 2010] support efficient compression of connected surface data, and can scale efficiently to larger scenes, but fail to reconstruct complex 3D structures. For active sensors, implicit volumetric approaches, in particular the method of Curless and Levoy [1996], have demonstrated compelling results [Curless and Levoy 1996; Levoy et al. 2000; Zhou and Koltun 2013], even at real-time rates [Izadi et al. 2011; Newcombe et al. 2011]. However, these rely on memory inefficient regular voxel grids, in turn restricting scale. This has led to either moving volume variants [Roth and Vona 2012; Whelan et al. 2012], which stream voxel data out-of-core as the sensor moves, but still constrain the size of the active volume. Or hierarchical data structures that subdivide space more effectively, but do not parallelize efficiently given added computational complexity [Zeng et al. 2012; Chen et al. 2013]. We contribute a new real-time surface reconstruction system which supports fine-quality reconstructions at scale. Our approach carries the benefits of volumetric approaches, but does not require either a memory constrained voxel grid or the computational overheads of a hierarchical data structure. Our method is based on a simple memory and speed efficient spatial hashing technique that compresses space, and allows for real-time fusion of referenced implicit surface data, without the need for a hierarchical data structure. Surface data is only stored densely in cells where measurements are observed. Additionally, data can be streamed efficiently in or out of the hash table, allowing for further scalability during sensor motion. While these types of efficient spatial hashing techniques have been proposed for a variety of rendering and collision detection tasks [Teschner et al. 2003; Lefebvre and Hoppe 2006; Bastos and Celes 2008; Alcantara et al. 2009; Pan and Manocha 2011; Garc?a et al. 2011], we describe the use of such data structures for surface reconstruction, where the underlying data needs to be continuously updated. We show interactive reconstructions of a variety of scenes, reconstructing both fine-grained and large-scale environments. We illustrate how all parts of our pipeline from depth map pre-processing, sensor pose estimation, depth map fusion, and surface rendering are performed at real-time rates on commodity graphics hardware. We conclude with a comparison to current state-of-the-art systems, illustrating improved performance and reconstruction quality. There is over three decades of research on 3D reconstruction. In this section we review relevant systems, with a focus on online reconstruction methods and active sensors. Unlike systems that focus on reconstruction from a complete set of 3D points [Hoppe et al. 1992; Kazhdan et al. 2006], online methods require incremental fusion of many overlapping depth maps into a single 3D representation that is continuously refined. Typically methods first register or align sequential depth maps using variants of the Iterative Closest Point (ICP) algorithm [Besl and McKay 1992; Chen and Medioni 1992]. Parametric methods [Chen and Medioni 1992; Higuchi et al. 1995] simply average overlapping samples, and connect points by assuming a simple surface topology (such as a cylinder or a sphere) to locally fit polygons. Extensions such as mesh zippering [Turk and Levoy 1994] select one depth map per surface region, remove redundant triangles in overlapping regions, and stitch meshes. These methods handle some denoising by local averaging of points, but are fragile in the presence of outliers and areas with high curvature. These challenges associated with working directly with polygon meshes have led to many other reconstruction methods. Point-based methods perform reconstruction by merging overlapping points, and avoid inferring connectivity. Rendering the final model is performed using point-based rendering techniques [Gross and Pfister 2007]. Given the output from most depth sensors are 3D point samples, it is natural for reconstruction methods to work directly with such data. Examples include in-hand scanning systems [Rusinkiewicz et al. 2002; Weise et al. 2009], which support reconstruction of only single small objects. At this small scale, high-quality [Weise et al. 2009] reconstructions have been achieved. Larger scenes have been reconstructed by trading real-time speed and quality [Henry et al. 2012; St?ckler and Behnke 2012]. These methods lack the ability to directly model connected surfaces, requiring additional expensive and often offline steps to construct surfaces; e.g., using volumetric data structures [Rusinkiewicz et al. 2002]. Height-map based representations explore the use of more compact 2.5D continuous surface representations for reconstruction [Pollefeys et al. 2008; Gallup et al. 2010]. These techniques are particularly useful for modeling large buildings with floors and walls,  since these appear as clear discontinuities in the height-map. Multilayered height-maps have been explored to support reconstruction of more complex 3D shapes such as balconies, doorways, and arches [Gallup et al. 2010]. While these methods support more efficient compression of surface data, the 2.5D representation fails to reconstruct many types of complex 3D structures. An alternative method is to use a fully volumetric data structure to implicitly store samples of a continuous function [Hilton et al. 1996; Curless and Levoy 1996; Wheeler et al. 1998]. In these methods, depth maps are converted into signed distance fields and cumulatively averaged into a regular voxel grid. The final surface is extracted as the zero-level set of the implicit function using isosurface polygonisation (e.g., [Lorensen and Cline 1987]) or raycasting. A well-known example is the method of Curless and Levoy [1996], which for active triangulation-based sensors such as laser range scanners and structured light cameras, can generate very high quality results [Curless and Levoy 1996; Levoy et al. 2000; Zhou and Koltun 2013]. KinectFusion [Newcombe et al. 2011; Izadi et al. 2011] recently adopted this volumetric method and demonstrated compelling real-time reconstructions using a commodity GPU. While shown to be a high quality reconstruction method, particularly given the computational cost, this approach suffers from one major limitation: the use of a regular voxel grid imposes a large memory footprint, representing both empty space and surfaces densely, and thus fails to reconstruct larger scenes without compromising quality. Scaling-up Volumetric Fusion Recent work begins to address this spatial limitation of volumetric methods in different ways. [Keller et al. 2013] use a point-based representation that captures qualities of volumetric fusion but removes the need for a spatial data structure. While demonstrating compelling scalable real-time reconstructions, the quality is not on-par with true volumetric methods. Moving volume methods [Roth and Vona 2012; Whelan et al. 2012] extend the GPU-based pipeline of KinectFusion. While still operating on a very restricted regular grid, these methods stream out voxels from the GPU based on camera motion, freeing space for new data to be stored. In these methods the streaming is one-way and lossy. Surface data is compressed to a mesh, and once moved to host cannot be streamed back to the GPU. While offering a simple approach for scalability, at their core these systems still use a regular grid structure, which means that the active volume must remain small to ensure fine-quality reconstructions. This limits reconstructions to scenes with close-by geometric structures, and cannot utilize the full range of data for active sensors such as the Kinect. This limit of regular grids has led researcher to investigate more efficient volumetric data structures. This is a well studied topic in the volume rendering literature, with efficient methods based on sparse voxel octrees [Laine and Karras 2011; K?mpe et al. 2013], simpler multi-level hierarchies and adaptive data structures [Kraus and Ertl 2002; Lefebvre et al. 2005; Bastos and Celes 2008; Reichl et al. 2012] and out-of-core streaming architectures for large datasets [Hadwiger et al. 2012; Crassin et al. 2009]. These approaches have begun to be explored in the context of online reconstruction, where the need to support real-time updates of the underlying data adds a fundamentally new challenge. For example, [Zhou et al. 2011] demonstrate a GPU-based octree which can perform Poisson surface reconstruction on 300K vertices at interactive rates. [Zeng et al. 2012] implement a 9to 10-level octree on the GPU, which extends the KinectFusion pipeline to a larger 8m ? 8m ? 2m indoor office space. The method however requires a complex octree structure to be implemented, with additional computational complexity and pointer overhead, with only limited gains in scale. In an octree, the resolution in each dimension increases by a factor of two at each subdivision level. This results in the need for a deep tree structure for efficient subdivision, which conversely impacts performance, in particular on GPUs where tree traversal leads to thread divergence. The rendering literature has proposed many alternative hierarchical data structures [Lefebvre et al. 2005; Kraus and Ertl 2002; Laine and Karras 2011; K?mpe et al. 2013; Reichl et al. 2012]. In [Chen et al. 2013] an N 3 hierarchy [Lefebvre et al. 2005] was adopted for 3D reconstruction at scale, and the optimal tree depth and branching factor were empirically derived (showing large branching factors and a shallow tree optimizes GPU performance). While avoiding the use of an octree, the system still carries computational overheads in realizing such a hierarchical data structure on the GPU. As such this leads to performance that is only real-time on specific scenes, and on very high-end graphics hardware.",
  "resources" : [ ]
}