{
  "uri" : "sig2011-a27-lee_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2011/a27-lee_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "ShadowDraw: Real-Time User Guidance for Freehand Drawing",
    "published" : "2011",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Yong Jae-Lee",
      "name" : "Yong Jae",
      "surname" : "Lee"
    }, {
      "uri" : "http://drinventor/C. Lawrence-Zitnick",
      "name" : "C. Lawrence",
      "surname" : "Zitnick"
    }, {
      "uri" : "http://drinventor/Michael F.-Cohen",
      "name" : "Michael F.",
      "surname" : "Cohen"
    } ]
  },
  "bagOfWords" : [ "user", "draw", "ShadowDraw", "dynamically", "update", "shadow", "image", "underlie", "user?s", "stroke", "first", "we", "do", "provide", "single", "image", "from", "which", "user", "can", "trace", "rather", "ShadowDraw", "automatically", "blend", "relevant", "image", "from", "large", "database", "construct", "shadow", "second", "system", "dynamically", "adapt", "user?s", "drawing", "real-time", "produce", "suggestion", "accordingly", "shadow", "create", "aggregate", "edge", "map", "from", "best", "database", "match", "spatially", "weight", "match", "score", "cr", "category", "i.", "3.8", "-lsb-", "Computing", "Methodologies", "-rsb-", "computer", "graphics?applications", "keyword", "large", "scale", "image", "retrieval", "shape", "matching", "interactive", "drawing", "similarly", "ask", "draw", "bicycle", "most", "we", "would", "have", "difficult", "time", "depict", "how", "frame", "wheel", "relate", "each", "other", "one", "solution", "search", "image", "thing", "we", "want", "draw", "either", "trace", "use", "some", "other", "way", "reference", "however", "aside", "from", "difficulty", "find", "photo", "what", "we", "want", "draw", "simply", "trace", "object", "edge", "eliminate", "much", "essence", "drawing", "i.e.", "very", "little", "freedom", "trace", "stroke", "conversely", "draw", "blank", "paper", "only", "image", "mind?s", "eye", "give", "drawer", "lot", "freedom", "freehand", "drawing", "can", "frustrate", "without", "significant", "training", "address", "we", "present", "ShadowDraw", "drawing", "interface", "automatically", "infer", "what", "you", "draw", "dynamically", "depict", "relevant", "shadow", "-lrb-", "figure", "-rrb-", "underneath", "drawing", "shadow", "may", "either", "use", "ignore", "drawer", "furthermore", "shadow", "from", "real", "image", "can", "enlighten", "artist", "gist", "many", "image", "simultaneously", "computer", "essence", "partner", "draw", "process", "provide", "guidance", "like", "teacher", "instead", "actually", "produce", "final", "artwork", "drawing", "bottom", "row", "Figure", "be", "draw", "same", "subject", "time", "use", "ShadowDraw", "Notice", "how", "user", "own", "creative", "style", "remain", "consistent", "between", "drawing", "while", "overall", "shape", "spacing", "more", "realistic", "ShadowDraw", "consist", "two", "main", "computational", "step", "plus", "user", "interface", "each", "window", "convert", "edge", "descriptor", "further", "code", "sketch", "distinct", "hash", "key", "use", "min-hash", "-lsb-", "Chum", "et", "al.", "2008", "-rsb-", "addition", "verification", "stage", "method", "determine", "blend", "weight", "unique", "work", "we", "purposely", "avoid", "paper", "make", "any", "claim", "system", "help", "produce", "more", "skilled", "drawer", "more", "artistic", "drawing", "here", "we", "briefly", "review", "related", "work", "large", "scale", "image", "retrieval", "technique", "especially", "those", "use", "line", "drawing", "query", "and/or", "aim", "construct", "new", "image", "drawing", "rather", "than", "start", "from", "blank", "page", "Scene", "Completion", "algorithm", "-lsb-", "Hays", "Efros", "2007", "-rsb-", "perform", "global", "scene", "match", "use", "query", "image", "which", "have", "hole", "improve", "retrieval", "accuracy", "sketch-based", "system", "researcher", "have", "also", "design", "descriptor", "provide", "better", "match", "between", "human", "draw", "sketch", "natural", "image", "-lsb-", "Chalechale", "et", "al.", "2005", "Hu", "et", "al.", "2010", "-rsb-", "similar", "image", "match", "stitch", "from", "large", "-lrb-", "few", "hundred", "thousand", "-rrb-", "image", "collection", "download", "from", "Flickr", "unlike", "previous", "method", "we", "end", "goal", "help", "user", "draw", "rather", "than", "perform", "image", "composition", "completion", "retrieval", "3d", "modeling", "furthermore", "ShadowDraw", "use", "only", "partial", "evolve", "draw", "query", "rather", "than", "other", "image", "and/or", "textual", "description", "more", "recently", "iCanDraw", "interface", "-lsb-", "Dixon", "et", "al.", "2010", "-rsb-", "provide", "step-by-step", "instruction", "corrective", "feedback", "guide", "user", "draw", "human", "face", "from", "reference", "image", "instead", "we", "use", "set", "approximately", "30,000", "natural", "image", "collect", "from", "internet", "via", "approximately", "40", "categorical", "query", "t-shirt", "bicycle", "car", "etc.", "although", "image", "have", "many", "extraneous", "background", "object", "frame", "line", "etc.", "expectation", "average", "contain", "edge", "user", "may", "want", "draw", "we", "scale", "image", "fit", "300x300", "pixel", "resolution", "i.e.", "long", "side", "scale", "300", "pixel", "method", "locally", "normalize", "magnitude", "edge", "sum", "normalize", "magnitude", "weight", "local", "curvature", "along", "length", "edge", "Patch", "descriptor", "each", "edge", "image", "we", "determine", "edge", "position", "find", "maximum", "response", "perpendicular", "edge", "direction", "similar", "canny", "edge", "detection", "-lsb-", "canny", "1986", "-rsb-", "give", "image", "database", "corresponding", "edge", "orientation", "we", "compute", "set", "edge", "descriptor", "since", "goal", "match", "edge", "image", "incomplete", "evolve", "drawing", "we", "compute", "descriptor", "locally", "over", "60x60", "patch", "since", "edge", "draw", "user", "typically", "less", "dense", "than", "natural", "image", "we", "use", "low", "dimensional", "version", "BiCE", "we", "define", "three", "dimensional", "histogram", "discrete", "edge", "orientation", "18", "position", "perpendicular", "edge", "position", "tangent", "edge", "min-hash", "have", "property", "probability", "two", "set", "have", "same", "hash", "value", "-lrb-", "i.e.", "collide", "-rrb-", "equal", "Jaccard", "similarity", "single", "min-hash", "can", "non-discriminative", "introduce", "many", "false", "positive", "retrieval", "especially", "descriptor", "nonsparse", "section", "we", "describe", "real-time", "matching", "pipeline", "between", "edge", "image", "database", "user?s", "draw", "show", "Figure", "render", "line", "have", "same", "style", "edge", "extract", "from", "natural", "image", "database", "i.e.", "edge", "image", "use", "match", "do", "use", "stylized", "stroke", "see", "user", "describe", "section", "we", "take", "advantage", "fact", "user?s", "stroke", "change", "gradually", "over", "time", "increase", "performance", "illustration", "spatial", "weight", "-lrb-", "-rrb-", "user?s", "view", "-lrb-", "-rrb-", "shadow", "image", "-lrb-", "-rrb-", "top", "two", "match", "corresponding", "spatial", "weight", "-lrb-", "top", "right", "-rrb-", "sine", "edge", "angle", "provide", "higher", "weight", "more", "informative", "vertical", "edge", "when", "determine", "horizontal", "offset", "similarly", "cosine", "horizontal", "edge", "we", "determine", "final", "sub-pixel", "offset", "add", "quadratic", "interpolation", "result", "peak", "response", "image", "weighting", "we", "now", "have", "set", "candidate", "image", "align", "edge", "image", "align", "use", "offset", "we", "goal", "blend", "align", "edge", "image", "shadow", "image", "help", "guide", "user", "draw", "blend", "weight", "should", "high", "pixel", "where", "good", "match", "between", "drawing", "candidate?s", "align", "edge", "low", "pixel", "where", "illustration", "spatial", "weighting", "show", "Figure", "we", "goal", "candidate", "image?s", "weight", "increase", "when", "its", "edge", "agree", "position", "orientation", "user?s", "stroke", "accomplish", "limit", "magnitude", "response", "from", "blur", "edge", "maximum", "response", "may", "result", "from", "single", "edge", "isolation", "aid", "computation", "we", "compute", "global", "match", "score", "each", "image", "use", "difference", "between", "however", "majority", "user?s", "stroke", "perpendicular", "image?s", "edge", "may", "negative", "we", "render", "final", "image", "paper", "texture", "background", "show", "Figure", "-lrb-", "-rrb-", "fast", "response", "critical", "create", "positive", "feedback", "loop", "which", "user", "obtain", "suggestion", "while", "still", "process", "draw", "stroke", "be", "couple", "comment", "indicate", "ShadowDraw", "sometimes", "distracting", "...", "essence", "what", "define", "ShadowDraw", "author", "would", "like", "thank", "Ce", "Liu", "many", "insightful", "discussion", "help", "shape", "work", "paper" ],
  "content" : "As the user draws, ShadowDraw dynamically updates a shadow image underlying the user?s strokes. First, we do not provide a single image from which the user can trace; rather ShadowDraw automatically blends relevant images from a large database to construct the shadows. Second, the system dynamically adapts to the user?s drawings in real-time and produces suggestions accordingly. Shadows are created by aggregating the edge maps from the best database matches, spatially weighted by their match scores. CR Categories: I.3.8 [Computing Methodologies]: Computer Graphics?Applications; Keywords: large scale image retrieval, shape matching, interactive drawing Similarly, if asked to draw a bicycle, most of us would have a difficult time depicting how the frame and wheels relate to each other. One solution is to search for an image of the thing we want to draw, and to either trace it or to use it in some other way as a reference. However, aside from the difficulty of finding a photo of what we want to draw, simply tracing object edges eliminates much of the essence of drawing, i.e., there is very little freedom in tracing strokes. Conversely, drawing on a blank paper with only the image in the mind?s eye gives the drawer a lot of freedom, but freehand drawing can be frustrating without significant training. To address this, we present ShadowDraw, a drawing interface that automatically infers what you are drawing and then dynamically depicts relevant shadows (Figures 5 and 6) underneath the drawing. These shadows may be either used or ignored by the drawer. Furthermore, shadows from real images can enlighten the artist with the gist of many images simultaneously. The computer, in essence, is a partner in the drawing process, providing guidance like a teacher, instead of actually producing the final artwork. The drawings in the bottom row of Figure 1 were drawn by the same subjects, this time using ShadowDraw. Notice how the users? own creative styles remain consistent between the drawings, while the overall shapes and spacing are more realistic. ShadowDraw consists of two main computational steps plus the user interface. Each window is converted to edge descriptors, and further coded as sketches with distinct hash keys using min-hash [Chum et al. 2008]. In addition, the verification stage and methods for determining the blending weights are unique to this work. We purposely avoid in this paper, making any claims that the system helps produce more skilled drawers or more artistic drawings. Here, we briefly review related work in large scale image retrieval techniques, especially those that use line drawings for the query and/or are aimed at constructing new images and drawings. Rather than starting from a blank page, the Scene Completion algorithm [Hays and Efros 2007] performs a global scene match using a query image, which has ?holes?. To improve retrieval accuracy of these sketch-based systems, researchers have also designed descriptors that provide better matches between human drawn sketches and natural images [Chalechale et al. 2005; Hu et al. 2010]. Similar images are matched and stitched from a large (few hundred thousand) image collection downloaded from Flickr. Unlike previous methods, our end goal is to help the user draw rather than to perform an image composition, completion, retrieval, or 3D modeling. Furthermore, ShadowDraw uses only a partial and evolving drawing for the query rather than other images and/or textual descriptions. More recently, the iCanDraw interface [Dixon et al. 2010] provides step-by-step instructions and corrective feedback to guide a user to draw a human face from a reference image. Instead, we use a set of approximately 30,000 natural images collected from the internet via approximately 40 categorical queries such as ?t-shirt?, ?bicycle?, ?car?, etc. Although such images have many extraneous backgrounds, objects, framing lines, etc., the expectation is that, on average, they will contain edges a user may want to draw. We scale the images to fit a 300x300 pixel resolution, i.e., the long side is scaled to 300 pixels. The method locally normalizes the magnitudes of the edges, and then sums the normalized magnitudes, weighted by local curvature, along the length of the edge. Patch descriptors For each edge image, we determine the edge positions by finding maxima in the responses perpendicular to the edge direction, similar to Canny edge detection [Canny 1986]. Given an image I in the database with corresponding edges E and orientations ?, we compute a set of edge descriptors d i ? D. Since the goal is to match an edge image E to incomplete and evolving drawings, we compute the descriptors locally over 60x60 patches. Since the edges drawn by a user are typically less dense than in natural images, we use a low dimensional version of BiCE. We define a three dimensional histogram, with 4 discrete edge orientations, 18 positions perpendicular to the edge, and 6 positions tangent to the edge. Min-hash has the property that the probability of two sets having the same hash value (i.e., ?colliding?) is equal to their Jaccard similarity. A single min-hash can be non-discriminative and introduce many false positive retrievals, especially if the descriptor is nonsparse. In this section, we describe the real-time matching pipeline between the edge images in the database and the user?s drawing, as shown in Figure 3. The rendered lines have the same style as the edges extracted from the natural images in the database, i.e., the edge image E  ? used for matching does not use the stylized strokes that are seen by the user described in Section 4. We take advantage of the fact that the user?s strokes change gradually over time to increase performance. Illustration of spatial weights: (a) user?s view, (b) shadow image, (c, d) top two matches and corresponding spatial weights (top right). The sine of the edge angles provides higher weights to the more informative vertical edges when determining the horizontal offsets, and similarly for T y and cosine with horizontal edges. We determine  the final sub-pixel offsets d x and d y by adding a quadratic interpolation of the resulting peak response in T x and T y to d x and d y . Image weighting We now have a set of candidate images, C, and their aligned edge images E i , aligned using offsets d i . Our goal is to blend these aligned edge images into a shadow image, S, that will help guide the user as they draw: The blending weight should be high for pixels where there is a good match between the drawing and the candidate?s aligned edges and low for pixels where there is not. An illustration of the spatial weighting is shown in Figure 4 . Our goal is for a candidate image?s weights to increase when its edges agree in position and orientation with the user?s strokes. This is accomplished by limiting the magnitude of the response from the blurred edges to the maximum response that may result from a single edge in isolation. To aid in the computation of v i , we compute a global match score h i for each image using the difference between ? + and ? ? , However, if a majority of the user?s strokes are perpendicular to the image?s edges, h i may be negative. We render the final image on a paper textured background as shown in Figure 5(d) . A fast response is critical in creating a positive feedback loop in which the user obtains suggestions while still in the process of drawing a stroke. ? There were a couple of comments indicating that ShadowDraw was sometimes distracting, such as ?... This is the essence of what defines ShadowDraw. The authors would like to thank Ce Liu for many insightful discussions and help in shaping the work in this paper.",
  "resources" : [ ]
}