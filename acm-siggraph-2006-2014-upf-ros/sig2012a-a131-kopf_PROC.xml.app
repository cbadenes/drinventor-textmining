{
  "uri" : "sig2012a-a131-kopf_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2012a/a131-kopf_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Quality Prediction for Image Completion",
    "published" : "2012",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Johannes-Kopf",
      "name" : "Johannes",
      "surname" : "Kopf"
    }, {
      "uri" : "http://drinventor/Wolf-Kienzle",
      "name" : "Wolf",
      "surname" : "Kienzle"
    }, {
      "uri" : "http://drinventor/Steven M.-Drucker",
      "name" : "Steven M.",
      "surname" : "Drucker"
    }, {
      "uri" : "http://drinventor/Sing Bing-Kang",
      "name" : "Sing Bing",
      "surname" : "Kang"
    } ]
  },
  "bagOfWords" : [ "we", "present", "data-driven", "method", "predict", "quality", "image", "completion", "method", "use", "automatically", "derive", "search", "space", "constraint", "patch", "source", "region", "which", "lead", "improve", "texture", "synthesis", "semantically", "more", "plausible", "result", "constraint", "also", "facilitate", "performance", "prediction", "allow", "we", "correlate", "output", "quality", "against", "feature", "possible", "region", "use", "synthesis", "we", "use", "we", "algorithm", "first", "crop", "complete", "stitch", "panorama", "we", "predictive", "ability", "use", "find", "optimal", "crop", "shape", "before", "completion", "compute", "potentially", "save", "significant", "amount", "computation", "we", "optimize", "crop", "include", "much", "original", "panorama", "possible", "while", "avoid", "region", "can", "less", "successfully", "fill", "we", "predictor", "can", "also", "apply", "hole", "filling", "interior", "image", "cr", "category", "i.", "4.9", "-lsb-", "image", "processing", "computer", "Vision", "-rsb-", "application", "keyword", "image", "completion", "quality", "prediction", "crop", "Links", "dl", "pdf", "EB", "same", "algorithm", "however", "can", "also", "use", "extend", "image", "beyond", "its", "original", "boundary", "useful", "fill", "beyond", "irregular", "boundary", "stitch", "panorama?this", "application", "focus", "paper", "casually", "shoot", "panorama", "often", "have", "irregular", "boundary", "-lrb-", "e.g.", "Figure", "-rrb-", "most", "user", "however", "prefer", "output", "image", "rectangular", "boundary", "alternative", "apply", "any", "exist", "completion", "algorithm", "fill", "miss", "region", "panorama", "bound", "box", "unfortunately", "all", "exist", "image", "completion", "algorithm", "fail", "occasion", "failure", "typically", "show", "up", "either", "inability", "synthesize", "some", "texture", "well", "result", "semantically", "implausible", "-lrb-", "see", "Figure", "-rrb-", "addition", "difficult", "anticipate", "when", "where", "algorithm", "fail", "give", "arbitrary", "input", "image", "paper", "we", "use", "machine", "learn", "predict", "quality", "image", "completion", "base", "prediction", "we", "compute", "crop", "shape", "before", "completion", "actually", "carry", "out", "avoid", "unnecessarily", "complete", "crop", "pixel", "validate", "train", "we", "prediction", "function", "we", "run", "mechanical", "Turk", "user", "study", "obtain", "about", "9,500", "good", "bad", "label", "crop", "from", "complete", "image", "from", "large", "number", "subject", "yet", "another", "user", "study", "we", "evaluate", "performance", "we", "automatic", "crop", "optimization", "addition", "example", "include", "paper", "all", "we", "result", "comparison", "include", "supplementary", "material", "while", "substantial", "amount", "previous", "work", "image", "completion", "-lrb-", "also", "refer", "inpainting", "image", "filling", "-rrb-", "best", "we", "knowledge", "we", "aware", "any", "method", "can", "predict", "quality", "before", "completion", "both", "case", "however", "texture", "have", "generate", "first", "we", "now", "briefly", "survey", "representative", "method", "image", "completion", "which", "we", "classify", "primarily", "example-based", "diffusionbased", "less", "appropriate", "complete", "stitch", "panorama", "large", "open-ended", "miss", "region", "due", "inability", "synthesize", "texture", "addition", "compensate", "local", "brightness", "change", "linearly", "fitting", "intensity", "match", "patch", "addition", "be", "design", "performance", "prediction", "mind", "know", "advance", "where", "every", "miss", "pixel", "may", "come", "from", "enable", "we", "predict", "perceive", "quality", "complete", "result", "use", "training", "datum", "we", "learn", "function", "map", "low-level", "feature", "closest", "known", "image", "region", "perceive", "quality", "complete", "result", "basic", "form", "energy", "minimization", "problem", "without", "random", "initialization", "algorithm", "tend", "exhibit", "quality", "issue", "blurry/incorrect", "texture", "semantically", "implausible", "result", "show", "figure", "we", "use", "similar", "heuristic", "which", "use", "texture", "segmentation", "select", "large", "restriction", "region", "relatively", "homogeneous", "content", "order", "facilitate", "predictability", "achieve", "continuation", "semantic", "region", "we", "consider", "use", "image", "segmentation", "technique", "-lsb-", "Jia", "Tang", "2003", "-rsb-", "however", "difficult", "control", "granularity", "result", "segment", "addition", "segment", "non-overlapping", "which", "might", "lead", "artifact", "form", "artificial", "hard", "edge", "result", "instead", "we", "oversegment", "superpixel", "associate", "each", "superpixel", "cluster", "similar", "superpixel", "surround", "cluster", "homogeneous", "overlap", "desire", "turn", "out", "add", "complexity", "algorithm", "necessary", "achieve", "good", "result", "instead", "we", "partition", "entire", "image", "nonoverlapping", "square", "tile", "each", "be", "16", "16", "pixel", "every", "boundary", "tile", "we", "compute", "segment", "comprise", "surround", "known", "tile", "sufficiently", "similar", "texture", "-lrb-", "decribe", "next", "paragraph", "-rrb-", "we", "goal", "construct", "function", "-lrb-", "-rrb-", "predict", "unknown", "label", "from", "feature", "vector", "gentle", "AdaBoost", "determine", "model", "parameter", "solve", "problem" ],
  "content" : "We present a data-driven method to predict the quality of an image completion method. It uses automatically derived search space constraints for patch source regions, which lead to improved texture synthesis and semantically more plausible results. These constraints also facilitate performance prediction by allowing us to correlate output quality against features of possible regions used for synthesis. We use our algorithm to first crop and then complete stitched panoramas. Our predictive ability is used to find an optimal crop shape before the completion is computed, potentially saving significant amounts of computation. Our optimized crop includes as much of the original panorama as possible while avoiding regions that can be less successfully filled in. Our predictor can also be applied for hole filling in the interior of images. CR Categories: I.4.9 [Image Processing and Computer Vision]: Applications; Keywords: image completion, quality prediction, cropping Links: DL PDF W EB The same algorithms, however, can also be used to extend an image beyond its original boundaries. This is useful for filling beyond the irregular boundaries of a stitched panorama?this application is the focus of this paper. Casually shot panoramas often have irregular boundaries (e.g., Figure 1). Most users, however, prefer output images with rectangular boundaries. The alternative is to apply any existing completion algorithm to fill the missing regions of the panorama bounding box. Unfortunately, all existing image completion algorithms fail on occasion; the failure typically shows up as either inability to synthesize some textures well or results that are semantically implausible (see Figure 2 ). In addition, it is difficult to anticipate when and where such algorithms will fail given an arbitrary input image. In this paper, we use machine learning to predict the quality of image completion. Based on the prediction we compute a crop shape before the completion is actually carried out, avoiding unnecessarily completing cropped pixels. To validate and train our prediction function, we ran a Mechanical Turk user study to obtain about 9,500 ?good? / ?bad? labels on crops from completed images from a large number of subjects. In yet another user study, we evaluated the performance of our automatic crop optimization. In addition to the examples included in this paper, all of our results and comparisons are included in the supplementary material. While there is a substantial amount of previous work on image completion (also referred to as inpainting or image filling), to the best of our knowledge, we are not aware of any methods that can predict quality before completion. In both cases, however, the texture has to be generated first. We now briefly survey representative methods for image completion, which we classify as primarily example-based or diffusionbased. They are less appropriate for completing stitched panoramas with large open-ended missing regions due to their inability to synthesize textures. In addition, they compensate for local brightness changes by linearly fitting the intensity of the matched patch. In addition, they were not designed with performance prediction in mind. Knowing in advance where every missing pixel may come from enables us to predict the perceived quality of the completed result. Using training data, we learn a function that maps low-level features of the closest known image regions to the perceived quality of the completed result. The basic form of the energy minimization problem is Without a random initialization the algorithm tends to exhibit quality issues such as blurry/incorrect textures and semantically implausible results, as shown in Figure 2 . We use a similar heuristic, which uses texture segmentation to select large restriction regions with relatively homogeneous content, in order to facilitate predictability and to achieve continuation of semantic regions. We considered using image segmentation techniques [Jia and Tang 2003], however, it is difficult to control the granularity of the resulting segments. In addition, these segments are non-overlapping, which might lead to artifacts in the form of artificial hard edges in the result. Instead, we oversegment into superpixels and then associate each superpixel with a cluster of similar superpixels surrounding it. These clusters are homogeneous and overlapping as desired. It turned out that the added complexity of these algorithms was not necessary for achieving good results; instead, we partition the entire image into nonoverlapping square tiles, each being 16?16 pixels. For every boundary tile, we compute a ?segment? comprising of surrounding known tiles of sufficiently similar texture (decribed in the next paragraph). Our goal is to construct a function f (v i ) that predicts the unknown label from a feature vector v i . Gentle AdaBoost determines the model parameters e k , t k , l k , and r k by solving the problem",
  "resources" : [ ]
}