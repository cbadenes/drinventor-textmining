{
  "uri" : "sig2008a-a139-ghosh_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2008a/a139-ghosh_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Practical Modeling and Acquisition of Layered Facial Reflectance",
    "published" : "2008",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Abhijeet-Ghosh",
      "name" : "Abhijeet",
      "surname" : "Ghosh"
    }, {
      "uri" : "http://drinventor/Tim-Hawkins",
      "name" : "Tim",
      "surname" : "Hawkins"
    }, {
      "uri" : "http://drinventor/Pieter-Peers",
      "name" : "Pieter",
      "surname" : "Peers"
    }, {
      "uri" : "http://drinventor/Sune-Frederiksen",
      "name" : "Sune",
      "surname" : "Frederiksen"
    }, {
      "uri" : "http://drinventor/Paul E.-Debevec",
      "name" : "Paul E.",
      "surname" : "Debevec"
    } ]
  },
  "bagOfWords" : [ "allow", "fast", "acquisition", "straightforward", "processing", "while", "achieve", "high", "level", "realism", "result", "model", "although", "previous", "research", "have", "capture", "model", "some", "individual", "component", "exist", "system", "have", "acquire", "model", "all", "reflectance", "component", "together", "live", "subject", "we", "demonstrate", "effectiveness", "we", "technique", "both", "qualitative", "visual", "comparison", "well", "quantitative", "validation", "extract", "model", "parameter", "against", "those", "available", "literature", "summary", "principal", "contribution", "work", "Marschner", "al.", "-lsb-", "2000", "-rsb-", "create", "facial", "rendering", "modulate", "diffuse", "component", "brdf", "diffuse", "albedo", "map", "estimate", "from", "multiple", "cross-polarized", "photograph", "face", "work", "assume", "lambertian", "reflection", "model", "ignore", "specular", "reflection", "-lsb-", "Zickler", "et", "al.", "2006", "-rsb-", "we", "estimate", "spatiallyvary", "specular", "reflectance", "parameter", "augment", "high", "fidelity", "normal", "estimate", "also", "include", "single", "scattering", "subsurface", "scattering", "model", "more", "recently", "Donner", "Jensen", "-lsb-", "2006", "-rsb-", "present", "easily", "parameterize", "spectrally-accurate", "version", "multi-layer", "model", "present", "method", "specifically", "design", "minimize", "number", "photograph", "-lrb-", "thus", "acquisition", "time", "-rrb-", "from", "which", "multi-layer", "scattering", "parameter", "can", "estimate", "concentration", "measure", "use", "photograph", "small", "patch", "skin", "nine", "different", "wavelength", "however", "model", "data-intensive", "both", "acquisition", "storage", "additionally", "inclusion", "exist", "render", "system", "require", "significant", "effort", "while", "obtain", "appearance", "model", "yield", "impressive", "result", "still", "require", "minute", "complete", "full", "capture", "consist", "thousand", "image", "contrast", "we", "method", "estimate", "more", "expressive", "facial", "reflectance", "model", "from", "just", "20", "photograph", "capture", "from", "single", "viewpoint", "result", "we", "method", "less", "datum", "intensive", "can", "implement", "high", "resolution", "relatively", "low", "cost", "avoid", "task", "build", "reflectance", "dataset", "from", "image", "from", "multiple", "viewpoint", "before", "discuss", "we", "skin", "reflectance", "model", "Sec", "each", "light", "cover", "linear", "polarizer", "pattern", "-lsb-", "Ma", "et", "al.", "2007", "-rsb-", "additionally", "vertically", "polarize", "lcd", "video", "projector", "aim", "towards", "center", "sphere", "stereo", "pair", "radiometrically", "calibrate", "10Megapixel", "Canon", "1D", "Mark", "III", "digital", "SLR", "camera", "place", "opposite", "side", "projector", "right", "camera", "use", "only", "geometry", "measurement", "horizontally", "polarize", "while", "left", "camera", "switch", "between", "horizontal", "vertical", "polarization", "through", "mechanical", "actuator", "calibration", "purpose", "use", "polarize", "illumination", "tune", "out", "specular", "reflection", "subject", "challenge", "reflectance", "measurement", "we", "have", "two", "different", "illuminant", "we", "setup", "lcd", "projector", "white", "LEDs", "compensate", "difference", "emit", "spectrum", "we", "measure", "response", "24", "ColorChecker", "square", "10", "corresponding", "skin", "patch", "different", "subject", "use", "svd", "we", "compute", "color", "matrix", "transform", "observe", "photograph", "common", "illuminant", "color", "space", "skin", "color", "do", "match", "well", "when", "use", "only", "ColorChecker", "sample", "include", "skin", "sample", "provide", "much", "closer", "match", "between", "different", "color", "space", "addition", "we", "subtract", "reference", "black", "level", "photograph", "subject", "from", "every", "record", "photograph", "under", "project", "illumination", "compensate", "black", "level", "illumination", "from", "projector", "Geometry", "Acquisition", "Accurate", "3d", "geometry", "subject", "require", "faithfully", "model", "subject?s", "skin", "reflectance", "paper", "we", "use", "method", "Ma", "et", "al.", "-lsb-", "2007", "-rsb-", "obtain", "geometry", "from", "stereo", "correspondence", "specular", "normal", "we", "capture", "four", "project", "color", "fringe", "pattern", "3d", "stereo", "reconstruction", "eight", "photograph", "subject", "under", "four", "different", "gradient", "illumination", "condition", "two", "polarization", "direction", "however", "alternative", "method", "can", "measure", "detailed", "facial", "geometry", "accurate", "surface", "normal", "could", "also", "use", "purpose", "addition", "twelve", "photograph", "eight", "more", "photograph", "record", "infer", "appropriate", "reflectance", "scattering", "model", "-lrb-", "sec", "eight", "photograph", "black", "level", "reference", "video", "projector", "-lrb-", "image", "-rrb-", "pair", "crossand", "parallel-polarized", "front-lit", "-lrb-", "i.e.", "full-on", "projector", "pattern", "-rrb-", "image", "model", "specular", "diffuse", "reflectance", "-lrb-", "image", "-rrb-", "four", "phase-shifted", "stripe", "pattern", "separate", "shallow", "deep", "scattering", "-lrb-", "image", "-rrb-", "Recording", "20", "photograph", "take", "just", "seconds", "we", "current", "setup", "major", "limit", "factor", "be", "frame", "rate", "digital", "slr", "camera", "use", "faster", "high", "resolution", "camera", "could", "reduce", "acquisition", "time", "under", "second", "we", "approximate", "skin", "reflectance", "combination", "four", "phenomenon", "specular", "reflection", "single", "scattering", "shallow", "multiple", "scattering", "deep", "multiple", "scattering", "-lrb-", "fig.", "-rrb-", "we", "later", "create", "rendering", "sum", "contribution", "four", "component", "modulate", "light", "receive", "scattering", "component", "appropriate", "transmittance", "term", "remainder", "section", "organize", "follow", "4.1", "introduce", "specular", "single", "scattering", "model", "we", "show", "how", "polarization", "can", "use", "isolate", "phenomenon", "from", "multiple", "subsurface", "scattering", "detail", "which", "datum", "require", "fit", "appropriate", "reflectance", "model", "4.2", "further", "separate", "multiple", "subsurface", "scattering", "deep", "shallow", "scattering", "both", "phenomenon", "generally", "maintain", "polarization", "light", "-lsb-", "Morgan", "Ridgway", "2000", "-rsb-", "multiple", "scattering", "phenomenon", "other", "hand", "generally", "depolarize", "light", "-lsb-", "tuchin", "2007", "-rsb-", "we", "therefore", "acquire", "datum", "under", "polarize", "spherical", "front-lit", "illumination", "record", "paralleland", "crosspolarize", "image", "each", "lighting", "condition", "cross-polarized", "image", "only", "include", "depolarize", "reflect", "light", "-lrb-", "i.e.", "due", "multiple", "scattering", "event", "-rrb-", "whereas", "parallel-polarized", "image", "contain", "both", "polarize", "well", "depolarized", "reflect", "light", "latter", "component", "dominate", "single", "scattering", "because", "probability", "de-polarization", "light", "increase", "exponentially", "each", "additional", "scattering", "event", "-lsb-", "Morgan", "Ridgway", "2000", "-rsb-", "we", "therefore", "treat", "any", "observe", "polarization", "preserve", "non-specular", "reflection", "result", "single", "scattering", "event", "polarization-difference", "image", "Figs.", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "show", "specular", "reflection", "single", "scattering", "face", "under", "spherical", "directional", "illumination", "respectively", "fig.", "-lrb-", "-rrb-", "tion", "region", "-lrb-", "-rrb-", "front-lit", "rendering", "spatially-varying", "specular", "reflectance", "-lrb-", "-rrb-", "front-lit", "render", "both", "spatially-varying", "specular", "reflectance", "model", "single", "scattering", "-lrb-", "-rrb-", "front-lit", "polarization", "difference", "image", "specular", "reflection", "single", "scattering", "graph", "extract", "specular", "distribution", "per", "region", "-lrb-", "-rrb-", "show", "effect", "multiple", "scatter", "illumination", "under", "same", "lighting", "condition", "Specular", "Reflection", "note", "-lsb-", "Debevec", "et", "al.", "2000", "Georghiades", "2003", "-rsb-", "spatially", "vary", "specular", "behavior", "skin", "important", "reproduce", "facial", "appearance", "realistically", "order", "minimize", "number", "measurement", "per-pixel", "estimation", "specular", "lobe", "albedo", "practical", "we", "model", "specular", "roughness", "distribution", "over", "region", "use", "microfacet", "brdf", "model", "however", "keep", "number", "measurement", "small", "we", "only", "use", "backscatter", "measurement", "from", "single", "photograph", "under", "point", "source", "illumination", "-lrb-", "i.e.", "fullon", "projector", "pattern", "-rrb-", "estimate", "per-region", "microfacet", "distribution", "torrence-sparrow", "-lsb-", "1967", "-rsb-", "model", "-lrb-", "-rrb-", "-lrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-rrb-", "-lrb-", "-rrb-", "where", "incident", "light", "direction", "view", "direction", "normalization", "constant", "-lrb-", "corresponding", "specular", "intensity", "we", "case", "-rrb-", "-lrb-", "-rrb-", "normalize", "distribution", "-lrb-", "-rrb-", "fresnel", "reflectance", "term", "base", "Snell?s", "law", "reflection", "geometric", "shadow", "mask", "term", "base", "v-shaped", "groove", "similar", "-lsb-", "Debevec", "et", "al.", "2000", "-rsb-", "we", "replace", "gaussian", "distribution", "original", "Torrance-Sparrow", "model", "data-driven", "distribution", "term", "derive", "directly", "from", "observe", "backscatter", "datum", "we", "extract", "data-driven", "distribution", "manner", "similar", "procedure", "discuss", "-lsb-", "ashikhmin", "2006", "-rsb-", "where", "effect", "Fresnel", "term", "geometric", "term", "assume", "minimal", "backscatter", "direction", "distribution-based", "brdf", "model", "simplify", "function", "proportional", "distribution", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "we", "use", "polarization-difference", "image", "face", "light", "from", "front", "observe", "backscattered", "specular", "reflection", "-lrb-", "addition", "single", "scattering", "-rrb-", "-lrb-", "fig.", "-lrb-", "-rrb-", "-rrb-", "eliminate", "effect", "single", "scattering", "we", "isolate", "region", "where", "specular", "reflection", "dominate", "consider", "only", "pixel", "above", "certain", "brightness", "threshold", "whose", "surface", "normal", "lie", "within", "cone", "45", "from", "view", "direction", "construct", "specular", "distribution", "argument", "45", "threshold", "specular", "lobe", "we", "have", "observe", "face", "much", "sharper", "than", "45", "single", "scattering", "predominately", "direct", "forward", "skin", "observe", "single", "scattering", "therefore", "dominate", "specular", "reflection", "hence", "can", "directly", "use", "estimate", "specular", "lobe", "similar", "angular", "intensity", "separation", "method", "commonly", "use", "tissue", "optics", "literature", "-lsb-", "Morgan", "Ridgway", "2000", "-rsb-", "we", "therefore", "bootstrap", "estimation", "process", "-lrb-", "initially", "-rrb-", "assume", "per-region", "constant", "specular", "intensity", "next", "we", "tabulate", "observe", "reflectance", "value", "against", "halfway", "vector", "correspond", "normal", "direction", "graph", "Fig.", "plot", "distribution", "obtain", "different", "facial", "region", "expect", "measure", "specular", "lobe", "shape", "differ", "different", "region", "finally", "we", "need", "infer", "per-pixel", "specular", "intensity", "we", "observe", "polarization-difference", "image", "under", "constant", "spherical", "illumination", "-lrb-", "e.g.", "fig.", "-lrb-", "-rrb-", "-rrb-", "dominate", "specular", "reflection", "all", "pixel", "unlike", "front-lit", "illuminate", "pixel", "where", "single", "scattering", "can", "dominate", "pixel", "face", "away", "from", "view", "-lrb-", "light", "-rrb-", "direction", "polarization-difference", "image", "under", "spherical", "illumination", "take", "encode", "specular", "intensity", "each", "pixel", "modulate", "view-dependent", "fresnel", "reflectance", "note", "illumination", "condition", "also", "one", "gradient", "pattern", "use", "compute", "surface", "normal", "-lsb-", "Ma", "et", "al.", "2007", "-rsb-", "thus", "additional", "photograph", "need", "record", "from", "we", "can", "estimate", "specular", "intensity", "use", "previously", "extract", "distribution", "factor", "out", "Fresnel", "reflectance", "effect", "assume", "constant", "index", "refraction", "1.38", "skin", "-lsb-", "Donner", "Jensen", "2005", "-rsb-", "formally", "let", "observe", "intensity", "polarizationdifference", "image", "under", "constant", "hemispherical", "illumination", "give", "pixel", "fix", "view", "direction", "follow", "hold", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "divide", "-lrb-", "numerically", "-rrb-", "hemispherically", "integrate", "brdf", "-lrb-", "assume", "1.0", "include", "Fresnel", "reflectance", "-rrb-", "best-fit", "specular", "intensity", "obtain", "further", "refine", "estimation", "specular", "distribution", "-lrb-", "-rrb-", "specular", "intensity", "we", "could", "iteratively", "alternate", "between", "estimate", "-lrb-", "-rrb-", "c.", "however", "we", "find", "single", "pass", "yield", "accurate", "result", "rendering", "obtain", "specular", "component", "under", "directional", "illumination", "from", "front", "can", "see", "Fig.", "-lrb-", "-rrb-", "render", "closely", "follow", "observe", "specular", "reflectance", "Fig.", "-lrb-", "-rrb-", "note", "difference", "between", "both", "due", "single", "scattering", "include", "polarization-difference", "photograph", "single", "scatter", "we", "model", "remain", "single", "scattering", "component", "st", "order", "single", "scattering", "brdf", "model", "Hanrahan", "Krueger", "-lsb-", "1993", "-rsb-", "singlescatter", "-lrb-", "-rrb-", "dt", "-lrb-", "cos", "-rrb-", "-lrb-", "-rrb-", "where", "scattering", "albedo", "dt", "transmittance", "term", "henyey-greenstein", "scattering", "phase", "function", "give", "-lrb-", "cos", "-rrb-", "-lrb-", "+2", "cos", "-rrb-", "3/2", "be", "angle", "between", "incident", "scatter", "direction", "mean", "cosine", "scatter", "angle", "similar", "specular", "lobe", "fit", "henyey-greenstein", "function", "fit", "match", "observe", "backscattering", "polarizationdifference", "image", "under", "directional", "illumination", "we", "assume", "observe", "single", "scattering", "mainly", "due", "top", "layer", "skin", "set", "index", "refraction", "layer", "1.38", "-lsb-", "Donner", "Jensen", "2005", "-rsb-", "furthermore", "we", "use", "observe", "polarizationdifference", "image", "under", "uniform", "spherical", "illumination", "minus", "specular", "intensity", "albedo", "single", "scattering", "fit", "give", "Torrance-Sparrow", "BRDF", "model", "rough", "specular", "surface", "we", "replace", "fresnel", "equation", "transmission", "smooth", "surface", "diffuse", "transmission", "dt", "due", "rough", "specular", "surface", "-lsb-", "ashikhmin", "et", "al.", "2000", "Donner", "Jensen", "2005", "-rsb-", "dt", "dt", "-lrb-", "-rrb-", "dt", "-lrb-", "-rrb-", "where", "dt", "-lrb-", "-rrb-", "1.0", "specular", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "specular", "reflectance", "we", "leverage", "polarizationdifference", "image", "under", "constant", "hemispherical", "illumination", "which", "encode", "per-pixel", "integral", "facilitate", "computation", "we", "build", "look-up", "table", "average", "diffuse", "transmittance", "value", "across", "face", "reduce", "fitting", "observe", "single", "scattering", "above", "brdf", "model", "simple", "search", "best", "channel-wise", "value", "minimize", "RMS", "error", "fit", "observe", "datum", "give", "slowly", "vary", "nature", "datum", "we", "find", "use", "single", "set", "channel-wise", "value", "across", "entire", "face", "sufficient", "front-lit", "rendering", "combined", "single", "scattering", "specular", "component", "show", "-lrb-", "-rrb-", "which", "closely", "match", "reference", "photograph", "Fig.", "-lrb-", "-rrb-", "multiple", "subsurface", "scattering", "light", "skin", "important", "phenomenon", "contribute", "significantly", "its", "soft", "appearance", "-lsb-", "Jensen", "et", "al.", "2001", "-rsb-", "without", "subsurface", "scattering", "rendering", "skin", "look", "too", "harsh", "however", "modeling", "skin", "single", "homogeneous", "scatter", "media", "result", "too", "soft", "waxy", "appearance", "scattering", "-lrb-", "direct", "-rrb-", "component", "-lrb-", "-rrb-", "separate", "deep", "scattering", "-lrb-", "indirect", "-rrb-", "component", "deep", "scattering", "exhibit", "more", "saturated", "coloring", "greater", "amount", "light", "diffusion", "than", "shallow", "scatter", "component", "possible", "physically-based", "model", "appearance", "skin", "represent", "two", "layer", "subsurface", "scattering", "medium", "-lrb-", "fig.", "-rrb-", "contrast", "bottom", "layer", "correspond", "dermi", "which", "-lrb-", "relatively", "-rrb-", "thick", "layer", "reddish", "hue", "due", "blood", "we", "therefore", "use", "approximate", "datadriven", "two-layer", "model", "where", "interface", "between", "both", "layer", "correspond", "only", "approximately", "interface", "between", "different", "skin", "layer", "we", "denote", "two", "scatter", "layer", "shallow", "deep", "emphasize", "we", "do", "precisely", "associate", "they", "specific", "anatomical", "skin", "layer", "measure", "per-pixel", "ratio", "between", "both", "layer", "we", "observe", "shallow", "layer", "scatter", "light", "much", "less", "than", "deep", "layer", "recently", "Nayar", "et", "al.", "-lsb-", "2006", "-rsb-", "present", "method", "separate", "photograph", "direct", "indirect", "component", "use", "high", "frequency", "illumination", "pattern", "scattering", "material", "frequency", "illumination", "pattern", "determine", "which", "part", "scatter", "light", "classify", "direct", "which", "part", "indirect", "we", "make", "observation", "select", "frequency", "pattern", "order", "thickness", "epidermis", "separate", "reflectance", "image", "contain", "deep", "scatter", "only", "image", "contain", "only", "shallow", "scattering", "we", "use", "four", "phase-shifted", "high-frequency", "pattern", "1.2mm-wide", "stripe", "from", "video", "projector", "separate", "component", "show", "Figs.", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "Fig.", "shallow", "scattering", "show", "relatively", "little", "color", "saturation", "relative", "deep", "scattering", "deep", "scattering", "exhibit", "less", "distinct", "texture", "detail", "correspond", "thesis", "direct", "component", "approximately", "correspond", "shallow", "scattering", "light", "epidermis", "while", "indirect", "component", "approximately", "correspond", "light", "which", "have", "scatter", "more", "deeply", "within", "dermi", "propose", "two", "layer", "subsurface", "scattering", "model", "sum", "contribution", "shallow", "deep", "scatter", "layer", "due", "way", "deep", "shallow", "scatter", "layer", "separate", "differ", "from", "-lsb-", "Donner", "Jensen", "2005", "-rsb-", "which", "individual", "layer", "contribution", "convolve", "accord", "Kubelka-Munk", "theory", "respect", "we", "two-layer", "model", "more", "data-driven", "nature", "than", "physically-based", "formally", "multiple", "subsurface", "scattering", "light", "skin", "can", "-lrb-", "-rrb-", "dot", "pattern", "-lrb-", "-rrb-", "full", "illumination", "-lrb-", "-rrb-", "zero-crossing", "-lrb-", "-rrb-", "scatter", "profile", "within", "dot", "-lrb-", "-rrb-", "fitted", "deep", "scatter", "tern", "use", "observe", "scattering", "profile", "-lrb-", "depict", "-lrb-", "-rrb-", "-rrb-", "-lrb-", "-rrb-", "subject", "under", "full", "illumination", "-lrb-", "-rrb-", "zero-crossing", "compute", "from", "subtract", "-lrb-", "-rrb-", "from", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "fitted", "deep", "scatter", "model", "versus", "observe", "scattering", "profile", "two", "different", "region", "note", "poor", "fit", "close", "peak", "because", "observe", "scattering", "profile", "also", "contain", "shallow", "scatter", "effect", "however", "further", "from", "peak", "where", "deep", "scattering", "dominate", "good", "fit", "obtain", "we", "separation", "technique", "further", "yield", "-lrb-", "-rrb-", "deep", "-lrb-", "-rrb-", "shallow", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "we", "employ", "dipole", "diffusion", "model", "approximate", "deep", "scatter", "component", "deep", "-lrb-", "-rrb-", "from", "measure", "scattering", "profile", "assume", "infinitely", "deep", "dermi", "subsequently", "we", "remove", "effect", "deep", "scatter", "from", "measure", "scattering", "profile", "use", "dipole", "fit", "estimate", "scattering", "parameter", "shallow", "scatter", "shallow", "-lrb-", "-rrb-", "use", "multipole", "model", "we", "discuss", "modeling", "both", "layer", "detail", "remainder", "subsection", "deep", "scatter", "we", "model", "deep", "scatter", "component", "use", "dipole", "diffusion", "model", "-lsb-", "Jensen", "et", "al.", "2001", "-rsb-", "??", "tr", "deep", "-lrb-", "-rrb-", "-lrb-", "tr", "-rrb-", "??", "tr", "-lrb-", "tr", "-rrb-", "-lrb-", "-rrb-", "where", "-lrb-", "-rrb-", "distance", "real", "source", "surface", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "distance", "virtual", "source", "surface", "-lrb-", "-rrb-", "require", "estimate", "two", "model", "parameter", "reduce", "albedo", "translucency", "-lrb-", "diffuse", "mean", "free", "path", "-rrb-", "tr", "optically", "dense", "material", "follow", "relation", "hold", "deep", "-lrb-", "??", "-rrb-", "-lrb-", "??", "-rrb-", "-lrb-", "-rrb-", "where", "deep", "diffuse", "albedo", "internal", "reflection", "parameter", "we", "compute", "??", "reflectance", "rough", "specular", "surface", "due", "hemispherical", "illumination", "we", "employ", "per-pixel", "deep", "value", "obtain", "from", "separated", "indirect", "component", "-lrb-", "fig.", "-lrb-", "-rrb-", "-rrb-", "after", "factor", "cosine", "falloff", "compute", "per-pixel", "value", "we", "estimate", "per-region", "-lrb-", "fig.", "-lrb-", "-rrb-", "-rrb-", "translucency", "value", "across", "face", "from", "scattering", "profile", "observe", "project", "-lrb-", "polarize", "-rrb-", "solid", "white", "pattern", "black", "dot", "face", "-lrb-", "fig.", "-lrb-", "-rrb-", "-rrb-", "we", "prefer", "use", "spatially-varying", "diffusion", "parameter", "instead", "use", "modulation", "texture", "we", "model", "result", "finer-scale", "control", "subsurface", "scattering", "while", "do", "achieve", "same", "accuracy", "model", "heterogeneous", "medium", "-lrb-", "i.e.", "skin", "-rrb-", "fully", "data-driven", "method", "-lsb-", "peer", "et", "al.", "2006", "-rsb-", "spatially", "vary", "parameter", "provide", "flexible", "yet", "compact", "approximation", "modeling", "observe", "variation", "different", "region", "face", "however", "extent", "shallow", "scattering", "much", "less", "than", "deep", "scattering", "therefore", "only", "consider", "inner", "two-third", "project", "black", "dot", "effect", "shallow", "scattering", "minimize", "dipole", "fit", "can", "compute", "accurately", "localize", "dot", "boundary", "important", "model", "fitting", "complicate", "blur", "dot", "edge", "scattering", "localize", "dot", "boundary", "we", "subtract", "dot", "image", "from", "fully-lit", "projector", "image", "fig.", "-lrb-", "-rrb-", "obtain", "image", "illuminate", "blurry", "dot", "dark", "background", "zero-crossing", "difference", "between", "negative", "positive", "dot", "image", "reliably", "indicate", "sharp", "estimate", "dot", "boundary", "Fig.", "-lrb-", "-rrb-", "use", "all", "information", "within", "each", "dot", "we", "perform", "radial", "average", "diffusion", "profile", "from", "center", "go", "outwards", "dot", "periphery", "use", "datum", "up", "two-third", "way", "-lrb-", "30", "pixel", "radius", "-rrb-", "fitting", "process", "result", "fitting", "process", "depict", "fig.", "-lrb-", "-rrb-", "can", "see", "fitted", "dipole", "match", "observation", "closely", "last", "two-third", "-lrb-", "fit", "region", "-rrb-", "while", "exhibit", "larger", "error", "first", "third", "scattering", "profile", "-lrb-", "extrapolate", "region", "-rrb-", "finally", "we", "average", "translucency", "estimate", "from", "dot", "each", "region", "blur", "estimate", "across", "region", "boundary", "shallow", "scatter", "most", "first", "third", "scattering", "profile", "observe", "under", "black", "dot", "pattern", "result", "both", "shallow", "deep", "scattering", "deep", "scattering", "estimate", "from", "inner", "two-third", "which", "we", "presume", "negligibly", "influence", "shallow", "scattering", "fig.", "-lrb-", "-rrb-", "illustrate", "effect", "clearly", "use", "estimate", "deep", "scatter", "dipole", "model", "we", "can", "remove", "effect", "deep", "scatter", "from", "observe", "scattering", "profile", "fit", "appropriate", "scatter", "model", "residual", "we", "model", "shallow", "scatter", "top", "epidermal", "layer", "skin", "multipole", "diffusion", "model", "-lsb-", "Donner", "Jensen", "2005", "-rsb-", "-lrb-", "tr", "-rrb-", "??", "tr", "shallow", "-lrb-", "-rrb-", "-lrb-", "tr", "-rrb-", "??", "tr", "we", "employ", "similar", "fitting", "process", "deep", "scatter", "fit", "where", "additional", "lookup", "table", "employ", "residual", "profile", "use", "shallow", "scatter", "albedo", "observe", "from", "separated", "direct", "component", "-lrb-", "fig.", "-lrb-", "-rrb-", "-rrb-", "we", "implementation", "we", "use", "multipole", "model", "five", "dipole", "assume", "layer", "depth", "0.5", "mm", "which", "roughly", "half", "width", "project", "separation", "pattern", "obtain", "fit", "we", "also", "assume", "index", "refraction", "1.38", "top", "layer", "skin", "further", "simplify", "multipole", "fitting", "we", "assume", "change", "index", "refraction", "between", "shallow", "deep", "scatter", "layer", "section", "we", "present", "result", "render", "we", "layered", "facial", "reflectance", "model", "corresponding", "fit", "obtain", "from", "acquire", "datum", "visualize", "result", "we", "modify", "popular", "PBRT", "ray", "tracer", "-lsb-", "pharr", "Humphreys", "2004", "-rsb-", "support", "we", "facial", "reflectance", "model", "render", "subsurface", "scattering", "we", "employ", "photon", "mapping", "-lsb-", "Jensen", "2001", "-rsb-", "add", "dipole", "-lsb-", "Jensen", "et", "al.", "2001", "-rsb-", "multipole", "diffusion", "-lsb-", "Donner", "Jensen", "2005", "-rsb-", "model", "shader", "PBRT", "we", "modify", "photon", "deposition", "phase", "include", "cosine", "incident", "photon", "modulate", "transmittance", "incidence", "during", "render", "phase", "we", "switch", "off", "one-bounce", "gathering", "use", "spatially-varying", "dipole", "multipole", "kernel", "respectively", "density", "estimation", "further", "modulation", "transmittance", "exitance", "we", "believe", "we", "facial", "reflectance", "model", "can", "also", "easily", "incorporate", "production", "render", "pipeline", "-lsb-", "Hery", "2003", "-rsb-", "fig.", "show", "layer", "facial", "reflectance", "which", "comprise", "we", "rendering", "image", "second", "from", "right", "show", "offline", "rendering", "face", "under", "novel", "illumination", "viewpoint", "which", "composition", "layer", "modulate", "corresponding", "transmittance", "term", "right", "validation", "photograph", "from", "side", "which", "use", "reflectance", "modeling", "despite", "significant", "change", "viewpoint", "relative", "lighting", "direction", "render", "closely", "resemble", "photograph", "include", "spatiallyvary", "specular", "subsurface", "reflectance", "because", "we", "setup", "use", "single", "camera", "reflectance", "modeling", "some", "texture", "stretch", "can", "observe", "side", "nose", "without", "correction", "lip", "part", "eyelid", "appear", "darker", "diffuse", "albedo", "than", "reference", "photograph", "because", "albedo", "compute", "from", "image", "under", "full-on", "spherical", "illumination", "which", "include", "partial", "occlusion", "from", "lip", "nose", "respectively", "we", "correct", "estimate", "diffuse", "albedo", "use", "inverse", "simulation", "fig.", "illustrate", "benefit", "we", "layered", "model", "acquire", "reflectance", "datum", "offline", "rendering", "female", "subject", "here", "we", "qualitatively", "compare", "layered", "render", "traditional", "render", "acquire", "datum", "include", "spatially-varying", "specular", "reflectance", "single", "layer", "subsurface", "scattering", "single", "layer", "rendering", "we", "extract", "dipole", "diffusion", "parameter", "from", "project", "dot", "pattern", "similar", "fitting", "process", "deep", "scatter", "layer", "despite", "both", "method", "use", "measure", "datum", "from", "same", "setup", "render", "we", "layered", "reflectance", "model", "additional", "single", "scattering", "shallow", "deep", "multiple", "scattering", "-lrb-", "-rrb-", "look", "much", "more", "skin-like", "compare", "render", "traditional", "model", "measure", "datum", "-lrb-", "-rrb-", "closer", "match", "validation", "photograph", "-lrb-", "-rrb-", "deep", "multiple", "scattering", "fit", "from", "observation", "modulate", "incident", "irradiance", "absorption", "transmittance", "shallow", "scatter", "layer", "hence", "first", "order", "effect", "interaction", "-lrb-", "reflectance", "transmittance", "-rrb-", "between", "shallow", "deep", "scatter", "layer", "automatically", "include", "estimate", "parameter", "deep", "multiple", "scattering", "individual", "layer", "show", "-lrb-", "a-b", "-rrb-", "-lrb-", "f-i", "-rrb-", "fig.", "-lrb-", "-rrb-", "result", "combine", "single", "layer", "subsurface", "scattering", "component", "-lrb-", "-rrb-", "specular", "layer", "-lrb-", "-rrb-", "-lrb-", "+2", "f-stop", "-rrb-", "fig.", "-lrb-", "-rrb-", "result", "combine", "four", "layer", "we", "model", "deep", "multiple", "scattering", "-lrb-", "-rrb-", "shallow", "multiple", "scattering", "-lrb-", "-rrb-", "-lrb-", "+2", "f-stop", "-rrb-", "single", "scattering", "-lrb-", "-rrb-", "-lrb-", "+5", "f-stop", "-rrb-", "specular", "reflectance", "-lrb-", "-rrb-", "-lrb-", "+2", "f-stop", "-rrb-", "note", "how", "deep", "multiple", "scattering", "-lrb-", "-rrb-", "contain", "less", "texture", "detail", "than", "single", "layer", "approximation", "-lrb-", "-rrb-", "which", "turn", "contain", "less", "detail", "than", "shallow", "multiple", "scattering", "layer", "-lrb-", "-rrb-", "Table", "list", "some", "dipole", "diffusion", "parameter", "fit", "we", "obtain", "from", "we", "measurement", "female", "subject", "corresponding", "value", "report", "literature", "means", "quantitative", "validation", "we", "technique", "can", "see", "we", "estimate", "diffusion", "parameter", "closer", "those", "report", "Weyrich", "et", "al.", "-lsb-", "2006", "-rsb-", "face", "than", "those", "report", "Jensen", "et", "al.", "-lsb-", "2001", "-rsb-", "who", "measure", "scattering", "skin", "patch", "forearm", "which", "most", "likely", "more", "translucent", "than", "facial", "skin", "order", "compare", "we", "extract", "specular", "distribution", "Torrance-Sparrow", "model", "those", "report", "literature", "we", "fit", "raw", "datum", "gaussian", "distribution", "roughness", "parameter", "obtain", "region-wise", "fit", "female", "subject", "-lrb-", "nose", "0.2", "eye", "0.25", "forehead", "0.3", "cheek", "0.325", "-rrb-", "very", "similar", "those", "report", "Weyrich", "et", "al.", "-lsb-", "2006", "-rsb-", "we", "also", "estimate", "per-channel", "single", "scattering", "henyey-greenstein", "phase", "function", "parameter", "between", "0.63", "0.7", "compare", "0.75", "report", "-lsb-", "Hanrahan", "Krueger", "1993", "-rsb-", "we", "slightly", "lower", "value", "can", "potentially", "attribute", "approximation", "some", "amount", "polarization", "preserve", "multiple", "scattering", "single", "scattering", "we", "model", "fig.", "show", "render", "result", "from", "five", "acquire", "face", "model", "top", "row", "fig.", "show", "ability", "we", "model", "reproduce", "original", "front-lit", "illumination", "condition", "use", "reflectance", "modeling", "two", "subject", "greenish", "tint", "near", "top", "photograph", "result", "from", "uneven", "color", "cross-polarized", "video", "projector", "use", "illuminant", "corresponding", "rendering", "do", "exhibit", "effect", "since", "albedo", "texture", "derive", "from", "spherical", "led", "illumination", "middle", "row", "fig.", "show", "two", "sideby-side", "rendering", "male", "subject", "light", "skin", "left", "pair", "show", "subject", "from", "original", "left", "camera", "viewpoint", "under", "novel", "illumination", "from", "additional", "point", "light", "source", "right", "camera", "show", "subject", "from", "novel", "viewpoint", "illuminate", "from", "frontal", "video", "projector", "both", "rendering", "substantially", "reproduce", "subject?s", "appearance", "we", "have", "also", "implement", "real-time", "render", "approach", "we", "acquire", "reflectance", "datum", "which", "leverage", "hybrid", "normal", "map", "-lsb-", "Ma", "et", "al.", "2007", "-rsb-", "together", "local", "shade", "model", "include", "infer", "specular", "reflectance", "single", "scattering", "which", "approximate", "subsurface", "scattering", "diffuse", "brdf", "model", "result", "real-time", "rendering", "can", "see", "final", "row", "fig.", "-lrb-", "-rrb-", "where", "male", "subject", "dark", "skin", "render", "from", "novel", "viewpoint", "together", "validation", "photograph", "while", "realtime", "rendering", "technique", "lack", "some", "subtle", "subsur", "face", "scattering", "effect", "we", "believe", "render", "technique", "hybrid", "normal", "map", "could", "useful", "interactive", "application", "technique", "d?Eon", "et", "al.", "-lsb-", "2007", "-rsb-", "could", "potentially", "also", "use", "we", "datum", "albeit", "higher", "computation", "cost", "simulate", "fuller", "range", "subsurface", "scattering", "effect", "real-time", "finally", "female", "subject", "render", "smile", "pose", "makeup", "from", "novel", "viewpoint", "fig.", "-lrb-", "-rrb-", "together", "validation", "photograph", "female", "subject", "could", "capture", "smile", "pose", "due", "short", "five-second", "capture", "process", "would", "difficult", "keep", "steady", "expression", "longer", "acquisition", "time", "we", "data-driven", "facial", "reflectance", "model", "also", "flexible", "enough", "model", "altered", "skin", "reflectance", "Limitations", "general", "we", "rendering", "bear", "close", "resemblance", "original", "photograph", "successfully", "reproduce", "appearance", "wide", "variety", "skin", "tone", "texture", "however", "due", "simplicity", "we", "model", "all", "effect", "model", "equal", "accuracy", "subtle", "difference", "can", "arise", "due", "difference", "specular", "roughness", "diffuse", "reflectance", "within", "facial", "region", "backlighting", "effect", "potentially", "reproduce", "correctly", "we", "model", "because", "dipole", "diffusion", "model", "use", "deep", "scattering", "know", "underestimate", "layered", "transmittance", "-lsb-", "Donner", "Jensen", "2005", "-rsb-", "while", "simplicity", "we", "model", "introduce", "some", "limitation", "also", "make", "practical", "method", "can", "easily", "implement", "exist", "render", "system", "additionally", "because", "we", "model", "can", "infer", "from", "few", "photograph", "require", "physical", "contact", "device", "measure", "scatter", "property", "more", "robust", "change", "due", "subject", "motion", "blood", "flow", "able", "capture", "facial", "appearance", "people", "natural", "facial", "expression", "hard", "maintain", "more", "than", "few", "seconds", "we", "have", "present", "practical", "method", "measure", "modeling", "appearance", "face", "from", "just", "twenty", "photograph", "capture", "from", "single", "viewpoint", "under", "environmental", "project", "illumination", "key", "technique", "separation", "facial", "appearance", "different", "layer", "represent", "specular", "reflectance", "single", "scattering", "shallow", "deep", "multiple", "scattering", "each", "layer", "model", "appropriate", "model", "can", "easily", "incorporate", "exist", "rendering", "system", "we", "method", "first", "practical", "system", "measure", "single", "scattering", "spatially-varying", "multilayer", "scattering", "parameter", "from", "live", "subject", "we", "have", "show", "obtain", "parameter", "quantitatively", "similar", "those", "report", "literature", "result", "rendering", "qualitatively", "close", "match", "reference", "photograph", "present", "system", "due", "its", "short", "acquisition", "time", "enable", "new", "possibility", "analyze", "time-varying", "effect", "facial", "reflectance", "example", "one", "could", "monitor", "change", "skin", "reflectance", "due", "blood", "flow", "sweat", "examine", "effect", "facial", "animation", "appearance", "skin", "finally", "we", "model", "currently", "miss", "model", "asperity", "scattering", "-lsb-", "Koenderink", "Pont", "2003", "-rsb-", "which", "result", "scattering", "thin", "layer", "facial", "hair", "can", "play", "significant", "role", "reproduce", "velvety", "peachy", "facial", "appearance", "many", "subject", "we", "would", "like", "thank", "Tomas", "Pereira", "Wan-Chun", "Ma", "valuable", "input", "Cynthia", "Richards", "David", "Price", "Krishna", "Mamidibathula", "sit", "subject", "Marko", "Vukovic", "Jay", "Busch", "Jen-Yuan", "Chiang", "assistance", "datum", "processing", "Bill", "Swartout", "Randy", "Hill", "Randolph", "Hall", "Max", "Nikias", "support", "assistance", "work", "we", "also", "thank", "Wolfgang", "Heidrich", "we", "annonymous", "reviewer", "valuable", "suggestion", "improve", "paper", "work", "sponsor", "University", "Southern", "California", "Office", "Provost", "U.S.", "Army", "Research", "Development", "Engineering", "command", "-lrb-", "rdecom", "-rrb-", "content", "information", "do", "necessarily", "reflect", "position", "policy", "US", "government", "official", "endorsement", "should", "infer", "-lrb-", "-rrb-", "rendering", "-lrb-", "-rrb-", "Photograph", "-lrb-", "-rrb-", "rendering", "-lrb-", "-rrb-", "Photograph", "-lrb-", "-rrb-", "rendering", "-lrb-", "-rrb-", "Photograph" ],
  "content" : "This allows for fast acquisition and straightforward processing, while achieving a high level of realism in the resulting models. Although previous research has captured and modeled some of these individual components, no existing system has acquired and modeled all of these reflectance components together of a live subject. We demonstrate the effectiveness of our technique with both qualitative visual comparisons as well as quantitative validation of extracted model parameters against those available in the literature. In summary, the principal contributions of this work are: Marschner at al. [2000] create facial renderings by modulating the diffuse component of such a BRDF with the diffuse albedo map estimated from multiple cross-polarized photographs of the face. These works assume a Lambertian reflection model, and ignore specular reflection. As in [Zickler et al. 2006], we estimate spatiallyvarying specular reflectance parameters, but augment this with high fidelity normal estimates and also include single scattering and subsurface scattering models. More recently, Donner and Jensen [2006] presented an easily parameterized, spectrally-accurate version of the multi-layer model. The presented method is specifically designed to minimize the number of photographs (and thus acquisition time) from which multi-layer scattering parameters can be estimated. These concentrations are measured using photographs of a small patch of skin at nine different wavelengths. However, the model is data-intensive in both acquisition and storage. Additionally, inclusion in existing rendering systems requires significant effort. While the obtained appearance model yields impressive results, it still requires a minute to complete a full capture consisting of thousands of images. In contrast, our method estimates a more expressive facial reflectance model from just 20 photographs captured from a single viewpoint. As a result our method is less data intensive, can be implemented in high resolution at a relatively low cost, and avoids the task of building reflectance datasets from images from multiple viewpoints. Before discussing our skin reflectance model in Sec. Each light is covered with a linear polarizer in the pattern of [Ma et al. 2007]. Additionally, a vertically polarized LCD video projector is aimed towards the center of the sphere. A stereo pair of radiometrically calibrated 10Megapixel Canon 1D Mark III digital SLR cameras are placed on opposite sides of the projector. The right camera, used only for geometry measurement, is horizontally polarized while the left camera switches between horizontal and vertical polarization through a mechanical actuator. Calibration The purpose of using polarized illumination is to tune out specular reflections on the subject. A challenge for reflectance measurement is that we have two different illuminants in our setup: the LCD projector, and the white LEDs. To compensate for the differences in emitted spectra, we measure the responses of 24 ColorChecker squares and 10 corresponding skin patches on different subjects. Using SVD, we compute a 3 ? 3 color matrix that transforms the observed photographs to a common illuminant color space. The skin colors did not match well when using only the ColorChecker samples. Including the skin samples provides a much closer match between the different color spaces. In addition, we subtract a reference black level photograph of the subject from every recorded photograph under projected illumination to compensate for the black level illumination from the projector. Geometry Acquisition Accurate 3D geometry of a subject is required to faithfully model the subject?s skin reflectance. In this paper we use the method of Ma et al. [2007] to obtain geometry from stereo correspondence and specular normals. For this we capture four projected color fringe patterns for 3D stereo reconstruction, and eight photographs of the subject under four different gradient illumination conditions and two polarization directions. However, alternative methods that can measure detailed facial geometry with accurate surface normals could also be used for this purpose. In addition to these twelve photographs, eight more photographs are recorded to infer the appropriate reflectance and scattering models (Sec. These eight photographs are: ? A black level reference for the video projector (1 image). ? A pair of crossand parallel-polarized front-lit (i.e., full-on projector pattern) images to model specular and diffuse reflectance (2 images). ? Four phase-shifted stripe patterns to separate shallow and deep scattering (4 images). Recording these 20 photographs takes just 5 seconds with our current setup, with the major limiting factor being the frame rate of the digital SLR cameras. Using faster high resolution cameras could reduce acquisition times to under a second. We approximate skin reflectance as a combination of four phenomena: specular reflection, single scattering, shallow multiple scattering, and deep multiple scattering ( Fig. 2 ). We later create renderings by summing the contributions of these four components, modulating the light received by the scattering components by appropriate transmittance terms. The remainder of this section is organized as follows. 4.1 introduces the specular and single scattering model. We show how polarization can be used to isolate these phenomena from multiple subsurface scattering, and detail which data is required to fit appropriate reflectance models. 4.2 further separates the multiple subsurface scattering into deep, and shallow scattering. Both phenomena generally maintain the polarization of light [Morgan and Ridgway 2000]. Multiple scattering phenomena, on the other hand, generally depolarizes light [Tuchin 2007]. We therefore acquire data under polarized spherical and front-lit illumination, and record paralleland crosspolarized images of each lighting condition. The cross-polarized images only include depolarized reflected light (i.e., due to multiple scattering events), whereas the parallel-polarized images contain both polarized as well as depolarized reflected light. The latter component is dominated by single scattering, because the probability of de-polarization of light increases exponentially with each additional scattering event [Morgan and Ridgway 2000]. We therefore treat any observed polarization preserving non-specular reflection as the result of single scattering events. The polarization-difference images in Figs. 3 (a) and (c) show specular reflections and single scattering on a face under spherical and directional illumination respectively. Figs. 3 (b) and tion into regions. (b) A front-lit rendering of the spatially-varying specular reflectance. (c) A front-lit rendering with both the spatially-varying specular reflectance and modeled single scattering. (d) Front-lit polarization difference image with specular reflection and single scattering. Graph: Extracted specular distributions per region. (d) show the effects of multiple scattered illumination under the same lighting conditions. Specular Reflection As noted in [Debevec et al. 2000; Georghiades 2003], the spatially varying specular behavior of skin is important for reproducing facial appearance realistically. In order to minimize the number of measurements, a per-pixel estimation of the specular lobe and albedo is not practical. We model the specular roughness distributions over a region using a microfacet BRDF model. However, to keep the number of measurement small, we only use backscattering measurements from a single photograph under point source illumination (i.e., a fullon projector pattern) to estimate per-region microfacet distributions for the Torrence-Sparrow [1967] model:\n          ?( k ? 1 , k ? 2 ) = c ? p( ( k ? h)F(r ? 1 ? n)( ? o k ? , 2 k ? ? 2 n) ? ? h)G ? , (1)\n          where k ? 1 is the incident light direction, k ? 2 is the viewing direction, c is a normalization constant (corresponding to specular intensity in our case), p( h) ? is the normalized distribution, F(r 0 , k ? ? h) ? is the Fresnel reflectance term based on Snell?s laws of reflection, and G is the geometric shadowing and masking term based on V-shaped grooves. Similar to [Debevec et al. 2000], we replace the Gaussian distribution in the original Torrance-Sparrow model with a data-driven distribution term derived directly from the observed backscattering data. We extract this data-driven distribution in a manner similar to the procedure discussed in [Ashikhmin 2006], where the effects of the Fresnel term and the geometric term are assumed to be minimal in the backscattering direction, and the distribution-based BRDF model simplifies to a function that is proportional to the distribution p( h): ? ?( k, ? k) ? = c ? r o ? p( h) ? . We use the polarization-difference image of the face lit from the front to observe the backscattered specular reflection (in addition to single scattering) ( Fig. 4(d) ). To eliminate the effects of single scattering, we isolate the regions where specular reflection dominates by considering only pixels above a certain brightness threshold and whose surface normals lie within a cone of 45 ? from the viewing direction for constructing the specular distributions. The argument for a 45 ? threshold is that the specular lobes we have observed for faces are much sharper than 45 ? , and single scattering is predominately directed forward in skin. The observed single scattering is therefore dominated by the specular reflection, and hence can be directly used to estimate the specular lobes. Similar angular and intensity separation methods are commonly used in the tissue optics literature [Morgan and Ridgway 2000]. We therefore bootstrap the estimation process by (initially) assuming a per-region constant specular intensity. Next, we tabulate the observed reflectance values against the halfway vectors corresponding to the normal direction. The graph in Fig. 4 plots distributions obtained for different facial regions. As expected, the measured specular lobe shape differs for the different regions. Finally, we need to infer a per-pixel specular intensity c. We observe that the polarization-difference image under constant spherical illumination (e.g., Fig. 3(a) ) is dominated by the specular reflection for all pixels, unlike front-lit illuminated pixels where single scattering can dominate for pixels facing away from the view (and light) direction. This polarization-difference image under spherical illumination is taken to encode the specular intensity at each pixel modulated by view-dependent Fresnel reflectance. Note that this illumination condition is also one of the gradient patterns used for computing the surface normals [Ma et al. 2007], and thus no additional photograph needs to be recorded. From this we can estimate the specular intensity using the previously extracted distributions, and factor out Fresnel reflectance effects, assuming a constant index of refraction of 1.38 for skin as in [Donner and Jensen 2005]. Formally, let the observed intensity in the polarizationdifference image under constant hemispherical illumination for a given pixel be c , for a fixed viewing direction k ? 2 , then the following holds: c = ?( k ? 1 , k ? 2 )( k ? 1 ? n)d?. ? By dividing c by the (numerically) hemispherically integrated BRDF (assuming c = 1.0, and including Fresnel reflectance) the best-fit specular intensity c is obtained. To further refine the estimation of the specular distribution p( h) ? and specular intensity c, we could iteratively alternate between estimating p( h) ? and c. However, we found that a single pass yields accurate results. A rendering of the obtained specular component under directional illumination from the front can be seen in Fig. 4(b) . This rendering closely follows the observed specular reflectance in Fig. 4(d) . Note that the differences between both are due to the single scattering included in the polarization-difference photograph. Single Scattering We model the remaining single scattering component with the 1 st order single scattering BRDF model of Hanrahan and Krueger [1993]: ? singlescatter ( k ? 1 , k ? 2 ) = ? ? T dt ? p(cos ? ) n ? ? k ? 1 + 1 n ? ? k ? 2 , (3)\n          where ? is the scattering albedo, T dt is the transmittance term, and p is the Henyey-Greenstein scattering phase function given as 1?g 2 p(cos ? ) = 4?(1?g+2g cos ? ) 3/2 , with ? being the angle between incident k ? 1 and scattered k ? 2 directions, and g the mean cosine of the scattering angle. Similar to the specular lobe fits, the Henyey-Greenstein function is fitted to match the observed backscattering in the polarizationdifference image under directional illumination. We assume that the observed single scattering is mainly due to the top layer of skin, and set the index of refraction of this layer to 1.38 as in [Donner and Jensen 2005]. Furthermore, we use the observed polarizationdifference image under uniform spherical illumination minus the specular intensity c as the albedo ? for the single scattering fit. Given that the Torrance-Sparrow BRDF models a rough specular surface, we replace the Fresnel equations for transmission in a smooth surface with diffuse transmission T dt due to the rough specular surface [Ashikhmin et al. 2000; Donner and Jensen 2005]: T dt = ? dt (x, ? i )? dt (x, ? o ), where:\n          ? dt (x, ? o ) = 1.0 ? ? specular (x, k ? 1 , k ? 2 )( n ? s ? k ? 1 )d?. (4)\n          As with the specular reflectance, we leverage the polarizationdifference image under constant hemispherical illumination which encodes this per-pixel integral. To facilitate computations, we build a look-up table for average diffuse transmittance values across the face. This reduces fitting the observed single scattering to the above BRDF model to a simple search for the best channel-wise g values that minimize the RMS error of the fit to the observed data. Given the slowly varying nature of the data, we found that using a single set of channel-wise g values across the entire face is sufficient. A front-lit rendering of the combined single scattering and specular component is shown in 4(c), which closely matches the reference photograph in Fig. 4(d) . Multiple subsurface scattering of light in skin is an important phenomena that contributes significantly to its soft appearance [Jensen et al. 2001]. Without subsurface scattering, renderings of skin look too harsh. However, modeling skin as a single homogeneous scattering media results in a too soft or ?waxy? appearance. scattering (direct) component. (b) Separated deep scattering (indirect) component. Deep scattering exhibits more saturated coloring and a greater amount of light diffusion than the shallow scattering component. A possible physically-based model for the appearance of skin is to represent it as a two layer subsurface scattering medium ( Fig. 2 ). In contrast, the bottom layer corresponds to the dermis, which is a (relatively) thick layer with a reddish hue due to blood. We will therefore use an approximate datadriven two-layer model, where the interface between both layers corresponds only approximately to the interface between the different skin layers. We denote the two scattering layers as shallow and deep to emphasize that we do not precisely associate them with specific anatomical skin layers. To measure the per-pixel ratio between both layers, we observe that the shallow layer scatters light much less than the deep layer. Recently, Nayar et al. [2006] presented a method to separate a photograph into direct and indirect components using high frequency illumination patterns. In scattering materials, the frequency of the illumination patterns determines which part of scattered light is classified as direct, and which part as indirect. We make the observation that selecting the frequency of the patterns to be on the order of the thickness of the epidermis, separates the reflectance into an image containing deep scattering only, and an image containing only shallow scattering. We use four phase-shifted high-frequency patterns of 1.2mm-wide stripes from a video projector. Separated components are shown in Figs. 3 (e) and (f), and Fig. 5 . The shallow scattering shows relatively little color saturation relative to the deep scattering, and the deep scattering exhibits less distinct texture detail. This corresponds to the thesis that the direct component approximately corresponds to the shallow scattering of light in the epidermis while the indirect component approximately corresponds to light which has scattered more deeply within the dermis. The proposed two layer subsurface scattering model sums the contributions of the shallow and deep scattering layers, due to the way the deep and shallow scattering layers are separated. This differs from [Donner and Jensen 2005] in which the individual layers? contributions are convolved according to the Kubelka-Munk theory. In this respect, our two-layer model is more data-driven in nature than physically-based. Formally, the multiple subsurface scattering of light in skin can be (a) Dot pattern (b) Full illumination (c) Zero-crossings (d) Scattering profiles within dots (e) Fitted deep scattering tern used to observe the scattering profiles (depicted in(d)). (b) Subject under full illumination. (c) Zero-crossings computed from subtracting (a) from (b). (e) Fitted deep scattering model versus the observed scattering profile for two different regions. Note that the poor fit close to the peak is because the observed scattering profile also contain shallow scattering effects. However, further from the peak, where deep scattering dominates, a good fit is obtained. Our separation technique then further yields:\n          R d (||x o ? x i ||) = R deep (||x o ? x i ||) + R shallow (||x o ? x i ||). (6)\n          We employ the dipole diffusion model to approximate the deep scattering component R deep (||x o ? x i ||) from measured scattering profiles, assuming an infinitely deep dermis. Subsequently, we remove the effects of deep scattering from the measured scattering profiles using the dipole fit, and estimate scattering parameters for the shallow scattering R shallow (||x o ? x i ||) using the multipole model. We will discuss the modeling of both layers in detail in the remainder of this subsection. Deep Scattering We model the deep scattering component using the dipole diffusion model [Jensen et al. 2001]:\n          ? 1 e ?? tr d r R deep (||x o ? x i ||) = 4? z r (? tr + d r ) d r 2 1 e ?? tr d v + z v (? tr + d v ) d v 2 , (7)\n          where z r (d r ) is the distance of the real source to the surface (x o ), and z v (d v ) is the distance of the virtual source to the surface (x o ). This requires estimating two model parameters: the reduced albedo ? for x o , and translucency (diffuse mean free path) l d = 1/? tr . For optically dense materials, the following relation holds for ? :  ? ? R deep = ? 1 + e ? 4 3 A 3(1?? ) e ? 3(1?? ) , (8) 2 where R deep is the diffuse albedo, and A is the internal reflection parameter that we compute as 1+? 1?? d d with ? d the reflectance of a rough specular surface due to hemispherical illumination. We employ the per-pixel R deep values obtained from the separated indirect component ( Fig. 5(b) ), after factoring in the cosine falloff, to compute per-pixel ? values. We estimate a per-region ( Fig. 4(a) ) translucency value l d across the face from the scattering profiles observed by projecting a (polarized) solid white pattern with black dots on the face ( Fig. 6(a) ). We prefer to use spatially-varying diffusion parameters instead of a using a modulation texture in our model as it results in a finer-scale control of the subsurface scattering. While this does not achieve the same accuracy to model a heterogeneous medium (i.e., skin) as with fully data-driven methods [Peers et al. 2006], the spatially varying parameters provide a flexible, yet compact, approximation for modeling the observed variation in different regions of the face. However, the extent of shallow scattering is much less than that of deep scattering. Therefore, by only considering the inner two-thirds of the projected black dots, the effects of shallow scattering are minimized, and a dipole fit can be computed. Accurately localizing the dot boundaries is important for model fitting and is complicated by the blurring of the dot edges by the scattering. To localize the dot boundaries, we subtract the dot image from the fully-lit projector image Fig. 6(b) , obtaining an image of illuminated blurry dots on a dark background. The zero-crossings of the difference between these negative and positive dot images reliably indicate sharp estimates of the dot boundaries as in Fig. 6(c) . To use all of the information within each dot, we perform a radial average of the diffusion profile from the center going outwards to the dot periphery and use data up to two-thirds of the way (a 30 pixel radius) for the fitting process. Results of this fitting process are depicted in Fig. 6(e) . As can be seen, the fitted dipole matches the observations closely in the last two-thirds (the fitted region), while exhibiting a larger error on the first third of the scattering profiles (extrapolated region). Finally, we average the translucency estimate from the dots in each region and blur the estimates across region boundaries. Shallow Scattering Most of the first third of the scattering profiles observed under the black dot pattern is the result of both shallow and deep scattering. The deep scattering is estimated from the inner two-thirds, which we presume to be negligibly influenced by the shallow scattering. Fig. 6(e) illustrates this effect clearly. Using the estimated deep scattering dipole model, we can remove the effects of deep scattering from the observed scattering profiles, and fit an appropriate scattering model to the residual. We model shallow scattering in the top epidermal layer of skin with the multipole diffusion model [Donner and Jensen 2005]:\n          ? n z r,i (1 + ? tr d r,i )e ?? tr d r,i R shallow (||x o ? x i ||) = 4? i=?n ? d r,i 3 z v,i (1 + ? tr d v,i )e ?? tr d v,i ? . We employ a similar fitting process to the deep scattering fit where an additional lookup table is employed for the residual profile using the shallow scattering albedo observed from the separated direct component ( Fig. 5(a) ). In our implementation, we use the multipole model with five dipoles and assume a layer depth of 0.5mm, which is roughly half the width of the projected separation patterns, for obtaining such a fit. We also assume an index of refraction of 1.38 for the top layer of skin. To further simplify the multipole fitting, we assume that there is no change in the index of refraction between the shallow and deep scattering layers. In this section, we present results rendered with our layered facial reflectance model and the corresponding fits obtained from the acquired data. To visualize the results, we modified the popular PBRT ray tracer [Pharr and Humphreys 2004] to support our facial reflectance model. To render subsurface scattering, we employ photon mapping [Jensen 2001], and added the dipole [Jensen et al. 2001] and multipole diffusion [Donner and Jensen 2005] models as a shader in PBRT. We modify the photon deposition phase to include the cosine of the incident photons and modulate by the transmittance at incidence. During the rendering phase, we switch off one-bounce gathering and use the spatially-varying dipole and multipole kernels respectively for density estimation with further modulation by the transmittance at exitance. We believe our facial reflectance model can also be easily incorporated in production rendering pipelines [Hery 2003]. Fig. 1 shows the layers of facial reflectance which comprise our renderings. The image second from the right shows an offline rendering of the face under novel illumination and viewpoint which is the composition of the layers modulated by the corresponding transmittance terms. At the right is a validation photograph from the side which was not used for reflectance modeling. Despite the significant change in viewpoint and relative lighting direction, the rendering closely resembles the photograph, including the spatiallyvarying specular and subsurface reflectance. Because our setup uses a single camera for reflectance modeling, some texture stretching can be observed at the sides of the nose. Without correction, the lips and parts of the eyelids will appear darker in the diffuse albedo than in the reference photograph, because the albedo is computed from images under full-on spherical illumination which includes partial occlusion from the lips and nose respectively. We correct the estimate of the diffuse albedo using an inverse simulation. Fig. 7 illustrates the benefit of our layered model for acquired reflectance data with offline renderings of a female subject. Here, we qualitatively compare the layered rendering with a traditional rendering with acquired data including spatially-varying specular reflectance + single layer subsurface scattering. For the single layer rendering, we extract dipole diffusion parameters from the projected dot patterns similar to the fitting process for the deep scattering layer. Despite both methods using measured data from the same setup, the rendering with our layered reflectance model with additional single scattering and shallow and deep multiple scattering (e) looks much more skin-like compared to rendering with the traditional model for measured data (c), and is a closer match to the validation photograph (b). The deep multiple scattering is fit from observations that modulate incident irradiance by the absorption and transmittance of the shallow scattering layer. Hence, first order effects of interactions (reflectance and transmittance) between the shallow and deep scattering layers are automatically included in the estimated parameters of deep multiple scattering. The individual layers are shown in (a-b), and (f-i). Fig. 7(c) is the result of combining the single layer subsurface scattering component (a) and the specular layer (b) (+2 f-stops). Fig. 7(e) is the result of combining the four layers in our model: deep multiple scattering (f), shallow multiple scattering (g) (+2 f-stops), single scattering (h) (+5 f-stops), and the specular reflectance (i) (+2 f-stops). Note how the deep multiple scattering (f) contains less texture detail than the single layer approximation (a), which in turn contains less detail than the shallow multiple scattering layer (g). Table 1 lists some of the dipole diffusion parameter fits we obtained from our measurements for the female subject and corresponding values reported in the literature as a means of quantitative validation of our technique. As can be seen, our estimated diffusion parameters are closer to those reported by Weyrich et al. [2006] for faces than those reported by Jensen et al. [2001] who measured the scattering on a skin patch on the forearm which is most likely more translucent than facial skin. In order to compare our extracted specular distributions for the Torrance-Sparrow model to those reported in the literature, we fit the raw data to a Gaussian distribution with roughness parameter m. The obtained region-wise fits of m for the female subject (nose = 0.2, eyes = 0.25, forehead = 0.3, cheeks = 0.325) are very similar to those reported by Weyrich et al. [2006]. We also estimated the per-channel single scattering Henyey-Greenstein phase function parameter g to be between 0.63 ? 0.7 compared to 0.75 reported in [Hanrahan and Krueger 1993]. Our slightly lower values for g can be potentially attributed to the approximation of some amount of polarization preserving multiple scattering as single scattering in our model. Fig. 8 shows rendering results from five acquired face models. The top row of Fig. 8 shows the ability of our model to reproduce the original front-lit illumination condition used for reflectance modeling for two subjects. A greenish tint near the top of the photographs results from uneven color in the cross-polarized video projector used as the illuminant. The corresponding renderings do not exhibit this effect since their albedo texture is derived from the spherical LED illumination. The middle row of Fig. 8 shows two sideby-side renderings of a male subject with light skin. The left pair shows the subject from the original left camera viewpoint but under novel illumination from an additional point light source. The right camera shows the subject from a novel viewpoint, illuminated from the frontal video projector. Both renderings substantially reproduce the subject?s appearance. We have also implemented a real-time rendering approach with our acquired reflectance data which leverages hybrid normal maps [Ma et al. 2007] together with a local shading model that includes the inferred specular reflectance and single scattering, and which approximates subsurface scattering by a diffuse BRDF model. Results of this real-time rendering can be seen in the final row of Fig. 8(i) , where a male subject with dark skin is rendered with from novel viewpoint together with a validation photograph. While the realtime renderings with this technique lack some of the subtle subsur- face scattering effects, we believe that such a rendering technique with hybrid normal maps could be useful for interactive applications. The technique of d?Eon et al. [2007] could potentially also be used with our data, albeit at a higher computation cost, to simulate a fuller range of subsurface scattering effects in real-time. Finally, the female subject is rendered in a smiling pose with makeup from novel viewpoint in Fig. 8(k) together with a validation photograph. The female subject could be captured in a smiling pose due to the short five-second capture process. It would be difficult to keep a steady expression for longer acquisition times. Our data-driven facial reflectance model is also flexible enough to model such altered skin reflectance. Limitations: In general, our renderings bear a close resemblance to the original photographs, successfully reproducing the appearance of a wide variety of skin tones and textures. However, due the simplicity of our model, not all effects are modeled with equal accuracy. Subtle differences can arise due to differences in the specular roughness and diffuse reflectance within facial regions. Backlighting effects are potentially not reproduced correctly with our model because the dipole diffusion model used for deep scattering is known to underestimate layered transmittance [Donner and Jensen 2005]. While the simplicity of our model introduces some limitations, it is also makes it a practical method that can be easily implemented in existing rendering systems. Additionally, because our model can be inferred from a few photographs and requires no physical contact device to measure scattering properties, it is more robust to changes due to subject motion or blood flow, and is able to capture the facial appearance of people in natural facial expressions that are hard to maintain for more than a few seconds. We have presented a practical method for measuring and modeling the appearance of a face from just twenty photographs captured from a single viewpoint under environmental and projected illumination. Key to the technique is the separation of facial appearance into different layers representing specular reflectance, single  scattering, and shallow and deep multiple scattering. Each layer is modeled by an appropriate model that can easily be incorporated in an existing rendering system. Our method is the first practical system that measures single scattering and spatially-varying multilayer scattering parameters from a live subject. We have shown that the obtained parameters are quantitatively similar to those reported in the literature, and that resulting renderings are qualitatively a close match to reference photographs. The presented system, due to its short acquisition times, enables new possibilities for analyzing time-varying effects of facial reflectance. For example one could monitor the change in skin reflectance due to blood flow or sweat, or examine the effects of facial animation on the appearance of skin. Finally, our model is currently missing a model for asperity scattering [Koenderink and Pont 2003], which is the result of scattering in a thin layer of facial hair and can play a significant role in reproducing the ?velvety? or ?peachy? facial appearance of many subjects. We would like to thank Tomas Pereira and Wan-Chun Ma for their valuable input, Cynthia Richards, David Price, and Krishna Mamidibathula for sitting as subjects, Marko Vukovic, Jay Busch, and Jen-Yuan Chiang for their assistance in data processing, Bill Swartout, Randy Hill, Randolph Hall, and Max Nikias for their support and assistance with this work. We also thank Wolfgang Heidrich and our annonymous reviewers for their valuable suggestions for improving the paper. This work was sponsored by the University of Southern California Office of the Provost and the U.S. Army Research, Development, and Engineering Command (RDECOM). The content of the information does not necessarily reflect the position or the policy of the US Government, and no official endorsement should be inferred. (c) Rendering (d) Photograph\n        (g) Rendering (h) Photograph\n        (k) Rendering (l) Photograph",
  "resources" : [ ]
}