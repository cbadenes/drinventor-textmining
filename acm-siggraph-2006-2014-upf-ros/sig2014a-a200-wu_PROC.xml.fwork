{
  "uri" : "sig2014a-a200-wu_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2014a/a200-wu_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Real-time Shading-based Refinement for Consumer Depth Cameras",
    "published" : "2014",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Shahram-Izadi",
      "name" : "Shahram",
      "surname" : "Izadi"
    } ]
  },
  "bagOfWords" : [ "cr", "category", "i.", "3.7", "-lsb-", "Computer", "Graphics", "-rsb-", "digitization", "image", "capture?applications", "i.", "4.8", "-lsb-", "image", "processing", "computer", "Vision", "-rsb-", "scene", "Analysis?Range", "Data", "Keywords", "shading-based", "refinement", "real-time", "depth", "camera", "raise", "question", "can", "type", "shading-based", "refinement", "use", "improve", "depth", "camera", "datum", "only", "leverage", "additional", "RGB", "camera", "which", "most", "sensor", "typically", "provide", "unfortunately", "shading-based", "refinement", "technique", "require", "information", "about", "incident", "lighting", "surface", "material", "scene", "most", "case", "requirement", "fulfil", "make", "assumption", "about", "albedo", "work", "control", "lighting", "-lsb-", "hern?ndez", "et", "al.", "2008", "Fanello", "et", "al.", "2014", "-rsb-", "studio", "setup", "-lsb-", "Ghosh", "et", "al.", "2011", "Debevec", "2012", "Bermano", "et", "al.", "2014", "-rsb-", "when", "move", "general", "uncontrolled", "scene", "sf", "method", "thus", "need", "estimate", "albedo", "illumination", "along", "geometry", "solve", "complex", "inverse", "rendering", "problem", "-lsb-", "Wu", "et", "al.", "2011", "Wu", "et", "al.", "2013", "Han", "et", "al.", "2013", "Yu", "et", "al.", "2013", "-rsb-", "novel", "patch-based", "gauss-newton", "solver", "GPU", "compute", "metrically", "faithful", "geometry", "real-time", "frame-rate", "most", "method", "rely", "heuristic", "assumption", "about", "correlation", "color", "depth", "e.g.", "edge", "both", "channel", "likely", "coincide", "Diebel", "Thrun", "-lsb-", "2006", "-rsb-", "compute", "upsampled", "depth", "use", "Markov-Random", "Field", "implement", "above", "heuristic", "through", "filter", "also", "feasible", "-lsb-", "Lindner", "et", "al.", "2007", "-rsb-", "instance", "use", "joint", "bilateral", "upsampling", "-lsb-", "Kopf", "et", "al.", "2007", "-rsb-", "similar", "idea", "have", "be", "explore", "joint", "reconstruction", "use", "stereo", "image", "depth", "datum", "where", "photometric", "constraint", "from", "stereo", "can", "exploit", "further", "datum", "refinement", "-lsb-", "Beder", "et", "al.", "2007", "Zhu", "et", "al.", "2008", "gudmundsson", "et", "al.", "2008", "-rsb-", "result", "however", "merely", "plausible", "metrically", "accurate", "texture-copy", "artifact", "frequently", "occur", "when", "texture", "variation", "mistake", "geometric", "detail", "one", "final", "set", "method", "increase", "resolution", "single", "depth", "image", "offline", "use", "learn", "database", "local", "patch", "-lsb-", "Aodha", "et", "al.", "2012", "-rsb-", "shape-from-shade", "Photometric", "Stereo", "related", "topic", "acquire", "3d", "shape", "object", "use", "shape-from-shading", "-lrb-", "sf", "-rrb-", "where", "naturally", "occur", "intensity", "pattern", "across", "image", "use", "extract", "3d", "geometry", "from", "single", "image", "-lsb-", "Horn", "1975", "Zhang", "et", "al.", "1999", "-rsb-", "Prados", "Faugeras", "-lsb-", "2005", "-rsb-", "Fanello", "et", "al.", "-lsb-", "2014", "-rsb-", "reconstruct", "various", "object", "include", "face", "use", "controlled", "light", "source", "near", "camera", "center", "Ahmed", "Farag", "-lsb-", "2007", "-rsb-", "demonstrate", "geometry", "estimation", "non-lambertian", "surface", "vary", "illumination", "condition", "make", "strong", "scene", "assumption", "B?hme", "et", "al.", "-lsb-", "2008", "-rsb-", "use", "near", "infrared", "image", "available", "time-of-flight", "-lrb-", "tof", "-rrb-", "camera", "relate", "depth", "intensity", "filter", "however", "unlike", "we", "method", "approach", "limit", "only", "tof", "camera", "collocation", "light", "source", "camera", "run", "offline", "do", "increase", "x/y", "resolution", "image", "recent", "method", "have", "show", "sf", "can", "refine", "coarse", "image-based", "shape", "model", "-lsb-", "Beeler", "et", "al.", "2012", "-rsb-", "even", "be", "capture", "under", "general", "uncontrolled", "lighting", "several", "camera", "-lsb-", "Wu", "et", "al.", "2011", "Wu", "et", "al.", "2013", "-rsb-", "rgb-d", "camera", "-lsb-", "Han", "et", "al.", "2013", "Yu", "et", "al.", "2013", "-rsb-", "end", "illumination", "albedo", "distribution", "well", "refine", "geometry", "find", "via", "inverse", "render", "optimization", "have", "lead", "work", "photometric", "stereo", "where", "multiple", "image", "scene", "capture", "under", "different", "controlled", "illumination", "compute", "geometry", "photometric", "stereo", "have", "demonstrate", "compelling", "reconstruction", "surface", "complex", "reflectance", "property", "-lsb-", "Mulligan", "Brolly", "2004", "Hern?ndez", "et", "al.", "2008", "Ghosh", "et", "al.", "2011", "Tunwattanapong", "et", "al.", "2013", "Debevec", "2012", "Bermano", "et", "al.", "2014", "Nehab", "et", "al.", "2005", "-rsb-", "Barron", "Malik", "-lsb-", "2013b", "-rsb-", "jointly", "solve", "reflectance", "shape", "illumination", "base", "prior", "derive", "statistically", "from", "image", "similar", "concept", "be", "also", "use", "offline", "intrinsic", "image", "decomposition", "rgb-d", "datum", "-lsb-", "Barron", "Malik", "2013a", "-rsb-", "zollh?fer", "et", "al.", "-lsb-", "2014b", "-rsb-", "use", "sf", "fit", "morphable", "face", "model", "rgb", "input", "stream", "Wei", "Hirzinger", "-lsb-", "1996", "-rsb-", "use", "deep", "neural", "network", "learn", "aspect", "physical", "model", "sf", "demonstrate", "moderate", "result", "very", "constrain", "scene", "4.1", "-rrb-", "subsequently", "albedo", "image", "compute", "lambertian", "reflectance", "incident", "irradiance", "function", "know", "smooth", "can", "represent", "only", "little", "error", "use", "first", "nine", "spherical", "harmonic", "basis", "function", "up", "2nd", "order", "-lsb-", "ramamoorthus", "Hanrahan", "2001", "-rsb-", "spherical", "harmonic", "basis", "function", "-lrb-", "-rrb-", "take", "unit", "surface", "normal", "-lrb-", "-rrb-", "input", "evaluate", "surface", "normal", "-lrb-", "-rrb-", "compute", "from", "depth", "map", "after", "apply", "gaussian", "filter", "remove", "noise", "we", "detect", "check", "angle", "between", "normal", "view", "direction", "greater", "than", "78", "-lrb-", "-rrb-", "weight", "which", "constrain", "estimate", "lighting", "similar", "lighting", "previous", "frame", "give", "estimate", "dense", "albedo", "image", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "compute", "GPU", "divide", "-lrb-", "-rrb-", "-lrb-", "-lrb-", "-rrb-", "-rrb-", "see", "eq", "previous", "method", "shading-based", "rgbd", "refinement", "-lsb-", "Han", "et", "al.", "2013", "-rsb-", "follow", "traditional", "two-step", "sf", "strategy", "i.e.", "first", "estimate", "normal", "field", "use", "refine", "depth", "shade", "gradient", "constraint", "smoothness", "constraint", "depth", "constraint", "temporal", "smoothness", "prior", "3d", "position", "-lrb-", "-rrb-", "-lrb-", "camera", "coordinate", "-rrb-", "depth", "point", "distance", "-lrb-", "-rrb-", "from", "camera", "-lrb-", "-rrb-", "where", "-lrb-", "-rrb-", "camera?s", "principal", "point", "focal", "length", "direction", "-lrb-", "-rrb-", "evaluate", "-lrb-", "-rrb-", "-lrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-rrb-", "-lrb-", "-rrb-", "where", "0.25", "Graph", "Laplacian", "weight", "1-ring", "neighborhood", "regular", "image", "triangle", "grid", "-lrb-", "fig.", "-rrb-", "-lrb-", "-rrb-", "compute", "accord", "eq", "where", "refine", "normal", "previous", "frame", "-lrb-", "-rrb-", "pixel", "previous", "frame", "correspond", "pixel", "-lrb-", "-rrb-", "current", "frame", "unlike", "offline", "model-based", "reconstruction", "approach", "where", "pixel", "correspondence", "implicitly", "give", "through", "track", "template", "-lsb-", "Wu", "et", "al.", "2013", "-rsb-", "we", "correspondence", "-lrb-", "-rrb-", "compute", "use", "gpu-based", "iterative", "closest", "point", "-lrb-", "icp", "-rrb-", "-lsb-", "Besl", "McKay", "1992", "-rsb-", "alignment", "between", "current", "previous", "depth", "map", "-lrb-", "-rrb-", "weight", "binary", "mask", "which", "decide", "corresponding", "image", "gradient", "come", "from", "shade", "variation", "albedo", "change", "even", "moderate", "resolution", "objective", "have", "considerable", "amount", "parameter", "-lrb-", "i.e.", "307k", "resolution", "640", "480", "-rrb-", "total", "number", "-lrb-", "9n", "-rrb-", "residual", "term", "depend", "shade", "gradient", "-lrb-", "2n", "term", "-rrb-", "depth", "-lrb-", "term", "-rrb-", "temporal", "-lrb-", "3n", "term", "-rrb-", "smoothness", "constraint", "-lrb-", "3n", "term", "-rrb-", "we", "compute", "solution", "corresponding", "normal", "equation", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "do", "PCG", "step", "-lrb-", "-rrb-", "end", "Write", "result", "global", "memory", "-lrb-", "-rrb-", "end", "end" ],
  "content" : "CR Categories: I.3.7 [Computer Graphics]: Digitization and Image Capture?Applications I.4.8 [Image Processing and Computer Vision]: Scene Analysis?Range Data Keywords: shading-based refinement, real-time, depth camera This raises the question: can this type of shading-based refinement be used to improve depth camera data, only by leveraging an additional RGB camera, which most sensors typically provide. Unfortunately, shading-based refinement techniques require information about the incident lighting and surface material in the scene. In most cases this requirement is fulfilled by making assumptions about albedo, and by working with controlled lighting [Hern?ndez et al. 2008; Fanello et al. 2014], and studio setups [Ghosh et al. 2011; Debevec 2012; Bermano et al. 2014]. When moving to general uncontrolled scenes, SfS methods thus need to estimate albedo and illumination along with the geometry by solving a complex inverse rendering problem [Wu et al. 2011; Wu et al. 2013; Han et al. 2013; Yu et al. 2013]. ? a novel patch-based Gauss-Newton solver on the GPU to compute metrically faithful geometry at real-time frame-rates. Most of these methods rely on heuristic assumptions about the correlation of color and depth, e.g., that edges in both channels likely coincide. Diebel and Thrun [2006] compute the upsampled depth using a Markov-Random Field. Implementing the above heuristics through filtering is also feasible [Lindner et al. 2007], for instance by using joint bilateral upsampling [Kopf et al. 2007]. Similar ideas have been explored for joint reconstruction using stereo images and depth data, where photometric constraints from stereo can be exploited for further data refinement [Beder et al. 2007; Zhu et al. 2008; Gudmundsson et al. 2008]. Their results, however, are merely plausible and not metrically accurate, and texture-copy artifacts frequently occur when texture variations are mistaken for geometric detail. One final set of methods increases the resolution of a single depth image offline using a learned database of local patches [Aodha et al. 2012]. Shape-from-Shading and Photometric Stereo A related topic acquires the 3D shape of an object using shape-from-shading (SfS) where the naturally occurring intensity patterns across an image are used to extract the 3D geometry from a single image [Horn 1975; Zhang et al. 1999]. Prados and Faugeras [2005] and Fanello et al. [2014] reconstruct various objects including faces, using controlled light sources near the camera center. Ahmed and Farag [2007] demonstrate geometry estimation for non-Lambertian surfaces and varying illumination conditions, but make strong scene assumptions. B?hme et al. [2008] use the near infrared image available on time-of-flight (ToF) cameras to relate depth to intensity for filtering. However, unlike our method, their approach is limited to only ToF cameras with collocation of light source and camera, runs offline, and does not increase the X/Y resolution of images. Recent methods have shown that SfS can refine coarse image-based shape models [Beeler et al. 2012], even if they were captured under general uncontrolled lighting with several cameras [Wu et al. 2011; Wu et al. 2013] or an RGB-D camera [Han et al. 2013; Yu et al. 2013]. To this end, illumination and albedo distributions, as well as refined geometry are found via inverse rendering optimization. This has led to work on photometric stereo where multiple images of a scene are captured under different controlled illumination to compute geometry. Photometric stereo has demonstrated compelling reconstructions of surfaces with complex reflectance properties [Mulligan and Brolly 2004; Hern?ndez et al. 2008; Ghosh et al. 2011; Tunwattanapong et al. 2013; Debevec 2012; Bermano et al. 2014; Nehab et al. 2005]. Barron and Malik [2013b] jointly solve for reflectance, shape and illumination, based on priors derived statistically from images. Similar concepts were also used for offline intrinsic image decomposition of RGB-D data [Barron and Malik 2013a]. Zollh?fer et al. [2014b] use SfS to fit a morphable face model to an RGB input stream. Wei and Hirzinger [1996] use deep neural networks to learn aspects of the physical model for SfS, demonstrating moderate results for very constrained scenes. 4.1), and subsequently an albedo image is computed. For Lambertian reflectance, the incident irradiance function is known to be smooth, and can be represented with only little error using the first nine spherical harmonics basis functions up to 2nd order [Ramamoorthi and Hanrahan 2001]. The spherical harmonics basis functions H k (n) take a unit surface normal n = (n x , n y , n z ) as input, and evaluate to: The surface normals n(i, j) are computed from the depth map after applying a Gaussian filter to remove noise. We detect these by checking if the angle between normal and viewing direction is greater than 78 ? . (3), weighted by ? L , which constrains the estimated lighting l to be similar to the lighting l p in the previous frame. Given l, an estimate of a dense albedo image I a with I a (i, j) = k(i, j) is 8 computed on the GPU by dividing I c (i, j) by k=0 l k H k (n(i, j)), see Eq. Previous methods for shading-based RGBD refinement [Han et al. 2013] follow the traditional two-step SfS strategy, i.e., they first estimate the normal field, and then use it to refine the depth. E g is the shading gradient constraint, E s is the smoothness constraint, E p is the depth constraint, and E r is a temporal smoothness prior. The 3D position p(i, j) (in camera coordinates) of a depth point at distance D(i, j) from the camera is: ? (i ? u x )/f x ? where (u x , u y ) is the camera?s principal point, and f x and f y are the focal lengths in x and y direction. (8), this evaluates to: ? D(i,j?1)(D(i,j)?D(i?1,j)) ? f y D(i?1,j)(D(i,j)?D(i,j?1)) n(i,  ? j) = ? ? . where w s = 0.25 is the Graph Laplacian weight for the 1-ring neighborhood on the regular image triangle grid ( Fig. 3 ), and p(i, j) is computed according to Eq. where n is the refined normal in the previous frame, and c(i, j) is the pixel in the previous frame corresponding to pixel (i, j) in the current frame. Unlike offline model-based reconstruction approaches, where pixel correspondences are implicitly given through a tracked template [Wu et al. 2013], our correspondences c(i, j) are computed using a GPU-based iterative closest point (ICP) [Besl and McKay 1992] alignment between current and previous depth maps. (7) to be weighted by a binary mask, which decides if the corresponding image gradient comes from shading variation or albedo change. Even at moderate resolutions, the objective has a considerable amount of parameters (i.e., ? 307k at a resolution of 640 ? 480). The total number (M = 9N ) of residual terms r k depends on the shading gradient (2N terms), depth (N terms), temporal (3N terms) and smoothness constraints (3N terms). We compute the ? ? as the solution of the corresponding normal equations: J(d k ) T J(d k )? = ?J(d k ) T F (d k ). K do PCG Step(p); end for Write Result To Global Memory(p); end for end for",
  "resources" : [ ]
}