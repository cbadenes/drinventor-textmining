{
  "uri" : "sig2011a-a130-dale_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2011a/a130-dale_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Video Face Replacement",
    "published" : "2011",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Mahmoud-Afifi",
      "name" : "Mahmoud",
      "surname" : "Afifi"
    }, {
      "uri" : "http://drinventor/Khaled F.-Hussain",
      "name" : "Khaled F.",
      "surname" : "Hussain"
    }, {
      "uri" : "http://drinventor/Hosny M.-Ibrahim",
      "name" : "Hosny M.",
      "surname" : "Ibrahim"
    }, {
      "uri" : "http://drinventor/Nagwa M.-Omar",
      "name" : "Nagwa M.",
      "surname" : "Omar"
    } ]
  },
  "bagOfWords" : [ "we", "present", "method", "replace", "facial", "performance", "video", "we", "approach", "account", "difference", "identity", "visual", "appearance", "speech", "timing", "between", "source", "target", "video", "unlike", "prior", "work", "do", "require", "substantial", "manual", "operation", "complex", "acquisition", "hardware", "only", "single-camera", "video", "we", "use", "3d", "multilinear", "model", "track", "facial", "performance", "both", "video", "use", "corresponding", "3d", "geometry", "we", "warp", "source", "target", "face", "retime", "source", "match", "target", "performance", "we", "compute", "optimal", "seam", "through", "video", "volume", "maintain", "temporal", "consistency", "final", "composite", "technique", "manipulate", "replace", "face", "photograph", "have", "mature", "point", "realistic", "result", "can", "obtain", "minimal", "user", "input", "-lrb-", "e.g.", "-lsb-", "Agarwala", "et", "al.", "2004", "Bitouk", "et", "al.", "2008", "Sunkavalli", "et", "al.", "2010", "-rsb-", "-rrb-", "Face", "replacement", "video", "however", "pose", "significant", "challenge", "due", "complex", "facial", "geometry", "well", "we", "perceptual", "sensitivity", "both", "static", "dynamic", "element", "face", "paper", "present", "method", "face", "replacement", "video", "achieve", "high-quality", "result", "use", "simple", "acquisition", "process", "unlike", "previous", "work", "we", "approach", "assume", "inexpensive", "hardware", "require", "minimal", "user", "intervention", "use", "single", "camera", "simple", "illumination", "we", "capture", "source", "video", "insert", "target", "video", "-lrb-", "fig.", "-rrb-", "finally", "we", "blend", "video", "compute", "optimal", "spatio-temporal", "seam", "novel", "mesh-centric", "gradient", "domain", "blend", "technique", "we", "system", "replace", "all", "part", "face", "target", "video", "from", "source", "video", "source", "target", "can", "have", "same", "person", "two", "different", "subject", "either", "source", "target", "can", "exist", "-lrb-", "i.e.", "uncontrolled", "-rrb-", "footage", "long", "face", "pose", "-lrb-", "i.e.", "rotation", "translation", "-rrb-", "approximately", "same", "lead", "handful", "unique", "useful", "scenario", "film", "video", "editing", "where", "video", "face", "replacement", "can", "apply", "example", "common", "multiple", "take", "same", "scene", "shoot", "close", "succession", "during", "television", "movie", "shoot", "while", "timing", "performance", "across", "take", "very", "similar", "subtle", "variation", "actor?s", "inflection", "expression", "distinguish", "one", "take", "from", "other", "result", "video", "face", "replacement", "can", "far", "superior", "common", "approach", "replace", "audio", "track", "only", "contrast", "multi-take", "video", "montage", "timing", "dub", "source", "completely", "different", "target", "face", "typically", "fully", "replace", "although", "partial", "replacement", "just", "mouth", "performance", "possible", "too", "here", "new", "footage", "shoot", "use", "old", "footage", "audiovisual", "guide", "timing", "performance", "roughly", "match", "final", "scenario", "replacement", "where", "target", "facial", "performance", "replace", "arbitrary", "source", "performance", "different", "subject", "useful", "example", "when", "replace", "stunt", "actor?s", "face", "capture", "dangerous", "environment", "star", "actor?s", "face", "record", "safe", "studio", "setting", "furthermore", "entertaining", "amateur", "put", "face", "friend", "family", "popular", "movie", "music", "video", "indeed", "active", "community", "user", "YouTube", "have", "form", "share", "video", "despite", "current", "manual", "process", "create", "they", "-lrb-", "e.g.", "search", "Obama", "Dance", "off", "-rrb-", "we", "video", "face", "replacement", "system", "would", "certainly", "benefit", "user", "dramatically", "simplify", "currently", "labor-intensive", "process", "make", "video", "head", "replacement", "difficult", "due", "complexity", "determine", "appropriate", "matte", "region", "contain", "hair", "method", "practical", "amateur", "setting", "also", "time", "consuming", "challenging", "professional", "however", "we", "mitigate", "limitation", "find", "coherent", "spatio-temporal", "seam", "blend", "minimize", "difference", "between", "source", "target", "video", "-lrb-", "sec", "main", "contribution", "paper", "new", "system", "video", "face", "replacement", "do", "require", "expensive", "equipment", "significant", "user", "intervention", "we", "develop", "novel", "spatio-temporal", "seam", "finding", "technique", "work", "mesh", "optimal", "coherent", "blending", "result", "we", "present", "result", "user", "study", "mechanical", "Turk", "demonstrate", "we", "system", "sufficient", "plausible", "face", "replacement", "difficult", "distinguish", "from", "real", "footage", "-lrb-", "sec", "however", "direct", "video-to-video", "face", "transfer", "present", "paper", "have", "be", "relatively", "unexplored", "Face", "Replacement", "Video", "use", "3D", "model", "traditional", "way", "replace", "face", "video", "acquire", "3d", "face", "model", "actor", "animate", "face", "relight", "render", "composite", "animated", "model", "source", "footage", "however", "method", "expensive", "typically", "require", "complex", "hardware", "significant", "user", "intervention", "achieve", "sufficient", "level", "realism", "however", "none", "method", "able", "synthesize", "subtlety", "facial", "performance", "actor", "morphable-model", "Face", "synthesis", "closely", "related", "we", "work", "image-based", "face", "capture", "method", "-lsb-", "Essa", "et", "al.", "1996", "DeCarlo", "Metaxas", "1996", "Pighin", "et", "al.", "1999", "Blanz", "et", "al.", "2003", "Vlasic", "et", "al.", "2005", "-rsb-", "sufficient", "approximate", "fit", "obtainable", "even", "new", "face", "present", "original", "dataset", "all", "example", "paper", "be", "capture", "1-2", "take", "we", "compute", "initial", "pose", "best", "align", "detect", "feature", "corresponding", "source", "feature", "face", "mesh", "give", "column", "vector", "target", "vertex", "position", "we", "can", "compute", "parameter", "th", "attribute", "best", "fit", "target", "geometry", "2011", "-rsb-", "order", "obtain", "better", "initialization", "identity", "parameter", "while", "can", "accomplish", "use", "gradient-domain", "fusion", "-lsb-", "p?rez", "et", "al.", "2003", "-rsb-", "we", "need", "specify", "region", "from", "align", "video", "need", "blended", "target", "video", "alternatively", "seam", "demarcate", "region", "composite", "come", "from", "target", "video", "from", "region", "come", "from", "align", "video", "addition", "seam", "need", "specify", "every", "frame", "composite", "video", "make", "very", "tedious", "user", "do", "while", "similar", "issue", "have", "be", "address", "previous", "work", "-lsb-", "Jia", "et", "al.", "2006", "Agarwala", "et", "al.", "2004", "Kwatra", "et", "al.", "2003", "-rsb-", "we", "problem", "have", "two", "important", "difference", "first", "face", "we", "blend", "often", "undergo", "large", "-lrb-", "rigid", "non-rigid", "-rrb-", "transformation", "seam", "computation", "need", "handle", "we", "formulate", "optimal", "seam", "computation", "problem", "label", "vertex", "face", "mesh", "belong", "source", "target", "video", "edge", "graph", "consist", "spatial", "edge", "correspond", "edge", "mesh", "-lrb-", "i.e.", "all", "edge", "between", "vertex", "-lrb-", "-rrb-", "its", "neighbor", "-lrb-", "-rrb-", "-rrb-", "well", "temporal", "edge", "between", "corresponding", "vertex", "from", "frame", "frame", "-lrb-", "i.e.", "between", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-rrb-", "appearance", "vertex", "-lrb-", "-rrb-", "do", "change", "over", "time", "either", "source", "target", "video", "weight", "term", "take", "large", "value", "thus", "make", "unlikely", "min-cut", "would", "pass", "through", "edge", "thus", "ensure", "vertex", "have", "same", "label", "over", "time", "however", "appearance", "vertex", "do", "change", "-lrb-", "due", "appearance", "feature", "hair", "eyebrow", "etc.", "-rrb-", "temporal", "weight", "drop", "set", "can", "directly", "specify", "user", "one", "single", "frame", "we", "re-use", "face", "mesh", "interpolate", "difference", "any", "give", "result", "total", "interaction", "time", "therefore", "order", "few", "minute", "which", "significantly", "less", "than", "what", "would", "require", "use", "exist", "video", "compositing", "method", "however", "expressiveness", "result", "stem", "exclusively", "from", "morphable", "model", "which", "limited", "lack", "detail", "nuance", "real", "facial", "performance", "video", "however", "matching", "can", "difficult", "novice", "may", "impossible", "source", "target", "from", "exist", "footage", "strong", "difference", "illuminations", "lead", "bleed", "artifact", "because", "sometimes", "possible", "seam", "avoid", "region" ],
  "content" : "We present a method for replacing facial performances in video. Our approach accounts for differences in identity, visual appearance, speech, and timing between source and target videos. Unlike prior work, it does not require substantial manual operation or complex acquisition hardware, only single-camera video. We use a 3D multilinear model to track the facial performance in both videos. Using the corresponding 3D geometry, we warp the source to the target face and retime the source to match the target performance. We then compute an optimal seam through the video volume that maintains temporal consistency in the final composite. Techniques for manipulating and replacing faces in photographs have matured to the point that realistic results can be obtained with minimal user input (e.g., [Agarwala et al. 2004; Bitouk et al. 2008;  Sunkavalli et al. 2010]). Face replacement in video, however, poses significant challenges due to the complex facial geometry as well as our perceptual sensitivity to both the static and dynamic elements of faces. This paper presents a method for face replacement in video that achieves high-quality results using a simple acquisition process. Unlike previous work, our approach assumes inexpensive hardware and requires minimal user intervention. Using a single camera and simple illumination, we capture source video that will be inserted into a target video ( Fig. 1 ). Finally, we blend the videos by computing an optimal spatio-temporal seam and a novel mesh-centric gradient domain blending technique. Our system replaces all or part of the face in the target video with that from the source video. Source and target can have the same person or two different subjects. And either the source or the target can be existing (i.e., uncontrolled) footage, as long as the face poses (i.e., rotation and translation) are approximately the same. This leads to a handful of unique and useful scenarios in film and video editing where video face replacement can be applied. For example, it is common for multiple takes of the same scene to be shot in close succession during a television or movie shoot. While the timing of performances across takes is very similar, subtle variations in the actor?s inflection or expression distinguish one take from the other. The resulting video face replacement can be far superior to the common approach of replacing the audio track only. In contrast to multi-take video montage, the timing of the dubbing source is completely different and the target face is typically fully replaced, although partial replacement of just the mouth performance is possible, too. Here the new footage is shot using the old footage as an audiovisual guide such that the timing of the performances roughly matches. A final scenario is replacement, where the target facial performance is replaced with an arbitrary source performance by a different subject. This is useful, for example, when replacing a stunt actor?s face, captured in a dangerous environment, with the star actor?s face, recorded in a safe studio setting. Furthermore, it is entertaining for amateurs to put faces of friends and family into popular movies or music videos. Indeed, an active community of users on YouTube has formed to share such videos despite the current manual process of creating them (e.g., search for ?Obama Dance Off?). Our video face replacement system would certainly benefit these users by dramatically simplifying the currently labor-intensive process of making these videos. Head replacement is difficult due to the complexities of determining an appropriate matte in regions containing hair. Such methods are not practical in an amateur setting and are also time consuming and challenging for professionals. However, we mitigate this limitation by finding a coherent spatio-temporal seam for blending that minimizes the differences between the source and target videos (Sec. The main contribution of this paper is a new system for video face replacement that does not require expensive equipment or significant user intervention. We developed a novel spatio-temporal seam finding technique that works on meshes for optimal coherent blending results. We present results of a user study on Mechanical Turk that demonstrates that our system is sufficient for plausible face replacement and difficult to distinguish from real footage (Sec. However, the direct video-to-video face transfer presented in this paper has been relatively unexplored. Face Replacement in Video using 3D Models The traditional way to replace faces in video is to acquire a 3D face model of the actor, to animate the face, and to relight, render, and composite the animated model into the source footage. However, these methods are expensive, and typically require complex hardware and significant user intervention to achieve a sufficient level of realism. However, none of these methods are able to synthesize the subtleties of the facial performance of an actor. Morphable-Models for Face Synthesis Closely related to our work are image-based face capture methods [Essa et al. 1996; DeCarlo and Metaxas 1996; Pighin et al. 1999; Blanz et al. 2003; Vlasic et al. 2005]. A sufficient approximate fit is obtainable even for new faces that are not present in the original dataset. All such examples in this paper were captured in 1-2 takes. Then, we compute the initial pose that best aligns the detected features with the corresponding source features in the face mesh. Given A i and a column vector g of target vertex positions, we can compute parameters for the i th attribute that best fit the target geometry as 2011] in order to obtain a better initialization of the identity parameters. While this can be accomplishing using gradient-domain fusion [P?rez et al. 2003], we need to specify the region from the aligned video that needs to be blended into the target video, or alternatively, the seam that demarcates the region in the composite that comes from the target video from the region that comes from the aligned video. In addition, this seam needs to be specified in every frame of the composite video, making it very tedious for the user to do. While a similar issue has been addressed in previous work [Jia et al. 2006; Agarwala et al. 2004; Kwatra et al. 2003], our problem has two important differences. First, the faces we are blending often undergo large (rigid and non-rigid) transformations, and the seam computation needs to be handle this. We formulate the optimal seam computation as a problem of labeling the vertices of the face mesh as belonging to the source or target video. The edges in the graph consist of spatial edges corresponding to the edges in the mesh (i.e., all the edges between a vertex f i (t) and its neighbor f j (t)) as well as temporal edges between corresponding vertices from frame to frame (i.e., between f i (t) and f i (t + 1)). If the appearance of vertex f i (t) does not change over time in either the source or target video, this weight term takes on a large value, thus making it unlikely that the min-cut would pass through this edge, thus ensuring that this vertex has the same label over time. However, if the appearance of the vertex does change (due to the appearance of features such as hair, eyebrows, etc.), the temporal weight drops. This set can be directly specified by the user in one single frame. We re-use the face mesh to interpolate these differences. For any given result, total interaction time is therefore on the order of a few minutes, which is significantly less than what would be required using existing video compositing methods. However, the expressiveness of the result stems exclusively from the morphable model, which is limited and lacks the detail and nuances of real facial performances in video. However such matching can be difficult for novices or may be impossible if the source and target are from existing footage. Strong differences in illuminations will lead to bleeding artifacts because it sometimes is not possible for the seam to avoid such regions.",
  "resources" : [ ]
}