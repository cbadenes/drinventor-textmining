{
  "uri" : "sig2013a-a173-kopf_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2013a/a173-kopf_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Content-Adaptive Image Downscaling",
    "published" : "2013",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Johannes-Kopf",
      "name" : "Johannes",
      "surname" : "Kopf"
    }, {
      "uri" : "http://drinventor/Ariel-Shamir",
      "name" : "Ariel",
      "surname" : "Shamir"
    }, {
      "uri" : "http://drinventor/Pieter-Peers",
      "name" : "Pieter",
      "surname" : "Peers"
    } ]
  },
  "bagOfWords" : [ "we", "test", "we", "algorithm", "wide", "range", "input", "image", "range", "from", "natural", "image", "line", "vector", "art", "all", "result", "be", "create", "same", "algorithm", "setting", "Figure", "13", "other", "figure", "throughout", "paper", "show", "representative", "result", "we", "algorithm", "we", "compare", "we", "method", "na?ve", "subsampling", "bicubic", "filter", "-lrb-", "arguably", "most", "commonly", "use", "rescaling", "algorithm", "-rrb-", "we", "result", "show", "we", "method", "yield", "sharper", "result", "-lrb-", "instance", "text", "-rrb-", "maintain", "detail", "better", "-lrb-", "e.g.", "lunar", "surface", "flower", "Figure", "13", "-rrb-", "preserve", "appearance", "high", "frequency", "texture", "-lrb-", "e.g.", "Figure", "leave", "-rrb-", "supplementary", "material", "we", "provide", "extensive", "comparison", "large", "set", "image", "compare", "we", "method", "wider", "range", "downscale", "method", "-lrb-", "include", "range", "linear", "filter", "unoptimized", "bilateral", "kernel", "Generalized", "sample", "-lsb-", "Nehab", "Hoppe", "2011", "-rsb-", "pixelated", "image", "abstraction", "-lsb-", "Gerstner", "et", "al.", "2012", "-rsb-", "-rrb-", "downscale", "we", "algorithm", "particularly", "well", "suit", "downscale", "cartoon", "vector", "art", "image", "create", "pixel", "art", "figure", "15", "show", "representative", "result", "when", "generate", "result", "we", "disable", "edge", "orientation", "constraint", "-lrb-", "section", "4.2", "-rrb-", "since", "we", "aim", "blocky", "old", "school", "look", "-lrb-", "i.e.", "big", "pixel", "-rrb-", "particular", "note", "we", "algorithm?s", "ability", "keep", "line", "feature", "connect", "comparison", "many", "line", "subsampled", "result", "interrupted", "while", "bicubic", "result", "exhibit", "wash", "out", "color", "due", "excessive", "smoothing", "we", "algorithm", "strike", "balance", "between", "both", "extreme", "keep", "outline", "sharp", "connected", "where", "ACM", "transaction", "Graphics", "Vol", "Article", "173", "publication", "date", "November", "2013", "color", "color", "color", "color", "Gerstner", "et", "al.", "result", "color", "color", "color", "color", "we", "result", "Gerstner", "et", "al.", "we", "result", "16", "color", "16", "color", "possible", "while", "too", "detailed", "area", "naturally", "resolve", "average", "out", "feature", "Extension", "Palette", "Reduction", "one", "particular", "form", "pixel", "art", "also", "include", "reduce", "color", "palette", "-lsb-", "Gerstner", "et", "al.", "2012", "-rsb-", "while", "focus", "we", "method", "we", "be", "interested", "investigate", "effectiveness", "apply", "color", "palette", "reduction", "postprocess", "we", "use", "mean", "shift", "segmentation", "follow", "description", "Comaniciu", "Meer?s", "paper", "-lsb-", "2002", "-rsb-", "-lrb-", "use", "Epanechnikov", "kernel", "fix", "spatial", "bandwidth", "-rrb-", "use", "color", "bandwidth", "parameter", "adjust", "number", "color", "output", "image", "we", "find", "work", "particularly", "well", "cartoon", "vector", "art", "input", "show", "Figure", "type", "image", "we", "method", "produce", "higher", "quality", "result", "than", "Gerstner", "et", "al.", "-lsb-", "2012", "-rsb-", "however", "mainly", "due", "we", "algorithm?s", "ability", "keep", "line", "feature", "connect", "when", "apply", "natural", "image", "however", "we", "find", "mean", "shift", "segmentation", "work", "well", "instead", "we", "use", "simple", "k-means", "clustering", "natural", "image", "where", "produce", "image", "similar", "quality", "Gerstner", "et", "al.", "-lsb-", "2012", "-rsb-", "-lrb-", "Figure", "-rrb-", "verify", "we", "algorithm", "we", "conduct", "formal", "user", "study", "51", "subject", "use", "Amazon", "mechanical", "Turk", "which", "we", "compare", "we", "algorithm", "against", "five", "alternative", "-lrb-", "-rrb-", "Generalized", "sample", "-lsb-", "Nehab", "Hoppe", "2011", "-rsb-", "which", "we", "consider", "state-of-the-art", "algorithm", "image", "scaling", "-lrb-", "-rrb-", "bicubic", "since", "one", "most", "commonly", "use", "scale", "algorithm", "-lrb-", "-rrb-", "subsampling", "its", "simplicity", "-lrb-", "-rrb-", "box", "filter", "because", "yield", "sharper", "result", "than", "bicubic", "-lrb-", "-rrb-", "unoptimized", "bilateral", "kernel", "verify", "effectiveness", "we", "optimization", "each", "test", "we", "show", "participant", "high", "resolution", "-lrb-", "400", "pixel", "long", "side", "-rrb-", "input", "image", "well", "two", "downscale", "re", "result", "user", "study", "compare", "we", "algorithm", "against", "several", "exist", "algorithm", "sult", "-lrb-", "128", "pixel", "-rrb-", "one", "produce", "we", "algorithm", "other", "produce", "one", "compete", "algorithm", "participant", "be", "ask", "which", "result", "represent", "better", "downscale", "version", "input", "image", "have", "choose", "either", "one", "result", "express", "preference", "time", "limit", "impose", "all", "image", "be", "show", "native", "display", "resolution", "participant", "be", "provide", "any", "means", "zoom", "image", "we", "do", "however", "control", "user", "distance", "from", "screen", "better", "simulate", "realistic", "application", "condition", "i.e.", "subject", "could", "move", "closer", "screen", "examine", "detail", "each", "participant", "present", "13", "test", "total", "each", "testing", "we", "algorithm", "against", "random", "compete", "algorithm", "different", "input", "image", "i.e.", "participant", "see", "same", "input", "image", "more", "than", "once", "we", "repeat", "every", "question", "throughout", "test", "filter", "unreliable", "participant", "remove", "all", "answer", "from", "participant", "who", "be", "consistent", "less", "than", "80", "test", "study", "we", "select", "variety", "natural", "image", "from", "MSRA", "Salient", "Object", "database", "-lsb-", "Liu", "et", "al.", "2007", "-rsb-", "span", "different", "category", "include", "people", "stochastic", "regular", "texture", "text", "smooth", "area", "image", "use", "study", "provide", "supplementary", "material", "result", "show", "Figure", "10", "analysis", "between", "each", "condition", "indicate", "we", "algorithm", "significantly", "prefer", "over", "each", "compete", "technique", "we", "method", "employ", "iterative", "optimization", "strategy", "downscale", "image", "consequently", "computationally", "more", "demand", "than", "classical", "linear", "rescaling", "filter", "follow", "we", "analyze", "performance", "we", "C++", "implementation", "run", "Intel", "Xeon", "E5640", "CPU", "2.66", "GHz", "we", "partially", "use", "multiple", "core", "we", "implementation", "we", "have", "fully", "parallelize", "optimize", "implementation", "convergence", "proof", "original", "em-algorithm", "do", "carry", "through", "onto", "we", "algorithm", "due", "we", "modification", "however", "we", "do", "encounter", "convergence", "issue", "several", "thousand", "image", "tested?if", "would", "happen", "one", "could", "simply", "terminate", "algorithm", "after", "fixed", "number", "iteration", "single", "iteration", "we", "algorithm", "linear", "both", "input", "output", "image", "size", "due", "content", "dependent", "nature", "we", "algorithm", "number", "iteration", "vary", "different", "output", "image", "same", "size", "Figure", "11", "report", "runtime", "-lrb-", "blue", "-rrb-", "number", "iteration", "-lrb-", "red", "-rrb-", "average", "over", "processing", "100", "randomly", "select", "natural", "image", "shaded", "region", "indicate", "standard", "deviation", "dash", "line", "indicate", "min?max", "range", "Figure", "11", "left", "output", "size", "keep", "fix", "80", "60", "pixel", "while", "input", "size", "vary", "from", "160", "120", "640", "480", "Figure", "11", "right", "output", "size", "vary", "from", "40", "30", "160", "120", "while", "input", "size", "remain", "fix", "640", "480", "pixel", "ACM", "transaction", "Graphics", "Vol", "Article", "173", "publication", "date", "November", "2013", "varying", "input", "dimension", "fixed", "output", "dimension", "varying", "output", "dimension", "fix", "input", "dimension", "downscale", "we", "algorithm", "particularly", "well", "suit", "downscale", "cartoon", "vector", "art", "image", "create", "pixel", "art", "figure", "15", "show", "representative", "result", "when", "generate", "result", "we", "disable", "edge", "orientation", "constraint", "-lrb-", "section", "4.2", "-rrb-", "since", "we", "aim", "blocky", "old", "school", "look", "-lrb-", "i.e.", "big", "pixel", "-rrb-", "particular", "note", "we", "algorithm?s", "ability", "keep", "line", "feature", "connect", "comparison", "many", "line", "subsampled", "result", "interrupted", "while", "bicubic", "result", "exhibit", "wash", "out", "color", "due", "excessive", "smoothing", "we", "algorithm", "strike", "balance", "between", "both", "extreme", "keep", "outline", "sharp", "connected", "where", "ACM", "transaction", "Graphics", "Vol", "Article", "173", "publication", "date", "November", "2013", "color", "color", "color", "color", "Gerstner", "et", "al.", "result", "color", "color", "color", "color", "we", "result", "Gerstner", "et", "al.", "we", "result", "16", "color", "16", "color", "possible", "while", "too", "detailed", "area", "naturally", "resolve", "average", "out", "feature", "Extension", "Palette", "Reduction", "one", "particular", "form", "pixel", "art", "also", "include", "reduce", "color", "palette", "-lsb-", "Gerstner", "et", "al.", "2012", "-rsb-", "while", "focus", "we", "method", "we", "be", "interested", "investigate", "effectiveness", "apply", "color", "palette", "reduction", "postprocess", "we", "use", "mean", "shift", "segmentation", "follow", "description", "Comaniciu", "Meer?s", "paper", "-lsb-", "2002", "-rsb-", "-lrb-", "use", "Epanechnikov", "kernel", "fix", "spatial", "bandwidth", "-rrb-", "use", "color", "bandwidth", "parameter", "adjust", "number", "color", "output", "image", "we", "find", "work", "particularly", "well", "cartoon", "vector", "art", "input", "show", "Figure", "type", "image", "we", "method", "produce", "higher", "quality", "result", "than", "Gerstner", "et", "al.", "-lsb-", "2012", "-rsb-", "however", "mainly", "due", "we", "algorithm?s", "ability", "keep", "line", "feature", "connect", "when", "apply", "natural", "image", "however", "we", "find", "mean", "shift", "segmentation", "work", "well", "instead", "we", "use", "simple", "k-means", "clustering", "natural", "image", "where", "produce", "image", "similar", "quality", "Gerstner", "et", "al.", "-lsb-", "2012", "-rsb-", "-lrb-", "Figure", "-rrb-", "verify", "we", "algorithm", "we", "conduct", "formal", "user", "study", "51", "subject", "use", "Amazon", "mechanical", "Turk", "which", "we", "compare", "we", "algorithm", "against", "five", "alternative", "-lrb-", "-rrb-", "Generalized", "sample", "-lsb-", "Nehab", "Hoppe", "2011", "-rsb-", "which", "we", "consider", "state-of-the-art", "algorithm", "image", "scaling", "-lrb-", "-rrb-", "bicubic", "since", "one", "most", "commonly", "use", "scale", "algorithm", "-lrb-", "-rrb-", "subsampling", "its", "simplicity", "-lrb-", "-rrb-", "box", "filter", "because", "yield", "sharper", "result", "than", "bicubic", "-lrb-", "-rrb-", "unoptimized", "bilateral", "kernel", "verify", "effectiveness", "we", "optimization", "each", "test", "we", "show", "participant", "high", "resolution", "-lrb-", "400", "pixel", "long", "side", "-rrb-", "input", "image", "well", "two", "downscale", "re", "result", "user", "study", "compare", "we", "algorithm", "against", "several", "exist", "algorithm", "sult", "-lrb-", "128", "pixel", "-rrb-", "one", "produce", "we", "algorithm", "other", "produce", "one", "compete", "algorithm", "participant", "be", "ask", "which", "result", "represent", "better", "downscale", "version", "input", "image", "have", "choose", "either", "one", "result", "express", "preference", "time", "limit", "impose", "all", "image", "be", "show", "native", "display", "resolution", "participant", "be", "provide", "any", "means", "zoom", "image", "we", "do", "however", "control", "user", "distance", "from", "screen", "better", "simulate", "realistic", "application", "condition", "i.e.", "subject", "could", "move", "closer", "screen", "examine", "detail", "each", "participant", "present", "13", "test", "total", "each", "testing", "we", "algorithm", "against", "random", "compete", "algorithm", "different", "input", "image", "i.e.", "participant", "see", "same", "input", "image", "more", "than", "once", "we", "repeat", "every", "question", "throughout", "test", "filter", "unreliable", "participant", "remove", "all", "answer", "from", "participant", "who", "be", "consistent", "less", "than", "80", "test", "study", "we", "select", "variety", "natural", "image", "from", "MSRA", "Salient", "Object", "database", "-lsb-", "Liu", "et", "al.", "2007", "-rsb-", "span", "different", "category", "include", "people", "stochastic", "regular", "texture", "text", "smooth", "area", "image", "use", "study", "provide", "supplementary", "material", "result", "show", "Figure", "10", "analysis", "between", "each", "condition", "indicate", "we", "algorithm", "significantly", "prefer", "over", "each", "compete", "technique", "we", "method", "employ", "iterative", "optimization", "strategy", "downscale", "image", "consequently", "computationally", "more", "demand", "than", "classical", "linear", "rescaling", "filter", "follow", "we", "analyze", "performance", "we", "C++", "implementation", "run", "Intel", "Xeon", "E5640", "CPU", "2.66", "GHz", "we", "partially", "use", "multiple", "core", "we", "implementation", "we", "have", "fully", "parallelize", "optimize", "implementation", "convergence", "proof", "original", "em-algorithm", "do", "carry", "through", "onto", "we", "algorithm", "due", "we", "modification", "however", "we", "do", "encounter", "convergence", "issue", "several", "thousand", "image", "tested?if", "would", "happen", "one", "could", "simply", "terminate", "algorithm", "after", "fixed", "number", "iteration", "single", "iteration", "we", "algorithm", "linear", "both", "input", "output", "image", "size", "due", "content", "dependent", "nature", "we", "algorithm", "number", "iteration", "vary", "different", "output", "image", "same", "size", "Figure", "11", "report", "runtime", "-lrb-", "blue", "-rrb-", "number", "iteration", "-lrb-", "red", "-rrb-", "average", "over", "processing", "100", "randomly", "select", "natural", "image", "shaded", "region", "indicate", "standard", "deviation", "dash", "line", "indicate", "min?max", "range", "Figure", "11", "left", "output", "size", "keep", "fix", "80", "60", "pixel", "while", "input", "size", "vary", "from", "160", "120", "640", "480", "Figure", "11", "right", "output", "size", "vary", "from", "40", "30", "160", "120", "while", "input", "size", "remain", "fix", "640", "480", "pixel", "ACM", "transaction", "Graphics", "Vol", "Article", "173", "publication", "date", "November", "2013", "varying", "input", "dimension", "fixed", "output", "dimension", "varying", "output", "dimension", "fix", "input", "dimension", "we", "have", "present", "novel", "content-adaptive", "image", "downscaling", "method", "adapt", "shape", "its", "downsample", "kernel", "yield", "sharper", "more", "detailed", "downscale", "result", "contrary", "common", "wisdom", "dictate", "frequency", "above", "Nyquist", "frequency", "introduce", "artifact", "downsampled", "image", "-lrb-", "form", "aliasing", "-rrb-", "we", "show", "careful", "sampling", "certain", "high", "frequency", "feature", "can", "still", "preserve", "downscale", "image", "without", "artifact", "give", "grow", "resolution", "gap", "between", "camera", "display", "device", "advent", "gigapixel", "panoramic", "imaging", "we", "believe", "work", "open", "up", "exciting", "area", "research", "plentiful", "avenue", "future", "research", "we", "work", "have", "show", "possible", "sometimes", "drastically", "improve", "quality", "over", "exist", "downscale", "method", "future", "work", "we", "would", "like", "further", "improve", "robustness", "method", "e.g.", "through", "smarter", "heuristic", "so", "we", "method", "always", "outperform", "simpler", "filter", "would", "also", "interesting", "look", "other", "signal", "than", "image", "input", "natural", "immediate", "step", "would", "analyze", "constrain", "temporal", "behavior", "we", "algorithm", "e.g.", "when", "apply", "video" ],
  "content" : "We tested our algorithm on a wide range of input images ranging from natural images to line and vector art. All results were created with the same algorithm settings. Figure 13 and other figures throughout the paper show representative results of our algorithm. We compare our method to na?ve subsampling and the bicubic filter (arguably the most commonly used rescaling algorithms). Our results show that our method yields sharper results (for instance on text), maintains details better (e.g., on the lunar surface or the flower in Figure 13), and preserves the appearance of high frequency textures (e.g., Figure 1 -left). In the supplementary material we provide an extensive comparison on a large set of images, and compare our method to a wider range of downscaling methods (including a range of linear filters, unoptimized bilateral kernels, Generalized Sampling [Nehab and Hoppe 2011], and Pixelated Image Abstraction [Gerstner et al. 2012]). Downscaling: Our algorithm is particularly well suited for downscaling cartoon and vector art images to create pixel art. Figures 1, 8, and 15 show representative results. When generating these results we disabled the edge orientation constraint (Section 4.2), since we are aiming for a blocky ?old school? look (i.e., big pixels). Of particular note is our algorithm?s ability to keep line features connected. In comparison, many lines in the subsampled results are interrupted, while the bicubic results exhibits washed out colors due to excessive smoothing. Our algorithm strikes a balance between both extremes: it keeps outlines sharp and connected where ACM Transactions on Graphics, Vol. 6, Article 173, Publication Date: November 2013\n          5 colors\n          4 colors\n          8 colors 6 colors Gerstner et al.?s results\n          8 colors 6 colors 5 colors 4 colors Our results\n          Gerstner et al., Our result, 16 colors 16 colors\n          possible, while in too detailed areas it naturally resolves to averaging out features. Extension for Palette Reduction: One particular form of pixel art also includes a reduced color palette [Gerstner et al. 2012]. While not the focus of our method, we were interested in investigating the effectiveness of applying color palette reduction in a postprocess. We use mean shift segmentation, following the description of Comaniciu and Meer?s paper [2002] (using the Epanechnikov kernel, and fixed spatial bandwidth h s = 4), and use the color bandwidth parameter h r to adjust the number of colors in the output image. We found that this works particularly well on cartoon and vector art inputs as shown in Figure 8 . On these type of images, our method produces higher quality results than Gerstner et al. [2012]. However, this is mainly due to our algorithm?s ability to keep line features connected. When applied to natural images, however, we found mean shift segmentation to not work well. Instead, we use simple k-means clustering for natural images, where it produces images of similar quality as Gerstner et al. [2012] ( Figure 9 ). To verify our algorithm we conducted a formal user study with 51 subjects using Amazon Mechanical Turk, in which we compare our algorithm against five alternatives: (1) Generalized Sampling [Nehab and Hoppe 2011], which we consider the state-of-the-art algorithm for image scaling, (2) bicubic, since it is one of the most commonly used scaling algorithms, (3) subsampling, for its simplicity, (4) box filtering, because it yields sharper results than bicubic, and (5) unoptimized bilateral kernels, to verify the effectiveness of our optimization. In each test we showed the participant the ?high resolution? (400 pixels on the long side) input image as well as two downscaled re- Results of the user study comparing our algorithm against several existing algorithms. sults (128 pixels), one produced by our algorithm, and the other produced by one of the competing algorithms. Participants were asked which result ?represents a better downscaled version of the input image?, and had to choose either one of the results or express ?no preference?. No time limit was imposed. All images were shown at native display resolution and participants were not provided with any means to zoom into the images. We did not, however, control the user distance from the screen to better simulate realistic application conditions, i.e., subjects could move closer to the screen to examine details. Each participant was presented 13 tests in total, each testing our algorithm against a random competing algorithm on a different input image, i.e., no participant saw the same input image more than once. We repeated every question throughout the test to filter unreliable participants by removing all answers from participants who were consistent on less than 80% of the tests. For the study we selected a variety of natural images from the MSRA Salient Object Database [Liu et al. 2007] that span different categories, including people, stochastic and regular textures, text, and smooth areas. The images used for the study are provided in the supplementary material. Results are shown in Figure 10 . A ? 2 -analysis between each condition indicates that our algorithm was significantly preferred over each of the competing techniques. Our method employs an iterative optimization strategy to downscale images, consequently, it is computationally more demanding than classical linear rescaling filters. In the following we analyze the performance of our C++ implementation, running on a Intel Xeon E5640 CPU at 2.66 GHz. We partially use multiple cores in our implementation, but we have not fully parallelized or optimized the implementation. The convergence proofs of the original EM-Algorithm do not carry through onto our algorithm due to our modifications. However, we did not encounter convergence issues on several thousand images tested?if this would happen one could simply terminate the algorithm after a fixed number of iterations. A single iteration of our algorithm is linear both in the input and output image sizes. Due to the content dependent nature of our algorithm, the number of iterations varies for different in-/output images of the same size. Figure 11 reports the runtime (blue) and number of iterations (red) averaged over processing 100 randomly selected natural images. The shaded region indicates the standard deviation and the dashed lines indicate the min?max ranges. In Figure 11 -left, the output size is kept fixed at 80?60 pixels, while the input size varies from 160?120 to 640?480. In Figure 11 -right, the output size varies from 40?30 to 160?120 while the input size remains fixed at 640?480 pixels. ACM Transactions on Graphics, Vol. 6, Article 173, Publication Date: November 2013\n          Varying input dimensions, fixed output dimensions Varying output dimensions, fixed input dimensions Downscaling: Our algorithm is particularly well suited for downscaling cartoon and vector art images to create pixel art. Figures 1, 8, and 15 show representative results. When generating these results we disabled the edge orientation constraint (Section 4.2), since we are aiming for a blocky ?old school? look (i.e., big pixels). Of particular note is our algorithm?s ability to keep line features connected. In comparison, many lines in the subsampled results are interrupted, while the bicubic results exhibits washed out colors due to excessive smoothing. Our algorithm strikes a balance between both extremes: it keeps outlines sharp and connected where ACM Transactions on Graphics, Vol. 6, Article 173, Publication Date: November 2013\n          5 colors\n          4 colors\n          8 colors 6 colors Gerstner et al.?s results\n          8 colors 6 colors 5 colors 4 colors Our results\n          Gerstner et al., Our result, 16 colors 16 colors\n          possible, while in too detailed areas it naturally resolves to averaging out features. Extension for Palette Reduction: One particular form of pixel art also includes a reduced color palette [Gerstner et al. 2012]. While not the focus of our method, we were interested in investigating the effectiveness of applying color palette reduction in a postprocess. We use mean shift segmentation, following the description of Comaniciu and Meer?s paper [2002] (using the Epanechnikov kernel, and fixed spatial bandwidth h s = 4), and use the color bandwidth parameter h r to adjust the number of colors in the output image. We found that this works particularly well on cartoon and vector art inputs as shown in Figure 8 . On these type of images, our method produces higher quality results than Gerstner et al. [2012]. However, this is mainly due to our algorithm?s ability to keep line features connected. When applied to natural images, however, we found mean shift segmentation to not work well. Instead, we use simple k-means clustering for natural images, where it produces images of similar quality as Gerstner et al. [2012] ( Figure 9 ). To verify our algorithm we conducted a formal user study with 51 subjects using Amazon Mechanical Turk, in which we compare our algorithm against five alternatives: (1) Generalized Sampling [Nehab and Hoppe 2011], which we consider the state-of-the-art algorithm for image scaling, (2) bicubic, since it is one of the most commonly used scaling algorithms, (3) subsampling, for its simplicity, (4) box filtering, because it yields sharper results than bicubic, and (5) unoptimized bilateral kernels, to verify the effectiveness of our optimization. In each test we showed the participant the ?high resolution? (400 pixels on the long side) input image as well as two downscaled re- Results of the user study comparing our algorithm against several existing algorithms. sults (128 pixels), one produced by our algorithm, and the other produced by one of the competing algorithms. Participants were asked which result ?represents a better downscaled version of the input image?, and had to choose either one of the results or express ?no preference?. No time limit was imposed. All images were shown at native display resolution and participants were not provided with any means to zoom into the images. We did not, however, control the user distance from the screen to better simulate realistic application conditions, i.e., subjects could move closer to the screen to examine details. Each participant was presented 13 tests in total, each testing our algorithm against a random competing algorithm on a different input image, i.e., no participant saw the same input image more than once. We repeated every question throughout the test to filter unreliable participants by removing all answers from participants who were consistent on less than 80% of the tests. For the study we selected a variety of natural images from the MSRA Salient Object Database [Liu et al. 2007] that span different categories, including people, stochastic and regular textures, text, and smooth areas. The images used for the study are provided in the supplementary material. Results are shown in Figure 10 . A ? 2 -analysis between each condition indicates that our algorithm was significantly preferred over each of the competing techniques. Our method employs an iterative optimization strategy to downscale images, consequently, it is computationally more demanding than classical linear rescaling filters. In the following we analyze the performance of our C++ implementation, running on a Intel Xeon E5640 CPU at 2.66 GHz. We partially use multiple cores in our implementation, but we have not fully parallelized or optimized the implementation. The convergence proofs of the original EM-Algorithm do not carry through onto our algorithm due to our modifications. However, we did not encounter convergence issues on several thousand images tested?if this would happen one could simply terminate the algorithm after a fixed number of iterations. A single iteration of our algorithm is linear both in the input and output image sizes. Due to the content dependent nature of our algorithm, the number of iterations varies for different in-/output images of the same size. Figure 11 reports the runtime (blue) and number of iterations (red) averaged over processing 100 randomly selected natural images. The shaded region indicates the standard deviation and the dashed lines indicate the min?max ranges. In Figure 11 -left, the output size is kept fixed at 80?60 pixels, while the input size varies from 160?120 to 640?480. In Figure 11 -right, the output size varies from 40?30 to 160?120 while the input size remains fixed at 640?480 pixels. ACM Transactions on Graphics, Vol. 6, Article 173, Publication Date: November 2013\n          Varying input dimensions, fixed output dimensions Varying output dimensions, fixed input dimensions We have presented a novel content-adaptive image downscaling method that adapts the shape of its downsampling kernel, yielding sharper and more detailed downscaled results. Contrary to common wisdom that dictates that frequencies above the Nyquist frequency introduce artifacts in the downsampled image (in the form of aliasing), we show that by careful sampling, certain high frequencies features can still be preserved in the downscaled image without artifacts. Given the growing ?resolution gap? between cameras and display devices and the advent of gigapixel panoramic imaging, we believe that this work opens up an exciting area of research. There are plentiful avenues for future research. Our work has shown that it is possible to sometimes drastically improve quality over existing downscaling methods. For future work we would like to further improve the robustness of the method, e.g., through smarter heuristics, so that our method always outperforms simpler filters. It would also be interesting to look at other signals than images as inputs. A natural immediate step would be to analyze and constrain the temporal behavior of our algorithm, e.g., when applying it to videos.",
  "resources" : [ ]
}