{
  "uri" : "sig2014-a37-su_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2014/a37-su_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Estimating Image Depth Using Shape Collections",
    "published" : "2014",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Hao-Su",
      "name" : "Hao",
      "surname" : "Su"
    }, {
      "uri" : "http://drinventor/Qixing-Huang",
      "name" : "Qixing",
      "surname" : "Huang"
    }, {
      "uri" : "http://drinventor/Niloy J.-Mitra",
      "name" : "Niloy J.",
      "surname" : "Mitra"
    }, {
      "uri" : "http://drinventor/Yangyan-Li",
      "name" : "Yangyan",
      "surname" : "Li"
    }, {
      "uri" : "http://drinventor/Leonidas J.-Guibas",
      "name" : "Leonidas J.",
      "surname" : "Guibas"
    } ]
  },
  "bagOfWords" : [ "cr", "category", "i.", "3.5", "-lsb-", "Computer", "Graphics", "-rsb-", "computational", "geometry", "object", "modeling?geometric", "algorithm", "image", "remain", "far", "most", "popular", "visual", "medium", "nowadays", "easy", "acquire", "distribute", "contain", "rich", "visual", "detail", "can", "easily", "view", "understand", "result", "ubiquitous", "web", "example", "important", "part", "object", "may", "occluded", "depth", "datum", "typically", "miss", "most", "common", "classical", "approach", "match", "input", "image", "set", "3d", "object", "database", "-lrb-", "i.e.", "prior", "-rrb-", "use", "best", "matching", "shape", "fill", "miss", "depth", "information", "moreover", "propose", "approach", "robust", "variation", "texture", "lighting", "condition", "key", "novelty", "show", "how", "single", "modestly-sized", "shape", "network", "can", "help", "infer", "depth", "information", "variety", "image", "object", "same", "class", "use", "learn", "deformation", "model", "base", "align", "shape", "network", "compensate", "fact", "image", "from", "model", "directly", "present", "database", "regularize", "model", "deformation", "use", "multi-way", "3d", "alignment", "between", "initial", "image", "point", "cloud", "shape", "neighborhood", "shape", "network", "process", "extract", "depth", "information", "image", "we", "also", "discover", "good", "correspondence", "between", "image", "network", "shape", "enable", "we", "connect", "image", "network", "transfer", "complementary", "information", "back", "forth", "data-driven", "geometry", "processing", "already", "Trimble", "3d", "warehouse", "contain", "many", "thousand", "example", "model", "per", "category", "most", "indoor", "object", "some", "popular", "outdoor", "category", "car", "airplane", "key", "task", "data-driven", "geometry", "processing", "technique", "establish", "high-quality", "correspondence", "-lrb-", "either", "pointor", "segment-level", "-rrb-", "across", "geometric", "object", "most", "exist", "image-shape", "match", "approach", "-lsb-", "cyr", "Kimia", "2004", "Xu", "et", "al.", "2011", "Wang", "et", "al.", "2013", "-rsb-", "convert", "problem", "image", "matching", "problem", "i.e.", "match", "image", "project", "view", "3d", "shape", "typically", "from", "estimate", "dense", "correspondence", "between", "silhouette", "curve", "interpolate", "correspondence", "interior", "pixel", "-lsb-", "Sun", "et", "al.", "2011", "-rsb-", "use", "icp-like", "approach", "recently", "Wang", "et", "al.", "-lsb-", "2013", "-rsb-", "propose", "technique", "directly", "estimate", "correspondence", "between", "entire", "image", "object", "practice", "technique", "limit", "match", "very", "similar", "object", "pose", "estimation", "exist", "vast", "body", "work", "determine", "pose", "object", "image", "relative", "calibrate", "camera", "thus", "can", "distinguish", "type", "local", "image", "feature", "point", "line", "curve", "segment", "whole", "contour", "-lsb-", "Chen", "et", "al.", "2003", "Dalal", "Triggs", "2005", "Oliva", "Torralba", "2006", "-rsb-", "recently", "researcher", "use", "learning-based", "scheme", "cast", "classification", "learn", "good", "feature", "viewpoint", "estimation", "-lsb-", "Zia", "et", "al.", "2013", "-rsb-", "depth", "estimation", "estimate", "depth", "image", "object", "long", "standing", "problem", "computer", "vision", "computer", "graphic", "other", "word", "do", "apply", "well", "man-made", "object", "real", "image", "which", "exhibit", "complicated", "geometry", "texture", "availability", "large", "collection", "depth", "image", "recent", "depth", "estimation", "approach", "base", "supervised", "learning", "-lsb-", "Hoiem", "et", "al.", "2005", "Saxena", "et", "al.", "2009", "-rsb-", "give", "exemplar", "depth", "image", "approach", "learn", "conditional", "probabilistic", "distribution", "pixel", "depths", "relative", "depths", "between", "neighbor", "pixel", "apply", "learn", "distribution", "infer", "depth", "information", "new", "image", "objective", "function", "minimize", "distance", "between", "point", "cloud", "deform", "shape", "deformation", "prior", "directly", "learn", "shape", "inherit", "several", "structure-preserving", "property", "-lrb-", "e.g.", "symmetry", "part", "structure", "-rrb-", "from", "shape", "collection", "objective", "function", "combine", "distance", "term", "which", "evaluate", "distance", "between", "corresponding", "point", "induce", "point", "cloud", "deform", "similar", "shape", "two", "prior", "term", "deformation", "model", "depth", "formation", "respectively", "embedded", "deformation", "consist", "list", "control", "point", "associate", "basis", "function", "-lrb-", "-rrb-", "give", "point", "its", "deform", "counterpart", "linear", "combination", "control", "point", "refer", "-lsb-", "Sumner", "et", "al.", "2007", "-rsb-", "how", "construct", "embedded", "deformation", "model", "shape", "let", "vector", "collect", "all", "transform", "control", "point", "let", "original", "control", "point", "other", "direction", "give", "pixel", "-lrb-", "-rrb-", "depth", "parameter", "specify", "its", "coordinate", "corresponding", "point", "give", "use", "dense", "correspondence", "we", "compute", "coordinate", "corresponding", "point", "each", "pixel", "-lrb-", "-rrb-", "-lrb-", "camera", "coordinate", "system", "-rrb-", "average", "z-coordinate", "corresponding", "point", "similar", "shape", "first", "term", "evaluate", "sum", "square", "distance", "between", "corresponding", "point", "here", "weight", "adjust", "higher", "more", "reliable", "correspondence", "-lrb-", "-rrb-" ],
  "content" : "CR Categories: I.3.5 [Computer Graphics]: Computational Geometry and Object Modeling?Geometric algorithms. Images remain by far the most popular visual medium. Nowadays they are easy to acquire and distribute, contain rich visual detail, can easily be viewed and understood and, as a result, are ubiquitous  in the Web. For example, important parts of objects may be occluded, and depth data is typically missing. The most common and classical approach is to match the input image to a set of 3D objects in a database (i.e., priors), and use the best matching shape to fill in missing depth information. Moreover, the proposed approach is robust to variations in textures and lighting conditions. The key novelties are: ? showing how a single modestly-sized shape network can help infer depth information for a variety of image objects of the same class; ? using learned deformation models based on an aligned shape network to compensate for the fact that the image is not from a model directly present in the database; ? regularizing model deformations using multi-way 3D alignment between the initial image point cloud and the shapes in a neighborhood of the shape network; In the process of extracting depth information on an image, we also discover good correspondences between the image and the network shapes, enabling us to connect the image to the network and transfer complementary information back and forth. Data-driven geometry processing. Already the Trimble 3D warehouse contains many thousands of example models per category for most indoor objects and some popular outdoor categories such as car and airplane. The key task in data-driven geometry processing technique is to establish high-quality correspondences (at either pointor segment-level) across geometric objects. Most existing image-shape matching approaches [Cyr and Kimia 2004; Xu et al. 2011; Wang et al. 2013] convert the problem into an image matching problem, i.e., matching images with projected views of 3D shapes. They typically start from estimating dense correspondences between silhouette curves, and then interpolate correspondences to interior pixels. [Sun et al. 2011] used an ICP-like approach. Recently, Wang et al. [2013] proposed a technique that directly estimates correspondences between entire image objects. In practice, these techniques are limited to matching very similar objects. Pose estimation. There exists a vast body of work to determine the pose of an object in an image relative to a calibrated camera. Thus, they can be distinguished by the type of local image features, such as points, lines, curve segments, whole contours [Chen et al. 2003; Dalal and Triggs 2005; Oliva and Torralba 2006]. Recently, researchers used learning-based scheme to cast it as a classification and learn good features for viewpoint estimation [Zia et al. 2013]. Depth estimation. Estimating the depth of an image object is a long standing problem in computer vision and computer graphics. In other words, they do not apply well on man-made objects in real images, which exhibit complicated geometries and textures. With the availability of large collection of depth images, recent depth estimation approaches are based on supervised learning [Hoiem et al. 2005; Saxena et al. 2009]. Given exemplar depth images, these approaches learn conditional probabilistic distributions of pixel depths and relative depths between neighboring pixels, and apply the learned distributions to infer the depth information of new images. The objective function minimizes the distance between the point cloud and the deformed shapes. As the deformation prior is directly learned by shapes, it inherits several structure-preserving properties (e.g., symmetry, part structure) from the shape collection. The objective function combines a distance term, which evaluates the distance between the corresponding points on the induced point cloud and the deformed similar shapes, and two prior terms on the deformation models and the depth in- formation, respectively. An embedded deformation consists of a list of control points p ? ? J and the associated basis functions B ? (?). Given a point x ? R 3 , its deformed counterpart is a linear combination of the control points: Refer to [Sumner et al. 2007] on how to construct embedded deformation models on shapes. Let c i,j be the vector that collects all transformed control points. Let c 0 i be the original control points. In the other direction, given a pixel p = (p x , p y ) T and a depth parameter z p specifying its z coordinate in ? C , the corresponding point in ? is given by Using the dense correspondences, we compute the z coordinate of the corresponding point of each pixel p = (p x , p y ) (in the camera coordinate system of C ? ) by averaging z-coordinates of the corresponding points of similar shapes: The first term evaluates the sum of squared distances between the corresponding points:  Here, p is a weight that is adjusted to be higher for more reliable correspondence (p, q i ).",
  "resources" : [ ]
}