{
  "uri" : "sig2013a-a173-kopf_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2013a/a173-kopf_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Content-Adaptive Image Downscaling",
    "published" : "2013",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Johannes-Kopf",
      "name" : "Johannes",
      "surname" : "Kopf"
    }, {
      "uri" : "http://drinventor/Ariel-Shamir",
      "name" : "Ariel",
      "surname" : "Shamir"
    }, {
      "uri" : "http://drinventor/Pieter-Peers",
      "name" : "Pieter",
      "surname" : "Peers"
    } ]
  },
  "bagOfWords" : [ "c63732b2c12e0a5e6a39396fb0701f014532d58e191f00c305f9908e26d18020", "p3a", "10.1145", "2508363.2508370", "name", "identification", "possible", "content-adaptive", "image", "downscale", "Johannes", "Kopf", "Ariel", "Shamir", "Microsoft", "Research", "Interdisciplinary", "Center", "Input", "Lanczos", "we", "result", "figure", "previous", "content-insensitive", "downscaling", "method", "have", "compromise", "between", "preserve", "sharpness", "while", "introduce", "aliasing", "artifact", "-lrb-", "e.g.", "subsample", "-rrb-", "prevent", "aliase", "expense", "smooth", "out", "fine", "detail", "edge", "-lrb-", "e.g.", "Bicubic", "Lanczos", "etc.", "-rrb-", "we", "new", "content-adaptive", "algorithm", "provide", "more", "balanced", "result", "crisp", "contain", "neither", "noise", "nor", "ringing", "mostly", "avoid", "aliase", "artifact", "-lrb-", "Merlon", "input", "image", "Nintendo", "Co.", "Ltd.", "-rrb-", "paper", "introduce", "novel", "content-adaptive", "image", "downscale", "method", "key", "idea", "optimize", "shape", "location", "downsample", "kernel", "better", "align", "local", "image", "feature", "we", "content-adaptive", "kernel", "form", "bilateral", "combination", "two", "gaussian", "kernel", "define", "over", "space", "color", "respectively", "yield", "continuum", "range", "from", "smooth", "edge/detail", "preserve", "kernel", "drive", "image", "content", "we", "optimize", "kernel", "represent", "input", "image", "well", "find", "output", "image", "from", "which", "input", "can", "well", "reconstruct", "technically", "realize", "iterative", "maximum-likelihood", "optimization", "use", "constrain", "variation", "expectation-maximization", "algorithm", "comparison", "previous", "downscale", "algorithm", "we", "result", "remain", "crisper", "without", "suffer", "from", "ring", "artifact", "besides", "natural", "image", "we", "algorithm", "also", "effective", "create", "pixel", "art", "image", "from", "vector", "graphic", "input", "due", "its", "ability", "keep", "linear", "feature", "sharp", "connected", "cr", "category", "i.", "4.1", "-lsb-", "Computer", "Graphics", "-rsb-", "image", "processing", "computer", "vision?sampling", "keyword", "image", "downscale", "Links", "dl", "pdf", "EB", "ODE", "introduction", "downscaling", "perhaps", "most", "commonly", "use", "image", "operation", "today", "we", "rarely", "view", "photo", "we", "just", "take", "its", "original", "resolution", "anymore", "instead", "instantly", "reduce", "from", "its", "original", "ACM", "Reference", "Format", "Kopf", "J.", "Shamir", "A.", "Peers", "P.", "2013", "content-adaptive", "image", "downscaling", "ACM", "Trans", "graph", "32", "Article", "173", "-lrb-", "November", "2013", "-rrb-", "page", "dous", "10.1145", "2508363.2508370", "http://doi.acm.org/10.1145/2508363.2508370", "copyright", "Notice", "permission", "make", "digital", "hard", "copy", "all", "part", "work", "personal", "classroom", "use", "grant", "without", "fee", "provide", "copy", "make", "distribute", "profit", "commercial", "advantage", "copy", "bear", "notice", "full", "citation", "fus", "rst", "page", "copyright", "component", "work", "own", "other", "than", "author", "-lrb-", "-rrb-", "must", "honor", "abstract", "credit", "permit", "copy", "otherwise", "republish", "post", "server", "redistribute", "list", "require", "prior", "specific", "permission", "and/or", "fee", "request", "permission", "from", "permissions@acm.org", "2013", "copyright", "hold", "Owner/Author", "publication", "rights", "license", "ACM", "0730-0301/13", "11-art173", "15.00", "DOI", "http://dx.doi.org/10.1145/2508363.2508370", "ACM", "transaction", "Graphics", "Vol", "32", "no.", "Article", "173", "publication", "date", "November", "2013", "Pieter", "Peers", "College", "William", "Mary", "Input", "Bilateral", "we", "result", "-lrb-", "-rrb-", "subsampling", "-lrb-", "-rrb-", "bicubic", "-lrb-", "-rrb-", "we", "result", "-lrb-", "-rrb-", "Input", "Figure", "subsampled", "bicubic", "we", "algorithm", "balancing", "sharpness", "antialiasing", "result", "sharp", "everywhere", "suffer", "severely", "from", "noise", "aliasing", "other", "hand", "result", "over-smoothe", "detail", "face", "avoid", "both", "problem", "produce", "crisp", "noise-free", "image", "exhibit", "only", "minimal", "aliasing", "multi-megapixel", "size", "much", "smaller", "dimension", "view", "camera", "viewfinder", "computer", "mobile", "screen", "web", "de", "facto", "standard", "image", "downscaling", "linear", "filter", "originate", "from", "signal", "processing", "community", "-lsb-", "wolberg", "1990", "-rsb-", "here", "image", "first", "convolve", "low-pass", "kernel", "reduce", "bandwidth", "before", "resample", "final", "resolution", "filter", "push", "image", "below", "Nyquist", "frequency", "prevent", "aliasing", "side", "effect", "result", "might", "suffer", "from", "loss", "fine", "detail", "blur", "sharp", "edge", "-lrb-", "figure", "2c", "-rrb-", "sharpen", "image", "use", "kernel", "more", "closely", "model", "sinc", "filter", "-lrb-", "e.g.", "lanczo", "-rrb-", "can", "cause", "ringing", "-lrb-", "figure", "-rrb-", "while", "simply", "subsample", "image", "without", "prefilter", "typically", "lead", "strong", "aliasing", "artifact", "-lrb-", "figure", "2b", "-rrb-", "because", "all", "method", "content-invariant", "-lrb-", "i.e.", "use", "invariant", "kernel", "-rrb-", "tradeoff", "between", "preserve", "detail", "prevent", "aliasing", "global", "work", "we", "present", "new", "content-adaptive", "downscaling", "algorithm", "classic", "method", "output", "pixel", "compute", "weighted", "sum", "input", "pixel", "can", "interpret", "associate", "average", "kernel", "every", "output", "pixel", "we", "key", "idea", "adapt", "shape", "kernel", "order", "better", "align", "they", "local", "image", "feature", "-lrb-", "figure", "2d", "-rrb-", "follow", "previous", "technique", "bilateral", "filter", "-lsb-", "Tomasi", "Manduchi", "1998", "-rsb-", "mean", "shift", "-lsb-", "Comaniciu", "et", "al.", "2002", "-rsb-", "we", "use", "kernel", "combination", "spatial", "gaussian", "kernel", "ensure", "locality", "color", "space", "gaussian", "kernel", "alignment", "image", "content", "simple", "parametric", "form", "kernel", "achieve", "good", "trade-off", "between", "173:2", "J.", "Kopf", "et", "al.", "Input", "Lanczos", "Bicubic", "we", "result", "sharpen", "Figure", "Lanczos", "kernel", "photoshop?s", "sharpen", "filter", "come", "expense", "ring", "artifact", "due", "negative", "lobe", "oscillation", "kernel", "we", "kernel", "strictly", "positive", "mostly", "without", "oscillation", "yield", "result", "practically", "free", "ring", "artifact", "Figure", "use", "average", "kernel", "downscale", "-lrb-", "-rrb-", "linear", "filum", "small", "number", "parameter", "optimize", "sufficient", "flexibility", "ter", "associate", "same", "averaging", "kernel", "every", "output", "pixel", "take", "shape", "image", "feature", "we", "formulate", "problem", "force", "global", "compromise", "between", "smoothing", "aliasing", "-lrb-", "-rrb-", "constrain", "reconstruction", "problem", "optimize", "set", "kerunoptimize", "bilateral", "kernel", "adapt", "image", "might", "miss", "nel", "whose", "combination", "would", "best", "reconstruct", "original", "image", "image", "feature", "depend", "placement", "center", "-lrb-", "e.g.", "optimize", "kernel", "constrain", "remain", "compact", "simple", "dial", "plate", "number", "-rrb-", "-lrb-", "-rrb-", "we", "optimize", "kernel", "adapt", "blob-shaped", "since", "correspond", "simple", "pixel", "image", "even", "more", "do", "suffer", "from", "miss", "disconnect", "output", "image", "color", "output", "pixel", "compute", "sum", "feature", "kernel-weighted", "input", "pixel", "color", "classic", "method", "all", "kernel", "have", "same", "shape", "arrange", "ring", "artifact", "near", "strong", "image", "edge", "-lrb-", "figure", "-rrb-", "many", "filin", "regular", "grid", "-lrb-", "figure", "4b", "-rrb-", "use", "just", "bilateral", "kernel", "without", "opter", "-lrb-", "e.g.", "bilinear", "bicubic", "etc.", "-rrb-", "have", "be", "develop", "-lsb-", "Wolberg", "timize", "parameter", "can", "align", "they", "image", "feature", "how1990", "-rsb-", "even", "mine", "from", "image", "datum", "-lsb-", "trigg", "2001", "-rsb-", "balance", "ever", "just", "like", "subsampling", "method", "might", "miss", "feature", "mathematical", "optimality", "perceptual", "quality", "downsamdepend", "location", "center", "-lrb-", "figure", "4c", "-rrb-", "we", "kernel", "plead", "result", "recent", "development", "-lsb-", "Nehab", "Hoppe", "2011", "-rsb-", "add", "also", "align", "themselves", "curved", "feature", "image", "since", "correction", "stage", "discrete", "signal", "before", "reconstruction", "resultthey", "optimize", "represent", "input", "image", "better", "tend", "ing", "less", "ringing", "similar", "computational", "cost", "however", "miss", "feature", "-lrb-", "figure", "4d", "-rrb-", "property", "particular", "impornone", "technique", "filter", "kernel", "adapt", "image", "tance", "when", "downscale", "image", "contain", "fine", "line", "like", "cartoon", "content?a", "filter", "remove", "aliase", "one", "area", "might", "produce", "art", "-lrb-", "figure", "15", "-rrb-", "ringing", "another", "contrast", "we", "method", "adapt", "shape", "location", "every", "kernel", "local", "image", "content", "produce", "sharper", "we", "local", "kernel", "parameter", "derive", "through", "iterative", "maxresult", "since", "we", "kernel", "strictly", "positive", "mostly", "without", "imum", "likelihood", "optimization", "use", "constrain", "variation", "oscillation", "we", "result", "practically", "free", "ring", "artifact", "expectation-maximization", "algorithm", "optimization", "yield", "continuum", "local", "kernel", "single", "framework", "range", "from", "different", "class", "algorithm", "focus", "retargeting", "image", "smoothing", "some", "place", "edge/detail", "preserve", "filter", "other", "different", "aspect", "ratio", "while", "preserve", "salient", "content", "depend", "local", "image", "content", "locally", "control", "sharpness", "image", "much", "possible", "-lrb-", "e.g.", "-lsb-", "Avidan", "Shamir", "Wolf", "against", "antialiasing", "we", "achieve", "good", "balance", "both", "objective", "et", "al.", "2007", "Rubinstein", "et", "al.", "2009", "Karni", "et", "al.", "2009", "-rsb-", "-rrb-", "however", "we", "algorithm", "also", "useful", "downscale", "cartoon", "vector", "method", "mostly", "gear", "towards", "alter", "aspect", "ratio", "art", "can", "also", "combine", "palette", "reduction", "create", "pixel", "only", "suit", "moderate", "reduction", "resolution", "-lrb-", "e.g.", "25", "art", "imagery", "because", "pixel", "usually", "appear", "bigger", "image", "50", "-rrb-", "furthermore", "retargeting", "method", "focus", "preserve", "blur", "linear", "resampling", "filter", "show", "even", "more", "severely", "salient", "content", "thus", "can", "alter", "global", "image", "composition", "subsample", "can", "produce", "sharp", "result", "take", "only", "fracour", "method", "other", "hand", "maintain", "image", "composition", "tion", "input", "pixel", "account", "might", "miss", "feature", "much", "possible", "can", "lead", "broken", "feature", "disconnect", "line", "we", "optimize", "kernel", "also", "produce", "crisp", "pixel", "art", "while", "minimize", "broken", "thumbnail", "creation", "can", "also", "view", "method", "reduce", "disconnect", "feature", "-lrb-", "see", "Figure", "15", "-rrb-", "size", "image", "Suh", "et", "al.", "-lsb-", "2003", "-rsb-", "propose", "compute", "thumbnail", "selectively", "crop", "scale", "image", "guide", "face", "detector", "we", "test", "we", "algorithm", "wide", "range", "natural", "vector", "saliency", "map", "Samadani", "et", "al.", "-lsb-", "2007", "-rsb-", "preserve", "original", "apgraphic", "input", "image", "we", "compare", "we", "result", "against", "extensive", "pearance", "thumbnail", "reintroduce", "artifact", "blur", "set", "alternative", "downscale", "method", "addition", "we", "perform", "noise", "lose", "downscale", "Trentacoste", "et", "al.", "-lsb-", "2011", "-rsb-", "also", "reina", "user", "study", "validate", "perceptual", "quality", "we", "result", "we", "troduce", "blur", "preview", "image", "camera?s", "view", "finder", "base", "method", "especially", "improve", "quality", "downscale", "image", "exon", "perceptual", "model", "instead", "preserve", "blur", "appearance", "hibit", "small", "detail", "stochastic", "texture", "input", "image", "we", "method", "target", "opposite", "selectively", "remove", "blur", "preserve", "small", "image", "detail", "texture", "previous", "work", "Gerstner", "et", "al.", "-lsb-", "2012", "-rsb-", "abstract", "image", "low", "resolution", "representation", "reduce", "color", "palette", "algorithm", "alternate", "classical", "image", "downscale", "technique", "find", "origin", "sambetween", "update", "slic", "-lrb-", "simple", "linear", "iterative", "clustering", "-rrb-", "superpling", "theory", "-lsb-", "Shannon", "1949", "-rsb-", "prefilter", "reconstruct", "sigpixel", "-lsb-", "Achanta", "et", "al.", "2012", "-rsb-", "refine", "color", "palette", "similar", "nal", "spatially", "constant", "lowpass", "filter", "order", "prevent", "aliasour", "method", "SLIC", "also", "work", "joint", "5d", "space", "location", "ing", "reconstructed", "signal", "however", "suppress", "high", "frecolor", "however", "slic", "segment", "image", "-lrb-", "i.e.", "hard", "assignment", "-rrb-", "quency", "also", "tend", "blur", "signal", "filter", "design", "whereas", "we", "method", "produce", "soft", "assignment", "input", "output", "more", "closely", "model", "-lrb-", "theoretically", "ideal", "-rrb-", "sinc", "filter", "pixel", "allow", "we", "better", "adapt", "underlie", "high", "resolution", "Lanczos", "come", "expense", "negative", "lobe", "can", "produce", "image", "ACM", "transaction", "Graphics", "Vol", "32", "no.", "Article", "173", "publication", "date", "November", "2013", "result", "Kernels", "Reconst", "-lrb-", "-rrb-", "input", "-lrb-", "-rrb-", "bicubic", "-lrb-", "-rrb-", "bilateral", "-lrb-", "-rrb-", "we", "result", "content-adaptive", "image", "downscale", "173:3", "Manson", "Schaefer", "-lsb-", "2012", "-rsb-", "present", "method", "generate", "mipmap", "adapt", "filter", "texture", "content", "surface", "parameterization", "Inglis", "Kaplan", "-lsb-", "2012", "-rsb-", "present", "method", "rasterize", "vector", "line", "art", "low", "resolution", "use", "rule", "establish", "pixel", "artist", "avoid", "certain", "artifact", "like", "jaggy", "preserve", "local", "continuity", "however", "contrast", "general", "downsampling", "strategy", "employ", "we", "method", "above", "technique", "downsample", "image", "content", "base", "application", "specific", "rule", "algorithm", "find", "local", "filter", "kernel", "we", "formulate", "we", "task", "reconstruction", "problem", "input", "image", "from", "smaller", "set", "local", "kernel", "function", "-lrb-", "probability", "density", "function", "-rrb-", "fix", "color", "define", "joint", "5d", "space", "location", "color", "we", "interpret", "each", "input", "image", "pixel", "sample", "draw", "randomly", "from", "one", "local", "kernel", "uniform", "probability", "sampling", "local", "kernel", "theoretically", "kernel", "can", "have", "any", "shape", "location", "however", "since", "correspond", "output", "pixel", "number", "constraint", "kernel", "necessary", "due", "application", "image", "downscaling", "first", "number", "kernel", "must", "equal", "number", "output", "pixel", "hence", "kernel", "can", "vanish", "during", "optimization", "second", "position", "can", "vary", "too", "much", "from", "output", "pixel", "grid", "size", "can", "vary", "too", "much", "from", "output", "pixel", "size", "Third", "prevent", "aliasing", "artifact", "we", "add", "orientation", "constraint", "describe", "section", "denote", "-lcb-", "-rcb-", "input", "image", "pixel", "-lrb-", "-rrb-", "where", "spatial", "coordinate", "corresponding", "CIELAB", "color", "pixel", "i.", "each", "reconstructed", "image", "pixel", "color", "define", "weighted", "sum", "kernel", "color", "-lrb-", "-rrb-", "where", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "unknown", "-rrb-", "weight", "kernel", "pixel", "relative", "all", "kernel", "overlap", "pixel", "-lrb-", "also", "unknown", "-rrb-", "kernel", "domain", "-lrb-", "-rrb-", "-lsb-", "-rsb-", "bilateral", "gaussian", "kernel", "we", "case", "i.e.", "we", "denote", "value", "kernel", "pixel", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "where", "normalization", "factor", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "ensure", "each", "probability", "density", "function", "-lrb-", "i.e.", "integrate", "-rrb-", "spatial", "component", "color", "component", "give", "-lrb-", "-rrb-", "exp", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "exp", "where", "mean", "covariance", "matrix", "spatial", "Gaussian", "mean", "variance", "color", "space", "Gaussian", "note", "spatial", "Gaussian", "characterize", "full", "covariance", "matrix", "can", "therefore", "take", "elliptical", "shape", "while", "color", "space", "Gaussian", "characterize", "only", "scalar", "variance", "remain", "isotropic", "we", "operate", "perceptually", "uniform", "cielab", "color", "space", "give", "we", "input", "image", "we", "search", "most", "probable", "set", "parameter", "-lcb-", "-rcb-", "kernel", "set", "unknown", "variable", "-lrb-", "-rrb-", "can", "produce", "-lrb-", "reconstruct", "-rrb-", "image", "use", "baye", "rule", "convert", "maximize", "-lrb-", "log", "-rrb-", "likelihood", "input", "image", "give", "model", "set", "kernel", "argmax", "pr", "-lrb-", "-rrb-", "problem", "well", "know", "statistics", "solve", "use", "expectation-maximization", "-lrb-", "em", "-rrb-", "algorithm", "-lsb-", "Hastie", "et", "al.", "2005", "-rsb-", "where", "unknown", "variable", "-lrb-", "-rrb-", "can", "see", "probability", "pixel", "draw", "from", "kernel", "k.", "ACM", "transaction", "Graphics", "Vol", "32", "no.", "Article", "173", "publication", "date", "November", "2013", "we", "initialize", "kernel", "correspond", "output", "pixel", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "10", "where", "-lrb-", "-rrb-", "center", "output", "pixel", "scale", "input", "image", "dimension", "ratio", "input", "output", "image", "width", "height", "respectively", "expectation", "step", "we", "compute", "soft", "assignment", "probability", "each", "pixel", "each", "kernel", "assume", "current", "estimate", "parameter", "correct", "-lrb-", "-rrb-", "pr", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "other", "word", "-lrb-", "-rrb-", "quantify", "how", "much", "input", "pixel", "contribute", "relatively", "final", "color", "output", "pixel", "maximization", "step", "we", "use", "soft", "assignment", "weighted", "maximum-likelihood", "fit", "update", "estimate", "parameter", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "10", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "note", "we", "control", "color", "space", "Gaussians", "directly", "constrain", "locality", "edge", "orientation", "describe", "next", "section", "we", "add", "third", "correction", "step", "after", "every", "maximization", "step", "step", "we", "enforce", "different", "constraint", "specific", "we", "downsample", "problem", "-lrb-", "section", "-rrb-", "algorithm", "proceed", "iteratively", "alternate", "between", "perform", "expectation", "maximization", "correction", "step", "terminate", "when", "convergence", "model", "parameter", "reach", "while", "summation", "equation", "10", "define", "over", "whole", "input", "image", "necessary", "practical", "implementation", "since", "kernel", "constrain", "size", "-lrb-", "see", "next", "section", "-rrb-", "please", "refer", "supplemental", "document", "detailed", "pseudo-code", "description", "constraint", "downscale", "more", "restricted", "problem", "than", "general", "signal", "reconstruction", "thus", "find", "optimal", "kernel", "shape", "weight", "minimize", "reconstruction", "error", "sufficient", "condition", "obtain", "good", "downscaled", "result", "we", "perform", "additional", "correction", "step", "after", "every", "maximization", "step", "enforce", "downscaling-specific", "constraint", "we", "identify", "three", "type", "constraint", "spatial", "constraint", "since", "output", "pixel", "position", "arrange", "perfect", "lattice", "important", "constrain", "location", "corresponding", "kernel", "otherwise", "potentially", "move", "too", "far", "from", "initial", "position", "which", "can", "lead", "scramble", "result", "appearance", "-lrb-", "figure", "-rrb-", "locality", "since", "all", "output", "pixel", "have", "same", "size", "kernel", "should", "also", "neither", "become", "too", "large", "vanish", "influence", "should", "remain", "local", "-lrb-", "figure", "-rrb-", "Edge", "orientation", "boundary", "between", "two", "neighbor", "kernel", "should", "have", "similar", "orientation", "boundary", "between", "two", "pixel", "output", "image", "-lrb-", "figure", "-rrb-", "173:4", "J.", "Kopf", "et", "al.", "-lrb-", "-rrb-", "unconstrained", "-lrb-", "-rrb-", "kernel", "-lrb-", "-rrb-", "constrain", "Figure", "spatial", "constraint", "important", "maintain", "grid", "topology", "kernel", "-lrb-", "-rrb-", "input", "-lrb-", "-rrb-", "unconstrained", "-lrb-", "-rrb-", "constrained", "figure", "enforce", "local", "kernel", "-lrb-", "-rrb-", "normalize", "small", "side-image", "show", "kernel", "-lrb-", "-rrb-", "dark", "pixel?s", "kernel", "grab", "long", "stretch", "line", "while", "its", "neighbor?s", "kernel", "completely", "avoid", "line", "-lrb-", "-rrb-", "smoothness", "kernel", "increase", "until", "more", "balanced", "configuration", "reach", "4.1", "spatial", "constraint", "retain", "characteristic", "grid", "topology", "output", "pixel", "we", "bias", "spatial", "mean", "towards", "smooth", "grid-like", "topology", "first", "we", "limit", "extent", "spatial", "mean", "can", "move", "constrain", "lie", "within", "box", "center", "around", "center", "output", "pixel", "second", "we", "increase", "smoothness", "move", "halfway", "between", "its", "estimate", "location", "mean", "its", "four", "neighbor", "formally", "we", "update", "11", "11", "clampbox", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "effect", "where", "n?n", "-lrb-", "4-connected", "-rrb-", "neighbor", "show", "Figure", "denote", "set", "cardinal", "spatial", "constraint", "4.2", "locality", "Edge", "Orientations", "we", "constrain", "shape", "spatial", "variance", "avoid", "vanishingly", "small", "exceedingly", "large", "kernel", "we", "first", "obtain", "singular", "value", "decomposition", "-lrb-", "-rrb-", "svd", "-lrb-", "-rrb-", "modify", "diagonal", "eigenvalue", "matrix", "clamp", "its", "element", "interval", "-lsb-", "0.05", "0.1", "-rsb-", "finally", "set", "12", "US", "where", "contain", "clamp", "eigenvalue", "while", "equation", "12", "impose", "hard", "constraint", "spatial", "component", "we", "kernel", "relatively", "smooth", "color", "component", "cause", "they", "align", "feature", "image", "general", "desire", "however", "certain", "situation", "too", "much", "adaptation", "can", "cause", "visual", "artifact", "we", "use", "color", "variance", "parameter", "which", "estimate", "directly", "control", "amount", "adaptation", "hence", "sharpness", "we", "result", "small", "cause", "kernel", "more", "sensitive", "color", "variation", "have", "sharper", "transition", "while", "larger", "lead", "smoother", "kernel", "reason", "freely", "estimate", "maximum", "likelihood", "estimation", "often", "yield", "too", "smooth", "configuration", "rather", "ACM", "transaction", "Graphics", "Vol", "32", "no.", "Article", "173", "publication", "date", "November", "2013", "-lrb-", "-rrb-", "input", "-lrb-", "-rrb-", "unconstrained", "-lrb-", "-rrb-", "constrained", "figure", "we", "detect", "strong", "pixel", "edge", "whose", "orientation", "deviate", "from", "edge", "between", "corresponding", "kernel", "-lrb-", "e.g.", "edge", "arrow", "-rrb-", "selectively", "increase", "smoothness", "kernel", "than", "estimate", "from", "datum", "we", "control", "explicitly", "locally", "adjust", "sharpness", "result", "most", "kernel", "we", "let", "remain", "its", "initial", "crisp", "set", "we", "only", "increase", "local", "smoothing", "under", "two", "specific", "condition", "-lrb-", "-rrb-", "when", "kernel", "become", "too", "dominant", "compare", "neighbor", "-lrb-", "-rrb-", "prevent", "staircase", "artifact", "follow", "each", "maximization", "step", "we", "search", "kernel", "match", "one", "condition", "correct", "they", "increase", "10", "-lrb-", "i.e.", "increase", "smoothness", "color", "kernel", "-rrb-", "locality", "while", "clamp", "eigenvalue", "avoid", "large", "spatial", "Gaussians", "result", "bilateral", "kernel", "can", "still", "have", "large", "spatial", "extent", "due", "normalization", "equation", "Figure", "6b", "illustrate", "instance", "problem", "small", "figure", "show", "normalize", "kernel", "weight", "-lrb-", "-rrb-", "two", "pixel", "subfigure", "-lrb-", "-rrb-", "kernel", "keep", "small", "color", "variance", "lead", "solution", "where", "one", "kernel", "grab", "all", "dark", "pixel", "line", "while", "other", "kernel", "grab", "light", "pixel", "surrounding", "even", "though", "spatial", "weight", "kernel", "line", "fall", "off", "quickly", "normalization", "cause", "they", "become", "large", "again", "because", "surround", "kernel", "have", "even", "lower", "weight", "due", "strong", "color", "adaption", "cause", "line", "feature", "become", "disconnect", "we", "correct", "behavior", "detect", "kernel", "grow", "too", "strong", "any", "direction", "selectively", "increase", "color", "variance", "first", "we", "compute", "directional", "variance", "each", "eight", "neighbor", "13", "-lrb-", "-rrb-", "max", "-lrb-", "-rrb-", "13", "where", "-lrb-", "-rrb-", "-lsb-", "-rsb-", "-lrb-", "-rrb-", "offset", "one", "eight", "neighbor", "any", "directional", "variance", "exceed", "threshk", "old", "0.2", "-lrb-", "where", "ratio", "input", "image?s", "width", "over", "output", "image?s", "width", "-rrb-", "we", "increase", "smoothness", "both", "current", "kernel", "respective", "neighbor", "effect", "heuristic", "illustrate", "Figure", "6c", "ability", "we", "algorithm", "keep", "linear", "feature", "connect", "while", "maintain", "sharpness", "can", "also", "nicely", "observe", "pixel", "art", "result", "figure", "15", "Edge", "Orientations", "form", "staircase", "artifact", "occur", "when", "orientation", "edge", "between", "two", "dissimilar", "pixel", "output", "pixel", "grid", "significantly", "different", "than", "orientation", "edge", "between", "corresponding", "kernel", "artifact", "most", "visible", "long", "line", "almost", "cardinal", "direction", "consider", "example", "horizontal", "edge", "mark", "arrow", "Figure", "7b", "corresponding", "image", "edge", "input", "image", "almost", "vertical", "we", "selectively", "remove", "false", "edge", "increase", "corresponding", "kernel", "first", "we", "detect", "strong", "edge", "between", "adjacent", "pixel", "testing", "neighbor", "kernel", "have", "abrupt", "transition", "horizontal", "vertical", "neighbor", "we", "measure", "strength", "edge", "between", "normalize", "kernel", "kn", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "transition", "between", "two", "kernel", "abrupt", "few", "pixel", "where", "both", "kernel", "take", "large", "value", "thus", "kn", "small", "we", "consider", "edge", "where", "kn", "0.08", "strong", "next", "we", "compute", "direction", "edge", "between", "kernel", "kn", "-lrb-", "-rrb-", "-lrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-rrb-", "256", "color", "12", "color", "Input", "quantize", "12", "color", "figure", "we", "method", "can", "also", "extend", "create", "pixel", "art", "limited", "color", "palette", "from", "cartoon", "vector", "input", "Color", "quantization", "achieve", "post-process", "use", "mean", "shift", "segmentation", "-lrb-", "input", "image", "Nintendo", "Co.", "Ltd.", "-rrb-", "Input", "Gerstner", "et", "al.", "we", "result", "Input", "16", "color", "16", "color", "Figure", "post-process", "color", "quantization", "use", "k-means", "clustering", "combine", "we", "content-aware", "downsampling", "method", "apply", "natural", "image", "yield", "similar", "result", "prior", "work", "kn", "deviate", "more", "than", "25", "degree", "from", "orientation", "pixel", "edge", "we", "consider", "false", "edge", "increase", "smoothness", "both", "kernel", "involve", "effect", "correction", "illustrate", "Figure", "7c", "result", "we", "test", "we", "algorithm", "wide", "range", "input", "image", "range", "from", "natural", "image", "line", "vector", "art", "all", "result", "be", "create", "same", "algorithm", "setting", "Figure", "13", "other", "figure", "throughout", "paper", "show", "representative", "result", "we", "algorithm", "we", "compare", "we", "method", "na?ve", "subsampling", "bicubic", "filter", "-lrb-", "arguably", "most", "commonly", "use", "rescaling", "algorithm", "-rrb-", "we", "result", "show", "we", "method", "yield", "sharper", "result", "-lrb-", "instance", "text", "-rrb-", "maintain", "detail", "better", "-lrb-", "e.g.", "lunar", "surface", "flower", "Figure", "13", "-rrb-", "preserve", "appearance", "high", "frequency", "texture", "-lrb-", "e.g.", "Figure", "leave", "-rrb-", "supplementary", "material", "we", "provide", "extensive", "comparison", "large", "set", "image", "compare", "we", "method", "wider", "range", "downscale", "method", "-lrb-", "include", "range", "linear", "filter", "unoptimized", "bilateral", "kernel", "Generalized", "sample", "-lsb-", "Nehab", "Hoppe", "2011", "-rsb-", "pixelated", "image", "abstraction", "-lsb-", "Gerstner", "et", "al.", "2012", "-rsb-", "-rrb-", "5.2", "user", "study", "5.1", "Pixel", "Art", "Downscaling", "Palette", "Reduction", "Downscaling", "we", "algorithm", "particularly", "well", "suit", "downscale", "cartoon", "vector", "art", "image", "create", "pixel", "art", "figure", "15", "show", "representative", "result", "when", "generate", "result", "we", "disable", "edge", "orientation", "constraint", "-lrb-", "section", "4.2", "-rrb-", "since", "we", "aim", "blocky", "old", "school", "look", "-lrb-", "i.e.", "big", "pixel", "-rrb-", "particular", "note", "we", "algorithm?s", "ability", "keep", "line", "feature", "connect", "comparison", "many", "line", "subsampled", "result", "interrupted", "while", "bicubic", "result", "exhibit", "wash", "out", "color", "due", "excessive", "smoothing", "we", "algorithm", "strike", "balance", "between", "both", "extreme", "keep", "outline", "sharp", "connected", "where", "ACM", "transaction", "Graphics", "Vol", "32", "no.", "Article", "173", "publication", "date", "November", "2013", "color", "color", "color", "color", "Gerstner", "et", "al.", "result", "color", "color", "color", "color", "we", "result", "Gerstner", "et", "al.", "we", "result", "16", "color", "16", "color", "possible", "while", "too", "detailed", "area", "naturally", "resolve", "average", "out", "feature", "Extension", "Palette", "Reduction", "one", "particular", "form", "pixel", "art", "also", "include", "reduce", "color", "palette", "-lsb-", "Gerstner", "et", "al.", "2012", "-rsb-", "while", "focus", "we", "method", "we", "be", "interested", "investigate", "effectiveness", "apply", "color", "palette", "reduction", "postprocess", "we", "use", "mean", "shift", "segmentation", "follow", "description", "Comaniciu", "Meer?s", "paper", "-lsb-", "2002", "-rsb-", "-lrb-", "use", "Epanechnikov", "kernel", "fix", "spatial", "bandwidth", "-rrb-", "use", "color", "bandwidth", "parameter", "adjust", "number", "color", "output", "image", "we", "find", "work", "particularly", "well", "cartoon", "vector", "art", "input", "show", "Figure", "type", "image", "we", "method", "produce", "higher", "quality", "result", "than", "Gerstner", "et", "al.", "-lsb-", "2012", "-rsb-", "however", "mainly", "due", "we", "algorithm?s", "ability", "keep", "line", "feature", "connect", "when", "apply", "natural", "image", "however", "we", "find", "mean", "shift", "segmentation", "work", "well", "instead", "we", "use", "simple", "k-means", "clustering", "natural", "image", "where", "produce", "image", "similar", "quality", "Gerstner", "et", "al.", "-lsb-", "2012", "-rsb-", "-lrb-", "Figure", "-rrb-", "verify", "we", "algorithm", "we", "conduct", "formal", "user", "study", "51", "subject", "use", "Amazon", "mechanical", "Turk", "which", "we", "compare", "we", "algorithm", "against", "five", "alternative", "-lrb-", "-rrb-", "Generalized", "sample", "-lsb-", "Nehab", "Hoppe", "2011", "-rsb-", "which", "we", "consider", "state-of-the-art", "algorithm", "image", "scaling", "-lrb-", "-rrb-", "bicubic", "since", "one", "most", "commonly", "use", "scale", "algorithm", "-lrb-", "-rrb-", "subsampling", "its", "simplicity", "-lrb-", "-rrb-", "box", "filter", "because", "yield", "sharper", "result", "than", "bicubic", "-lrb-", "-rrb-", "unoptimized", "bilateral", "kernel", "verify", "effectiveness", "we", "optimization", "each", "test", "we", "show", "participant", "high", "resolution", "-lrb-", "400", "pixel", "long", "side", "-rrb-", "input", "image", "well", "two", "downscale", "re", "173:6", "J.", "Kopf", "et", "al.", "Figure", "10", "result", "user", "study", "compare", "we", "algorithm", "against", "several", "exist", "algorithm", "sult", "-lrb-", "128", "pixel", "-rrb-", "one", "produce", "we", "algorithm", "other", "produce", "one", "compete", "algorithm", "participant", "be", "ask", "which", "result", "represent", "better", "downscale", "version", "input", "image", "have", "choose", "either", "one", "result", "express", "preference", "time", "limit", "impose", "all", "image", "be", "show", "native", "display", "resolution", "participant", "be", "provide", "any", "means", "zoom", "image", "we", "do", "however", "control", "user", "distance", "from", "screen", "better", "simulate", "realistic", "application", "condition", "i.e.", "subject", "could", "move", "closer", "screen", "examine", "detail", "each", "participant", "present", "13", "test", "total", "each", "testing", "we", "algorithm", "against", "random", "compete", "algorithm", "different", "input", "image", "i.e.", "participant", "see", "same", "input", "image", "more", "than", "once", "we", "repeat", "every", "question", "throughout", "test", "filter", "unreliable", "participant", "remove", "all", "answer", "from", "participant", "who", "be", "consistent", "less", "than", "80", "test", "study", "we", "select", "variety", "natural", "image", "from", "MSRA", "Salient", "Object", "database", "-lsb-", "Liu", "et", "al.", "2007", "-rsb-", "span", "different", "category", "include", "people", "stochastic", "regular", "texture", "text", "smooth", "area", "image", "use", "study", "provide", "supplementary", "material", "result", "show", "Figure", "10", "analysis", "between", "each", "condition", "indicate", "we", "algorithm", "significantly", "prefer", "over", "each", "compete", "technique", "5.3", "Performance", "we", "method", "employ", "iterative", "optimization", "strategy", "downscale", "image", "consequently", "computationally", "more", "demand", "than", "classical", "linear", "rescaling", "filter", "follow", "we", "analyze", "performance", "we", "C++", "implementation", "run", "Intel", "Xeon", "E5640", "CPU", "2.66", "GHz", "we", "partially", "use", "multiple", "core", "we", "implementation", "we", "have", "fully", "parallelize", "optimize", "implementation", "convergence", "proof", "original", "em-algorithm", "do", "carry", "through", "onto", "we", "algorithm", "due", "we", "modification", "however", "we", "do", "encounter", "convergence", "issue", "several", "thousand", "image", "tested?if", "would", "happen", "one", "could", "simply", "terminate", "algorithm", "after", "fixed", "number", "iteration", "single", "iteration", "we", "algorithm", "linear", "both", "input", "output", "image", "size", "due", "content", "dependent", "nature", "we", "algorithm", "number", "iteration", "vary", "different", "output", "image", "same", "size", "Figure", "11", "report", "runtime", "-lrb-", "blue", "-rrb-", "number", "iteration", "-lrb-", "red", "-rrb-", "average", "over", "processing", "100", "randomly", "select", "natural", "image", "shaded", "region", "indicate", "standard", "deviation", "dash", "line", "indicate", "min?max", "range", "Figure", "11", "left", "output", "size", "keep", "fix", "80", "60", "pixel", "while", "input", "size", "vary", "from", "160", "120", "640", "480", "Figure", "11", "right", "output", "size", "vary", "from", "40", "30", "160", "120", "while", "input", "size", "remain", "fix", "640", "480", "pixel", "ACM", "transaction", "Graphics", "Vol", "32", "no.", "Article", "173", "publication", "date", "November", "2013", "varying", "input", "dimension", "fixed", "output", "dimension", "varying", "output", "dimension", "fix", "input", "dimension", "Figure", "11", "average", "runtime", "-lrb-", "blue", "-rrb-", "number", "iteration", "-lrb-", "red", "-rrb-", "from", "process", "100", "random", "natural", "image", "shaded", "region", "indicate", "standard", "deviation", "dash", "line", "indicate", "min-max", "range", "left/right", "figure", "show", "result", "vary", "input/output", "image", "dimension", "while", "keep", "other", "fix", "5.4", "Limitations", "we", "algorithm", "rely", "number", "heuristic", "constraint", "prevent", "certain", "downscale", "artifact", "-lrb-", "section", "-rrb-", "would", "desirable", "incorporate", "constraint", "directly", "EM", "optimization", "however", "most", "constraint", "fundamentally", "different", "nature", "EM", "step", "process", "each", "kernel", "independently", "constraint", "other", "hand", "rely", "relation", "between", "neighbor", "kernel", "hence", "can", "directly", "solve", "step", "therefore", "constraint", "handle", "additional", "third", "step", "due", "content-adaptive", "nature", "we", "algorithm", "behave", "temporally", "less", "coherent", "than", "linear", "filter", "when", "apply", "smooth", "animation", "e.g.", "slow", "zoom", "picture", "we", "result", "flicker", "slightly", "while", "each", "individual", "image", "appear", "crisper", "exhibit", "more", "detail", "please", "refer", "supplementary", "material", "video", "illustrate", "issue", "similar", "problem", "can", "occur", "symmetric", "feature", "input", "image", "example", "we", "algorithm", "fail", "preserve", "symmetry", "yellow", "button", "Figure", "12", "we", "algorithm", "do", "prevent", "aliase", "under", "all", "circumstance", "consequently", "we", "method", "do", "perform", "well", "most", "standard", "aliasing", "test", "e.g.", "zone", "plate", "pattern", "Figure", "12", "furthermore", "we", "result", "can", "reach", "quality", "well-trained", "expert", "achieve", "when", "manually", "hint", "font", "manually", "create", "pixel", "art", "-lrb-", "figure", "12", "bottom", "-rrb-", "while", "we", "method", "significantly", "improve", "quality", "downscale", "image", "exhibit", "small", "detail", "eye", "stochastic", "texture", "do", "always", "produce", "better", "result", "image", "blur", "feature", "image", "contain", "structured", "texture", "latter", "case", "despite", "we", "effort", "-lrb-", "section", "-rrb-", "staircase", "can", "still", "occur", "artifact", "show", "up", "particular", "long", "almost", "cardinal", "line", "e.g.", "right", "edge", "sign", "top", "row", "Figure", "13", "systematic", "investigation", "artifact", "can", "find", "supplementary", "material", "accompany", "web", "site", "lastly", "since", "equation", "-lrb-", "-rrb-", "may", "have", "multiple", "local", "minimum", "we", "may", "reach", "slightly", "different", "solution", "depend", "we", "initialization", "supplementary", "material", "accompany", "web", "site", "we", "show", "various", "sensible", "initialization", "choice", "yield", "similar", "solution", "we", "settle", "use", "middle", "gray", "initialization", "which", "work", "well", "we", "test", "content-adaptive", "image", "downscale", "173:7", "Input", "Bicubic", "we", "result", "Input", "Bicubic", "we", "result", "figure", "12", "Limitations", "we", "method", "top", "we", "algorithm", "fail", "preserve", "symmetric", "arrangement", "yellow", "button", "mario?s", "overall", "middle", "we", "method", "specifically", "design", "prevent", "aliase", "under", "all", "circumstance", "bottom", "we", "method", "can", "compete", "manually", "downscale", "image", "-lrb-", "Mario", "input", "image", "Nintendo", "Co.", "Ltd.", "-rrb-", "conclusion", "we", "have", "present", "novel", "content-adaptive", "image", "downscaling", "method", "adapt", "shape", "its", "downsample", "kernel", "yield", "sharper", "more", "detailed", "downscale", "result", "contrary", "common", "wisdom", "dictate", "frequency", "above", "Nyquist", "frequency", "introduce", "artifact", "downsampled", "image", "-lrb-", "form", "aliasing", "-rrb-", "we", "show", "careful", "sampling", "certain", "high", "frequency", "feature", "can", "still", "preserve", "downscale", "image", "without", "artifact", "give", "grow", "resolution", "gap", "between", "camera", "display", "device", "advent", "gigapixel", "panoramic", "imaging", "we", "believe", "work", "open", "up", "exciting", "area", "research", "plentiful", "avenue", "future", "research", "we", "work", "have", "show", "possible", "sometimes", "drastically", "improve", "quality", "over", "exist", "downscale", "method", "future", "work", "we", "would", "like", "further", "improve", "robustness", "method", "e.g.", "through", "smarter", "heuristic", "so", "we", "method", "always", "outperform", "simpler", "filter", "would", "also", "interesting", "look", "other", "signal", "than", "image", "input", "natural", "immediate", "step", "would", "analyze", "constrain", "temporal", "behavior", "we", "algorithm", "e.g.", "when", "apply", "video", "acknowledgement", "work", "part", "support", "nsf", "iis-1217765", "Israeli", "Science", "Foundation", "-lrb-", "grant", "no.", "324/11", "-rrb-", "reference", "chanta", "R.", "hajus", "a.", "mith", "K.", "UCCHI", "a.", "ua", "P.", "USSTRUNK", "S.", "2012", "slic", "superpixel", "compare", "stateACM", "transaction", "Graphics", "Vol", "32", "no.", "Article", "173", "publication", "date", "November", "2013", "of-the-art", "superpixel", "method", "IEEE", "Trans", "pattern", "Anal", "Mach", "Intell", "34", "11", "2274", "2282", "VIDAN", "S.", "HAMIR", "A.", "Seam", "carve", "content-aware", "image", "resize", "ACM", "transaction", "graphic", "-lrb-", "Proc", "SIGGRAPH", "2007", "-rrb-", "26", "article", "no.", "10", "omaniciu", "D.", "eer", "P.", "ember", "S.", "2002", "mean", "shift", "robust", "approach", "toward", "feature", "space", "analysis", "IEEE", "transaction", "Pattern", "analysis", "machine", "Intelligence", "24", "603", "619", "erstner", "T.", "ARLO", "D.", "LEXA", "M.", "inkelstein", "a.", "ingold", "Y.", "ealen", "a.", "2012", "pixelated", "image", "abstraction", "Proceedings", "International", "Symposium", "NonPhotorealistic", "Animation", "Rendering", "-lrb-", "npar", "-rrb-", "29", "36", "astie", "T.", "ibshiranus", "R.", "RIEDMAN", "J.", "ranklin", "J.", "2005", "element", "statistical", "learning", "datum", "mining", "inference", "prediction", "mathematical", "intelligencer", "27", "83", "85", "ngli", "T.", "C.", "APLAN", "C.", "S.", "2012", "pixelate", "vector", "line", "art", "Proceedings", "Symposium", "Non-Photorealistic", "Animation", "Rendering", "21", "28", "ARNI", "Z.", "reedman", "D.", "OTSMAN", "C.", "2009", "energybased", "image", "deformation", "Proceedings", "Symposium", "Geometry", "Processing", "-lrb-", "SGP", "2009", "-rrb-", "1257", "1268", "iu", "T.", "UN", "J.", "HENG", "N.-N.", "ang", "X.", "hum", "h.-y", "2007", "learn", "detect", "salient", "object", "Proceedings", "IEEE", "Conference", "Computer", "Vision", "Pattern", "recognition", "-lrb-", "cvpr", "2007", "-rrb-", "anson", "J.", "CHAEFER", "S.", "2012", "parameterization-aware", "mip-mapping", "Computer", "Graphics", "Forum", "-lrb-", "Proc", "Eurographics", "Symposium", "rendering", "-rrb-", "31", "1455", "1463", "ehab", "D.", "OPPE", "H.", "2011", "Generalized", "sampling", "computer", "graphic", "Tech", "rep.", "feb.", "ubinstein", "m.", "hamir", "a.", "vidan", "S.", "2009", "multioperator", "media", "retargeting", "ACM", "transaction", "graphic", "-lrb-", "Proceedings", "SIGGRAPH", "2009", "-rrb-", "28", "11", "amadanus", "R.", "IM", "S.", "H.", "retter", "D.", "2007", "Representative", "image", "thumbnail", "good", "browsing", "Proceedings", "International", "conference", "image", "processing", "-lrb-", "icip", "2007", "-rrb-", "193", "196", "HANNON", "C.", "E.", "1949", "communication", "presence", "noise", "Proceedings", "Institute", "Radio", "Engineers", "37", "10", "21", "UH", "B.", "ING", "H.", "EDERSON", "B.", "B.", "ACOBS", "D.", "W.", "2003", "Automatic", "thumbnail", "crop", "its", "effectiveness", "Proceedings", "16th", "annual", "acm", "symposium", "user", "interface", "software", "technology", "95", "104", "omasus", "C.", "anduchus", "R.", "1998", "bilateral", "filter", "gray", "color", "image", "Proceedings", "IEEE", "International", "Conference", "Computer", "Vision", "-lrb-", "ICCV", "98", "-rrb-", "836", "846", "rentacoste", "m.", "antiuk", "R.", "eidrich", "W.", "2011", "blur-aware", "image", "downsizing", "Computer", "Graphics", "Forum", "-lrb-", "Proc", "eurographic", "2011", "-rrb-", "30", "573", "582", "rigg", "B.", "2001", "empirical", "filter", "estimation", "subpixel", "interpolation", "matching", "Proceedings", "IEEE", "International", "Conference", "Computer", "Vision", "-lrb-", "ICCV", "2001", "-rrb-", "550", "557", "OLBERG", "G.", "1990", "Digital", "image", "warping", "IEEE", "Computer", "Society", "Press", "Los", "Alamitos", "CA", "USA", "OLF", "L.", "UTTMANN", "M.", "ohen", "D.", "2007", "nonhomogeneous", "content-driven", "video-retargeting", "Proceedings", "IEEE", "International", "Conference", "Computer", "Vision", "-lrb-", "ICCV", "2007", "-rrb-", "173:8", "J.", "Kopf", "et", "al.", "Input", "Subsampling", "Bicubic", "Input", "Subsampling", "Bicubic", "Figure", "13", "comparison", "natural", "image", "downscale", "use", "subsampling", "bicubic", "we", "algorithm", "fully", "appreciate", "quality", "difference", "downsampled", "result", "we", "recommend", "view", "result", "native", "resolution", "when", "view", "electronically", "extended", "set", "result", "can", "find", "supplementary", "material", "Input", "Downscaled", "Figure", "14", "selection", "downscale", "result", "various", "output", "resolution", "range", "from", "32", "24", "192", "144", "-lrb-", "original", "resolution", "708", "531", "384", "288", "Snow", "Leopard", "flower", "respectively", "-rrb-", "we", "method", "produce", "good", "result", "any", "scale", "supplementary", "material", "we", "compare", "against", "bicubic", "filter", "slowly", "zoom", "video", "Input", "Subsampling", "Figure", "15", "we", "method", "can", "use", "create", "pixel", "art", "from", "draw", "input", "note", "ability", "we", "algorithm", "keep", "feature", "connect", "-lrb-", "e.g.", "outline", "-rrb-", "furthermore", "staircase", "correction", "step", "disabled", "achieve", "typical", "quantize", "look", "pixel", "art", "-lrb-", "input", "image", "Nintendo", "Co.", "Ltd.", "-rrb-", "ACM", "transaction", "Graphics", "Vol", "32", "no.", "Article", "173", "publication", "date", "November", "2013", "we", "result", "Input", "we", "result", "Input", "Input", "Bicubic", "we", "result", "input" ],
  "content" : "\n  \n    c63732b2c12e0a5e6a39396fb0701f014532d58e191f00c305f9908e26d18020\n    p3a\n    10.1145/2508363.2508370\n    Name identification was not possible. \n  \n  \n    \n      \n        Content-Adaptive Image Downscaling\n      \n      Johannes Kopf Ariel Shamir Microsoft Research The Interdisciplinary Center\n      \n        \n      \n      Input Lanczos Our result\n      \n        Figure 1: Previous content-insensitive downscaling methods have to compromise between preserving sharpness while introducing aliasing artifacts (e.g., subsampling), or preventing aliasing at the expense of smoothing out fine details and edges (e.g., Bicubic, Lanczos, etc.). Our new content-adaptive algorithm provides a more balanced result, that is crisp and contains neither noise nor ringing, and mostly avoids aliasing artifacts. (?Merlon? input image c Nintendo Co., Ltd.)\n      \n      This paper introduces a novel content-adaptive image downscaling method. The key idea is to optimize the shape and locations of the downsampling kernels to better align with local image features. Our content-adaptive kernels are formed as a bilateral combination of two Gaussian kernels defined over space and color, respectively. This yields a continuum ranging from smoothing to edge/detail preserving kernels driven by image content. We optimize these kernels to represent the input image well, by finding an output image from which the input can be well reconstructed. This is technically realized as an iterative maximum-likelihood optimization using a constrained variation of the Expectation-Maximization algorithm. In comparison to previous downscaling algorithms, our results remain crisper without suffering from ringing artifacts. Besides natural images, our algorithm is also effective for creating pixel art images from vector graphics inputs, due to its ability to keep linear features sharp and connected. CR Categories: I.4.1 [Computer Graphics]: Image Processing and Computer Vision?Sampling Keywords: Images, Downscaling Links: DL PDF W EB C ODE\n      \n        \n        \n        \n        \n      \n    \n    \n      \n        1 Introduction\n      \n      Downscaling is perhaps the most commonly used image operation today. We rarely view a photo we just took at its original resolution anymore. Instead, it is instantly reduced from its original\n      ACM Reference Format Kopf, J., Shamir, A., Peers, P. 2013. Content-Adaptive Image Downscaling. ACM Trans. Graph. 32, 6, Article 173 (November 2013), 8 pages. DOI = 10.1145/2508363.2508370 http://doi.acm.org/10.1145/2508363.2508370. Copyright Notice Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the fi rst page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org . 2013 Copyright held by the Owner/Author. Publication rights licensed to ACM. 0730-0301/13/11-ART173 $15.00. DOI: http://dx.doi.org/10.1145/2508363.2508370\n      ACM Transactions on Graphics, Vol. 32, No. 6, Article 173, Publication Date: November 2013\n      Pieter Peers College of William & Mary\n      Input Bilateral Our result\n      \n        \n      \n      (b) Subsampling (c) Bicubic (d) Our result\n      (a) Input Figure 2 :\n      subsampled\n      bicubic Our algorithm\n      \n        Balancing sharpness and antialiasing: the result is sharp everywhere but suffers severely from noise and aliasing. On the other hand, the result, over-smoothes detail in the face. avoids both problems and produces a crisp, noise-free image that exhibits only minimal aliasing.\n      \n      multi-megapixel size to much smaller dimensions to be viewed on a camera viewfinder, on a computer or mobile screen, or on the web. The de facto standard for image downscaling are linear filters, originating from the signal processing community [Wolberg 1990]. Here, the image is first convolved with a low-pass kernel to reduce the bandwidth before it is resampled to the final resolution. The filtering pushes the image below the Nyquist frequency and prevents aliasing, but as a side effect the result might suffer from loss of fine details and blurring of sharp edges ( Figure 2c ). Sharpening these images or using kernels that more closely model a sinc filter (e.g., Lanczos) can cause ringing ( Figure 3 ), while simply subsampling the image without prefiltering typically leads to strong aliasing artifacts ( Figure 2b ). Because all these methods are content-invariant (i.e., they use invariant kernels), the tradeoff between preserving detail and preventing aliasing is global. In this work we present a new content-adaptive downscaling algorithm. As in classic methods, the output pixels are computed as a weighted sum of the input pixels. This can be interpreted as associating an averaging kernel to every output pixel. Our key idea is to adapt the shape of these kernels in order to better align them with local image features ( Figure 2d ). Following previous techniques such as bilateral filtering [Tomasi and Manduchi 1998] and mean shift [Comaniciu et al. 2002], we use kernels that are a combination of a spatial Gaussian kernel ensuring locality, and a color space Gaussian kernel for alignment with the image content. The simple parametric form of these kernels achieves a good trade-off between\n      173:2\n      ?\n      J. Kopf et al.\n      \n        \n      \n      Input Lanczos Bicubic Our result sharpened\n      \n        Figure 3: The Lanczos kernel or Photoshop?s ?Sharpen? filter come at the expense of ringing artifacts due to negative lobes and oscillations in their kernels. Our kernels are strictly positive and mostly without oscillations, yielding results that are practically free of ringing artifacts. Figure 4: Using averaging kernels for downscaling: (b) linear fila small number of parameters to optimize, and sufficient flexibility ters associate the same averaging kernel with every output pixel, to take on the shape of image features. We formulate the problem as forcing a global compromise between smoothing and aliasing. (c) a constrained reconstruction problem and optimize for a set of kerunoptimized bilateral kernels adapt to the image, but might ?miss? nels whose combination would best reconstruct the original image. image features depending on the placement of their centers (e.g., The optimized kernels are constrained to remain compact, simple, the dial plate numbers). (d) Our optimized kernels adapt to the and ?blob-shaped?, since they correspond to simple pixels in the image even more, but do not suffer from missed or disconnected output image: the color of the output pixel is computed as the sum features. of kernel-weighted input pixel colors. In classic methods, all kernels have the same shape and are arranged ringing artifacts near strong image edges ( Figure 3 ). Many filin a regular grid ( Figure 4b ). Using just bilateral kernels without opters (e.g., bilinear, bicubic, etc.) have been developed [Wolberg timizing their parameters can align them with image features. How1990], and even mined from image data [Triggs 2001], that balance ever, just like the subsampling method, they might ?miss? features mathematical optimality with perceptual quality of the downsamdepending on the location of their center ( Figure 4c ). Our kernels pled result. Recent developments [Nehab and Hoppe 2011] add a also align themselves with curved features in the image, but since correction stage on the discrete signal before reconstruction, resultthey are optimized to represent the input image better, they tend to ing in less ringing at a similar computational cost. However, in not miss features ( Figure 4d ). This property is of particular impornone of these techniques the filtering kernel is adapted to the image tance when downscaling images that contain fine lines, like cartoon content?a filter that removes aliasing in one area, might produce art (Figures 1, 8, 15) ringing in another. In contrast, our method adapts the shape and location of every kernel to the local image content, producing sharper Our local kernel parameters are derived through an iterative maxresults. Since our kernels are strictly positive and mostly without imum likelihood optimization using a constrained variation of the oscillations our results are practically free of ringing artifacts. Expectation-Maximization algorithm. This optimization yields a continuum of local kernels in a single framework, ranging from A different class of algorithms focuses on retargeting an image smoothing in some places to edge/detail preserving filters in others, to different aspect ratios while preserving the salient content of depending on local image content. By locally controlling sharpness the image as much as possible (e.g., [Avidan and Shamir ; Wolf against antialiasing, we achieve a good balance of both objectives. et al. 2007; Rubinstein et al. 2009; Karni et al. 2009]). However, Our algorithm is also useful for downscaling cartoon and vector these methods are mostly geared towards altering aspect ratio, and art, and can also be combined with palette reduction to create pixel are only suited for moderate reductions in resolution (e.g., 25% to art imagery. Because pixels usually appear bigger in these images, 50%). Furthermore, retargeting methods focus on preserving the the blurring of linear resampling filters shows even more severely. salient content, and thus can alter the global image composition. Subsampling can produce sharp results, but it takes only a fracOur method, on the other hand, maintains the image composition tion of the input pixels into account, and might miss features. This as much as possible. can lead to broken features and disconnected lines. Our optimized kernels also produce crisp pixel art, while minimizing broken or Thumbnail creation can also be viewed as a method to reduce the disconnected features (see Figure 1 , 8, 15). size of an image. Suh et al. [2003] propose to compute thumbnails by selectively cropping and scaling images guided by face detectors We tested our algorithm on a wide range of natural and vector or saliency maps. Samadani et al. [2007] preserve the original apgraphic input images. We compare our results against an extensive pearance in thumbnails by reintroducing artifacts such as blurring set of alternative downscaling methods. In addition, we performed and noise lost in downscaling. Trentacoste et al. [2011] also reina user study to validate the perceptual quality of our results. Our troduce blur for previewing images on a camera?s view finder based method especially improves the quality of downscaled images exon a perceptual model. Instead of preserving the blurred appearance hibiting small details or stochastic textures. of the input image, our method targets the opposite by selectively removing blur to preserve small image detail and texture. 2 Previous Work Gerstner et al. [2012] abstract an image in a low resolution representation with a reduced color palette. Their algorithm alternates Classical image downscaling techniques find their origin in sambetween updating SLIC (Simple Linear Iterative Clustering) superpling theory [Shannon 1949], and prefilter and reconstruct the sigpixels [Achanta et al. 2012] and refining the color palette. Similar to nal with a spatially constant lowpass filter in order to prevent aliasour method, SLIC also works in the joint 5D space of location and ing in the reconstructed signal. However, by suppressing high frecolor. However, SLIC segments the image (i.e., hard assignment), quencies they also tend to blur the signal. Filters that are designed whereas our method produces a soft assignment of input to output to more closely model the (theoretically ideal) sinc filter, such as pixels, allowing us to better adapt to the underlying high resolution Lanczos, come at the expense of negative lobes that can produce image. ACM Transactions on Graphics, Vol. 32, No. 6, Article 173, Publication Date: November 2013\n      \n      Result Kernels\n      Reconst.\n      \n        \n        \n      \n      (a) Input\n      (b) Bicubic (c) Bilateral (d) Our result\n      Content-Adaptive Image Downscaling\n      ?\n      173:3\n      Manson and Schaefer [2012] present a method for generating mipmaps that adapts the filtering to the texture content and surface parameterization. Inglis and Kaplan [2012] present a method for rasterizing vector line art at low resolution, using rules established by pixel artists to avoid certain artifacts like jaggies and preserve local continuity. However, in contrast to the general downsampling strategy employed by our method, the above techniques downsample image content based on application specific rules.\n      \n        3 Algorithm\n        To find the local filtering kernels, we formulate our task as a reconstruction problem of the input image from a smaller set of local kernel functions w k (probability density functions) with fixed colors ? k , and defined in the joint 5D space of location and color. We interpret each input image pixel as a sample drawn randomly from one of the local kernels with uniform probability and then sampling this local kernel. Theoretically, these kernels can have any shape and location. However, since they correspond to output pixels, a number of constraints on the kernels are necessary due to the application to image downscaling. First, the number of kernels must be equal to the number of output pixels, hence, no kernel can vanish during optimization. Second, their position cannot vary too much from the output pixel grid and their size cannot vary too much from the output pixel size. Third, to prevent aliasing artifacts, we add orientation constraints as described in Section 4. Denote X = {x i } as the input image with pixels x i = (p i , c i ), where p i are the spatial coordinates and c i the corresponding CIELAB color of pixel i. Each reconstructed image pixel color c i is defined as a weighted sum of the kernel colors ? k :\n        \n          1\n          c = ? (i)?\n        \n        \n          1\n          i ? k k k\n        \n        where ? k (i) = ? w n w k (i) n (i) is the (unknown) weight of kernel k at pixel i relative to all kernels overlapping pixel i. The (also unknown) kernels w k : domain(X) ? [0, 1] are bilateral Gaussian kernels in our case, i.e., we denote the value of kernel k at pixel i as:\n        \n          2\n          1 w (i) = f (i)g (i),\n        \n        \n          2\n          k k k W k\n        \n        where the normalization factor W k = ? j f k ( j)g k ( j) ensures that each w k is a probability density function (i.e., integrates to 1). The spatial component f k and the color component g k are given by:\n        \n          3\n          f k (i) = exp ? 2 1 (p i ? ? k ) ? k ?1 (p i ? ? k ) , and\n        \n        \n          4\n          c i ? ? k 2\n        \n        \n          4\n          g k (i) = exp ? 2? 2 ,\n        \n        k where ? k and ? k are the mean and covariance matrix of the spatial Gaussian, and ? k and ? k are the mean and variance of the color space Gaussian. Note that the spatial Gaussian is characterized by a full covariance matrix and can therefore take on elliptical shapes, while the color space Gaussian is characterized only by a scalar variance and remains isotropic, as we operate in the perceptually uniform CIELAB color space. Given our input image X, we search for the most probable set of parameters ? = {? k , ? k , ? k , ? k } of the kernels, and set of unknown variables ? k (i) that can produce (reconstruct) this image. Using Bayes rule, this converts to maximizing the (log) likelihood of the input image given the model of the set of kernels:\n        \n          5\n          argmax Pr(X | ? ). ?\n        \n        This problem is well known in statistics and solved using the Expectation-Maximization (EM) algorithm [Hastie et al. 2005] where the unknown variables ? k (i) can be seen as the probability of pixel i to be drawn from kernel k. ACM Transactions on Graphics, Vol. 32, No. 6, Article 173, Publication Date: November 2013\n        We initialize kernel k corresponding to output pixel (x, y) as: r\n        \n          6\n          ? k ? (x k , y k ) , ? k ? 0 3 x r 0 3 y , ? k ? 1 2 , 2 1 , 1 2 , ? k ? 10 ?4 ,\n        \n        where (x k , y k ) is the center of output pixel k scaled to input image dimensions, and r x , r y are the ratios of input and output image width and height, respectively. In the expectation step we compute soft assignment probabilities of each pixel to each kernel, assuming the current estimate of the parameters is correct:\n        \n          7\n          ? k (i) ? Pr(k | x i ; ? ) = k (i) . ? n n (i)\n        \n      \n      \n        w w\n        In other words, ? k (i) quantifies how much an input pixel i contributes relatively to the final color of the output pixel k. In the maximization step we use these soft assignments in a weighted maximum-likelihood fit to update the estimate of the parameters ? :\n        \n          8\n          ? ? ? i ? k (i)p i ,\n        \n        \n          9\n          k ? i ? k (i) ? k ? ? i ? k (i)(p i ? ? k )(p i ? ? k ) , ? i ? k (i)\n        \n        \n          10\n          ? k ? ? i ? k (i)c i . ? i ? k (i)\n        \n        Note, that we control the color space Gaussians? ? k directly to constrain the locality and edge orientations as described in the next section. We add a third correction step after every maximization step. In this step we enforce the different constraints specific to our downsampling problem (Section 4). The algorithm proceeds iteratively, alternating between performing expectation, maximization, and correction steps, and terminates when convergence of the model parameters is reached. While the summations in Equations 8?10 are defined over the whole input image, this is not necessary in a practical implementation, since the kernels are constrained in size (see next section). Please refer to the supplemental document for a detailed pseudo-code description.\n      \n      \n        4 Constraints\n        Downscaling is a more restricted problem than general signal reconstruction, and thus finding the optimal kernel shape and weight that minimizes the reconstruction error is not a sufficient condition for obtaining a good downscaled result. We perform an additional correction step after every maximization step to enforce downscaling-specific constraints. We identified three types of such constraints: 1. Spatial constraints: Since the output pixel positions are arranged in a perfect lattice, it is important to constrain the locations of the corresponding kernels. Otherwise, they potentially move too far from their initial positions, which can lead to a scrambled result appearance ( Figure 5 ). 2. Locality: since all output pixels have the same size, the kernels should also neither become too large or vanish. Their influence should remain local ( Figure 6 ). 3. Edge orientations: The boundary between two neighboring kernels should have a similar orientation as the boundary between the two pixels in the output image ( Figure 7 ).\n        173:4\n        ?\n        J. Kopf et al.\n        \n          \n        \n        (a) Unconstrained\n        (b) Kernels\n        (c) Constrained\n        \n          Figure 5: Spatial constraints are important to maintain the grid topology of the kernels.\n          \n        \n        (a) Input (b) Unconstrained (c) Constrained\n         Figure 6 : Enforcing local kernels. ? k (i).\n        normalized\n      \n      \n        The small side-images show the kernels (b) The dark pixel?s kernel grabs a long stretch of the line, while its neighbor?s kernel completely avoids the line. (c) The smoothness of the kernels are increased until a more balanced configuration is reached.\n        ? k\n        4.1 Spatial Constraints\n        To retain the characteristics of the grid topology of the output pixels, we bias the spatial mean ? k towards a smooth grid-like topology. First, we limit the extent the spatial mean can move by constraining ? k to lie within a box, centered around the center of the output pixel. Second, we increase smoothness by moving ? k halfway between its estimated location and the the mean of its four neighbors. Formally, we update\n        \n          11\n          k k k k k\n        \n        \n          11\n          ? ? clampBox 1 2 ? + 1 2 ? , (x , y ) ? ( r 4 x , r 4 y ) ,\n        \n        k\n      \n      \n        N 4 , and N k. The effect\n        where ? k = ? n?N 4 ? n / k (4-connected) neighbors of is shown in Figure 5 .\n        4 denotes the set of cardinal k of these spatial constraints\n        4.2 Locality and Edge Orientations\n        We constrain the shape of the spatial variance ? k to avoid vanishingly small or exceedingly large kernels. We first obtain the singular value decomposition (U, S,V ) = SVD(? k ), and modify the diagonal eigenvalue matrix S by clamping its elements to the interval [0.05, 0.1], and finally set\n        \n          12\n          ? k ? US V ,\n        \n        where S contains the clamped eigenvalues. While Equation 12 imposes a hard constraint on the spatial component of our kernels to be relatively smooth, the color component causes them to align with features in the image. In general this is desired, however, in certain situations too much adaptation can cause visual artifacts. We use the color variance parameter ? k , which is not estimated, to directly control the amount of adaptation, and, hence, the sharpness of our results. Small ? k cause kernels to be more sensitive to color variations and have sharper transitions, while larger ? k lead to smoother kernels. The reason for not freely estimating ? k is that the maximum likelihood estimation often yields too smooth configurations. Rather ACM Transactions on Graphics, Vol. 32, No. 6, Article 173, Publication Date: November 2013\n        \n          \n        \n        (a) Input (b) Unconstrained (c) Constrained\n        \n          Figure 7: We detect strong pixel edges whose orientation deviates from the edge between the corresponding kernels (e.g., the edge with the arrow), and selectively increase the smoothness of these kernels.\n        \n        than estimating ? k from the data, we control it explicitly to locally adjust the sharpness of the result. For most kernels we let ? k remain at its initial ?crisp? setting, and we only increase local smoothing under two specific conditions: (1) when kernels become too dominant compared to their neighbors, and (2) to prevent staircasing artifacts. Following each maximization step we search for kernels that match one of these conditions, and correct them by increasing ? k by 10% (i.e., increase the smoothness of the color kernel). Locality: While clamping the eigenvalues of ? k avoids large spatial Gaussians, the resulting bilateral kernels can still have a large spatial extent due to the normalization in Equation 7. Figure 6b illustrates an instance of this problem. The small figures show the normalized kernel weights ? k (i) for two pixels. In subfigure (b) the kernels keep a small color variance, leading to a solution where one kernel grabs all dark pixels on the line, while the other kernels grab the light pixels in the surrounding. Even though the spatial weights of the kernel on the line fall off quickly, the normalization causes them to become large again, because the surrounding kernels have even lower weights due to the strong color adaption. This causes the line feature to become disconnected. We correct this behavior by detecting kernels that are growing too strong in any direction, and then selectively increase their color variance. First, we compute the directional variance for each of the eight neighbors:\n        \n          13\n          s d = ? (i) max 0, (p i ? ? ) ? d 2 ,\n        \n        \n          13\n          k ? k k i\n        \n        where d ? (a, b) | a, b ? [?1, 1] \\ (0, 0) is the offset to one of the eight neighbors. If any directional variance s d exceed a threshk old of 0.2r x (where r x is the ratio of the input image?s width over the output image?s width), we increase the smoothness of both the current kernel and the respective neighbor. The effect of this heuristic is illustrated in Figure 6c . The ability of our algorithm to keep linear features connected while maintaining sharpness can also be nicely observed in the pixel art results in Figures 1, 8, and 15. Edge Orientations: A form of staircasing artifacts occur when the orientation of an edge between two dissimilar pixels in the output pixel grid is significantly different than the orientation of the edge between the corresponding kernels. This artifact is most visible on long lines with almost cardinal direction. Consider, for example, the horizontal edge marked with an arrow in Figure 7b . The corresponding image edge in the input image is almost vertical. We selectively remove such false edges by increasing ? k of the corresponding kernels. First, we detect strong edges between adjacent pixels by testing for neighboring kernels that have an abrupt transition. If k and n are horizontal or vertical neighbors, we measure the strength of the edge between the normalized kernels f kn = ? i ? k (i)? n (i). If the transition between the two kernels is abrupt, there will be few pixels where both kernels take on large values, and, thus, f kn will be small. We consider edges where f kn < 0.08r x r y as strong. Next, we compute the direction of the edge between the kernels as d kn = ? i ? ? k (i)/(? k (i) + ? n (i)) . If\n        256 colors\n        12 colors\n        \n          \n        \n        Input Not quantized 12 colors\n        \n          Figure 8: Our method can also be extended to create pixel art with a limited color palette from cartoon and vector inputs. Color quantization is achieved in a post-process using mean shift segmentation. (Input image c Nintendo Co., Ltd.)\n          \n        \n        Input Gerstner et al., Our result, Input 16 colors 16 colors\n        \n          Figure 9: Post-process color quantization using k-means clustering combined with our content-aware downsampling methods applied to natural images yields similar results to prior work.\n        \n        d kn deviates by more than 25 degrees from the orientation of the pixel edge, we consider this a false edge and increase the smoothness of both kernels involved. The effect of this correction is illustrated in Figure 7c .\n      \n      \n        5 Results\n        We tested our algorithm on a wide range of input images ranging from natural images to line and vector art. All results were created with the same algorithm settings. Figure 13 and other figures throughout the paper show representative results of our algorithm. We compare our method to na?ve subsampling and the bicubic filter (arguably the most commonly used rescaling algorithms). Our results show that our method yields sharper results (for instance on text), maintains details better (e.g., on the lunar surface or the flower in Figure 13), and preserves the appearance of high frequency textures (e.g., Figure 1 -left). In the supplementary material we provide an extensive comparison on a large set of images, and compare our method to a wider range of downscaling methods (including a range of linear filters, unoptimized bilateral kernels, Generalized Sampling [Nehab and Hoppe 2011], and Pixelated Image Abstraction [Gerstner et al. 2012]).\n        \n          5.2 User Study 5.1 Pixel Art Downscaling and Palette Reduction\n          Downscaling: Our algorithm is particularly well suited for downscaling cartoon and vector art images to create pixel art. Figures 1, 8, and 15 show representative results. When generating these results we disabled the edge orientation constraint (Section 4.2), since we are aiming for a blocky ?old school? look (i.e., big pixels). Of particular note is our algorithm?s ability to keep line features connected. In comparison, many lines in the subsampled results are interrupted, while the bicubic results exhibits washed out colors due to excessive smoothing. Our algorithm strikes a balance between both extremes: it keeps outlines sharp and connected where ACM Transactions on Graphics, Vol. 32, No. 6, Article 173, Publication Date: November 2013\n          5 colors\n          4 colors\n          8 colors 6 colors Gerstner et al.?s results\n          8 colors 6 colors 5 colors 4 colors Our results\n          Gerstner et al., Our result, 16 colors 16 colors\n          possible, while in too detailed areas it naturally resolves to averaging out features. Extension for Palette Reduction: One particular form of pixel art also includes a reduced color palette [Gerstner et al. 2012]. While not the focus of our method, we were interested in investigating the effectiveness of applying color palette reduction in a postprocess. We use mean shift segmentation, following the description of Comaniciu and Meer?s paper [2002] (using the Epanechnikov kernel, and fixed spatial bandwidth h s = 4), and use the color bandwidth parameter h r to adjust the number of colors in the output image. We found that this works particularly well on cartoon and vector art inputs as shown in Figure 8 . On these type of images, our method produces higher quality results than Gerstner et al. [2012]. However, this is mainly due to our algorithm?s ability to keep line features connected. When applied to natural images, however, we found mean shift segmentation to not work well. Instead, we use simple k-means clustering for natural images, where it produces images of similar quality as Gerstner et al. [2012] ( Figure 9 ). To verify our algorithm we conducted a formal user study with 51 subjects using Amazon Mechanical Turk, in which we compare our algorithm against five alternatives: (1) Generalized Sampling [Nehab and Hoppe 2011], which we consider the state-of-the-art algorithm for image scaling, (2) bicubic, since it is one of the most commonly used scaling algorithms, (3) subsampling, for its simplicity, (4) box filtering, because it yields sharper results than bicubic, and (5) unoptimized bilateral kernels, to verify the effectiveness of our optimization. In each test we showed the participant the ?high resolution? (400 pixels on the long side) input image as well as two downscaled re-\n          173:6\n          ?\n          J. Kopf et al.\n          \n            Figure 10:\n          \n          Results of the user study comparing our algorithm against several existing algorithms.\n          sults (128 pixels), one produced by our algorithm, and the other produced by one of the competing algorithms. Participants were asked which result ?represents a better downscaled version of the input image?, and had to choose either one of the results or express ?no preference?. No time limit was imposed. All images were shown at native display resolution and participants were not provided with any means to zoom into the images. We did not, however, control the user distance from the screen to better simulate realistic application conditions, i.e., subjects could move closer to the screen to examine details. Each participant was presented 13 tests in total, each testing our algorithm against a random competing algorithm on a different input image, i.e., no participant saw the same input image more than once. We repeated every question throughout the test to filter unreliable participants by removing all answers from participants who were consistent on less than 80% of the tests. For the study we selected a variety of natural images from the MSRA Salient Object Database [Liu et al. 2007] that span different categories, including people, stochastic and regular textures, text, and smooth areas. The images used for the study are provided in the supplementary material. Results are shown in Figure 10 . A ? 2 -analysis between each condition indicates that our algorithm was significantly preferred over each of the competing techniques.\n        \n        \n          5.3 Performance\n          Our method employs an iterative optimization strategy to downscale images, consequently, it is computationally more demanding than classical linear rescaling filters. In the following we analyze the performance of our C++ implementation, running on a Intel Xeon E5640 CPU at 2.66 GHz. We partially use multiple cores in our implementation, but we have not fully parallelized or optimized the implementation. The convergence proofs of the original EM-Algorithm do not carry through onto our algorithm due to our modifications. However, we did not encounter convergence issues on several thousand images tested?if this would happen one could simply terminate the algorithm after a fixed number of iterations. A single iteration of our algorithm is linear both in the input and output image sizes. Due to the content dependent nature of our algorithm, the number of iterations varies for different in-/output images of the same size. Figure 11 reports the runtime (blue) and number of iterations (red) averaged over processing 100 randomly selected natural images. The shaded region indicates the standard deviation and the dashed lines indicate the min?max ranges. In Figure 11 -left, the output size is kept fixed at 80?60 pixels, while the input size varies from 160?120 to 640?480. In Figure 11 -right, the output size varies from 40?30 to 160?120 while the input size remains fixed at 640?480 pixels. ACM Transactions on Graphics, Vol. 32, No. 6, Article 173, Publication Date: November 2013\n          Varying input dimensions, fixed output dimensions Varying output dimensions, fixed input dimensions\n           Figure 11 :\n        \n      \n      \n        Average runtime (blue) and number of iterations (red) from processing 100 random natural images. The shaded region indicates the standard deviation, and the dashed lines indicate the min-max range. The left/right figures show the result of varying the input/output image dimensions while keeping the other fixed.\n        5.4 Limitations\n        Our algorithm relies on a number of heuristic constraints to prevent certain downscaling artifacts (Section 4). It would be desirable to incorporate these constraints directly into the EM optimization, however, most of these constraints are of a fundamentally different nature. The EM steps process each kernel independently. The constraints, on the other hand, rely on the relation between neighboring kernels, and hence, cannot be directly solved in the E or M step. Therefore, these constraints are handled in an additional third step.  Due to the content-adaptive nature our algorithm behaves temporally less coherent than linear filters when applied to smooth animations, e.g., a slow zoom into a picture. Our results are flickering slightly, while each individual image appears crisper and exhibits more detail. Please refer to the supplementary material for videos illustrating this issue. A similar problem can occur for symmetric features in input images. For example, our algorithm fails to preserve the symmetry of the yellow buttons in Figure 12. Our algorithm does not prevent aliasing under all circumstances. Consequently, our method does not perform well on most standard aliasing tests, e.g., the zone plate pattern in Figure 12. Furthermore, our results cannot reach the quality that well-trained experts achieve when manually hinting fonts and manually creating pixel art (Figure 12, bottom). While our method significantly improves the quality of downscaled images exhibiting small details such as eyes or stochastic textures, it does not always produce better results on images with blurred features, or images that contain structured textures. In the latter case, despite our efforts (Section 4), staircasing can still occur. This artifact shows up in particular on long, almost cardinal lines, e.g., the right edge of the sign in the top row of Figure 13. A systematic investigation of this artifact can be found in the supplementary material and accompanying web site. Lastly, since Equation (5) may have multiple local minima, we may reach slightly different solutions depending on our initialization. In the supplementary material and accompanying web site we show that various sensible initialization choices yield similar solutions. We settled on using a ?middle gray? initialization, which worked well in our tests.\n        Content-Adaptive Image Downscaling\n        ?\n        173:7\n        \n          \n        \n        Input\n        \n          \n        \n        Bicubic\n        \n          \n        \n        Our result\n        \n          \n        \n        Input\n        Bicubic\n        Our result\n        \n          \n        \n        Figure 12: Limitations of our method.\n      \n      \n        Top: our algorithm fails to preserve the symmetric arrangement of the yellow buttons on Mario?s overall. Middle: Our method was not specifically designed to prevent aliasing under all circumstances. Bottom: Our method cannot compete with manually downscaled images. (?Mario? input image c Nintendo Co., Ltd.)\n      \n      \n        6 Conclusions\n        We have presented a novel content-adaptive image downscaling method that adapts the shape of its downsampling kernel, yielding sharper and more detailed downscaled results. Contrary to common wisdom that dictates that frequencies above the Nyquist frequency introduce artifacts in the downsampled image (in the form of aliasing), we show that by careful sampling, certain high frequencies features can still be preserved in the downscaled image without artifacts. Given the growing ?resolution gap? between cameras and display devices and the advent of gigapixel panoramic imaging, we believe that this work opens up an exciting area of research. There are plentiful avenues for future research. Our work has shown that it is possible to sometimes drastically improve quality over existing downscaling methods. For future work we would like to further improve the robustness of the method, e.g., through smarter heuristics, so that our method always outperforms simpler filters. It would also be interesting to look at other signals than images as inputs. A natural immediate step would be to analyze and constrain the temporal behavior of our algorithm, e.g., when applying it to videos.\n      \n      \n        Acknowledgements\n        This work was in part supported by NSF IIS-1217765 and by the Israeli Science Foundation (grant no. 324/11).\n      \n      \n        References\n        \n          A CHANTA , R., S HAJI , A., S MITH , K., L UCCHI , A., F UA , P., AND S USSTRUNK  ? , S. 2012. Slic superpixels compared to stateACM Transactions on Graphics, Vol. 32, No. 6, Article 173, Publication Date: November 2013\n        \n        of-the-art superpixel methods. IEEE Trans. Pattern Anal. Mach. Intell. 34, 11, 2274?2282. A VIDAN , S., AND S HAMIR , A. Seam carving for content-aware image resizing. ACM Transactions on Graphics, (Proc. SIGGRAPH 2007) 26, 3, article no. 10. C OMANICIU , D., M EER , P., AND M EMBER , S. 2002. Mean shift: A robust approach toward feature space analysis. IEEE Transactions on Pattern Analysis and Machine Intelligence 24, 603?619. G ERSTNER , T., D E C ARLO , D., A LEXA , M., F INKELSTEIN , A., G INGOLD , Y., AND N EALEN , A. 2012. Pixelated image abstraction. Proceedings of the International Symposium on NonPhotorealistic Animation and Rendering (NPAR), 29?36. H ASTIE , T., T IBSHIRANI , R., F RIEDMAN , J., AND F RANKLIN , J. 2005. The elements of statistical learning: data mining, inference and prediction. The Mathematical Intelligencer 27, 2, 83?85. I NGLIS , T. C., AND K APLAN , C. S. 2012. Pixelating vector line art. Proceedings of the Symposium on Non-Photorealistic Animation and Rendering, 21?28. K ARNI , Z., F REEDMAN , D., AND G OTSMAN , C. 2009. Energybased image deformation. Proceedings of the Symposium on Geometry Processing (SGP 2009), 1257?1268. L IU , T., S UN , J., Z HENG , N.-N., T ANG , X., AND S HUM , H.-Y. 2007. Learning to detect a salient object. Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2007), 1?8. M ANSON , J., AND S CHAEFER , S. 2012. Parameterization-aware mip-mapping. Computer Graphics Forum (Proc. Eurographics Symposium on Rendering) 31, 4, 1455?1463. N EHAB , D., AND H OPPE , H. 2011. Generalized sampling for computer graphics. Tech. rep., feb. R UBINSTEIN , M., S HAMIR , A., AND A VIDAN , S. 2009. Multioperator media retargeting. ACM Transactions on Graphics (Proceedings SIGGRAPH 2009) 28, 3, 1?11. S AMADANI , R., L IM , S. H., AND T RETTER , D. 2007. Representative image thumbnails for good browsing. Proceedings of the International Conference on Image Processing (ICIP 2007), 193?196. S HANNON , C. E. 1949. Communication in the presence of noise. Proceedings of the Institute of Radio Engineers 37, 1, 10?21. S UH , B., L ING , H., B EDERSON , B. B., AND J ACOBS , D. W. 2003. Automatic thumbnail cropping and its effectiveness. Proceedings of the 16th annual ACM symposium on User interface software and technology, 95?104. T OMASI , C., AND M ANDUCHI , R. 1998. Bilateral filtering for gray and color images. Proceedings of IEEE International Conference on Computer Vision (ICCV ?98), 836?846. T RENTACOSTE , M., M ANTIUK , R., AND H EIDRICH , W. 2011. Blur-aware image downsizing. Computer Graphics Forum (Proc. Eurographics 2011) 30, 2, 573?582. T RIGGS , B. 2001. Empirical filter estimation for subpixel interpolation and matching. Proceedings of IEEE International Conference on Computer Vision (ICCV 2001) 2, 550?557. W OLBERG , G. 1990. Digital Image Warping. IEEE Computer Society Press, Los Alamitos, CA, USA. W OLF , L., G UTTMANN , M., AND C OHEN -O R , D. 2007. Nonhomogeneous content-driven video-retargeting. Proceedings of IEEE International Conference on Computer Vision (ICCV 2007), 1?6.\n        173:8\n        ?\n        J. Kopf et al.\n        \n          \n        \n        Input Subsampling Bicubic\n        \n          \n        \n        Input Subsampling Bicubic\n        \n          Figure 13: A comparison of natural images downscaled using subsampling, bicubic, and our algorithm. To fully appreciate the quality difference of the downsampled results, we recommend viewing the results in native resolution when viewed electronically. An extended set of results can be found in the supplementary material.\n          \n        \n        Input\n        Downscaled\n        \n          Figure 14: A selection of downscaled results at various output resolutions ranging from 32 ? 24 to 192 ? 144 (original resolution: 708 ? 531 and 384 ? 288 for the ?Snow Leopard? and ?Flowers? respectively). Our method produces good results at any scale. In the supplementary material we compare against the bicubic filter on slowly zooming videos.\n          \n        \n        Input Subsampling\n        \n          Figure 15: Our method can be used to create pixel art from drawn inputs. Note the ability of our algorithm to keep features connected (e.g., the outline). Furthermore, the ?staircase? correction step was disabled to achieve the typical quantized look of pixel art. (Input images c Nintendo Co., Ltd.)\n        \n        ACM Transactions on Graphics, Vol. 32, No. 6, Article 173, Publication Date: November 2013\n        Our result Input\n        Our result Input\n        Input\n        Bicubic Our result Input\n      \n    \n  ",
  "resources" : [ ]
}