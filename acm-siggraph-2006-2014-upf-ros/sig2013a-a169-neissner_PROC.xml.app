{
  "uri" : "sig2013a-a169-neissner_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2013a/a169-neissner_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Real-time 3D Reconstruction at Scale using Voxel Hashing",
    "published" : null,
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ ]
  },
  "bagOfWords" : [ "online", "3d", "reconstruction", "gain", "newfound", "interest", "due", "availability", "real-time", "consumer", "depth", "camera", "basic", "problem", "take", "live", "overlap", "depth", "map", "input", "incrementally", "fuse", "single", "3d", "model", "challenging", "particularly", "when", "real-time", "performance", "desire", "without", "trade", "quality", "scale", "we", "contribute", "online", "system", "large", "fine", "scale", "volumetric", "reconstruction", "base", "memory", "speed", "efficient", "datum", "structure", "surface", "datum", "only", "store", "densely", "where", "measurement", "observe", "additionally", "datum", "can", "stream", "efficiently", "out", "hash", "table", "allow", "further", "scalability", "during", "sensor", "motion", "we", "show", "interactive", "reconstruction", "variety", "scene", "reconstruct", "both", "fine-grained", "detail", "large", "scale", "environment", "while", "3d", "reconstruction", "established", "field", "computer", "vision", "graphic", "now", "gain", "newfound", "momentum", "due", "wide", "availability", "depth", "camera", "-lrb-", "Microsoft", "Kinect", "Asus", "Xtion", "-rrb-", "ability", "obtain", "reconstruction", "real-time", "open", "up", "various", "interactive", "application", "include", "augmented", "reality", "-lrb-", "ar", "-rrb-", "where", "real-world", "geometry", "can", "fuse", "3d", "graphic", "render", "live", "user", "autonomous", "guidance", "robot", "reconstruct", "respond", "rapidly", "environment", "even", "provide", "immediate", "feedback", "user", "during", "3d", "scanning", "online", "reconstruction", "require", "incremental", "fusion", "many", "overlap", "depth", "map", "single", "3d", "representation", "continuously", "refine", "challenging", "particularly", "when", "real-time", "performance", "require", "without", "trading", "fine-quality", "reconstruction", "spatial", "scale", "many", "state-of-the-art", "online", "technique", "therefore", "employ", "different", "type", "underlie", "datum", "structure", "accelerate", "use", "graphic", "hardware", "point-based", "method", "-lrb-", "e.g.", "-lsb-", "Rusinkiewicz", "et", "al.", "2002", "Weise", "et", "al.", "2009", "-rsb-", "-rrb-", "use", "simple", "unstructured", "representation", "closely", "map", "range", "depth", "sensor", "input", "lack", "ability", "directly", "reconstruct", "connected", "surface", "height-map", "base", "representation", "-lsb-", "pollefey", "et", "al.", "2008", "Gallup", "et", "al.", "2010", "-rsb-", "support", "efficient", "compression", "connected", "surface", "datum", "can", "scale", "efficiently", "larger", "scene", "fail", "reconstruct", "complex", "3d", "structure", "hierarchical", "datum", "structure", "subdivide", "space", "more", "effectively", "do", "parallelize", "efficiently", "give", "add", "computational", "complexity", "-lsb-", "Zeng", "et", "al.", "2012", "Chen", "et", "al.", "2013", "-rsb-", "we", "contribute", "new", "real-time", "surface", "reconstruction", "system", "which", "support", "fine-quality", "reconstruction", "scale", "we", "approach", "carry", "benefit", "volumetric", "approach", "do", "require", "either", "memory", "constrain", "voxel", "grid", "computational", "overhead", "hierarchical", "datum", "structure", "section", "we", "review", "relevant", "system", "focus", "online", "reconstruction", "method", "active", "sensor", "Parametric", "method", "-lsb-", "Chen", "Medioni", "1992", "Higuchi", "et", "al.", "1995", "-rsb-", "simply", "average", "overlap", "sample", "connect", "point", "assume", "simple", "surface", "topology", "-lrb-", "cylinder", "sphere", "-rrb-", "locally", "fit", "polygon", "challenge", "associate", "work", "directly", "polygon", "mesh", "have", "lead", "many", "other", "reconstruction", "method", "larger", "scene", "have", "be", "reconstruct", "trade", "real-time", "speed", "quality", "-lsb-", "Henry", "et", "al.", "2012", "St?ckler", "Behnke", "2012", "-rsb-", "method", "lack", "ability", "directly", "model", "connected", "surface", "require", "additional", "expensive", "often", "offline", "step", "construct", "surface", "e.g.", "use", "volumetric", "datum", "structure", "-lsb-", "Rusinkiewicz", "et", "al.", "2002", "-rsb-", "while", "method", "support", "more", "efficient", "compression", "surface", "datum", "2.5", "representation", "fail", "reconstruct", "many", "type", "complex", "3d", "structure", "while", "show", "high", "quality", "reconstruction", "method", "particularly", "give", "computational", "cost", "approach", "suffer", "from", "one", "major", "limitation", "use", "regular", "voxel", "grid", "impose", "large", "memory", "footprint", "represent", "both", "empty", "space", "surface", "densely", "thus", "fail", "reconstruct", "larger", "scene", "without", "compromise", "quality", "scaling-up", "Volumetric", "fusion", "recent", "work", "begin", "address", "spatial", "limitation", "volumetric", "method", "different", "way", "surface", "datum", "compress", "mesh", "once", "move", "host", "can", "stream", "back", "GPU", "limit", "reconstruction", "scene", "close-by", "geometric", "structure", "can", "utilize", "full", "range", "datum", "active", "sensor", "Kinect", "approach", "have", "begin", "explore", "context", "online", "reconstruction", "where", "need", "support", "real-time", "update", "underlie", "datum", "add", "fundamentally", "new", "challenge", "example", "-lsb-", "Zhou", "et", "al.", "2011", "-rsb-", "demonstrate", "gpu-based", "octree", "which", "can", "perform", "Poisson", "surface", "reconstruction", "300k", "vertex", "interactive", "rate", "method", "however", "require", "complex", "octree", "structure", "implement", "additional", "computational", "complexity", "pointer", "overhead", "only", "limited", "gain", "scale", "single", "depth", "map", "datum", "integrate", "grid", "uniformly", "sweep", "through", "volume", "cull", "voxel", "outside", "view", "frustum", "project", "all", "voxel", "center", "depth", "map", "update", "store", "sdf", "value", "key", "challenge", "become", "how", "design", "datum", "structure", "exploit", "underlie", "sparsity", "tsdf", "representation", "we", "goal", "build", "real-time", "system", "employ", "spatial", "hash", "scheme", "scalable", "volumetric", "reconstruction", "hash", "table", "unstructured", "i.e.", "neighbor", "voxel", "block", "store", "spatially", "can", "different", "part", "hash", "table", "we", "find", "element", "same", "world", "space", "position", "we", "can", "immediately", "return", "reference", "bucket", "lock", "write", "all", "other", "allocation", "same", "bucket", "stagger", "until", "next", "frame", "process", "entry", "find", "bucket", "have", "link", "list", "associate", "-lrb-", "offset", "value", "last", "entry", "set", "-rrb-", "we", "also", "have", "traverse", "list", "synchronization", "require", "deletion", "directly", "within", "bucket", "before", "integration", "new", "tsdf", "voxel", "block", "must", "allocate", "fall", "within", "footprint", "each", "input", "depth", "sample", "also", "within", "truncation", "region", "surface", "measurement", "idealized", "case", "each", "depth", "sample", "would", "model", "entire", "frustum", "rather", "than", "single", "ray", "voxel", "block", "subsequently", "free", "its", "index", "append", "end", "list" ],
  "content" : "Online 3D reconstruction is gaining newfound interest due to the availability of real-time consumer depth cameras. The basic problem takes live overlapping depth maps as input and incrementally fuses these into a single 3D model. This is challenging particularly when real-time performance is desired without trading quality or scale. We contribute an online system for large and fine scale volumetric reconstruction based on a memory and speed efficient data structure. Surface data is only stored densely where measurements are observed. Additionally, data can be streamed efficiently in or out of the hash table, allowing for further scalability during sensor motion. We show interactive reconstructions of a variety of scenes, reconstructing both fine-grained details and large scale environments. While 3D reconstruction is an established field in computer vision and graphics, it is now gaining newfound momentum due to the wide availability of depth cameras (such as the Microsoft Kinect and Asus Xtion). The ability to obtain reconstructions in real-time opens up various interactive applications including: augmented reality (AR) where real-world geometry can be fused with 3D graphics and rendered live to the user; autonomous guidance for robots to reconstruct and respond rapidly to their environment; or even to provide immediate feedback to users during 3D scanning. Online reconstruction requires incremental fusion of many overlapping depth maps into a single 3D representation that is continuously refined. This is challenging particularly when real-time performance is required without trading fine-quality reconstructions and spatial scale. Many state-of-the-art online techniques therefore employ different types of underlying data structures accelerated using graphics hardware. Point-based methods (e.g., [Rusinkiewicz et al. 2002; Weise et al. 2009]) use simple unstructured representations that closely map to range and depth sensor input, but lack the ability to directly reconstruct connected surfaces. Height-map based representations [Pollefeys et al. 2008; Gallup et al. 2010] support efficient compression of connected surface data, and can scale efficiently to larger scenes, but fail to reconstruct complex 3D structures. Or hierarchical data structures that subdivide space more effectively, but do not parallelize efficiently given added computational complexity [Zeng et al. 2012; Chen et al. 2013]. We contribute a new real-time surface reconstruction system which supports fine-quality reconstructions at scale. Our approach carries the benefits of volumetric approaches, but does not require either a memory constrained voxel grid or the computational overheads of a hierarchical data structure. In this section we review relevant systems, with a focus on online reconstruction methods and active sensors. Parametric methods [Chen and Medioni 1992; Higuchi et al. 1995] simply average overlapping samples, and connect points by assuming a simple surface topology (such as a cylinder or a sphere) to locally fit polygons. These challenges associated with working directly with polygon meshes have led to many other reconstruction methods. Larger scenes have been reconstructed by trading real-time speed and quality [Henry et al. 2012; St?ckler and Behnke 2012]. These methods lack the ability to directly model connected surfaces, requiring additional expensive and often offline steps to construct surfaces; e.g., using volumetric data structures [Rusinkiewicz et al. 2002]. While these methods support more efficient compression of surface data, the 2.5D representation fails to reconstruct many types of complex 3D structures. While shown to be a high quality reconstruction method, particularly given the computational cost, this approach suffers from one major limitation: the use of a regular voxel grid imposes a large memory footprint, representing both empty space and surfaces densely, and thus fails to reconstruct larger scenes without compromising quality. Scaling-up Volumetric Fusion Recent work begins to address this spatial limitation of volumetric methods in different ways. Surface data is compressed to a mesh, and once moved to host cannot be streamed back to the GPU. This limits reconstructions to scenes with close-by geometric structures, and cannot utilize the full range of data for active sensors such as the Kinect. These approaches have begun to be explored in the context of online reconstruction, where the need to support real-time updates of the underlying data adds a fundamentally new challenge. For example, [Zhou et al. 2011] demonstrate a GPU-based octree which can perform Poisson surface reconstruction on 300K vertices at interactive rates. The method however requires a complex octree structure to be implemented, with additional computational complexity and pointer overhead, with only limited gains in scale. For a single depth map, data is integrated into the grid by uniformly sweeping through the volume, culling voxels outside of the view frustum, projecting all voxel centers into the depth map, and updating stored SDF values. The key challenge becomes how to design a data structure that exploits this underlying sparsity in the TSDF representation. Our goal is to build a real-time system that employs a spatial hashing scheme for scalable volumetric reconstruction. The hash table is unstructured; i.e., neighboring voxel blocks are not stored spatially, but can be in different parts of the hash table. If we find an element with the same world space position we can immediately return a reference. If a bucket is locked for writing, all other allocations for the same bucket are staggered until the next frame is processed. If no entry is found, and the bucket has a linked list associated (the offset value of the last entry is set), we also have to traverse this list. Synchronization is not required for deletion directly within the bucket. Before integration of new TSDFs, voxel blocks must be allocated that fall within the footprint of each input depth sample, and are also within the truncation region of the surface measurement. In an idealized case, each depth sample would be modeled as an entire frustum rather than a single ray. If a voxel block is subsequently freed, its index is appended to the end of the list.",
  "resources" : [ ]
}