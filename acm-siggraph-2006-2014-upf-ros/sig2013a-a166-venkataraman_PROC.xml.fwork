{
  "uri" : "sig2013a-a166-venkataraman_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2013a/a166-venkataraman_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "PiCam: An Ultra-Thin High Performance Monolithic Camera Array",
    "published" : "2013",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Kartik-Venkataraman",
      "name" : "Kartik",
      "surname" : "Venkataraman"
    }, {
      "uri" : "http://drinventor/Dan-Lelescu",
      "name" : "Dan",
      "surname" : "Lelescu"
    }, {
      "uri" : "http://drinventor/Jacques-Duparr?",
      "name" : "Jacques",
      "surname" : "Duparr?"
    }, {
      "uri" : "http://drinventor/Andrew-McMahon",
      "name" : "Andrew",
      "surname" : "McMahon"
    }, {
      "uri" : "http://drinventor/Gabriel-Molina",
      "name" : "Gabriel",
      "surname" : "Molina"
    }, {
      "uri" : "http://drinventor/Priyam-Chatterjee",
      "name" : "Priyam",
      "surname" : "Chatterjee"
    }, {
      "uri" : "http://drinventor/Robert-Mullis",
      "name" : "Robert",
      "surname" : "Mullis"
    }, {
      "uri" : "http://drinventor/Shree-Nayar",
      "name" : "Shree",
      "surname" : "Nayar"
    } ]
  },
  "bagOfWords" : [ "cr", "category", "i.", "3.7", "-lsb-", "Computer", "Graphics", "-rsb-", "digitization", "image", "capture?applications", "i.", "4.4", "-lsb-", "image", "processing", "computer", "Vision", "-rsb-", "restoration?inverse", "filter", "i.", "4.8", "-lsb-", "image", "processing", "computer", "Vision", "-rsb-", "scene", "analysis?range", "datum", "we", "refer", "basic", "camera", "array", "module", "picam", "-lrb-", "figure", "-rrb-", "choice", "aperture", "size", "number", "aperture", "picam", "guide", "need", "regain", "resolution", "suppress", "aperture", "size", "reduction", "through", "post-capture", "superresolution", "process", "concept", "array", "camera", "novel", "itself", "have", "be", "considerable", "prior", "work", "design", "array", "camera", "various", "application", "-lsb-", "Rander", "et", "al.", "1997", "Yang", "et", "al.", "2002", "Zhang", "Chen", "2004", "Tanida", "et", "al.", "2001", "Tanida", "et", "al.", "2003", "Duparr", "et", "al.", "2004", "Bruckner", "et", "al.", "2010", "-rsb-", "software", "pipeline", "present", "section", "what", "know", "today", "integral", "photography", "Taylor", "extend", "idea", "dynamic", "scene", "use", "linear", "array", "still", "camera", "synchronize", "trigger", "simultaneously", "synchronous", "system", "51", "video", "camera", "surround", "scene", "hemisphere", "discuss", "Rander", "et", "al.", "-lsb-", "1997", "-rsb-", "other", "approach", "most", "notably", "-lsb-", "Yang", "et", "al.", "2002", "-rsb-", "-lsb-", "Zhang", "Chen", "2004", "-rsb-", "use", "off-the-shelf", "camera", "without", "explicit", "synchronization", "between", "they", "more", "recently", "method", "propose", "Nomura", "et", "al.", "-lsb-", "2007", "-rsb-", "capture", "scene", "collage", "from", "multiple", "point", "view", "use", "flexible", "array", "design", "use", "plastic", "frame", "onto", "which", "set", "camera", "can", "mount", "variety", "layout", "which", "can", "physically", "flex", "vary", "shape", "array", "optical", "design", "most", "resemble", "original", "plenoptic", "camera", "Adelson", "Wang", "-lsb-", "1992", "-rsb-", "Georgiev", "et", "al.", "-lsb-", "2011", "-rsb-", "slightly", "modify", "approach", "suggest", "where", "lenslet", "array", "move", "beyond", "focal", "plane", "main", "lens", "focus", "plenoptic", "camera", "take", "step", "direction", "superresolve", "light", "field", "enable", "they", "perform", "fusion", "super-resolution", "-lrb-", "interleaved", "fusion", "-rrb-", "compare", "ng?s", "work", "however", "approach", "do", "consider", "impact", "pixel", "blur", "snr", "Bayer", "crosstalk", "lens", "blur", "do", "use", "formal", "stabilize", "non-blind", "complete", "image", "restoration", "process", "we", "do", "we", "approach", "however", "IBP", "essentially", "implement", "Maximum", "Likelihood", "-lrb-", "ML", "-rrb-", "solution", "superresolution", "problem", "Horisaki", "et", "al.", "-lsb-", "2008", "-rsb-", "irregular", "lens", "arrangement", "use", "ensure", "component", "image", "be", "non-identical", "used", "superresolution", "algorithm", "restore", "high-resolution", "image", "motivate", "compound", "eye", "insect", "Duparr", "et", "al.", "-lsb-", "2004", "-rsb-", "develop", "array", "camera", "use", "sophisticated", "micro-optical", "fabrication", "technique", "Color", "Filters", "secondly", "picam", "do", "use", "Bayer", "color", "filter", "pattern", "choose", "filter", "pattern", "need", "optimal", "both", "Lens", "Focal", "length", "finally", "focal", "length", "picam", "array", "its", "corresponding", "hyperfocal", "distance", "shorter", "compare", "equivalent", "legacy", "camera", "autofocus", "actuator", "may", "necessity", "because", "its", "lens", "have", "shorter", "hyperfocal", "distance", "which", "fundamentally", "determine", "its", "ability", "focus", "near", "object", "-lsb-", "kingslake", "1951", "-rsb-", "hyperfocal", "distance", "define", "closest", "distance", "which", "lens", "can", "focus", "while", "keep", "object", "infinity", "acceptably", "sharp", "function", "focal", "length", "f-number", "approximate", "where", "focal", "length", "lens", "its", "f-number", "circle", "confusion", "thus", "near", "focus", "distance", "lens", "become", "half", "hyperfocal", "distance", "adjust", "optical", "format", "from", "1000", "750", "800", "600", "1280", "1024", "pixel", "while", "simultaneously", "hold", "f-number", "constant", "f3", ".1", "show", "cross-hatched", "dot", "curve", "fact", "high-end", "camera", "often", "design", "employ", "optical", "lowpass", "filter", "attenuate", "higher", "order", "frequency", "mitigate", "aliasing", "Figure", "show", "typical", "pixel", "stack", "which", "light", "incident", "microlen", "very", "top", "stack", "-lrb-", "-rrb-", "corresponding", "sinc", "filter", "frequency", "domain", "cutoff", "-lrb-", "2w", "-rrb-", "-lrb-", "2w", "-rrb-", "legacy", "picam", "pixel", "color", "filter", "layer", "provide", "suitable", "surface", "effective", "microlen", "formation", "spatial", "domain", "square", "pixel", "can", "model", "box", "filter", "which", "frequency", "domain", "sinc", "function", "example", "f2", ".0", "lens", "optical", "format", "1000", "750", "1.75", "pixel", "mtf20", "-lrb-", "spatial", "frequency", "which", "MTF", "20", "-rrb-", "1627lw/ph", "while", "corresponding", "mtf20", "value", "after", "pixel", "sampling", "blur", "take", "account", "around", "1000lw/ph", "achieve", "functionality", "necessitate", "each", "focal", "plane", "pixel", "group", "have", "its", "own", "independent", "row", "control", "logic", "surface", "generate", "detect", "corresponding", "corner", "image", "black", "white", "checkerboard", "chart", "-lrb-", "30x25", "square", "-rrb-", "pixel", "value", "from", "image", "location", "obtain", "through", "2d", "interpolation", "since", "location", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "do", "map", "integer", "grid", "location", "camera", "spatial", "filter", "apply", "matching", "score", "before", "decision", "order", "increase", "spatial", "support", "reduce", "spurious", "noise", "artifact", "final", "depth", "map", "common", "practice", "many", "stereo", "algorithm", "matrix", "represent", "total", "blur", "due", "optics", "sensor", "which", "assume", "spatially-invariant", "Maximum-a-Posteriori", "Formulation", "estimate", "can", "do", "through", "different", "sr", "approach", "-lrb-", "e.g.", "subspace", "method", "-lsb-", "Vandewalle", "et", "al.", "2007", "-rsb-", "sparse", "representation", "patch", "-lsb-", "Yang", "et", "al.", "2008", "-rsb-", "compressive", "-lsb-", "Sen", "Darabi", "2009", "-rsb-", "move", "least", "square", "sr", "-lsb-", "bose", "Ahuja", "2006", "-rsb-", "-rrb-", "map-based", "solution", "also", "popular", "sr", "literature", "see", "-lsb-", "Hardie", "et", "al.", "1997", "Farsiu", "et", "al.", "2004", "Protter", "Elad", "2009", "Pickup", "et", "al.", "2007", "-rsb-", "reference", "therein", "when", "l2-norm", "use", "likelihood", "term", "-lrb-", "under", "gaussian", "noise", "assumption", "-rrb-", "fuse", "hr", "image", "form", "transfer", "pixel", "from", "LR", "image", "reference", "camera?s", "hr", "grid", "use", "total", "displacement", "calculate", "during", "optical", "distortion", "calibration", "parallax", "detection", "important", "point", "need", "raise", "about", "commutativity", "matrix", "here", "however", "so", "when", "deal", "practical", "scene", "depth", "discontinuity", "where", "different", "object", "scene", "would", "shift", "differently", "each", "LR", "camera", "LR", "gradient", "upsampled", "blur", "inverse", "shift", "onto", "coordinate", "reference", "hr", "image", "where", "accumulate", "normalize", "per", "equation", "example", "Zomet", "et", "al.", "-lsb-", "2001", "-rsb-", "median", "filter", "use", "while", "El-Yamany", "Papamichalis", "-lsb-", "2008", "-rsb-", "apply", "more", "robust", "m-estimator", "likelihood", "term", "Protter", "Elad", "-lsb-", "2009", "-rsb-", "video", "super-resolution", "explicit", "motion", "compensation", "describe", "form", "weighted", "patch-based", "gra", "dient", "use", "bilateral", "weight", "since", "problem", "super-resolution", "ill-posed", "we", "use", "statistical", "prior", "regularize", "hr", "estimate", "current", "prior", "use", "image", "restoration", "include", "version", "total", "variation", "-lrb-", "tv", "-rrb-", "-lsb-", "Rudin", "et", "al.", "1992", "-rsb-", "approach", "include", "bilateral-tv", "-lsb-", "Farsiu", "et", "al.", "2006", "-rsb-", "autoregressive", "model", "prior", "-lsb-", "Bishop", "et", "al.", "2009", "-rsb-", "Gaussian", "Mixture", "model", "-lsb-", "Mitra", "Veeraraghavan", "2012", "-rsb-", "although", "tv", "prior", "encourage", "preservation", "edge", "restore", "image", "base", "global", "image", "statistics", "edge", "image", "approach", "spatial", "hr-image", "gradient", "different", "order", "weigh", "use", "bilateral", "weighting", "per-channel", "estimation", "optimal", "cross-channel", "approach", "always", "preferable", "algorithm", "computationally", "intensive", "while", "efficiency", "be", "exploit", "allow", "pipeline", "scale", "mobile", "device", "remain", "active", "area", "work", "due", "constrain", "nature", "power", "compute", "availability", "form", "factor" ],
  "content" : "CR Categories: I.3.7 [Computer Graphics]: Digitization and Image Capture?Applications I.4.4 [Image Processing and Computer Vision]: Restoration?Inverse filtering I.4.8 [Image Processing and Computer Vision]: Scene Analysis?Range data; We refer to this basic camera array module as PiCam ( Figure 2 ). The choice of aperture size and number of apertures in the PiCam is guided by the need to regain the resolution that is suppressed in the aperture size reduction through a post-capture superresolution process. The concept of array cameras is not novel in itself and there has been considerable prior work in designing array cameras for various applications [Rander et al. 1997; Yang et al. 2002; Zhang and Chen 2004; Tanida et al. 2001; Tanida et al. 2003; Duparr? et al. 2004; Bruckner et al. 2010]. The software pipeline is presented in Section 4. This is what is known today as integral photography. Taylor extended that idea to dynamic scenes by using a linear array of still cameras synchronized to trigger simultaneously. A synchronous system with 51 video cameras surrounding the scene in a hemisphere is discussed in Rander et al. [1997]. Other approaches, most notably [Yang et al. 2002] and [Zhang and Chen 2004], used off-the-shelf cameras without explicit synchronization between them. More recently, a method was proposed in Nomura et al. [2007] to capture scene collages from multiple points of view using a flexible array design. They used a plastic frame onto which sets of cameras can be mounted in a variety of layouts and which can be physically flexed to vary the shape of the array. Their optical design most resembles the original plenoptic camera in Adelson and Wang [1992]. In Georgiev et al. [2011] a slightly modified approach is suggested, where the lenslet array is moved beyond the focal plane of the main lens. This focused plenoptic camera takes a step in the direction of superresolving the light field as this enables them to perform a fusion super-resolution (interleaved fusion) compared to Ng?s work. However, this approach does not consider the impact of pixel blur and SNR, Bayer crosstalk, and lens blur, and does not use a formal stabilized, non-blind, and complete image restoration process as we do in our approach. However, the IBP is essentially implementing a Maximum Likelihood (ML) solution to the superresolution problem. In Horisaki et al. [2008] an irregular lens arrangement was used to ensure that component images were non-identical and used superresolution algorithms to restore a high-resolution image. Motivated by compound eyes in insects, Duparr? et al. [2004] developed an array camera using sophisticated micro-optical fabrication techniques. Color Filters: Secondly, PiCam does not use a Bayer color filter pattern. The chosen filter pattern needs to be optimal for both. Lens Focal Length: Finally, the focal length of the PiCam array and its corresponding hyperfocal distance is shorter as compared to that of an equivalent legacy camera. The autofocus actuator may not be a necessity because its lens has a shorter hyperfocal distance which fundamentally determines its ability to focus on near objects [Kingslake 1951]. The hyperfocal distance is defined as the closest distance at which a lens can be focused while keeping objects at infinity acceptably sharp. It is a function of the focal length and F-Number and is approximated by h = f 2 + f , where f is F c the focal length of the lens, F is its F-number, and c is the circle of confusion. Thus, the near focus distance of the lens becomes half the hyperfocal distance. Adjusting the optical format from 1000 ? 750 to 800 ? 600 or 1280 ? 1024 pixels, while simultaneously holding the F-number constant at F3.1, is shown by cross-hatched and dotted curves. In fact, in high-end cameras, often the design employs an optical lowpass filter to attenuate higher order frequencies to mitigate the aliasing. Figure 5 shows a typical pixel stack, in which light is incident on the microlens at the very top of the stack. (d) The corresponding sinc filter in frequency domain with cutoffs 1/(2W 1 ) and 1/(2W 2 ) for the legacy and PiCam pixels\n            the color filter layer and provides a suitable surface for effective microlens formation. In the spatial domain, the square pixel can be modeled as a box filter which, in the frequency domain, is the sinc function. For example, for an F2.0 lens with an optical format of 1000 ? 750, 1.75? pixels, the MTF20 (the spatial frequency at which MTF is 20%) is 1627lw/ph, while the corresponding MTF20 value after the pixel sampling blur is taken into account is around 1000lw/ph. Achieving such functionality necessitates each of the focal plane pixel groups to have its own independent row control logic. The surface is generated by detecting corresponding corners in an image of a black and white checkerboard chart (30x25 squares). The pixel values from the image locations y c , y r , and y s are obtained through 2D interpolation since the locations (i c , j c ), (i r , j r ), and (i s , j s ) do not map to integer grid locations in the cameras y c , y r , or y s . Spatial filtering is applied to the matching scores before the decision in order to increase spatial support and reduce spurious noise artifacts in the final depth map, as is common practice in many stereo algorithms. The matrix H represents the total blur due to optics and sensor, which is assumed spatially-invariant 1 . Maximum-a-Posteriori Formulation: Estimating x can be done through different SR approaches (e.g., subspace methods [Vandewalle et al. 2007], sparse representation of patches [Yang et al. 2008], compressive [Sen and Darabi 2009], moving least squares SR [Bose and Ahuja 2006]). MAP-based solutions are also popular in the SR literature, see [Hardie et al. 1997; Farsiu et al. 2004; Protter and Elad 2009; Pickup et al. 2007], and references therein. when the L2-norm is used for the likelihood term (under Gaussian noise assumption). A fused HR image is formed by transferring pixels from the LR images to the reference camera?s HR grid, using the total displacements calculated during optical distortion calibration and parallax detection. An important point needs to be raised about the commutativity of H and W p matrices here. However, this is not so when dealing with practical scenes with depth discontinuities where different objects in the scene would shift differently in each LR camera. These LR gradients are then upsampled, blurred by H T and inverse shifted onto the coordinates of the reference HR image, where they are accumulated and normalized, as per Equation 4. For example, in Zomet et al. [2001] a median filtering was used, while El-Yamany and Papamichalis [2008] applied a more robust M-estimator to the likelihood term. In Protter and Elad [2009], a video super-resolution with no explicit motion compensation is described, by forming weighted, patch-based gra- dients using bilateral weights. Since the problem of super-resolution is ill-posed, we use a statistical prior to regularize the HR estimate. Current priors used in image restoration include versions of the Total Variation (TV) [Rudin et al. 1992] approach, including bilateral-TV [Farsiu et al. 2006], autoregressive model prior [Bishop et al. 2009], and Gaussian Mixture Models [Mitra and Veeraraghavan 2012]. Although TV priors encourage the preservation of edges in the restored image, they are based on global image statistics of edges in an image. In that approach, spatial HR-image gradients of different orders are weighed using a bilateral weighting. As per-channel estimation is not optimal, a cross-channel approach is always preferable. The algorithms are computationally intensive and while efficiencies are being exploited to allow the pipeline to scale to mobile devices, this remains an active area of work due to the constrained nature of power and compute  availability in these form factors.",
  "resources" : [ ]
}