{
  "uri" : "sig2013a-a169-neissner_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2013a/a169-neissner_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Real-time 3D Reconstruction at Scale using Voxel Hashing",
    "published" : null,
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ ]
  },
  "bagOfWords" : [ "we", "system", "use", "simple", "spatial", "hash", "scheme", "compress", "space", "allow", "real-time", "access", "update", "implicit", "surface", "datum", "without", "need", "regular", "hierarchical", "grid", "datum", "structure", "we", "illustrate", "how", "all", "part", "we", "pipeline", "from", "depth", "map", "pre-processing", "camera", "pose", "estimation", "depth", "map", "fusion", "surface", "rendering", "perform", "real-time", "rate", "commodity", "graphic", "hardware", "we", "conclude", "comparison", "current", "state-of-the-art", "online", "system", "illustrate", "improved", "performance", "reconstruction", "quality", "active", "sensor", "implicit", "volumetric", "approach", "particular", "method", "Curless", "Levoy", "-lsb-", "1996", "-rsb-", "have", "demonstrate", "compelling", "result", "-lsb-", "Curless", "Levoy", "1996", "Levoy", "et", "al.", "2000", "Zhou", "Koltun", "2013", "-rsb-", "even", "real-time", "rate", "-lsb-", "Izadi", "et", "al.", "2011", "Newcombe", "et", "al.", "2011", "-rsb-", "have", "lead", "either", "move", "volume", "variant", "-lsb-", "Roth", "Vona", "2012", "Whelan", "et", "al.", "2012", "-rsb-", "which", "stream", "voxel", "datum", "out-of-core", "sensor", "move", "still", "constrain", "size", "active", "volume", "we", "method", "base", "simple", "memory", "speed", "efficient", "spatial", "hash", "technique", "compress", "space", "allow", "real-time", "fusion", "reference", "implicit", "surface", "datum", "without", "need", "hierarchical", "datum", "structure", "additionally", "datum", "can", "stream", "efficiently", "out", "hash", "table", "allow", "further", "scalability", "during", "sensor", "motion", "we", "show", "interactive", "reconstruction", "variety", "scene", "reconstruct", "both", "fine-grained", "large-scale", "environment", "we", "illustrate", "how", "all", "part", "we", "pipeline", "from", "depth", "map", "pre-processing", "sensor", "pose", "estimation", "depth", "map", "fusion", "surface", "rendering", "perform", "real-time", "rate", "commodity", "graphic", "hardware", "we", "conclude", "comparison", "current", "state-of-the-art", "system", "illustrate", "improved", "performance", "reconstruction", "quality", "unlike", "system", "focus", "reconstruction", "from", "complete", "set", "3d", "point", "-lsb-", "Hoppe", "et", "al.", "1992", "Kazhdan", "et", "al.", "2006", "-rsb-", "online", "method", "require", "incremental", "fusion", "many", "overlap", "depth", "map", "single", "3d", "representation", "continuously", "refine", "extension", "mesh", "zippering", "-lsb-", "Turk", "Levoy", "1994", "-rsb-", "select", "one", "depth", "map", "per", "surface", "region", "remove", "redundant", "triangle", "overlap", "region", "stitch", "mesh", "render", "final", "model", "perform", "use", "point-based", "rendering", "technique", "-lsb-", "Gross", "Pfister", "2007", "-rsb-", "height-map", "base", "representation", "explore", "use", "more", "compact", "2.5", "continuous", "surface", "representation", "reconstruction", "-lsb-", "Pollefeys", "et", "al.", "2008", "Gallup", "et", "al.", "2010", "-rsb-", "technique", "particularly", "useful", "modeling", "large", "building", "floor", "wall", "since", "appear", "clear", "discontinuity", "height-map", "final", "surface", "extract", "zero-level", "set", "implicit", "function", "use", "isosurface", "polygonisation", "-lrb-", "e.g.", "-lsb-", "Lorensen", "Cline", "1987", "-rsb-", "-rrb-", "raycasting", "well-known", "example", "method", "Curless", "Levoy", "-lsb-", "1996", "-rsb-", "which", "active", "triangulation-based", "sensor", "laser", "range", "scanner", "structured", "light", "camera", "can", "generate", "very", "high", "quality", "result", "-lsb-", "Curless", "Levoy", "1996", "Levoy", "et", "al.", "2000", "Zhou", "Koltun", "2013", "-rsb-", "kinectfusion", "-lsb-", "Newcombe", "et", "al.", "2011", "Izadi", "et", "al.", "2011", "-rsb-", "recently", "adopt", "volumetric", "method", "demonstrate", "compelling", "real-time", "reconstruction", "use", "commodity", "GPU", "-lsb-", "Keller", "et", "al.", "2013", "-rsb-", "use", "point-based", "representation", "capture", "quality", "volumetric", "fusion", "remove", "need", "spatial", "datum", "structure", "move", "volume", "method", "-lsb-", "Roth", "Vona", "2012", "Whelan", "et", "al.", "2012", "-rsb-", "extend", "gpu-based", "pipeline", "kinectfusion", "while", "still", "operate", "very", "restricted", "regular", "grid", "method", "stream", "out", "voxel", "from", "GPU", "base", "camera", "motion", "free", "space", "new", "datum", "store", "-lsb-", "Zeng", "et", "al.", "2012", "-rsb-", "implement", "9to", "10-level", "octree", "GPU", "which", "extend", "KinectFusion", "pipeline", "larger", "8m", "8m", "2m", "indoor", "office", "space", "octree", "resolution", "each", "dimension", "increase", "factor", "two", "each", "subdivision", "level", "while", "avoid", "use", "octree", "system", "still", "carry", "computational", "overhead", "realize", "hierarchical", "datum", "structure", "GPU", "lead", "performance", "only", "real-time", "specific", "scene", "very", "high-end", "graphic", "hardware", "we", "extend", "volumetric", "method", "Curless", "Levoy", "-lsb-", "1996", "-rsb-", "reconstruct", "high-quality", "3d", "surface", "real-time", "scale", "incrementally", "fuse", "noisy", "depth", "map", "memory", "speed", "efficient", "datum", "structure", "Curless", "Levoy", "have", "prove", "produce", "compelling", "result", "give", "simple", "cumulative", "average", "sample", "method", "support", "incremental", "update", "make", "topological", "assumption", "regard", "surface", "approximate", "noise", "characteristic", "triangulation", "base", "sensor", "effectively", "further", "while", "implicit", "representation", "store", "isosurface", "can", "readily", "extract", "we", "method", "address", "main", "drawback", "Curless", "Levoy", "support", "efficient", "scalability", "next", "we", "review", "Curless", "Levoy", "method", "before", "description", "we", "new", "approach", "let", "we", "consider", "regular", "dense", "voxel", "grid", "assume", "input", "sequence", "depth", "map", "depth", "sensor", "initialize", "some", "origin", "relative", "grid", "-lrb-", "typically", "center", "grid", "-rrb-", "first", "rigid", "six", "degree-of-freedom", "-lrb-", "6dof", "-rrb-", "ego-motion", "sensor", "estimate", "typically", "use", "variant", "ICP", "-lsb-", "Besl", "McKay", "1992", "Chen", "Medioni", "1992", "-rsb-", "each", "voxel", "grid", "contain", "two", "value", "sign", "distance", "weight", "all", "voxel", "project", "onto", "same", "pixel", "consider", "part", "depth", "sample?s", "footprint", "each", "voxel", "sign", "distance", "from", "voxel", "center", "observe", "surface", "measurement", "store", "positive", "distance", "front", "negative", "behind", "near", "zero", "surface", "interface", "region", "can", "adapt", "size", "approximate", "sensor", "noise", "gaussian", "variance", "base", "depth", "-lsb-", "Chang", "et", "al.", "1994", "Nguyen", "et", "al.", "2012", "-rsb-", "finally", "voxel", "-lrb-", "front", "surface", "-rrb-", "part", "each", "depth", "sample?s", "footprint", "outside", "truncation", "region", "explicitly", "mark", "free-space", "allow", "removal", "outlier", "base", "free-space", "violation", "Voxel", "Hashing", "give", "Curless", "Levoy", "truncate", "sdf", "around", "surface", "majority", "datum", "store", "regular", "voxel", "grid", "marked", "either", "free", "space", "unobserved", "space", "rather", "than", "surface", "datum", "we", "approach", "specifically", "avoid", "use", "dense", "hierarchical", "datum", "structure", "remove", "need", "memory", "intensive", "regular", "grid", "computationally", "complex", "hierarchy", "volumetric", "fusion", "instead", "we", "use", "simple", "hash", "scheme", "compactly", "store", "access", "update", "implicit", "surface", "representation", "graphic", "community", "efficient", "spatial", "hash", "method", "have", "be", "explore", "context", "variety", "2d/3d", "rendering", "collision", "detection", "task", "-lsb-", "Teschner", "et", "al.", "2003", "Lefebvre", "Hoppe", "2006", "Bastos", "Celes", "2008", "Alcantara", "et", "al.", "2009", "Pan", "Manocha", "2011", "Garc?a", "et", "al.", "2011", "-rsb-", "sophisticated", "method", "have", "be", "propose", "efficient", "gpu-based", "hash", "greatly", "reduce", "number", "hash", "entry", "collision", "non-trivial", "3d", "reconstruction", "geometry", "unknown", "ahead", "time", "continually", "change", "therefore", "we", "hash", "technique", "must", "support", "dynamic", "allocation", "update", "while", "minimize", "resolve", "potential", "hash", "entry", "collision", "without", "require", "a-priori", "knowledge", "contain", "surface", "geometry", "approach", "design", "we", "datum", "structure", "we", "have", "purposefully", "choose", "extend", "simple", "hash", "scheme", "-lsb-", "Teschner", "et", "al.", "2003", "-rsb-", "while", "more", "sophisticated", "method", "exist", "we", "show", "empirically", "we", "method", "efficient", "term", "speed", "quality", "scalability", "hash", "table", "sparsely", "efficiently", "store", "update", "tsdf", "follow", "we", "describe", "datum", "structure", "more", "detail", "demonstrate", "how", "can", "efficiently", "implement", "GPU", "we", "highlight", "some", "core", "feature", "we", "datum", "structure", "include", "ability", "efficiently", "compress", "volumetric", "tsdf", "while", "maintain", "surface", "resolution", "without", "need", "hierarchical", "spatial", "datum", "structure", "fuse", "new", "tsdf", "sample", "efficiently", "hash", "table", "base", "insertion", "update", "while", "minimize", "collision", "lightweight", "bidirectional", "streaming", "voxel", "block", "between", "host", "GPU", "allow", "unbounded", "reconstruction", "extraction", "isosurface", "from", "datum", "structure", "efficiently", "use", "standard", "raycasting", "polygonization", "operation", "render", "camera", "pose", "estimation", "System", "Pipeline", "we", "pipeline", "depict", "fig.", "each", "occupied", "entry", "we", "hash", "table", "refer", "allocate", "voxel", "block", "each", "voxel", "we", "store", "tsdf", "weight", "additional", "color", "value", "we", "hash", "function", "allow", "efficient", "look-up", "voxel", "block", "use", "specify", "-lrb-", "integer", "round", "-rrb-", "world", "coordinate", "we", "hash", "function", "aim", "minimize", "number", "collision", "ensure", "duplicate", "exist", "table", "give", "new", "input", "depth", "map", "we", "begin", "perform", "fusion", "-lrb-", "also", "refer", "integration", "-rrb-", "we", "first", "allocate", "new", "voxel", "block", "insert", "block", "descriptor", "hash", "table", "base", "input", "depth", "map", "next", "we", "sweep", "each", "allocate", "voxel", "block", "update", "SDF", "color", "weight", "each", "contain", "voxel", "base", "input", "depth", "color", "sample", "addition", "we", "garbage", "collect", "voxel", "block", "which", "too", "far", "from", "isosurface", "contain", "weight", "involve", "free", "allocate", "memory", "well", "remove", "voxel", "block", "entry", "from", "hash", "table", "step", "ensure", "we", "datum", "structure", "remain", "sparse", "over", "time", "after", "integration", "we", "raycast", "implicit", "surface", "from", "current", "estimate", "camera", "pose", "extract", "isosurface", "include", "associate", "color", "extract", "depth", "color", "buffer", "use", "input", "camera", "pose", "estimation", "give", "next", "input", "depth", "map", "projective", "point-plane", "icp", "-lsb-", "Chen", "Medioni", "1992", "-rsb-", "perform", "estimate", "new", "6dof", "camera", "pose", "ensure", "pose", "estimation", "perform", "frame-to-model", "rather", "than", "frame-to-frame", "mitigate", "some", "issue", "drift", "-lrb-", "particularly", "small", "scene", "-rrb-", "-lsb-", "Newcombe", "et", "al.", "2011", "-rsb-", "finally", "we", "algorithm", "perform", "bidirectional", "streaming", "between", "GPU", "host", "hash", "entry", "-lrb-", "associate", "voxel", "block", "-rrb-", "stream", "host", "world", "position", "exit", "estimate", "camera", "view", "frustum", "previously", "stream", "out", "voxel", "block", "can", "also", "stream", "back", "GPU", "datum", "structure", "when", "revisit", "area", "fig.", "show", "we", "voxel", "hash", "datum", "structure", "conceptually", "infinite", "uniform", "grid", "subdivide", "world", "voxel", "block", "each", "block", "small", "regular", "voxel", "grid", "we", "current", "implementation", "voxel", "block", "compose", "voxel", "we", "use", "efficient", "GPU", "accelerate", "hash", "table", "manage", "allocation", "retrieval", "voxel", "block", "hash", "table", "store", "hash", "entry", "each", "contain", "pointer", "allocate", "voxel", "block", "Voxel", "block", "can", "retrieve", "from", "hash", "table", "use", "integer", "world", "coordinate", "-lrb-", "-rrb-", "find", "coordinate", "3d", "point", "world", "space", "achieve", "simple", "multiplication", "rounding", "we", "map", "from", "world", "coordinate", "-lrb-", "-rrb-", "hash", "value", "-lrb-", "-rrb-", "use", "follow", "hash", "function", "where", "large", "prime", "number", "-lrb-", "we", "case", "73856093", "19349669", "83492791", "respectively", "base", "-lsb-", "Teschner", "et", "al.", "2003", "-rsb-", "-rrb-", "hash", "table", "size", "addition", "store", "pointer", "voxel", "block", "each", "hash", "entry", "also", "contain", "associated", "world", "position", "offset", "pointer", "handle", "collision", "efficiently", "-lrb-", "describe", "next", "section", "-rrb-", "struct", "HashEntry", "-lcb-", "short", "position", "-lsb-", "-rsb-", "short", "offset", "int", "pointer", "-rcb-", "Conceptually", "infinite", "uniform", "grid", "partition", "world", "use", "we", "hash", "function", "we", "map", "from", "integer", "world", "coordinate", "hash", "bucket", "which", "store", "small", "array", "pointer", "regular", "grid", "voxel", "block", "each", "voxel", "block", "contain", "grid", "sdf", "value", "when", "information", "red", "block", "get", "add", "collision", "appear", "which", "resolve", "use", "second", "element", "hash", "bucket", "collision", "appear", "multiple", "allocate", "block", "map", "same", "hash", "value", "-lrb-", "see", "red", "block", "Fig.", "-rrb-", "we", "handle", "collision", "uniformly", "organize", "hash", "table", "bucket", "one", "per", "unique", "hash", "value", "each", "bucket", "sequentially", "store", "small", "number", "hash", "entry", "when", "collision", "occur", "we", "store", "block", "pointer", "next", "available", "sequential", "entry", "bucket", "-lrb-", "see", "Fig.", "-rrb-", "find", "voxel", "block", "particular", "world", "position", "we", "first", "evaluate", "we", "hash", "function", "lookup", "traverse", "associate", "bucket", "until", "we", "block", "entry", "find", "achieve", "simply", "compare", "store", "hash", "entry", "world", "position", "query", "position", "reasonable", "selection", "hash", "table", "bucket", "size", "-lrb-", "see", "later", "-rrb-", "rarely", "bucket", "overflow", "however", "happen", "we", "append", "link", "list", "entry", "fill", "up", "other", "free", "spot", "next", "available", "bucket", "-lrb-", "relative", "-rrb-", "pointer", "link", "list", "store", "offset", "field", "hash", "table", "entry", "list", "append", "full", "bucket", "set", "offset", "pointer", "last", "entry", "bucket", "all", "follow", "entry", "chained", "use", "offset", "field", "order", "create", "additional", "link", "bucket", "we", "linearly", "search", "across", "hash", "table", "free", "slot", "store", "we", "entry", "append", "link", "list", "accordingly", "we", "avoid", "last", "entry", "each", "bucket", "locally", "reserve", "link", "list", "head", "show", "later", "we", "choose", "table", "bucket", "size", "keep", "number", "collision", "therefore", "append", "link", "list", "minimum", "most", "scene", "impact", "overall", "performance", "insertion", "insert", "new", "hash", "entry", "we", "first", "evaluate", "hash", "function", "determine", "target", "bucket", "we", "iterate", "over", "all", "bucket", "element", "include", "possible", "list", "attach", "last", "entry", "otherwise", "we", "look", "first", "empty", "position", "within", "bucket", "position", "bucket", "available", "we", "insert", "new", "hash", "entry", "bucket", "full", "we", "append", "element", "its", "link", "list", "element", "-lrb-", "see", "Fig.", "-rrb-", "avoid", "race", "condition", "when", "insert", "hash", "entry", "parallel", "we", "lock", "bucket", "atomically", "write", "when", "suitable", "empty", "position", "find", "eliminate", "duplicate", "entry", "ensure", "link", "list", "consistency", "may", "delay", "some", "allocation", "marginally", "however", "practice", "cause", "degradation", "reconstruction", "quality", "-lrb-", "observe", "result", "supplementary", "video", "-rrb-", "particularly", "Curless", "Levoy", "method", "support", "order", "independent", "update", "retrieval", "read", "hash", "entry", "query", "position", "we", "compute", "hash", "value", "perform", "linear", "search", "within", "corresponding", "bucket", "note", "we", "do", "require", "bucket", "fill", "from", "leave", "right", "describe", "below", "remove", "value", "can", "lead", "fragmentation", "so", "traversal", "do", "stop", "when", "empty", "entry", "find", "bucket", "given", "world", "position", "we", "first", "compute", "hash", "linearly", "search", "corresponding", "hash", "bucket", "include", "list", "traversal", "we", "have", "find", "match", "entry", "without", "list", "traversal", "we", "can", "simply", "delete", "last", "element", "bucket", "non-zero", "offset", "store", "-lrb-", "i.e.", "element", "list", "head", "-rrb-", "we", "copy", "hash", "entry", "point", "offset", "last", "element", "bucket", "delete", "from", "its", "current", "position", "otherwise", "entry", "-lrb-", "non-head", "-rrb-", "element", "link", "list", "we", "delete", "correct", "list", "pointer", "accordingly", "-lrb-", "see", "Fig.", "-rrb-", "however", "case", "we", "need", "modify", "link", "list", "we", "lock", "bucket", "atomically", "stagger", "further", "list", "operation", "bucket", "until", "next", "frame", "we", "process", "depth", "sample", "parallel", "insert", "hash", "entry", "allocate", "voxel", "block", "within", "truncation", "region", "around", "observe", "surface", "size", "truncation", "adapt", "base", "variance", "depth", "compensate", "larger", "uncertainty", "distant", "measurement", "-lsb-", "Chang", "et", "al.", "1994", "Nguyen", "et", "al.", "2012", "-rsb-", "each", "input", "depth", "sample", "we", "instantiate", "ray", "interval", "bind", "truncation", "region", "give", "predefined", "voxel", "resolution", "block", "size", "we", "use", "dda", "-lsb-", "Amanatides", "Woo", "1987", "-rsb-", "determine", "all", "voxel", "block", "intersect", "ray", "each", "candidate", "find", "we", "insert", "new", "voxel", "block", "entry", "hash", "table", "we", "would", "allocate", "all", "voxel", "block", "within", "truncation", "region", "intersect", "frustum", "practice", "however", "lead", "degradation", "performance", "-lrb-", "currently", "10-fold", "-rrb-", "we", "ray-based", "approximation", "provide", "balance", "between", "performance", "precision", "give", "continuous", "nature", "reconstruction", "frame", "rate", "sensor", "mobility", "user", "practice", "lead", "hole", "appear", "between", "voxel", "block", "larger", "distance", "-lrb-", "see", "result", "accompany", "video", "-rrb-", "once", "we", "have", "successfully", "insert", "entry", "hash", "table", "we", "allocate", "portion", "preallocated", "heap", "memory", "GPU", "store", "voxel", "block", "datum", "heap", "linear", "array", "memory", "allocate", "once", "upon", "initialization", "divide", "contiguous", "block", "-lrb-", "mapping", "size", "voxel", "block", "-rrb-", "manage", "maintain", "list", "available", "block", "list", "linear", "buffer", "index", "all", "unallocated", "block", "new", "block", "allocate", "use", "last", "index", "list", "since", "list", "access", "parallel", "synchronization", "necessary", "increment", "decrement", "end", "list", "pointer", "use", "atomic", "operation", "we", "update", "all", "allocate", "voxel", "block", "currently", "within", "camera", "view", "frustum", "after", "previous", "step", "-lrb-", "see", "section", "-rrb-", "all", "voxel", "block", "truncation", "region", "visible", "surface", "allocate", "further", "significant", "amount", "voxel", "block", "outside", "view", "frustum", "under", "assumption", "tsdf", "integration", "can", "do", "very", "efficiently", "only", "select", "available", "block", "inside", "current", "camera", "frustum", "Voxel", "Block", "selection", "select", "voxel", "block", "integration", "we", "first", "parallel", "access", "all", "hash", "table", "entry", "store", "corresponding", "binary", "flag", "array", "occupied", "visible", "voxel", "block", "zero", "otherwise", "we", "scan", "array", "use", "parallel", "prefix", "sum", "technique", "-lsb-", "Harris", "et", "al.", "2007", "-rsb-", "facilitate", "large", "scan", "size", "-lrb-", "we", "hash", "table", "can", "have", "million", "entry", "-rrb-", "we", "use", "three", "level", "up", "down", "sweep", "use", "scan", "result", "we", "compact", "hash", "table", "another", "buffer", "which", "contain", "all", "hash", "entry", "point", "voxel", "block", "within", "view", "frustum", "-lrb-", "see", "Fig.", "-rrb-", "note", "voxel", "block", "copy", "just", "associate", "hash", "entry", "Implicit", "surface", "Update", "generate", "list", "hash", "entry", "process", "parallel", "update", "tsdf", "value", "single", "GPGPU", "kernel", "execute", "each", "associate", "block", "one", "thread", "allocate", "per", "voxel", "mean", "voxel", "block", "process", "single", "GPU", "multiprocessor", "thus", "maximize", "cache", "hit", "minimize", "code", "divergence", "practice", "more", "efficient", "than", "assign", "single", "thread", "process", "entire", "voxel", "block", "update", "voxel", "block", "involve", "re-computation", "associate", "tsdf", "weight", "color", "Distance", "value", "integrate", "use", "run", "average", "Curless", "Levoy", "-lsb-", "Curless", "Levoy", "1996", "-rsb-", "we", "set", "integration", "weight", "accord", "depth", "value", "order", "incorporate", "noise", "characteristic", "sensor", "i.e.", "more", "weight", "give", "nearer", "depth", "measurement", "which", "we", "assume", "less", "noise", "one", "important", "part", "integration", "step", "update", "all", "voxel", "block", "fall", "current", "frustum", "irrespective", "whether", "reside", "current", "truncation", "region", "can", "due", "surface", "be", "physically", "move", "small", "outlier", "depth", "map", "be", "allocate", "previously", "which", "longer", "observe", "block", "treat", "any", "differently", "continuously", "update", "show", "next", "however", "we", "evaluate", "all", "voxel", "block", "after", "integration", "identify", "candidate", "potential", "garbage", "collection", "Garbage", "Collection", "Garbage", "collection", "remove", "voxel", "block", "allocate", "due", "noisy", "outlier", "move", "surface", "step", "operate", "compacted", "hash", "table", "we", "obtain", "previously", "each", "associate", "voxel", "block", "we", "perform", "summarization", "step", "obtain", "both", "minimum", "absolute", "tsdf", "value", "maximum", "weight", "maximum", "weight", "voxel", "block", "zero", "minimum", "tsdf", "larger", "than", "threshold", "we", "flag", "block", "deletion", "second", "pass", "parallel", "we", "delete", "all", "flag", "entry", "use", "hash", "table", "delete", "operation", "describe", "previously", "when", "hash", "entry", "get", "delete", "successfully", "we", "also", "free", "corresponding", "voxel", "block", "append", "voxel", "block", "pointer", "heap", "-lrb-", "cf.", "section", "-rrb-", "we", "perform", "raycast", "extract", "implicitly", "store", "isosurface", "first", "we", "compute", "end", "point", "each", "ray", "conservatively", "rasterize", "entire", "bound", "box", "all", "allocate", "voxel", "block", "current", "view", "frustum", "parallel", "we", "rasterize", "each", "voxel", "block", "-lrb-", "retrieve", "from", "compact", "hash", "table", "buffer", "compute", "during", "integration", "-rrb-", "two", "pass", "generate", "two", "z-buffer", "minimum", "maximum", "depth", "demonstrate", "another", "benefit", "we", "linear", "hash", "table", "datum", "structure", "-lrb-", "over", "hierarchical", "datum", "structure", "-rrb-", "allow", "fast", "parallel", "access", "all", "allocate", "block", "operation", "rasterization", "each", "output", "pixel", "we", "march", "ray", "from", "associate", "minimum", "maximum", "depth", "value", "during", "march", "we", "must", "evaluate", "tsdf", "neighboring", "world", "position", "along", "current", "ray", "step", "unallocated", "voxel", "block", "also", "consider", "empty", "space", "within", "occupy", "voxel", "block", "we", "apply", "tri-linear", "interpolation", "look", "up", "eight", "neighbor", "voxel", "one", "special", "case", "need", "consider", "sampling", "across", "voxel", "block", "boundary", "deal", "we", "retrieve", "neighbor", "voxel", "lookup", "via", "hash", "table", "rather", "than", "sampling", "voxel", "block", "directly", "practice", "we", "use", "hash", "table", "lookup", "irrespective", "whether", "voxel", "block", "boundary", "due", "caching", "reduce", "register", "count", "per", "thread", "non-divergent", "code", "increase", "performance", "over", "direct", "block", "sampling", "we", "have", "also", "try", "use", "one-voxel", "overlap", "region", "around", "block", "order", "simplify", "tri-linear", "read", "without", "need", "access", "multiple", "voxel", "block", "however", "approximately", "double", "memory", "footprint", "we", "find", "require", "overlap", "synchronization", "surface", "integration", "bear", "significant", "computational", "overhead", "locate", "surface", "interface", "-lrb-", "zero-crossing", "-rrb-", "we", "determine", "sign", "change", "current", "previous", "-lrb-", "tri-linearly-interpolated", "-rrb-", "tsdf", "value", "we", "ignore", "zero-crossing", "from", "negative", "positive", "refer", "back-facing", "surface", "geometry", "order", "speed", "up", "ray", "march", "we", "skip", "predefined", "interval", "-lrb-", "half", "minimum", "truncation", "value", "-rrb-", "avoid", "miss", "isosurface", "provide", "only", "coarse", "zero-crossing", "position", "refine", "further", "we", "use", "iterative", "line", "search", "once", "zero-crossing", "detect", "estimate", "true", "surface", "location", "Camera", "Tracking", "once", "surface", "extract", "via", "raycasting", "can", "shaded", "render", "use", "frame-to-model", "camera", "pose", "estimation", "-lsb-", "Newcombe", "et", "al.", "2011", "-rsb-", "we", "use", "next", "input", "frame", "along", "raycasted", "depth", "map", "estimate", "pose", "ensure", "new", "pose", "estimate", "prior", "depth", "map", "fusion", "pose", "estimate", "use", "point-plane", "variant", "icp", "-lsb-", "Chen", "Medioni", "1992", "-rsb-", "projective", "datum", "association", "point-plane", "energy", "function", "linearize", "-lsb-", "low", "2004", "-rsb-", "GPU", "matrix", "use", "parallel", "reduction", "solve", "via", "singular", "value", "decomposition", "CPU", "we", "datum", "structure", "also", "store", "associate", "color", "datum", "we", "incorporate", "weighting", "factor", "point-plane", "error-metric", "base", "color", "consistency", "between", "extract", "input", "rgb", "value", "-lsb-", "Johnson", "Bing", "Kang", "1999", "-rsb-", "basic", "datum", "structure", "describe", "so", "far", "allow", "high-resolution", "voxel", "block", "model", "beyond", "resolution", "range", "current", "commodity", "depth", "camera", "-lrb-", "see", "section", "-rrb-", "however", "GPU", "memory", "performance", "become", "consideration", "when", "we", "attempt", "maintain", "surface", "datum", "far", "outside", "view", "frustum", "hash", "table", "deal", "issue", "allow", "unbounded", "reconstruction", "we", "utilize", "bidirectional", "gpu-host", "streaming", "scheme", "we", "unstructured", "datum", "structure", "well-suited", "purpose", "since", "streaming", "voxel", "block", "out", "do", "require", "any", "reorganization", "hash", "table", "we", "create", "active", "region", "define", "sphere", "contain", "current", "camera", "view", "frustum", "safety", "region", "around", "standard", "kinect", "we", "assume", "depth", "range", "up", "eight", "meter", "we", "locate", "center", "sphere", "four", "meter", "from", "camera", "position", "use", "radius", "eight", "meter", "-lrb-", "see", "Figure", "-rrb-", "bidirectional", "streaming", "voxel", "block", "happen", "every", "frame", "beginning", "pipeline", "directly", "after", "pose", "estimation", "stream", "voxel", "block", "out", "active", "region", "we", "first", "access", "hash", "table", "parallel", "mark", "voxel", "block", "which", "move", "out", "active", "region", "all", "candidate", "we", "delete", "corresponding", "hash", "entry", "append", "they", "efficiently", "intermediate", "buffer", "second", "pass", "all", "hash", "entry", "correspond", "voxel", "block", "copy", "another", "intermediate", "buffer", "original", "voxel", "block", "clear", "corresponding", "location", "append", "back", "heap", "so", "can", "reuse", "finally", "intermediate", "buffer", "copy", "back", "host", "access", "host", "voxel", "datum", "longer", "organize", "hash", "table", "instead", "we", "logically", "subdivide", "world", "space", "uniformly", "chunk", "-lrb-", "we", "current", "implementation", "each", "set", "1m", "-rrb-", "Voxel", "block", "append", "chunk", "use", "link", "list", "each", "voxel", "block", "we", "store", "voxel", "block", "descriptor", "which", "correspond", "hash", "entry", "datum", "well", "voxel", "datum", "host-to-gpu", "streaming", "we", "first", "identify", "chunk", "completely", "fall", "spherical", "active", "region", "again", "due", "user", "move", "back", "previously", "reconstruct", "region", "contrast", "gputo-cpu", "streaming", "which", "work", "per", "voxel", "block", "level", "cputo-gpu", "streaming", "operate", "per", "chunk", "basis", "so", "chunk", "identify", "streaming", "all", "voxel", "block", "chunk", "stream", "GPU", "enhance", "performance", "give", "high", "host-gpu", "bandwidth", "ability", "efficiently", "cull", "voxel", "block", "outside", "view", "frustum", "due", "limited", "CPU", "compute", "per", "frame", "streaming", "from", "host-togpu", "stagger", "one", "chunk", "per", "frame", "we", "select", "chunk", "tag", "streaming", "most", "near", "camera", "frustum", "center", "we", "copy", "chunk", "GPU", "via", "intermediate", "buffer", "create", "gpu-to-host", "streaming", "after", "copy", "GPU", "parallel", "we", "insert", "voxel", "block", "descriptor", "entry", "hash", "table", "allocate", "voxel", "block", "memory", "from", "heap", "copy", "voxel", "datum", "accordingly", "similar", "allocation", "phase", "-lrb-", "see", "section", "-rrb-", "however", "when", "streaming", "datum", "all", "hash", "entry", "must", "insert", "within", "single", "frame", "rather", "than", "stagger", "insertion", "stream", "voxel", "block", "we", "check", "descriptor", "atomically", "compare", "whether", "position", "occupy", "table", "entry", "exist", "we", "proceed", "search", "next", "available", "free", "position", "bucket", "-lrb-", "describe", "below", "we", "ensure", "duplicate", "-rrb-", "otherwise", "we", "write", "stream", "hash", "entry", "position", "hash", "table", "bucket", "full", "entry", "append", "end", "list", "both", "write", "free", "entry", "directly", "bucket", "append", "end", "link", "list", "must", "perform", "atomically", "one", "important", "consideration", "streaming", "ensure", "voxel", "block", "never", "duplicate", "host", "GPU", "lead", "potential", "memory", "leak", "give", "host-to-gpu", "streaming", "stagger", "rare", "case", "where", "voxel", "block", "wait", "stream", "may", "enter", "view", "frustum", "we", "must", "verify", "new", "allocation", "voxel", "block", "staggered", "region", "end", "we", "store", "binary", "occupancy", "grid", "GPU", "where", "each", "entry", "correspond", "particular", "chunk", "set", "bit", "indicate", "chunk", "reside", "GPU", "allocation", "can", "occur", "region", "otherwise", "chunk", "should", "assume", "host", "allocation", "should", "avoid", "binary", "grid", "carry", "little", "GPU", "memory", "overhead", "512kb", "256", "can", "easily", "re-allocated", "on-the-fly", "extend", "larger", "scene", "we", "have", "implement", "we", "datum", "structure", "use", "DirectX", "11", "Compute", "Shaders", "we", "use", "Asus", "Xtion", "scene", "Fig.", "10", "kinect", "Windows", "camera", "all", "other", "scene", "both", "provide", "rgb-d", "datum", "30Hz", "result", "live", "scene", "capture", "we", "test", "scene", "show", "figure", "11", "well", "supplementary", "material", "we", "capture", "variety", "indoor", "outdoor", "scene", "under", "variety", "lighting", "condition", "while", "quality", "active", "infrared", "sensor", "affect", "significantly", "outdoor", "scene", "we", "system", "still", "manage", "reconstruct", "large-scale", "outdoor", "scene", "fine", "quality", "statue", "fig.", "show", "result", "after", "online", "scan", "20m", "long", "corridor", "museum", "about", "4m", "high", "statue", "which", "capture", "reconstruct", "live", "under", "minute", "passageway", "-lrb-", "fig.", "11", "top", "-rrb-", "show", "pathway", "shop", "30m", "long", "reconstruct", "live", "QUEENS", "-lrb-", "Fig.", "11", "middle", "-rrb-", "show", "large", "courtyard", "-lrb-", "stretch", "16m", "12m", "2m", "-rrb-", "reconstruct", "approximately", "minute", "finally", "bookshop", "-lrb-", "fig.", "11", "bottom", "-rrb-", "show", "three", "level", "bookstore", "reconstruct", "under", "minute", "reconstruction", "demonstrate", "both", "scale", "quality", "be", "all", "reconstruct", "well", "above", "30hz", "frame", "rate", "kinect", "show", "figure", "allow", "potential", "increase", "voxel", "resolution", "additional", "icp", "step", "more", "robust", "camera", "tracking", "we", "use", "voxel", "size", "4mm", "fig.", "10", "10mm", "fig.", "11", "we", "also", "test", "we", "system", "2mm", "voxel", "without", "visible", "improvement", "overall", "reconstruction", "quality", "while", "highlight", "limit", "current", "depth", "sense", "technology", "we", "believe", "open", "up", "new", "possibility", "future", "depth", "acquisition", "hardware", "we", "measure", "performance", "we", "entire", "pipeline", "include", "run-time", "overhead", "-lrb-", "display", "rendering", "-rrb-", "Intel", "Core", "i7", "3.4", "GHz", "CPU", "16gb", "RAM", "single", "NVIDIA", "GeForce", "GTX", "Titan", "average", "timing", "among", "all", "test", "scene", "21.8", "m", "-lrb-", "46f", "p", "-rrb-", "8.0", "m", "-lrb-", "37", "overall", "pipeline", "-rrb-", "ICP", "pose", "estimation", "-lrb-", "15", "iteration", "-rrb-", "4.6", "m", "-lrb-", "21", "-rrb-", "surface", "integration", "4.8", "m", "-lrb-", "22", "-rrb-", "surface", "extraction", "shading", "-lrb-", "include", "color", "phong", "shade", "-rrb-", "4.4", "m", "-lrb-", "20", "-rrb-", "streaming", "input", "datum", "processing", "separate", "timing", "each", "test", "scene", "provide", "fig.", "we", "datum", "structure", "use", "total", "34mb", "hash", "table", "all", "auxiliary", "buffer", "allow", "hash", "table", "21", "entry", "each", "contain", "12", "byte", "we", "experiment", "show", "bucket", "size", "two", "provide", "best", "performance", "leave", "we", "about", "million", "bucket", "we", "pre-allocate", "1gb", "heap", "memory", "provide", "space", "voxel", "datum", "GPU", "voxel", "per", "block", "-lrb-", "byte", "per", "voxel", "-rrb-", "correspond", "18", "voxel", "block", "note", "21", "hash", "entry", "only", "index", "18", "voxel", "block", "result", "low", "hash", "occupancy", "thus", "minimize", "hash", "collision", "average", "we", "find", "about", "140k", "voxel", "block", "allocate", "when", "capture", "we", "test", "scene", "voxel", "size", "8mm", "-lrb-", "vary", "scene", "complexity", "-rrb-", "correspond", "equal", "amount", "occupied", "hash", "entry", "result", "hash", "table", "occupancy", "120k", "bucket", "single", "entry", "10k", "bucket", "two", "entry", "bucket", "size", "two", "hash", "table", "size", "21", "all", "test", "scene", "run", "only", "0.1", "bucket", "overflow", "handle", "link", "list", "across", "all", "scene", "largest", "list", "length", "three", "total", "700", "link", "list", "entry", "allocate", "across", "all", "scene", "which", "negligible", "compare", "hash", "table", "size", "average", "less", "than", "300mb", "memory", "allocate", "surface", "datum", "-lrb-", "less", "than", "600mb", "color", "-rrb-", "compare", "favorably", "regular", "grid", "would", "require", "well", "over", "5gb", "-lrb-", "include", "color", "-rrb-", "same", "voxel", "resolution", "-lrb-", "8mm", "-rrb-", "spatial", "extent", "-lrb-", "8m", "depth", "-rrb-", "also", "leave", "enough", "space", "encode", "RGB", "datum", "directly", "store", "voxel", "-lrb-", "see", "Fig.", "11", "-rrb-", "practice", "simple", "hash", "scheme", "small", "bucket", "size", "large", "hash", "table", "size", "work", "well", "we", "scenario", "we", "can", "tolerate", "larger", "sparser", "-lrb-", "21", "-rrb-", "hash", "table", "size", "because", "memory", "footprint", "hash", "table", "insignificant", "-lrb-", "34mb", "-rrb-", "compare", "voxel", "block", "buffer", "-lrb-", "which", "pre-allocated", "1gb", "-rrb-", "smaller", "hash", "table", "size", "cause", "higher", "occupancy", "decrease", "performance", "example", "statue", "scene", "we", "standard", "setting", "-lrb-", "21", "element", "-rrb-", "occupy", "6.4", "hash", "table", "run", "21m", "200k", "element", "occupancy", "rise", "65", "performance", "reduce", "24.8", "m", "160k", "element", "occupancy", "rise", "81", "performance", "further", "fall", "25.6", "ms.", "we", "live", "system", "we", "choose", "larger", "table", "size", "we", "favor", "performance", "over", "small", "memory", "gain", "we", "pipeline", "currently", "use", "atomic", "operation", "per", "hash", "bucket", "allocation", "streaming", "show", "we", "timing", "across", "all", "scene", "sequential", "operation", "cause", "negligible", "performance", "overhead", "due", "hash", "collision", "be", "minimal", "more", "sophisticated", "hash", "approach", "-lsb-", "Lefebvre", "Hoppe", "2006", "Bastos", "Celes", "2008", "Alcantara", "et", "al.", "2009", "Pan", "Manocha", "2011", "Garc?a", "et", "al.", "2011", "-rsb-", "could", "further", "reduce", "collision", "allow", "smaller", "hash", "table", "however", "how", "method", "deal", "high", "throughput", "datum", "fusion", "streaming", "unclear", "also", "important", "stress", "we", "simple", "hash", "method", "work", "well", "practice", "handle", "scalability", "quality", "framerate", "40fp", "across", "all", "scene", "assageway", "reconstruction", "Fig.", "we", "show", "quality", "performance", "we", "method", "compare", "previous", "work", "all", "code", "test", "same", "hardware", "-lrb-", "see", "above", "-rrb-", "fixed", "number", "ICP", "iteration", "-lrb-", "15", "-rrb-", "we", "algorithm", "support", "real-time", "streaming", "we", "conduct", "comparison", "similar", "move", "volume", "approach", "first", "we", "compare", "against", "Extended", "fusion", "-lsb-", "Roth", "Vona", "2012", "Whelan", "et", "al.", "2012", "-rsb-", "use", "regular", "uniform", "grid", "include", "streaming", "scale-up", "volumetric", "fusion", "second", "we", "compare", "against", "hierarchical", "fusion", "-lsb-", "Chen", "et", "al.", "2013", "-rsb-", "support", "larger", "move", "volume", "than", "other", "approach", "correspond", "timing", "show", "fig.", "most", "significant", "limitation", "hierarchy", "datum", "structure", "overhead", "cause", "performance", "drop", "particularly", "complex", "scene", "we", "test", "scene", "entire", "hierarchy", "pipeline", "-lrb-", "include", "pose", "estimation", "fusion", "streaming", "-rrb-", "run", "15hz", "which", "lower", "than", "input", "frame", "rate", "note", "measurement", "base", "reference", "implementation", "Chen", "et", "al.", "-lsb-", "2013", "-rsb-", "we", "system", "also", "perform", "favorably", "compare", "streaming", "regular", "grid", "term", "frame-rate", "-lrb-", "label", "Extended", "Fig.", "-rrb-", "we", "attribute", "processing", "empty", "voxel", "regular", "grid", "-lrb-", "particularly", "during", "random", "GPU", "memory", "access", "e.g.", "raycast", "-rrb-", "streaming", "overhead", "further", "show", "fig.", "we", "reconstruction", "quality", "higher", "than", "approach", "quality", "Extended", "fusion", "limit", "small", "spatial", "extent", "move", "volume", "which", "mean", "much", "Kinect", "datum", "out", "range", "integrate", "hierarchical", "fusion", "suffer", "from", "poor", "frame", "rate", "cause", "input", "datum", "skip", "severely", "affect", "pose", "estimation", "quality", "result", "inaccurate", "surface", "integration", "drift", "large-scale", "scene", "type", "drift", "might", "cause", "unnaturally", "twisted", "model", "show", "Fig.", "give", "we", "more", "efficient", "datum", "structure", "which", "run", "faster", "than", "Kinect", "camera", "frame", "rate", "additional", "time", "can", "spend", "improve", "accuracy", "pose", "estimation", "increase", "number", "ICP", "iteration", "we", "find", "we", "result", "encourage", "particularly", "give", "drift", "correction", "explicitly", "handle", "while", "we", "method", "do", "suffer", "from", "small", "drift", "we", "system", "produce", "comparable", "result", "can", "use", "real-time", "application", "we", "online", "method", "can", "also", "use", "live", "preview", "combine", "approach", "higher-quality", "offline", "reconstruction", "we", "have", "present", "new", "datum", "structure", "design", "specifically", "online", "reconstruction", "use", "widely-available", "consumer", "depth", "camera", "we", "approach", "leverage", "power", "implicit", "surface", "volumetric", "fusion", "reconstruction", "do", "so", "use", "compact", "spatial", "hash", "scheme", "which", "remove", "both", "overhead", "regular", "grid", "hierarchical", "datum", "structure", "we", "hash", "scheme", "support", "real-time", "performance", "without", "forgo", "scale", "finer", "quality", "reconstruction", "all", "operation", "design", "efficient", "parallel", "graphic", "hardware", "inherent", "unstructured", "nature", "we", "method", "remove", "overhead", "hierarchical", "spatial", "datum", "structure", "capture", "key", "quality", "volumetric", "fusion", "further", "extend", "bound", "reconstruction", "we", "method", "support", "lightweight", "streaming", "without", "major", "datum", "structure", "reorganization", "we", "have", "demonstrate", "performance", "increase", "over", "state-of-theart", "even", "regular", "grid", "implementation", "datum", "structure", "memory", "efficient", "can", "allow", "color", "datum", "directly", "incorporate", "reconstruction", "which", "can", "also", "use", "improve", "robustness", "registration", "due", "high", "performance", "we", "datum", "structure", "available", "time", "budget", "can", "utilize", "further", "improve", "camera", "pose", "estimation", "which", "directly", "improve", "reconstruction", "quality", "over", "exist", "online", "approach", "we", "thank", "Dennis", "Bautembach", "Jiawen", "Chen", "Vladlen", "Koltun", "Qian-Yi", "Zhou", "code/data", "Christoph", "Buchenau", "mesh", "rendering", "university", "Cambridge", "Erlangen-Nuremberg", "film", "access", "work", "part", "fund", "German", "Research", "Foundation", "-lrb-", "DFG", "-rrb-", "grant", "grk-1773", "heterogeneous", "image", "Systems" ],
  "content" : "Our system uses a simple spatial hashing scheme that compresses space, and allows for real-time access and updates of implicit surface data, without the need for a regular or hierarchical grid data structure. We illustrate how all parts of our pipeline from depth map pre-processing, camera pose estimation, depth map fusion, and surface rendering are performed at real-time rates on commodity graphics hardware. We conclude with a comparison to current state-of-the-art online systems, illustrating improved performance and reconstruction quality. For active sensors, implicit volumetric approaches, in particular the method of Curless and Levoy [1996], have demonstrated compelling results [Curless and Levoy 1996; Levoy et al. 2000; Zhou and Koltun 2013], even at real-time rates [Izadi et al. 2011; Newcombe et al. 2011]. This has led to either moving volume variants [Roth and Vona 2012; Whelan et al. 2012], which stream voxel data out-of-core as the sensor moves, but still constrain the size of the active volume. Our method is based on a simple memory and speed efficient spatial hashing technique that compresses space, and allows for real-time fusion of referenced implicit surface data, without the need for a hierarchical data structure. Additionally, data can be streamed efficiently in or out of the hash table, allowing for further scalability during sensor motion. We show interactive reconstructions of a variety of scenes, reconstructing both fine-grained and large-scale environments. We illustrate how all parts of our pipeline from depth map pre-processing, sensor pose estimation, depth map fusion, and surface rendering are performed at real-time rates on commodity graphics hardware. We conclude with a comparison to current state-of-the-art systems, illustrating improved performance and reconstruction quality. Unlike systems that focus on reconstruction from a complete set of 3D points [Hoppe et al. 1992; Kazhdan et al. 2006], online methods require incremental fusion of many overlapping depth maps into a single 3D representation that is continuously refined. Extensions such as mesh zippering [Turk and Levoy 1994] select one depth map per surface region, remove redundant triangles in overlapping regions, and stitch meshes. Rendering the final model is performed using point-based rendering techniques [Gross and Pfister 2007]. Height-map based representations explore the use of more compact 2.5D continuous surface representations for reconstruction [Pollefeys et al. 2008; Gallup et al. 2010]. These techniques are particularly useful for modeling large buildings with floors and walls,  since these appear as clear discontinuities in the height-map. The final surface is extracted as the zero-level set of the implicit function using isosurface polygonisation (e.g., [Lorensen and Cline 1987]) or raycasting. A well-known example is the method of Curless and Levoy [1996], which for active triangulation-based sensors such as laser range scanners and structured light cameras, can generate very high quality results [Curless and Levoy 1996; Levoy et al. 2000; Zhou and Koltun 2013]. KinectFusion [Newcombe et al. 2011; Izadi et al. 2011] recently adopted this volumetric method and demonstrated compelling real-time reconstructions using a commodity GPU. [Keller et al. 2013] use a point-based representation that captures qualities of volumetric fusion but removes the need for a spatial data structure. Moving volume methods [Roth and Vona 2012; Whelan et al. 2012] extend the GPU-based pipeline of KinectFusion. While still operating on a very restricted regular grid, these methods stream out voxels from the GPU based on camera motion, freeing space for new data to be stored. [Zeng et al. 2012] implement a 9to 10-level octree on the GPU, which extends the KinectFusion pipeline to a larger 8m ? 8m ? 2m indoor office space. In an octree, the resolution in each dimension increases by a factor of two at each subdivision level. While avoiding the use of an octree, the system still carries computational overheads in realizing such a hierarchical data structure on the GPU. As such this leads to performance that is only real-time on specific scenes, and on very high-end graphics hardware. We extend the volumetric method of Curless and Levoy [1996] to reconstruct high-quality 3D surfaces in real-time and at scale, by incrementally fusing noisy depth maps into a memory and speed efficient data structure. Curless and Levoy have proven to produce compelling results given a simple cumulative average of samples. The method supports incremental updates, makes no topological assumptions regarding surfaces, and approximates the noise characteristics of triangulation based sensors effectively. Further, while an implicit representation, stored isosurfaces can be readily extracted. Our method addresses the main drawback of Curless and Levoy: supporting efficient scalability. Next, we review the Curless and Levoy method, before the description of our new approach. Let us consider a regular dense voxel grid, and assume the input is a sequence of depth maps. The depth sensor is initialized at some origin relative to this grid (typically the center of the grid). First, the rigid six degree-of-freedom (6DoF) ego-motion of the sensor is estimated, typically using variants of ICP [Besl and McKay 1992; Chen and Medioni 1992]. Each voxel in the grid contains two values: a signed distance and weight. All voxels that project onto the same pixel are considered part of the depth sample?s footprint. At each of these voxels a signed distance from the voxel center to the observed surface measurement is stored, with positive distances in front, negative behind, and nearing zero at the surface interface. This region can be adapted in size, approximating sensor noise as a Gaussian with variance based on depth [Chang et al. 1994; Nguyen et al. 2012]. Finally, voxels (in front of the surface) that are part of each depth sample?s footprint, but outside of the truncation region are explicitly marked as free-space. This allows removal of outliers based on free-space violations. Voxel Hashing Given Curless and Levoy truncate SDFs around the surface, the majority of data stored in the regular voxel grid is marked either as free space or as unobserved space rather than surface data. Our approach specifically avoids the use of a dense or hierarchical data structure, removing the need for a memory intensive regular grid or computationally complex hierarchy for volumetric fusion. Instead, we use a simple hashing scheme to compactly store, access and update an implicit surface representation. In the graphics community, efficient spatial hashing methods have been explored in the context of a variety of 2D/3D rendering and collision detection tasks [Teschner et al. 2003; Lefebvre and Hoppe 2006; Bastos and Celes 2008; Alcantara et al. 2009; Pan and Manocha 2011; Garc?a et al. 2011]. Sophisticated methods have been proposed for efficient GPU-based hashing that greatly reduce the number of hash entry collisions. This is non-trivial for 3D reconstruction as the geometry is unknown ahead of time and continually changing. Therefore, our hashing technique must support dynamic allocations and updates, while minimizing and resolving potential hash entry collisions, without requiring a-priori knowledge of the contained surface geometry. In approaching the design of our data structure, we have purposefully chosen and extended a simple hashing scheme [Teschner et al. 2003], and while more sophisticated methods exist, we show empirically that our method is efficient in terms of speed, quality, and scalability. The hash table sparsely and efficiently stores and updates TSDFs. In the following we describe the data structure in more detail, and demonstrate how it can be efficiently implemented on the GPU. We highlight some of the core features of our data structure, including: ? The ability to efficiently compress volumetric TSDFs, while maintaining surface resolution, without the need for a hierarchical spatial data structure. ? Fusing new TSDF samples efficiently into the hash table, based on insertions and updates, while minimizing collisions. ? Lightweight bidirectional streaming of voxel blocks between host and GPU, allowing unbounded reconstructions. ? Extraction of isosurfaces from the data structure efficiently using standard raycasting or polygonization operations, for rendering and camera pose estimation. System Pipeline Our pipeline is depicted in Fig. 2 . Each occupied entry in our hash table refers to an allocated voxel block. At each voxel we store a TSDF, weight, and an additional color value. Our hashing function allows an efficient look-up of voxel blocks, using specified (integer rounded) world coordinates. Our hash function aims to minimize the number of collisions and ensures no duplicates exist in the table. Given a new input depth map, we begin by performing fusion (also referred to as integration). We first allocate new voxel blocks and insert block descriptors into the hash table, based on an input depth map. Next we sweep each allocated voxel block to update the SDF, color and weight of each contained voxel, based on the input depth and color samples. In addition, we garbage collect voxel blocks which are too far from the isosurface and contain no weight. This involves freeing allocated memory as well as removing the voxel block entry from the hash table. These steps ensure that our data structure remains sparse over time. After integration, we raycast the implicit surface from the current estimated camera pose to extract the isosurface, including associated colors. This extracted depth and color buffer is used as input for camera pose estimation: given the next input depth map, a projective point-plane ICP [Chen and Medioni 1992] is performed to estimate the new 6DoF camera pose. This ensures that pose estimation is performed frame-to-model rather than frame-to-frame mitigating some of the issues of drift (particularly for small scenes) [Newcombe et al. 2011]. Finally, our algorithm performs bidirectional streaming between GPU and host. Hash entries (and associated voxel blocks) are streamed to the host as their world positions exit the estimated camera view frustum. Previously streamed out voxel blocks can also be streamed back to the GPU data structure when revisiting areas. Fig. 3 shows our voxel hashing data structure. Conceptually, an infinite uniform grid subdivides the world into voxel blocks. Each block is a small regular voxel grid. In our current implementation a voxel block is composed of 8 3 voxels. We use an efficient GPU accelerated hash table to manage allocation and retrieval of voxel blocks. The hash table stores hash entries, each containing a pointer to an allocated voxel block. Voxel blocks can be retrieved from the hash table using integer world coordinates (x, y, z). Finding the coordinates for a 3D point in world space is achieved by simple multiplication and rounding. We map from a world coordinate (x, y, z) to hash value H(x, y, z) using the following hashing function: where p 1 , p 2 , and p 3 are large prime numbers (in our case 73856093, 19349669, 83492791 respectively, based on [Teschner et al. 2003]), and n is the hash table size. In addition to storing a pointer to the voxel block, each hash entry also contains the associated world position, and an offset pointer to handle collisions efficiently (described in the next section). struct HashEntry { short position[3]; short offset; int pointer; }; Conceptually, an infinite uniform grid partitions the world. Using our hash function, we map from integer world coordinates to hash buckets, which store a small array of pointers to regular grid voxel blocks. Each voxel block contains an 8 3 grid of SDF values. When information for the red block gets added, a collision appears which is resolved by using the second element in the hash bucket. Collisions appear if multiple allocated blocks are mapped to the same hash value (see red block in Fig. 3 ). We handle collisions by uniformly organizing the hash table into buckets, one per unique hash value. Each bucket sequentially stores a small number of hash entries. When a collision occurs, we store the block pointer in the next available sequential entry in the bucket (see Fig. 4 ). To find the voxel block for a particular world position, we first evaluate our hash function, and lookup and traverse the associated bucket until our block entry is found. This is achieved by simply comparing the stored hash entry world position with the query position. With a reasonable selection of the hash table and bucket size (see later), rarely will a bucket overflow. However, if this happens, we append a linked list entry, filling up other free spots in the next available buckets. The (relative) pointers for the linked lists are stored in the offset field of the hash table entries. Such a list is appended to a full bucket by setting the offset pointer for the last entry in the bucket. All following entries are then chained using the offset field. In order to create additional links for a bucket, we linearly search across the hash table for a free slot to store our entry, appending to the link list accordingly. We avoid the last entry in each bucket, as this is locally reserved for the link list head. As shown later, we choose a table and bucket size that keeps the number of collisions and therefore appended linked lists to a minimum for most scenes, as to not impact overall performance. Insertion To insert new hash entries, we first evaluate the hash function and determine the target bucket. We then iterate over all bucket elements including possible lists attached to the last entry. Otherwise, we look for the first empty position within the bucket. If a position in the bucket is available, we insert the new hash entry. If the bucket is full, we append an element to its linked list element (see Fig. 4 ). To avoid race conditions when inserting hash entries in parallel, we lock a bucket atomically for writing when a suitable empty position is found. This eliminates duplicate entries and ensures linked list consistency. This may delay some allocations marginally. However, in practice this causes no degradation in reconstruction quality (as observed in the results and supplementary video), particularly as the Curless and Levoy method supports order independent updates. Retrieval To read the hash entry for a query position, we compute the hash value and perform a linear search within the corresponding bucket. Note that we do not require a bucket to be filled from left to right. As described below, removing values can lead to fragmentation, so traversal does not stop when empty entries are found in the bucket. For a given world position we first compute the hash and then linearly search the corresponding hash bucket including list traversal. If we have found the matching entry without list traversal we can simply delete it. If it is the last element of the bucket and there was a non-zero offset stored (i.e., the element is a list head), we copy the hash entry pointed to by the offset into the last element of the bucket, and delete it from its current position. Otherwise if the entry is a (non-head) element in the linked list, we delete it and correct list pointers accordingly (see Fig. 4 ). However, in the case we need to modify the linked list, we lock the bucket atomically and stagger further list operations for this bucket until the next frame. We process  depth samples in parallel, inserting hash entries and allocating voxel blocks within the truncation region around the observed surface. The size of the truncation is adapted based on the variance of depth to compensate for larger uncertainty in distant measurements [Chang et al. 1994; Nguyen et al. 2012]. For each input depth sample, we instantiate a ray with an interval bound to the truncation region. Given the predefined voxel resolution and block size, we use DDA [Amanatides and Woo 1987] to determine all the voxel blocks that intersect with the ray. For each candidate found, we insert a new voxel block entry into the hash table. We would then allocate all voxel blocks within the truncation region that intersect with this frustum. In practice however, this leads to degradation in performance (currently 10-fold). Our ray-based approximation provides a balance between performance and precision. Given the continuous nature of the reconstruction, the frame rate of the sensor, and the mobility of the user, this in practice leads to no holes appearing between voxel blocks at larger distances (see results and accompanying video). Once we have successfully inserted an entry into the hash table, we allocate a portion of preallocated heap memory on the GPU to store voxel block data. The heap is a linear array of memory, allocated once upon initialization. It is divided into contiguous blocks (mapping to the size of voxel blocks), and managed by maintaining a list of available blocks. This list is a linear buffer with indices to all unallocated blocks. A new block is allocated using the last index in the list. Since the list is accessed in parallel, synchronization is necessary, by incrementing or decrementing the end of list pointer using an atomic operation. We update all allocated voxel blocks that are currently within the camera view frustum. After the previous step (see Section 5), all voxel blocks in the truncation region of the visible surface are allocated. Further, a significant amount of voxel blocks will be outside the viewing frustum. Under these assumptions, TSDF integration can be done very efficiently by only selecting available blocks inside the current camera frustum. Voxel Block Selection To select voxel blocks for integration, we first in parallel access all hash table entries, and store a corresponding binary flag in an array for an occupied and visible voxel block, or zero otherwise. We then scan this array using a parallel prefix sum technique [Harris et al. 2007]. To facilitate large scan sizes (our hash table can have millions of entries) we use a three level up and down sweep. Using the scan results we compact the hash table into another buffer, which contains all hash entries that point to voxel blocks within the view frustum (see Fig. 5 ). Note that voxel blocks are not copied, just their associated hash entries. Implicit Surface Update The generated list of hash entries is then processed in parallel to update TSDF values. A single GPGPU kernel is executed for each of the associated blocks, with one thread allocated per voxel. That means that a voxel block will be processed on a single GPU multiprocessor, thus maximizing cache hits and minimizing code divergence. In practice, this is more efficient than assigning a single thread to process an entire voxel block. Updating voxel blocks involves re-computation of the associated TSDFs, weights and colors. Distance values are integrated using a running average as in Curless and Levoy [Curless and Levoy 1996]. We set the integration weights according to the depth values in order to incorporate the noise characteristics of the sensor; i.e., more weight is given to nearer depth measurements for which we assume less noise. One important part of the integration step is to update all voxel blocks that fall into the current frustum, irrespective of whether they reside in the current truncation region. This can be due to surfaces being physically moved, or small outliers in the depth map being allocated previously, which are no longer observed. These blocks are not treated any differently, and continuously updated. As shown next however, we evaluate all voxel blocks after integration to identify such candidates for potential garbage collection. Garbage Collection Garbage collection removes voxel blocks allocated due to noisy outliers and moved surfaces. This step operates on the compacted hash table we obtained previously. For each associated voxel block we perform a summarization step to obtain both the minimum absolute TSDF value and the maximum weight. If the maximum weight of a voxel block is zero or the minimum TSDF is larger than a threshold we flag the block for deletion. In a second pass, in parallel we delete all flagged entries using the hash table delete operation described previously. When a hash entry gets deleted successfully, we also free the corresponding voxel block by appending the voxel block pointer to the heap (cf. Section 5). We perform raycasting to extract the implicitly stored isosurface. First, we compute the start and end points for each ray by conservatively rasterizing the entire bounding box of all allocated voxel blocks in the current view frustum. In parallel, we rasterize each voxel block (retrieved from the compact hash table buffer computed during integration) in two passes, and generate two z-buffers for the minimum and maximum depth. This demonstrates another benefit for our linear hash table data structure (over hierarchical data structures), allowing fast parallel access to all allocated blocks for operations such as rasterization. For each output pixel, we march a ray from the associated minimum to the maximum depth values. During marching we must evaluate the TSDF at neighboring world positions along the current ray. In this step, unallocated voxel blocks are also considered as empty space. Within occupied voxel blocks, we apply tri-linear interpolation by looking up the eight neighboring voxels. One special case  that needs to be considered is sampling across voxel block boundaries. To deal with this, we retrieve neighboring voxels by lookup via the hash table rather than sampling the voxel block directly. In practice, we use hash table lookups irrespective of whether the voxel is on a block boundary. Due to caching, reduced register count per thread, and non-divergent code, this increases performance over direct block sampling. We have also tried using a one-voxel overlap region around blocks in order to simplify tri-linear reads without the need of accessing multiple voxel blocks. However, that approximately doubled the memory footprint and we found that required overlap synchronization for surface integration bears significant computational overhead. To locate the surface interface (zero-crossing) we determine sign changes for current and previous (tri-linearly-interpolated) TSDF values. We ignore zero-crossings from negative to positive as this refers to back-facing surface geometry. In order to speed up ray marching, we skip a predefined interval (half the minimum truncation value). This avoids missing isosurfaces but provides only coarse zero-crossing positions. To refine further, we use iterative line search once a zero-crossing is detected to estimate the true surface location. Camera Tracking Once the surface is extracted via raycasting, it can be shaded for rendering, or used for frame-to-model camera pose estimation [Newcombe et al. 2011]. We use the next input frame along with the raycasted depth map to estimate pose. This ensures that the new pose is estimated prior to depth map fusion. Pose is estimated using the point-plane variant of ICP [Chen and Medioni 1992] with projective data association. The point-plane energy function is linearized [Low 2004] on the GPU to a 6 ? 6 matrix using a parallel reduction and solved via Singular Value Decomposition on the CPU. As our data structure also stores associated color data, we incorporate a weighting factor in the point-plane error-metric based on color consistency between extracted and input RGB values [Johnson and Bing Kang 1999]. The basic data structure described so far allows for high-resolution voxel blocks to be modeled beyond the resolution and range of current commodity depth cameras (see Section 9). However, GPU memory and performance become a consideration when we attempt to maintain surface data far outside of the view frustum in the hash table. To deal with this issue and allow unbounded reconstructions, we utilize a bidirectional GPU-Host streaming scheme. Our unstructured data structure is well-suited for this purpose, since streaming voxel blocks in or out does not require any reorganization of the hash table. We create an active region defined as a sphere containing the current camera view frustum and a safety region around it. For a standard Kinect, we assume a depth range up to eight meters. We locate the center of the sphere four meters from the camera position and use a radius of eight meters (see Figure 6 ). Bidirectional streaming of voxel blocks happens every frame at the beginning of the pipeline directly after pose estimation. To stream voxel blocks out of the active region, we first access the hash table in parallel and mark voxel blocks which moved out of the active region. For all these candidates we delete corresponding hash entries, and append them efficiently to an intermediate buffer. In a second pass, for all these hash entries, corresponding voxel blocks are copied to another intermediate buffer. The original voxel blocks are then cleared and corresponding locations are appended back to the heap, so they can be reused. Finally, these intermediate buffers are copied back to the host for access. On the host, voxel data is no longer organized into a hash table. Instead, we logically subdivide the world space uniformly into chunks (in our current implementation each set to 1m 3 ). Voxel blocks are appended to these chunks using a linked list. For each voxel block we store the voxel block descriptor which corresponds to hash entry data, as well as the voxel data. For Host-to-GPU streaming we first identify chunks that completely fall into the spherical active region again, due to the user moving back to a previously reconstructed region. In contrast to GPUto-CPU streaming which works on a per voxel block level, CPUto-GPU streaming operates on a per chunk basis. So if a chunk is identified for streaming all voxel blocks in that chunk will be streamed to the GPU. This enhances performance, given the high host-GPU bandwidth and ability to efficiently cull voxel blocks outside of the view frustum. Due to limited CPU compute per frame, streaming from host-toGPU is staggered, one chunk per frame. We select the chunk tagged for streaming that is most near to the camera frustum center. We then copy the chunk to the GPU via the intermediate buffers created for GPU-to-Host streaming. After copying to the GPU, in parallel we insert voxel block descriptors as entries into the hash table, allocating voxel block memory from the heap, and copy voxel data accordingly. This is similar to the allocation phase (see Section 5), however, when streaming data, all hash entries must be inserted within a single frame, rather than staggering the insertions. For a streamed voxel block we check the descriptor and atomically compare whether the position is occupied in the table. If an entry exists, we proceed to search for the next available free position in the bucket (as described below, we ensure that there are no duplicates). Otherwise we write the streamed hash entry at that position into the hash table. If the bucket is full, the entry is appended at the end of the list. Both writing a free entry directly in the bucket or appending it to the end of a linked list must be performed atomically. One important consideration for streaming is to ensure that voxel blocks are never duplicated on host or GPU, leading to potential memory leaks. Given that Host-to-GPU streaming is staggered, there are rare cases where voxel blocks waiting to be streamed may enter the view frustum. We must verify that there is no new allocation of these voxel blocks in these staggered regions. To this end we store a binary occupancy grid on the GPU, where each entry corresponds to a particular chunk. Setting the bit indicates that the chunk resides on the GPU and allocations can occur in this region. Otherwise the chunk should be assumed to be on the host and allocations should be avoided. This binary grid carries little GPU memory overhead 512KB for 256 3 m 3 , and can be easily re-allocated on-the-fly to extend to larger scenes. We have implemented our data structure using DirectX 11 Compute Shaders. We use an Asus Xtion for scenes in Fig. 10 and a Kinect for Windows camera for all other scenes, both providing RGB-D data at 30Hz. Results of live scene captures for our test scenes are shown in Figures 1 and 11 as well as supplementary material. We captured a variety of indoor and outdoor scenes under a variety of lighting conditions. While the quality of active infrared sensors is affected significantly in outdoor scenes, our system still manages to reconstruct large-scale outdoor scenes with fine quality. STATUES in Fig. 1 shows the result after an online scan of a ? 20m long corridor in a museum with about 4m high statues, which was captured and reconstructed live in under 5 minutes. PASSAGEWAY ( Fig. 11 top) shows a pathway of shops ? 30m long reconstructed live. QUEENS ( Fig. 11 middle) shows a large courtyard (stretching ? 16m ? 12m ? 2m) reconstructed in approximately 4 minutes. Finally, BOOKSHOP ( Fig. 11 bottom) shows three levels of a bookstore reconstructed in under 6 minutes. These reconstructions demonstrate both scale and quality, and were all reconstructed well above the 30Hz frame rate of the Kinect as shown in Figure 7 . This allows for potential increase of voxel resolution and additional ICP steps for more robust camera tracking. We use a voxel size of 4mm for Fig. 8 , 10 and 10mm for Fig. 1 , 9, 11. We also tested our system with < 2mm voxels without visible improvements in overall reconstruction quality. While this highlights limits of current depth sensing technology, we believe that this opens up new possibilities for future depth acquisition hardware. We measured performance of our entire pipeline including run-time overhead (such as display rendering) on an Intel Core i7 3.4GHz CPU, 16GB of RAM, and a single NVIDIA GeForce GTX Titan. Average timings among all test scenes is 21.8ms (?46f ps) with 8.0ms (37% of the overall pipeline) for ICP pose estimation (15 iterations), 4.6ms (21%) for surface integration, 4.8ms (22%) for surface extraction and shading (including colored phong shading), and 4.4ms (20%) for streaming and input data processing. Separate timings for each test scene are provided in Fig. 7 . Our data structure uses a total of 34MB for the hash table and all auxiliary buffers. This allows a hash table with 2 21 entries, each containing 12 bytes. Our experiments show that a bucket size of two provides best performance leaving us with about 1 million buckets. We pre-allocate 1GB of heap memory to provide space for voxel data on the GPU. With 8 3 voxels per block (8 byte per voxel) this corresponds to 2 18 voxel blocks. Note that 2 21 hash entries only index to 2 18 voxel blocks resulting in a low hash occupancy, thus minimizing hash collisions. On average we found that about 140K voxel blocks are allocated when capturing our test scenes at a voxel size of 8mm (varying with scene complexity). This corresponds to an equal amount of occupied hash entries, resulting in a hash table occupancy with 120K buckets with a single entry, and 10K buckets with two entries. With a bucket size of two and hash table size of 2 21 , all test scenes run with only 0.1% bucket overflow. These are handled by linked lists and across all scenes the largest list length is three. In total ?700 linked list entries are allocated across all scenes, which is negligible compared to the hash table size. On average less than 300MB memory is allocated for surface data (less than 600MB with color). This compares favorably to a regular grid that would require well over 5GB (including color) at the same voxel resolution (8mm) and spatial extent (8m in depth). This also leaves enough space to encode RGB data directly into the stored voxels (see Fig. 11 ). In practice this simple hashing scheme with small bucket size and large hash table size works well. In our scenario we can tolerate larger and sparser (2 21 ) hash table sizes, because the memory footprint of the hash table is insignificant (?34MB) compared to the voxel block buffer (which is pre-allocated to 1GB). Smaller hash table sizes cause higher occupancy and decrease performance. For example, in the STATUES scene our standard settings (2 21 elements) occupies ?6.4% of the hash table and runs at ?21ms, with 200K elements occupancy rises to ?65% and performance is reduced to ?24.8ms, and with 160K elements occupancy rises to ?81% with performance further falling to 25.6ms. In our live system, we chose larger table sizes as we favored performance over the small memory gains. Our pipeline currently uses atomic operations per hash bucket for allocation and streaming. As shown by our timings across all scenes, these sequential operations cause negligible performance overheads, due to hash collisions being minimal. More sophisticated hashing approaches [Lefebvre and Hoppe 2006; Bastos and Celes 2008; Alcantara et al. 2009; Pan and Manocha 2011; Garc?a et al. 2011] could further reduce collisions and allow smaller hash tables. However, how these methods deal with the high throughput of data, fusion and streaming is unclear. It is also important to stress that our simple hashing method works well in practice, handling scalability and quality at framerates >40fps across all scenes. P ASSAGEWAY reconstruction. In Fig. 9 we show the quality and performance of our method compared to previous work. All code was tested on the same hardware (see above) with a fixed number of ICP iterations (15). As our algorithm supports real-time streaming, we conducted comparisons with similar moving volume approaches. First, we compare against Extended Fusion [Roth and Vona 2012; Whelan et al. 2012] that use a regular uniform grid including streaming to scale-up volumetric fusion. Second, we compare against Hierarchical Fusion [Chen et al. 2013] that supports larger moving volumes than other approaches. Corresponding timings are shown in Fig. 7 . The most significant limitation of the hierarchy is the data structure overhead causing a performance drop, particularly in complex scenes. In our test scenes the entire hierarchy pipeline (including pose estimation, fusion, and streaming) runs at ? 15Hz, which is lower than the input frame rate. Note that these measurements are based on the reference implementation by Chen et al. [2013]. Our system also performs favorably compared to streaming regular grids in terms of frame-rate (labeled Extended in Fig. 7 ). We attribute this to processing of empty voxels in the regular grid (particularly during random GPU memory access; e.g., raycasting) and streaming overhead. Further, as shown in Fig. 8 , our reconstruction quality is higher than these approaches. The quality of Extended Fusion is limited by the small spatial extent of the moving volume, which means much of the Kinect data is out of range and not integrated. Hierarchical Fusion suffers from the poor frame rate causing input data to be skipped. This severely affects pose estimation quality resulting in inaccurate surface integration and drift. In large-scale scenes this type of drift might cause unnaturally twisted models as shown in Fig. 9 . Given our more efficient data structure, which runs faster than the Kinect camera frame rate, additional time can be spent improving the accuracy of the pose estimation by increasing the number of ICP iterations. We find our results encouraging, particularly given no drift correction is explicitly handled. While our method does suffer from small drifts, our system produces comparable results, and can be used for real-time applications. Our online method can also be used as a live preview, and combined with such approaches for higher-quality offline reconstruction. We have presented a new data structure designed specifically for online reconstruction using widely-available consumer depth cameras. Our approach leverages the power of implicit surfaces and volumetric fusion for reconstruction, but does so using a compact spatial hashing scheme, which removes both the overhead of regular grids and hierarchical data structures. Our hashing scheme supports real-time performance without forgoing scale or finer quality reconstruction. All operations are designed to be efficient for parallel graphics hardware. The inherent unstructured nature of our method removes the overhead of hierarchical spatial data structures, but captures the key qualities of volumetric fusion. To further extend the bounds of reconstruction, our method supports lightweight streaming without major data structure reorganization. We have demonstrated performance increases over the state-of-theart, even regular grid implementations. The data structure is memory  efficient and can allow color data to be directly incorporated in the reconstruction, which can also be used to improve the robustness of registration. Due to the high performance of our data structure, the available time budget can be utilized for further improving camera pose estimation, which directly improves reconstruction quality over existing online approaches. We thank Dennis Bautembach, Jiawen Chen, Vladlen Koltun and Qian-Yi Zhou for code/data, Christoph Buchenau for mesh rendering, and Universities of Cambridge and Erlangen-Nuremberg for filming access. This work was part funded by the German Research Foundation (DFG), grant GRK-1773 Heterogeneous Image Systems.",
  "resources" : [ ]
}