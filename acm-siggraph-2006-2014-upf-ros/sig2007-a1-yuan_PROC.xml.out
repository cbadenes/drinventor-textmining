{
  "uri" : "sig2007-a1-yuan_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2007/a1-yuan_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Image Deblurring with Blurred/Noisy Image Pairs",
    "published" : null,
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ ]
  },
  "bagOfWords" : [ "we", "demonstrate", "effectiveness", "we", "approach", "use", "number", "indoor", "outdoor", "image", "take", "off-the-shelf", "hand-held", "camera", "poor", "lighting", "environment", "kernel", "estimation", "we", "show", "very", "accurate", "initial", "kernel", "can", "recover", "from", "blur", "image", "exploit", "large", "scale", "sharp", "image", "structure", "noisy", "image", "we", "also", "propose", "gain-controlled", "deconvolution", "further", "suppress", "ringing", "artifact", "smooth", "image", "region", "we", "have", "find", "motion", "between", "two", "blurred/noisy", "image", "when", "take", "quick", "succession", "mainly", "translation", "we", "approach", "we", "significantly", "reduce", "artifact", "non-blind", "deconvolution", "take", "advantage", "noisy", "image", "-lsb-", "Levin", "2006", "-rsb-", "image", "segmented", "several", "layer", "different", "kernel", "both", "technique", "physically", "move", "element", "lens", "sensor", "counterbalance", "camera", "shake", "typically", "capture", "image", "can", "sharp", "be", "take", "shutter", "speed", "2-3", "stop", "faster", "-lsb-", "Liu", "Gamal", "2001", "-rsb-", "CMOS", "sensor", "can", "capture", "multiple", "high-speed", "frame", "within", "normal", "exposure", "time", "pixel", "motion", "replace", "pixel", "one", "high-speed", "frame", "denoise", "can", "perform", "joint/cross", "bilateral", "filter", "use", "flash/no-flash", "image", "-lsb-", "Petschnigg", "et", "al.", "2004", "Eisemann", "Durand", "2004", "-rsb-", "spatio-temporal", "filter", "video", "sequence", "-lsb-", "Bennett", "McMillan", "2005", "-rsb-", "we", "approach", "estimate", "kernel", "only", "from", "two", "image", "without", "need", "special", "hardware", "another", "related", "work", "-lsb-", "Jia", "et", "al.", "2004", "-rsb-", "also", "use", "pair", "image", "where", "color", "blur", "image", "transfer", "noisy", "image", "without", "kernel", "estimation", "paper", "we", "demonstrate", "we", "propose", "technique", "can", "obtain", "much", "accurate", "kernel", "compare", "Lim", "Silverstein?s", "approach", "produce", "almost", "artifact-free", "image", "propose", "de-ringing", "approach", "deconvolution", "we", "take", "pair", "image", "blur", "image", "slow", "shutter", "speed", "low", "iso", "noisy", "image", "high", "shutter", "speed", "high", "iso", "noisy", "image", "usually", "underexpose", "have", "very", "low", "snr", "since", "camera", "noise", "dependent", "image", "intensity", "level", "-lsb-", "Liu", "et", "al.", "2006", "-rsb-", "moreover", "noise", "high", "iso", "image", "also", "larger", "than", "low", "iso", "image", "since", "noise", "amplify", "camera", "gain", "noisy", "image", "sharp", "because", "we", "use", "fast", "shutter", "speed", "above", "safe", "shutter", "speed", "we", "pre-multiply", "noisy", "image", "ratio", "iso", "iso", "compensate", "exposure", "difference", "between", "blur", "noisy", "image", "where", "exposure", "time", "otherwise", "gamma", "noisy", "image", "we", "compute", "denoise", "image", "-lsb-", "Portilla", "et", "al.", "2003", "-rsb-", "-lrb-", "see", "section", "detail", "-rrb-", "we", "represent", "lose", "detail", "layer", "residual", "image", "we", "first", "important", "observation", "denoise", "image", "very", "good", "initial", "approximation", "purpose", "kernel", "estimation", "from", "equation", "-lrb-", "-rrb-", "power", "spectrum", "image", "mainly", "lie", "denoise", "image", "moreover", "large", "scale", "sharp", "image", "structure", "make", "important", "contribution", "kernel", "estimation", "show", "we", "experiment", "synthetic", "real", "image", "accurate", "kernel", "can", "obtain", "use", "nonblind", "convolution", "we", "second", "observation", "ringing", "artifact", "from", "residual", "deconvolution", "-lrb-", "equation", "-lrb-", "-rrb-", "-rrb-", "smaller", "than", "those", "from", "deconvolution", "-lrb-", "equation", "-lrb-", "-rrb-", "-rrb-", "because", "have", "much", "smaller", "magnitude", "than", "after", "be", "offset", "denoise", "image", "also", "provide", "crucial", "gain", "signal", "control", "deconvolution", "process", "so", "we", "can", "suppress", "ring", "artifact", "especially", "smooth", "image", "region", "we", "propose", "de-ringing", "approach", "use", "gain-controlled", "deconvolution", "algorithm", "further", "reduce", "ring", "artifact", "above", "three", "step", "kernel", "estimation", "-lrb-", "section", "-rrb-", "residual", "deconvolution", "-lrb-", "section", "-rrb-", "de-ringing", "-lrb-", "section", "-rrb-", "iterate", "refine", "estimate", "blur", "kernel", "deconvoluted", "image", "section", "we", "show", "simple", "constrain", "least-square", "optimization", "able", "produce", "very", "good", "initial", "kernel", "iterative", "kernel", "estimation", "goal", "kernel", "estimation", "find", "blur", "kernel", "from", "initialization", "regularization", "stabilize", "solution", "we", "use", "Tikhonov", "regularization", "method", "positive", "scalar", "solve", "min", "Ak", "true", "image", "-lrb-", "also", "show", "Figure", "-lrb-", "-rrb-", "-rrb-", "-lrb-", "-rrb-", "matlab?s", "deconvblind", "routine", "result", "-lrb-", "-rrb-", "fergus?s", "result", "finest", "level", "-lrb-", "-rrb-", "Lim", "Silverstein?s", "result", "-lrb-", "-rrb-", "estimate", "kernel", "without", "hysteresis", "thresholding", "-lrb-", "-rrb-", "we", "result", "finest", "level", "-lrb-", "-rrb-", "true", "kernel", "default", "value", "set", "we", "adopt", "Landweber", "method", "-lsb-", "Engl", "et", "al.", "2000", "-rsb-", "iteratively", "update", "follow", "set", "+1", "+1", "normalize", "+1", "+1", "+1", "iteration", "stop", "when", "change", "between", "two", "step", "sufficiently", "small", "we", "typically", "run", "about", "20", "30", "iteration", "set", "1.0", "algorithm", "fast", "use", "FFT", "take", "about", "12", "seconds", "64", "64", "kernel", "800", "600", "image", "zoomed-in", "-lrb-", "-rrb-", "middle", "image", "-lrb-", "-rrb-", "estimate", "kernel", "use", "only", "image", "patch", "-lrb-", "-rrb-", "bottom", "image", "-lrb-", "-rrb-", "estimate", "kernel", "use", "whole", "image", "above", "iterative", "algorithm", "can", "implement", "scale", "space", "make", "solution", "overcome", "local", "minimal", "we", "compute", "two", "mask", "low", "high", "set", "two", "threshold", "low", "high", "low", "larger", "contain", "high", "after", "kernel", "estimation", "we", "set", "all", "element", "outside", "mask", "high", "zero", "reduce", "noise", "level", "l.", "next", "finer", "level", "we", "set", "all", "element", "+1", "outside", "up-sampled", "mask", "low", "zero", "further", "reduce", "noise", "hysteresis", "thresholding", "perform", "from", "coarse", "fine", "pyramid", "construct", "use", "downsampling", "factor", "until", "kernel", "size", "coarsest", "level", "reach", "we", "typically", "choose", "low", "0.03", "high", "0.05", "result", "discussion", "we", "first", "compare", "we", "estimate", "kernel", "true", "kernel", "use", "synthetic", "example", "figure", "-lrb-", "a-c", "-rrb-", "show", "two", "blur", "image", "noisy", "image", "denoise", "image", "blur", "image", "synthesize", "two", "41", "41", "known", "kernel", "figure", "-lrb-", "-rrb-", "show", "kernel", "estimate", "matlab?s", "deconvblind", "routine", "-lrb-", "blind", "deconvolution", "-rrb-", "use", "denoise", "image", "initialization", "figure", "-lrb-", "-rrb-", "show", "coarse-to-fine", "kernel", "-lrb-", "finest", "level", "-rrb-", "estimate", "fergus?s", "algorithm", "only", "use", "blur", "image", "-lsb-", "Fergus", "et", "al.", "2006", "-rsb-", "Matlab", "code", "release", "Fergus", "-lrb-", "http://people.csail.mit.edu/fergus/", "-rrb-", "we", "exhaustively", "tune", "all", "option", "fergus?s", "algorithm", "select", "different", "region", "image", "produce", "best", "result", "fergus?s", "algorithm", "recover", "much", "better", "kernel", "than", "those", "use", "matlab?s", "blind", "deconvolution", "figure", "-lrb-", "-rrb-", "result", "from", "-lsb-", "Lim", "Silverstein", "2006", "-rsb-", "fine", "detail", "thin", "structure", "kernel", "recover", "figure", "-lrb-", "-rrb-", "also", "show", "we", "kernel", "estimation", "without", "hysteresis", "thresholding", "which", "very", "noisy", "Figure", "show", "we", "result", "real", "image", "20", "iteration", "note", "standard", "rl", "result", "contain", "unpleasant", "ring", "artifact", "dark", "light", "ripple", "around", "strong", "image", "feature", "kernel", "one", "trajectory", "show", "Figure", "-lrb-", "-rrb-", "we", "also", "compare", "two", "kernel", "use", "select", "image", "patch", "whole", "image", "Kernel", "estimation", "insensitive", "select", "region", "kernel", "size", "very", "large", "92", "92", "pixel", "give", "blur", "kernel", "true", "image", "can", "reconstruct", "from", "i.", "Figure", "-lrb-", "-rrb-", "show", "deconvolution", "result", "use", "standard", "richardson-lucy", "-lrb-", "rl", "-rrb-", "algorithm", "after", "20", "iteration", "true", "kernel", "result", "image", "contain", "visible", "ring", "artifact", "dark", "light", "ripple", "around", "bright", "feature", "image", "more", "iteration", "introduce", "only", "more", "image", "detail", "also", "more", "ringing", "Fergus", "et", "al.", "-lsb-", "2006", "-rsb-", "also", "observe", "issue", "from", "result", "noised", "signal", "blur", "kernel", "box", "filter", "-lrb-", "-rrb-", "standard", "deconvolution", "result", "from", "-lrb-", "-rrb-", "-lrb-", "d-e", "-rrb-", "blur", "residual", "signal", "its", "deconvolution", "result", "-lrb-", "-rrb-", "residual", "deconvolution", "result", "Notice", "ring", "artifact", "-lrb-", "-rrb-", "smaller", "than", "-lrb-", "-rrb-", "ringing", "effect", "due", "well-known", "Gibbs", "phenomenon", "fourier", "analysis", "discontinuous", "point", "discontinuity", "could", "image", "edge", "point", "boundary", "artificially", "introduce", "inadequate", "spatial", "sampling", "image", "kernel", "larger", "blur", "kernel", "stronger", "ringing", "artifact", "key", "we", "approach", "we", "perform", "deconvolution", "relative", "image", "quantity", "reduce", "absolute", "amplitude", "signal", "instead", "do", "deconvolution", "directly", "image", "we", "perform", "deconvolution", "residual", "blur", "image", "recover", "residual", "image", "final", "reconstructed", "image", "enforce", "non-negativity", "pixel", "value", "after", "each", "iteration", "residual", "image", "offset", "back", "subtract", "constant", "where", "???", "correlation", "operator", "Figure", "-lrb-", "-rrb-", "show", "deconvolution", "result", "use", "residual", "rl", "algorithm", "same", "number", "iteration", "compare", "standard", "rl", "result", "-lrb-", "figure", "-lrb-", "-rrb-", "-rrb-", "ringing", "effect", "reduce", "Figure", "show", "1d", "example", "residual", "deconvolution", "ringing", "artifact", "from", "significantly", "weaker", "than", "those", "because", "magnitude", "-lrb-", "after", "subtract", "from", "-rrb-", "much", "smaller", "than", "residual", "deconvolution", "lessen", "ringing", "effect", "can", "fully", "eliminate", "they", "show", "Figure", "-lrb-", "-rrb-", "another", "example", "show", "figure", "-lrb-", "-rrb-", "we", "observe", "ringing", "effect", "most", "distracting", "smooth", "region", "because", "human", "perception", "can", "tolerate", "small", "scale", "ringing", "highly", "textured", "region", "we", "have", "also", "find", "mid-scale", "ringing", "effect", "more", "noticeable", "compare", "fine", "detail", "large", "scale", "sharp", "structure", "image", "note", "strong", "ringing", "mainly", "cause", "high", "contrast", "edge", "magnitude", "ringing", "proportional", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "gain", "-lrb-", "-rrb-", "iter", "-lrb-", "-rrb-", "iter", "10", "-lrb-", "-rrb-", "iter", "kernel", "estimate", "use", "-lrb-", "d-f", "-rrb-", "deconvolution", "result", "standard", "rl", "-lrb-", "green", "-rrb-", "residual", "rl", "-lrb-", "blue", "-rrb-", "gain-controlled", "rl", "-lrb-", "red", "-rrb-", "after", "iteration", "10", "20", "plot", "bottom-right", "blownup", "view", "Notice", "ringing", "effect", "amplify", "propagate", "standard", "rl", "residual", "rl", "suppress", "gain-controlled", "rl", "magnitude", "image", "gradient", "gain-controlled", "richardson-lucy", "-lrb-", "rl", "-rrb-", "we", "modify", "residual", "rl", "algorithm", "introduce", "gain", "map", "Gain", "where", "gain", "multiplier", "-lrb-", "-rrb-", "suppress", "contrast", "recover", "residual", "image", "since", "rl", "ratio-based", "algorithm", "ringing", "effect", "amplify", "each", "iteration", "ratio", "-lrb-", "+1", "+1", "-rrb-", "-lrb-", "-rrb-", "multiply", "factor", "less", "than", "one", "each", "iteration", "suppress", "propagation", "ringing", "effect", "Notice", "multiply", "factor", "decrease", "overall", "magnitude", "signal", "decrease", "contrast", "signal", "because", "ratio", "-lrb-", "+1", "+1", "-rrb-", "increase", "magnitude", "signal", "each", "iteration", "last", "iteration", "we", "do", "multiply", "gain", "map", "gain", "since", "we", "want", "suppress", "contrast", "ring", "smooth", "region", "while", "avoid", "suppression", "sharp", "edge", "gain", "map", "should", "small", "smooth", "region", "large", "other", "hence", "we", "define", "gain", "map", "use", "gradient", "denoise", "image", "parameter", "control", "degree", "suppression", "aggregated", "image", "gradient", "multiple", "scale", "have", "also", "be", "use", "HDR", "compression", "-lsb-", "Fattal", "et", "al.", "2002", "Li", "et", "al.", "2005", "-rsb-", "here", "gradient", "denoise", "image", "provide", "gain", "signal", "adaptively", "suppress", "ringing", "effect", "different", "region", "Figure", "show", "1d", "example", "gain-controlled", "rl", "we", "can", "see", "residual", "rl", "can", "reduce", "magnitude", "ring", "compare", "standard", "rl", "both", "standard", "rl", "residual", "rl", "magnitude", "ring", "increase", "spatial", "range", "ring", "spread", "gradually", "after", "each", "iteration", "control", "from", "gain", "map", "ringing", "effect", "suppress", "each", "iteration", "-lrb-", "-rrb-", "blurred/noisy", "image", "-lrb-", "-rrb-", "residual", "rl", "-lrb-", "-rrb-", "gain-controlled", "rl", "-lrb-", "-rrb-", "detail", "layer", "-lrb-", "-rrb-", "final", "image", "-lrb-", "-rrb-", "ring", "layer", "ringing", "artifact", "produce", "de-ringing", "image", "-lrb-", "-rrb-", "detail", "layer", "-lrb-", "-rrb-", "extract", "from", "residual", "rl", "result", "-lrb-", "-rrb-", "guidance", "use", "joint/cross", "bilateral", "filter", "we", "final", "image", "-lrb-", "-rrb-", "obtain", "add", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "together", "-lrb-", "e.g.", "gain", "0.8", "flat", "region", "-rrb-", "most", "importantly", "propagation", "ringing", "greatly", "prevent", "so", "ringing", "significantly", "reduce", "Figure", "-lrb-", "-rrb-", "show", "gain-controlled", "rl", "result", "clean", "deconvolution", "result", "large", "scale", "sharp", "edge", "compare", "residual", "rl", "result", "figure", "-lrb-", "-rrb-", "however", "some", "fine", "detail", "inevitably", "suppress", "gain-controlled", "rl", "fortunately", "we", "able", "add", "fine", "scale", "image", "detail", "residual", "rl", "result", "use", "follow", "approach", "add", "detail", "we", "extract", "fine", "scale", "detail", "layer", "from", "residual", "rl", "result", "where", "-lrb-", "-rrb-", "-lrb-", "-lrb-", "-rrb-", "-rrb-", "filtered", "image", "-lrb-", "-rrb-", "low-pass", "filter", "other", "word", "detail", "layer", "obtain", "high-pass", "filter", "we", "use", "joint/cross", "bilateral", "filter", "-lsb-", "Petschnigg", "et", "al.", "2004", "Eisemann", "Durand", "2004", "-rsb-", "preserve", "large", "scale", "edge", "-lrb-", "-lrb-", "-rrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-rrb-", "where", "spatial", "signal", "deviation", "gaussian", "kernel", "-lrb-", "-rrb-", "neighbor", "window", "normalization", "term", "default", "value", "1.6", "0.08", "Figure", "-lrb-", "-rrb-", "show", "extract", "detail", "layer", "two", "shot", "corresponding", "point", "pair", "top", "right", "in-plane", "rotation", "correction", "use", "two", "manually", "specify", "line", "bottom", "experiment", "repeat", "four", "user", "-lrb-", "-rrb-", "each", "cell", "-lrb-", "4x4", "grid", "-rrb-", "one", "color", "dot", "represent", "difference", "vector", "between", "one", "corresponding", "point", "pair", "two", "shot", "grid", "unit", "0.5", "pixel", "cell", "center", "coordinate", "origin", "compose", "gain-controlled", "rl", "result", "detail", "layer", "produce", "we", "final", "image", "show", "figure", "-lrb-", "-rrb-", "ringing", "layer", "-lrb-", "figure", "-lrb-", "-rrb-", "-rrb-", "can", "also", "obtain", "subtract", "from", "filter", "image", "we", "expect", "ringing", "layer", "mainly", "contain", "ripple-like", "ringing", "effect", "final", "result", "ringing", "artifact", "significantly", "reduce", "while", "recover", "image", "detail", "from", "deconvolution", "well", "preserve", "figure", "-lrb-", "c-d", "-rrb-", "show", "another", "example", "result", "after", "de-ringing", "computed", "gain", "map", "summarize", "we", "iterative", "image", "deblurr", "algorithm", "consist", "follow", "step", "estimate", "kernel", "compute", "residual", "deconvolution", "image", "compute", "gain-controlled", "deconvolution", "image", "construct", "final", "image", "add", "detail", "layer", "iteration", "stop", "when", "change", "sufficiently", "small", "image", "acquisition", "practice", "we", "require", "one", "image", "take", "soon", "after", "another", "minimize", "misalignment", "between", "two", "image", "we", "have", "two", "option", "capture", "image", "pair", "very", "quickly", "first", "two", "successive", "shot", "different", "camera", "setting", "trigger", "laptop", "computer", "connect", "camera", "free", "user", "from", "change", "camera", "setting", "between", "two", "shot", "second", "we", "use", "exposure", "bracket", "build", "many", "DSLR", "camera", "mode", "two", "successive", "shot", "can", "take", "different", "shutter", "speed", "press", "shutter", "only", "once", "use", "two", "option", "time", "interval", "between", "two", "shot", "can", "very", "small", "typically", "only", "1/5", "second", "which", "small", "fraction", "typical", "shutter", "speed", "-lrb-", "second", "-rrb-", "blur", "image", "motion", "between", "two", "shot", "mainly", "small", "translation", "we", "assume", "blur", "image", "can", "model", "single", "blur", "kernel", "i.e.", "dominant", "motion", "translation", "because", "translation", "only", "result", "offset", "kernel", "unnecessary", "align", "two", "image", "we", "can", "also", "manually", "change", "camera", "setting", "between", "two", "shot", "case", "we", "have", "find", "dominant", "motion", "between", "two", "shot", "translation", "in-plane", "rotation", "correct", "in-plane", "rotation", "we", "simply", "draw", "two", "corresponding", "line", "blurred/noisy", "image", "blur", "image", "line", "can", "specify", "along", "straight", "object", "boundary", "connect", "two", "corner", "feature", "noisy", "image", "rotate", "around", "its", "image", "center", "two", "line", "virtually", "parallel", "advanced", "exposure", "bracket", "allow", "more", "control", "build", "future", "camera", "manual", "alignment", "become", "unnecessary", "quantitatively", "measure", "relative", "motion", "between", "two", "shot", "we", "have", "perform", "usability", "study", "we", "ask", "four", "user", "continuously", "take", "two", "shot", "pattern", "wall", "-lrb-", "show", "top", "right", "figure", "-rrb-", "use", "laptop", "control", "manual", "control", "compact", "camera", "DSLR", "camera", "two", "shot", "have", "blur", "take", "same", "camera", "setting", "four", "corresponding", "point", "nearby", "image", "corner", "two", "shot", "extract", "we", "correct", "transformation", "-lrb-", "only", "translation", "laptop", "control", "in-plane", "rotation", "after", "translation", "manual", "control", "-rrb-", "between", "two", "shot", "bottom", "row", "Figure", "show", "registration", "error", "after", "correction", "each", "cell", "dot", "represent", "difference", "vector", "between", "pair", "corresponding", "point", "overall", "pixel", "error", "less", "than", "pixel", "full", "image", "resolution", "surprisingly", "best", "align", "image", "obtain", "use", "laptop", "control", "DSLR", "camera", "image", "denoising", "noisy", "image", "we", "apply", "wavelet-based", "denoising", "algorithm", "-lsb-", "Portilla", "et", "al.", "2003", "-rsb-", "Matlab", "code", "from", "http://decsai.ugr.es/", "javier/denoise", "we", "have", "also", "experiment", "bilateral", "filter", "find", "hard", "achieve", "good", "balance", "between", "remove", "noise", "preserve", "detail", "even", "careful", "parameter", "tuning", "we", "apply", "we", "approach", "variety", "blurred/noisy", "image", "pair", "low", "lighting", "environment", "use", "compact", "camera", "-lrb-", "canon", "s60", "5m", "pixel", "-rrb-", "DSLR", "camera", "-lrb-", "canon", "20d", "8m", "pixel", "-rrb-", "comparison", "we", "compare", "we", "approach", "denoising", "-lsb-", "Portilla", "et", "al.", "2003", "-rsb-", "standard", "rl", "algorithm", "Figure", "from", "leave", "right", "show", "blur", "image", "noisy", "image", "-lrb-", "enhance", "-rrb-", "denoise", "image", "standard", "rl", "result", "-lrb-", "use", "we", "estimate", "kernel", "-rrb-", "we", "result", "kernel", "size", "31", "31", "33", "33", "40", "40", "three", "example", "we", "manually", "tune", "noise", "parameter", "-lrb-", "standard", "deviation", "-rrb-", "denoising", "algorithm", "achieve", "best", "visual", "balance", "between", "noise", "removal", "detail", "preservation", "compare", "denoise", "result", "show", "Figure", "-lrb-", "-rrb-", "we", "result", "Figure", "-lrb-", "-rrb-", "contain", "much", "more", "fine", "detail", "tiny", "texture", "fabric", "first", "example", "thin", "grid", "structure", "crown", "second", "example", "clear", "text", "camera", "last", "example", "because", "noise", "image", "scale", "up", "from", "very", "dark", "low", "contrast", "image", "partial", "color", "information", "also", "lose", "we", "approach", "recover", "correct", "color", "through", "image", "deblurring", "Figure", "-lrb-", "-rrb-", "show", "standard", "rl", "deconvoution", "result", "which", "exhibit", "unpleasant", "ringing", "artifact", "large", "noise", "Figure", "10", "show", "blurred/noisy", "pair", "contain", "thin", "hair", "sweater", "detailed", "structure", "image", "capture", "compact", "camera", "noisy", "image", "have", "very", "strong", "noise", "most", "fabric", "texture", "sweater", "faithfully", "recover", "we", "result", "last", "column", "second", "row", "Figure", "10", "show", "estimate", "initial", "kernel", "refine", "kernel", "iterative", "optimization", "iteration", "number", "typically", "we", "experiment", "refined", "kernel", "have", "sharper", "sparser", "shape", "than", "initial", "one", "large", "kernel", "Figure", "11", "show", "example", "large", "blur", "compact", "camera", "kernel", "size", "87", "87", "original", "resolution", "1200", "1600", "image", "show", "here", "crop", "975", "1146", "compare", "state-of-art", "single", "image", "kernel", "estimation", "approach", "-lsb-", "Fergus", "et", "al.", "2006", "-rsb-", "which", "largest", "kernel", "30", "pixel", "we", "approach", "use", "image", "pair", "significantly", "extend", "degree", "blur", "can", "handle", "small", "noise", "kernel", "moderately", "dim", "lighting", "environment", "we", "may", "capture", "input", "image", "small", "noise", "blur", "show", "Figure", "12", "typical", "case", "assume", "Jia?s", "approach", "-lsb-", "2004", "-rsb-", "which", "color", "transfer", "base", "algorithm", "third", "fourth", "column", "Figure", "12", "color", "transfer", "result", "-lsb-", "Jia", "et", "al.", "2004", "-rsb-", "histogram", "equalization", "result", "from", "blur", "image", "denoise", "image", "note", "color", "can", "accurately", "transfer", "-lrb-", "e.g.", "Buddha?s", "golden", "hat", "-rrb-", "because", "both", "approach", "use", "global", "mapping", "we", "result", "only", "recover", "more", "detail", "-lrb-", "e.g.", "horizontal", "line", "background", "-rrb-", "also", "have", "similar", "color", "blur", "image", "all", "detail", "Table", "show", "shutter", "speed", "iso", "setting", "example", "Figure", "-12", "we", "able", "reduce", "exposure", "time", "-lrb-", "shutter", "speed", "iso", "-rrb-", "about", "10", "stop", "we", "have", "propose", "image", "deblurr", "approach", "use", "pair", "blurred/noisy", "image", "we", "approach", "take", "advantage", "both", "image", "produce", "high", "quality", "reconstruct", "image", "formulate", "image", "deblurr", "problem", "use", "two", "image", "we", "have", "develop", "iterative", "deconvolution", "algorithm", "which", "can", "estimate", "very", "good", "initial", "kernel", "significantly", "reduce", "deconvolution", "artifact", "special", "hardware", "require", "we", "propose", "approach", "use", "off-the-shelf", "hand-held", "camera", "Limitations", "remain", "we", "approach", "however", "we", "approach", "share", "common", "limitation", "most", "image", "deblurr", "technique", "assume", "single", "spatial-invariant", "blur", "kernel", "spatial-variant", "kernel", "possible", "locally", "estimate", "kernel", "different", "part", "image", "blend", "deconvolution", "result", "most", "significantly", "we", "approach", "require", "two", "image", "we", "envision", "ability", "capture", "pair", "eventually", "move", "camera", "firmware", "thereby", "make", "two-shot", "capture", "easier", "faster", "we", "technique", "can", "also", "apply", "hybrid", "image", "system", "-lsb-", "Ben-Ezra", "Nayar", "2003", "-rsb-", "combine", "code", "exposure", "photography", "-lsb-", "raskar", "et", "al.", "2006", "-rsb-", "we", "thank", "anonymous", "reviewer", "help", "we", "improve", "paper", "Stephen", "Lin", "he", "help", "video", "production", "proofread", "work", "perform", "when", "Lu", "Yuan", "visit", "Microsoft", "Research", "Asia", "Lu", "Yuan", "Long", "Quan", "be", "support", "part", "Hong", "Kong", "RGC", "porject", "619005", "619006", "-lrb-", "-rrb-", "blur", "image", "-lrb-", "-rrb-", "noisy", "image", "-lrb-", "-rrb-", "denoise", "image", "-lrb-", "-rrb-", "rl", "deconvolution", "-lrb-", "-rrb-", "we", "result" ],
  "content" : "We demonstrate the effectiveness of our approach using a number of indoor and outdoor images taken by off-the-shelf hand-held cameras in poor lighting environments. In kernel estimation, we show that a very accurate initial kernel can be recovered from the blurred image by exploiting the large scale, sharp image structures in the noisy image. We also propose a gain-controlled deconvolution to further suppress the ringing artifacts in smooth image regions. We have found that the motion between two blurred/noisy images, when taken in a quick succession, is mainly a translation. In our approach, we significantly reduce the artifacts in a non-blind deconvolution by taking advantage of the noisy image. In [Levin 2006], the image is segmented into several layers with different kernels. Both techniques physically move an element of the lens, or the sensor, to counterbalance the camera shake. Typically, the captured image can be as sharp as if it were taken with a shutter speed 2-3 stops faster. In [Liu and Gamal 2001], a CMOS sensor can capture multiple high-speed frames within a normal exposure time. The pixel with motion replaced with the pixel in one of the high-speed frames. Denoising can be performed by a joint/cross bilateral filter using flash/no-flash images [Petschnigg et al. 2004; Eisemann and Durand 2004], or by a spatio-temporal filter for video sequences [Bennett and McMillan 2005]. Our approach estimates the kernel only from two images, without the need for special hardware. Another related work [Jia et al. 2004] also uses a pair of images, where the colors of the blurred image are transferred into the noisy image without kernel estimation. In this paper, we demonstrate that our proposed techniques can obtain much accurate kernel compared with Lim and Silverstein?s approach, and produce almost artifact-free image by a proposed de-ringing approach in deconvolution. We take a pair of images: a blurred image B with a slow shutter speed and low ISO, and a noisy image N with high shutter speed and high ISO. The noisy image is usually underexposed and has a very low SNR since camera noise is dependent on the image intensity level [Liu et al. 2006]. Moreover, the noise in the high ISO image is also larger than that in the low ISO image since the noise is amplified by camera gain. But the noisy image is sharp because we use a fast shutter speed that is above the safe shutter speed. We pre-multiply the noisy image by a ratio ISO ISO N B ?t ?t B N to compensate for the exposure difference between the blurred and noisy images, where ?t is the exposure time. Otherwise, a gamma For the noisy image N, we compute a denoised image N D [Portilla et al. 2003] (See Section 7 for details). We represent the lost detail layer as a residual image ?I: Our first important observation is that the denoised image N D is a very good initial approximation to I for the purpose of kernel estimation from Equation (1). The power spectrum of the image I mainly lies in the denoised image N D . Moreover, the large scale, sharp image structures in N D make important contributions for the kernel estimation. As will be shown in our experiments on synthetic and real images, accurate kernels can be obtained using B and N D in nonblind convolution. Our second observation is that the ringing artifacts from residual deconvolution of ?I (Equation (3)) are smaller than those from deconvolution of I (Equation (1)) because ?B has a much smaller magnitude than B after being offset by N D ? K. The denoised image N D also provides a crucial gain signal to control the deconvolution process so that we can suppress ringing artifacts, especially in smooth image regions. We propose a de-ringing approach using a gain-controlled deconvolution algorithm to further reduce ringing artifacts. The above three steps kernel estimation (Section 4), residual deconvolution (Section 5), and de-ringing (Section 6) are iterated to refine the estimated blur kernel K and the deconvoluted image I. In this section, we show that a simple constrained least-squares optimization is able to produce a very good initial kernel. Iterative kernel estimation. The goal of kernel estimation is to find the blur kernel K from B = I ? K with the initialization I = N D . Regularization. To stabilize the solution, we use Tikhonov regularization method with a positive scalar ? by solving min k ||Ak ? true image (also shown in Figure 4(e) ). (d) Matlab?s deconvblind routine results. (e) Fergus?s result at finest 4 levels. (f) Lim and Silverstein?s result. (g) estimated kernels without hysteresis thresholding. (h) our result at the finest 4 levels. (i) true kernels. The default value of ? is set at 5. We adopt the Landweber method [Engl et al. 2000] to iteratively update as follows. Set k i n+1 = 0 if k i n+1 < 0, and normalize k i n+1 = k i n+1 / ? i k i n+1 . The iteration stops when the change between two steps is sufficiently small. We typically run about 20 to 30 iterations by setting ? = 1.0. The algorithm is fast using FFT, taking about 8 to 12 seconds for a 64 ? 64 kernel and a 800 ? 600 image. zoomed-in in (b). The middle image in (c) is the estimated kernel using only image patches in (b). The bottom image in (c) is the estimated kernel using the whole image. The above iterative algorithm can be implemented in scale space to make the solution to overcome the local minimal. We compute two masks M low and M high by setting two thresholds t low and t high . M low is larger and contains M high . After kernel estimation, we set all elements of K l outside the mask M high to zero to reduce the noise at level l. Then, at the next finer level l + 1, we set all elements of K l+1 outside the up-sampled mask of M low to zero to further reduce noise. This hysteresis thresholding is performed from coarse to fine. ? The pyramids are constructed using a downsampling factor of 1/ 2 until the kernel size at the coarsest level reaches 9 ? 9. We typically choose t low = 0.03, and t high = 0.05. Results and discussion. We first compare our estimated kernel with the true kernel using a synthetic example. Figures 2(a-c) show two blurred images, a noisy image, and a denoised image. The blurred images are synthesized with two 41 ? 41 known kernels. Figure 2(d) shows kernels estimated by Matlab?s deconvblind routine (a blind deconvolution) using the denoised image N D as initialization. Figure 2(e) shows coarse-to-fine kernels (the finest 4 levels) estimated by Fergus?s algorithm only using the blurred image [Fergus et al. 2006]. The Matlab code is released by Fergus ( http://people.csail.mit.edu/fergus/). We exhaustively tune all options in Fergus?s algorithm and select different regions in the image to produce the best results. Fergus?s algorithm recovers much better kernels than those using Matlab?s blind deconvolution. Figure 2(f) is result from [Lim and Silverstein 2006]. The fine details and thin structures of the kernels are recovered. Figure 2(g) also shows our kernel estimation without hysteresis thresholding, which is very noisy. Figure 3 shows our result on real images. 20 iterations. Note that standard RL results contain unpleasant ?ringing? artifacts dark and light ripples around strong image features. of the kernel. One such trajectories is shown in Figure 3(c) . We also compare two kernels using selected image patches and the whole image. Kernel estimation is insensitive to the selected regions. The kernel size is very large, with 92 ? 92 pixels. Given the blur kernel K, the true image can be reconstructed from B = K ? I. Figure 4(a) shows the deconvolution results using a standard Richardson-Lucy (RL) algorithm after 20 iterations with the true kernels. The resulting images contain visible ?ringing? artifacts, with dark and light ripples around bright features in the image. More iterations introduce not only more image details but also more ringing. Fergus et al. [2006] also observed this issue from their results. noised signal. The blur kernel is a box filter. (c) is the standard deconvolution result from (a). (d-e) are the blurred residual signal and its deconvolution result. (f) is the residual deconvolution result. Notice that ringing artifact in (f) is smaller than that in (c). The ringing effects are due to the well-known Gibbs phenomena in Fourier analysis at discontinuous points. The discontinuities could be at image edge points, boundaries or are artificially introduced by the inadequate spatial sampling of the images or the kernels. The larger the blur kernel, the stronger the ringing artifacts are. The key to our approach is that we perform the deconvolution on relative image quantities to reduce the absolute amplitude of the signals. Instead of doing the deconvolution directly on the image B, we perform deconvolution on the residual blurred image ?B = ?I ? K to recover the residual image ?I. The final reconstructed image is I = N D + ?I. It enforces the non-negativity of pixel values. After each iteration, the residual image is offset back by subtracting the constant 1: where ??? is the correlation operator. Figure 4(b) shows the deconvolution results using the residual RL algorithm with the same number of iterations. Compared with the standard RL results (Figure 4(a)), the ringing effects are reduced. Figure 5 shows a 1D example of the residual deconvolution. The ringing artifacts from ?I are significantly weaker than those in I because the magnitude of ?B (after subtracting N D ? K from B) is much smaller than that of B. The residual deconvolution lessened the ringing effects, but cannot fully eliminate them, as shown in Figure 4(b) . Another example is shown in Figure 7(b) . We observe that the ringing effects are most distracting in smooth regions because human perception can tolerate small scale ringing in highly textured regions. We have also found that the mid-scale ringing effects are more noticeable compared with the fine details and large scale sharp structures in the image. Note that the strong ringing is mainly caused by high contrast edges and the magnitude of ringings is proportional to the\n        0 8 0 6 0 4 0 2 0 (a) B (b) N D (c) I gain (d) iter. 1 (e) iter. 10 (f) iter. The kernel is estimated using B and N D . (d-f) deconvolution results by standard RL (green), residual RL(blue), and gain-controlled RL (red), after iteration 1, 10, and 20. The plot at the bottom-right are blownup views. Notice that the ringing effects are amplified and propagated in standard RL and residual RL, but suppressed in gain-controlled RL. magnitude of image gradient. Gain-controlled Richardson-Lucy (RL). We modify the residual RL algorithm by introducing a gain map I Gain : where I Gain is a multiplier (? 1) to suppress the contrast of the recovered residual image ?I. Since RL is a ratio-based algorithm, the ringing effects are amplified at each iteration by the ratio K ? (?I ?B+1 n +1)?K in (6). Multiplying a factor less than one at each iteration will suppress the propagation of the ringing effects. Notice that multiplying a factor will not decrease the overall magnitude of the signal but decrease the contrast of the signal because the ratio K ? (?I ?B+1 n +1)?K will increase the magnitude of the signal in each iteration. At the last iteration, we do not multiply the gain map I Gain . Since we want to suppress the contrast of ringing in the smooth regions while avoiding suppression of sharp edges, the gain map should be small in smooth regions and large in others. Hence, we define the gain map using the gradient of the denoised image as: The parameter ? controls the degree of suppression. Aggregated image gradients at multiple scales have also been used in HDR compression [Fattal et al. 2002; Li et al. 2005]. Here, the gradients of denoised image provide a gain signal to adaptively suppress the ringing effects in different regions. Figure 6 shows a 1D example of gain-controlled RL. As we can see, the residual RL can reduce the magnitude of ringing compared with the standard RL. In both standard RL and residual RL, the magnitude of ringing increases and the spatial range of ringing spreads gradually, after each iteration. With the control from the gain map, the ringing effects are suppressed at each iteration (a) blurred/noisy image (b) I, by residual RL (c) , by gain-controlled RL (d) detail layer I (e) final image (f) ringing layer ringing artifacts and produces de-ringing image I g in (c). The detail layer I d in (d) is extracted from the residual RL result in (b) with the guidance of the I g using a joint/cross bilateral filter. Our final image in (e) is obtained by adding (c) and (d) together. (e.g., I Gain = 0.8 in flat region). Most importantly, the propagation of ringing is greatly prevented so that the ringing is significantly reduced. Figure 7(c) shows a gain-controlled RL result I g . It is a clean deconvolution result with large scale sharp edges, compared with the residual RL result I in Figure 7(c) . However, some fine details are inevitably suppressed by gain-controlled RL. Fortunately, we are able to add fine scale image details for the residual RL result I using the following approach. Adding details. We extract the fine scale detail layer I d = I ? I from the residual RL result I, where I(x) = F(I(x)) is a filtered image and F(?) is a low-pass filter. In other words, the details layer is obtained by a high-pass filtering. We use joint/cross bilateral filtering [Petschnigg et al. 2004; Eisemann and Durand 2004] as it preserves large scale edges in I g :\n        F(I(x); I g ) = Z 1 x x ?W ? (x) G d (x ? x )G r (I(x) ? I g (x )) ? I x ,\n        where ? d and ? r are spatial and signal deviations of Gaussian kernels G d and G r . W (x) is a neighboring window and Z x is a normalization term. The default values of ? d and ? r are 1.6 and 0.08. Figure 7(d) shows the extracted detail layer. in two shots as corresponding point pairs. Top right: in-plane rotation correction using two manually specified lines. Bottom: The experiment was repeated by four users (A,B,C,D). In each cell (a 4x4 grid), one color dot represents a difference vector between one of corresponding point pairs in two shots. The grid unit is 0.5 pixel and cell center is the coordinate origin. Composing the gain-controlled RL result I g and the detail layer I d produces our final image, as shown in Figure 7(e) . The ringing layer ( Figure 7(f) ) can also be obtained by subtracting I g from the filtered image I. As we expected, the ringing layer mainly contains the ripple-like ringing effects. In the final result, the ringing artifacts are significantly reduced while the recovered image details from deconvolution are well preserved. Figures 4 (c-d) show another example of results after de-ringing and the computed gain map. To summarize, our iterative image deblurring algorithm consists of the following steps: estimate the kernel K, compute the residual deconvolution image I, compute the gain-controlled deconvolution image I g , and construct the final image by adding the detail layer I d . The iterations stop when the change is sufficiently small. Image acquisition In practice, we require one image be taken soon after another, to minimize misalignment between two images. We have two options to capture such image pairs very quickly. First, two successive shots with different camera settings are triggered by a laptop computer connected to the camera. This frees the user from changing camera settings between two shots. Second, we use exposure bracketing built in many DSLR cameras. In this mode, two successive shots can be taken with different shutter speeds by pressing the shutter only once. Using these two options, the time interval between two shots can be very small, typically only 1/5 second which is a small fraction of typical shutter speed (> 1 second) of the blurred image. The motion between two such shots is mainly a small translation if we assume that the blurred image can be modeled by a single blur kernel, i.e., the dominant motion is translation. Because the translation only results in an offset of the kernel, it is unnecessary to align two images. We can also manually change the camera settings between two shots. In this case, we have found that the dominant motions between two shots are translation and in-plane rotation. To correct in-plane rotation, we simply draw two corresponding lines in the blurred/noisy images. In the blurred image, the line can be specified along a straight object boundary or by connecting two corner features. The noisy image is rotated around its image center such  that two lines are virtually parallel. If an advanced exposure bracketing allowing more controls is built to future cameras, this manual alignment will become unnecessary. To quantitatively measure relative motion between two shots, we have performed a usability study. We asked four users to continuously take two shots of a pattern on the wall (as shown in the top right of Figure 8 ), using laptop control and manual control, with a compact camera and a DSLR camera. Two shots have no blur and are taken with the same camera settings. Then, four corresponding points nearby the image corners in two shots are extracted. We correct the transformation (only translation for laptop control, but in-plane rotation after translation for manual control) between two shots. The bottom row of Figure 8 shows registration errors after the correction. In each cell, a dot represents a difference vector between a pair of corresponding points. The overall pixel error is less than 2 pixels at the full image resolution. Not surprisingly, the best aligned image is obtained using laptop control and a DSLR camera. Image denoising For the noisy image N, we apply a wavelet-based denoising algorithm [Portilla et al. 2003] with Matlab code from http://decsai.ugr.es/ ?javier/denoise/. We have also experimented with bilateral filtering but found that it is hard to achieve a good balance between removing noise and preserving details, even with careful parameter tuning. We apply our approach to a variety of blurred/noisy image pairs in low lighting environments using a compact camera (Canon S60, 5M pixels) and a DSLR camera (Canon 20D, 8M pixels). Comparison. We compare our approach with denoising [Portilla et al. 2003], and a standard RL algorithm. Figure 9 , from left to right, shows a blurred image, noisy image (enhanced), denoised image, standard RL result (using our estimated kernel), and our result. The kernel sizes are 31 ? 31, 33 ? 33, and 40 ? 40 for the three examples. We manually tune the noise parameter (standard deviation) in the denoising algorithm to achieve a best visual balance between noise removal and detail preservation. Compared with denoised results shown in Figure 9(c) , our results in Figure 9(e) contain much more fine details, such as tiny textures on the fabric in the first example, thin grid structures on the crown in the second example, and clear text on the camera in the last example. Because the noise image is scaled up from a very dark, low contrast image, partial color information is also lost. Our approach recovers correct colors through image deblurring. Figure 9(d) shows standard RL deconvoution results which exhibit unpleasant ringing artifacts. Large noise. Figure 10 shows a blurred/noisy pair containing thin hairs and a sweater with detailed structures. The images are captured by the compact camera and the noisy image has very strong noises. Most fabric textures on the sweater are faithfully recovered in our result. The last column in the second row of Figure 10 shows the estimated initial kernel and the refined kernel by the iterative optimization. The iteration number is typically 2 or 3 in our experiments. The refined kernel has a sharper and sparser shape than the initial one. Large kernel. Figure 11 shows an example with a large blur by the compact camera. The kernel size is 87 ? 87 at the original resolution 1200 ? 1600. The image shown here is cropped to 975 ? 1146. Compared with the state-of-art single image kernel estimation approach [Fergus et al. 2006] in which the largest kernel is 30 pixels, our approach using an image pair significantly extends the degree of blur that can be handled. Small noise and kernel. In a moderately dim lighting environment, we may capture input images with small noise and blur, as shown in Figure 12 . This is a typical case assumed in Jia?s approach [2004] which is a color transfer based algorithm. The third and fourth columns in Figure 12 are color transferred result [Jia et al. 2004] and histogram equalization result from the blurred image to the denoised image. Note that the colors cannot be accurately transferred (e.g., Buddha?s golden hat) because both approaches use global mappings. Our result not only recovers more details (e.g., horizontal lines on background) but also has similar colors to the blurred image for all details. Table 1 shows the shutter speeds and ISO settings of examples in Figure 9 -12. We are able to reduce exposure time (shutter speed ? ISO) by about 10 stops. We have proposed an image deblurring approach using a pair of blurred/noisy images. Our approach takes advantage of both images to produce a high quality reconstructed image. By formulating the image deblurring problem using two images, we have developed an iterative deconvolution algorithm which can estimate a very good initial kernel and significantly reduce deconvolution artifacts. No special hardware is required. Our proposed approach uses off-the-shelf, hand-held cameras. Limitations remain in our approach, however. Our approach shares the common limitation of most image deblurring techniques: assuming a single, spatial-invariant blur kernel. For spatial-variant kernel, it is possible to locally estimate kernels for different parts of the image and blend deconvolution results. Most significantly, our approach requires two images. We envision that the ability to capture such pairs will eventually move into the camera firmware, thereby making two-shots capture easier and faster. Our techniques can also be applied in a hybrid image system [Ben-Ezra and Nayar 2003] or combined with coded exposure photography [Raskar et al. 2006]. We thank the anonymous reviewers for helping us to improve this paper, Stephen Lin for his help in video production and proofreading. This work is performed when Lu Yuan visited Microsoft Research Asia. Lu Yuan and Long Quan were supported in part by Hong Kong RGC porjects 619005 and 619006. (a) blurred image (b) noisy image (c) denoised image (d) RL deconvolution (e) our result",
  "resources" : [ ]
}