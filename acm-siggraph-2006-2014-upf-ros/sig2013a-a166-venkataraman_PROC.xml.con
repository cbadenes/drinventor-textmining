{
  "uri" : "sig2013a-a166-venkataraman_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2013a/a166-venkataraman_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "PiCam: An Ultra-Thin High Performance Monolithic Camera Array",
    "published" : "2013",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Kartik-Venkataraman",
      "name" : "Kartik",
      "surname" : "Venkataraman"
    }, {
      "uri" : "http://drinventor/Dan-Lelescu",
      "name" : "Dan",
      "surname" : "Lelescu"
    }, {
      "uri" : "http://drinventor/Jacques-Duparr?",
      "name" : "Jacques",
      "surname" : "Duparr?"
    }, {
      "uri" : "http://drinventor/Andrew-McMahon",
      "name" : "Andrew",
      "surname" : "McMahon"
    }, {
      "uri" : "http://drinventor/Gabriel-Molina",
      "name" : "Gabriel",
      "surname" : "Molina"
    }, {
      "uri" : "http://drinventor/Priyam-Chatterjee",
      "name" : "Priyam",
      "surname" : "Chatterjee"
    }, {
      "uri" : "http://drinventor/Robert-Mullis",
      "name" : "Robert",
      "surname" : "Mullis"
    }, {
      "uri" : "http://drinventor/Shree-Nayar",
      "name" : "Shree",
      "surname" : "Nayar"
    } ]
  },
  "bagOfWords" : [ "we", "develop", "camera", "array", "4x4", "sensor", "array", "where", "each", "sensor", "support", "1000", "750", "pixel", "4:3", "aspect", "ratio", "synthesize", "high", "resolution", "image", "output", "we", "processing", "megapixel", "image", "lens", "array", "consist", "type", "lens", "red", "green", "bluewhere", "each", "have", "f-number", "3.1", "diagonal", "field", "view", "56", "focal", "length", "2mm", "overall", "camera", "module", "height", "less", "than", "3.5", "mm", "compare", "height", "anywhere", "between", "5.2", "mm", "6.0", "mm", "legacy", "camera", "module", "key", "challenge", "create", "robust", "imaging", "system", "estimation", "accurate", "depth", "parallax", "stage", "result", "resolution", "depth", "map", "least", "count", "-lrb-", "highest", "degree", "accuracy", "measurement", "-rrb-", "disparity", "between", "two", "camera", "function", "system", "noise", "blur", "practice", "we", "have", "find", "lr", "pixel", "put", "limit", "depth", "map", "accuracy", "how", "depth", "resolution", "change", "distance", "since", "disparity", "function", "depth", "we", "let", "u?v", "-lrb-", "-rrb-", "represent", "disparity", "between", "two", "camera", "distance", "u?v", "-lrb-", "-rrb-", "represent", "disparity", "distance", "-lrb-", "where", "-rrb-", "u?v", "-lrb-", "-rrb-", "u?v", "-lrb-", "-rrb-", "constraint", "can", "use", "determine", "how", "estimate", "value", "depth", "change", "increase", "object", "distance", "Figure", "11", "show", "variation", "accuracy", "depth", "estimate", "object", "distance", "obviously", "key", "aspect", "how", "successful", "approach", "be", "reasonable", "alternative", "conventional", "camera", "design", "lie", "how", "effective", "superresolution", "recover", "resolution", "encode", "aliased", "signal", "LR", "image", "array", "under", "all", "lighting", "scene", "condition", "Figure", "show", "we", "system", "behavior", "capture", "high", "frequency", "image", "ability", "camera", "array", "capture", "high", "frequency", "signal", "fundamentally", "define", "lens", "f-number", "-lrb-", "mtf", "-rrb-", "optical", "format", "lens", "pixel", "size", "-lrb-", "pixel", "mtf", "-rrb-", "superresolution", "factor", "Figure", "12", "show", "how", "resolution", "final", "super-resolved", "image", "change", "vary", "value", "parameter", "extrapolate", "from", "current", "reference", "design", "-lrb-", "highlight", "red", "-rrb-", "use", "f3", ".1", "lens", "1000", "750", "1.75", "front-side", "illuminate", "-lrb-", "FSI", "-rrb-", "pixel", "per", "camera", "use", "information", "present", "Figure", "table", "can", "use", "determine", "how", "much", "resolution", "be", "trade", "off", "array", "camera", "comparison", "legacy", "camera", "gain", "depth", "information", "we", "consider", "sensor", "size", "-lrb-", "3264", "2448", "-rrb-", "pixel", "size", "-lrb-", "1.4", "-rrb-", "f-number", "-lrb-", "f2", ".4", "-rrb-", "iphone5", "corresponding", "array", "camera", "similar", "specification", "would", "array", "each", "sub-array", "have", "800", "600", "1.4", "pixel", "f2", ".4", "lens", "achievable", "resolution", "-lrb-", "mtf20", "-rrb-", "comparable", "system", "would", "950", "lw/ph", "-lrb-", "highlight", "blue", "-rrb-", "comparison", "achievable", "resolution", "-lrb-", "mtf20", "-rrb-", "iphone5", "2000lw/ph", "-lrb-", "figure", "-rrb-", "tell", "we", "we", "trade", "resolution", "factor", "depth", "information", "Figure", "13", "we", "also", "illustrate", "effect", "use", "some", "new", "development", "discuss", "section", "4.2", "-lrb-", "namely", "likelihood", "gradient", "formation", "filter", "uncertainty", "processing", "-rrb-", "quality", "restoration", "akin", "perform", "more", "classical", "likelihood", "computation", "basically", "translate", "form", "single", "likelihood", "-lrb-", "filter", "-rrb-", "fusion-populated", "hr", "grid", "position", "where", "we", "use", "median", "filter", "any", "pixel", "stack", "form", "interpolate", "any", "hole", "hr", "grid", "degrade", "image", "quality", "may", "even", "interfere", "correct", "reconstruction", "frequency", "error", "operation", "precede", "map", "processing", "play", "larger", "role", "Figure", "15", "show", "comparison", "noise", "performance", "camera", "array", "against", "iphone5", "100lux", "illumination", "we", "offset", "exposure", "time", "camera", "array", "compensate", "faster", "lens", "iphone5", "figure", "show", "zoom", "out", "region", "relative", "noise", "difference", "between", "two", "camera", "both", "visually", "use", "snr", "metric", "-lrb-", "both", "measure", "ysnr", "about", "39db", "-rrb-", "we", "see", "we", "camera", "array", "perform", "close", "noise", "performance", "iphone5", "must", "point", "out", "however", "smaller", "exposure", "time", "also", "lead", "more", "motion", "blur", "final", "analysis", "adequate", "solution", "one", "can", "only", "address", "corresponding", "faster", "lens", "PiCam", "we", "have", "also", "compare", "we", "camera", "against", "iphone5", "both", "indoors", "outdoors", "all", "scene", "be", "capture", "same", "time", "picam", "iphone5", "under", "same", "illumination", "condition", "Figure", "14", "top", "two", "row", "show", "couple", "example", "indoor", "outdoor", "shot", "last", "row", "show", "example", "post", "capture", "refocus", "application", "virtue", "have", "relatively", "small", "optical", "format", "-lrb-", "-rrb-", "shorter", "focal", "length", "compare", "legacy", "8mp", "camera", "mobile", "device", "hyperfocal", "distance", "we", "imaging", "system", "40cm", "thus", "addition", "all", "object", "from", "20cm", "be", "capture", "focus", "computed", "depth", "map", "allow", "one", "achieve", "degree", "post-capture", "refocus", "provide", "creative", "flexibility", "photographer", "iphone5", "have", "larger", "aperture", "correspondingly", "large", "hyperfocal", "distance", "-lrb-", "100cm", "-rrb-", "top", "row", "image", "iphone5", "focus", "near", "object", "-lrb-", "50cm", "-rrb-", "have", "correspondingly", "short", "depth", "field", "so", "background", "picture", "have", "defocus", "blur", "contrast", "PiCam", "have", "everything", "focus", "background", "appear", "sharper", "than", "do", "iphone5", "second", "point", "consider", "degree", "refocus", "ability", "clearly", "dependent", "resolution", "depth", "map", "thus", "object", "give", "distance", "from", "camera", "may", "refocus", "against", "its", "background", "long", "background", "object", "distance", "larger", "than", "depth", "resolution", "distance", "-lrb-", "see", "Figure", "11", "-rrb-", "last", "row", "Figure", "14", "show", "example", "image", "be", "refocus", "first", "foreground", "focus", "background", "focus", "we", "synthesize", "high", "resolution", "image", "show", "trace", "chromatic", "fringing", "could", "improve", "better", "color", "tuning", "tone", "mapping", "area", "future", "work", "finally", "picam", "3d", "capable", "capture", "device", "give", "its", "ability", "compute", "depth", "textured", "surface", "should", "enable", "handheld", "digitization", "device", "capable", "create", "point", "cloud", "lend", "themselves", "subsequent", "meshing", "we", "capture", "object", "-lrb-", "chinese", "dragon", "-rrb-", "show", "Figure", "16", "-lrb-", "-rrb-", "tabletop", "distance", "50cm", "convert", "depth", "map", "from", "object", "point", "cloud", "filter", "depth", "map", "reveal", "just", "high", "confidence", "depth", "value", "total", "87000", "point", "be", "render", "texture", "result", "figure", "show", "Figure", "16", "-lrb-", "-rrb-", "addition", "above", "application", "picam", "architecture", "also", "enable", "view", "synthesis", "from", "any", "position", "array", "also", "front", "behind", "array", "synthesis", "procedure", "consist", "three", "step", "calculate", "displacement", "each", "image", "array", "virtual", "viewpoint", "compute", "depth", "map", "virtual", "viewpoint", "form", "color", "image", "viewpoint", "method", "enable", "one", "showcase", "motion", "parallax", "generate", "stereo", "leave", "right", "view", "be", "able", "generate", "different", "viewpoint", "when", "combine", "real-time", "gyroscope", "reading", "mobile", "device", "provide", "viewer", "sense", "scene", "depth", "rich", "interactive", "experience", "we", "show", "example", "accompany", "video", "we", "approach", "computational", "array", "camera", "have", "show", "robustness", "generate", "high", "resolution", "color", "image", "under", "vary", "imaging", "condition", "addition", "picam", "provide", "significant", "difference", "over", "legacy", "camera", "relax", "z-height", "constraint", "considerably", "resolution", "we", "system", "function", "optical", "format", "f-number", "lens", "pixel", "size", "number", "camera", "array", "depend", "application", "appropriate", "choice", "imaging", "system", "processing", "parameter", "allow", "one", "scale", "resolution", "system", "without", "hit", "z-height", "constraint", "additionally", "potential", "assemble", "system", "multiple", "distribute", "array", "allow", "greater", "range", "imaging", "view", "synthesis", "which", "could", "benefit", "application", "security", "automotive", "we", "system", "also", "fault", "tolerant", "extent", "since", "failure", "camera", "array", "lead", "graceful", "degradation", "system", "performance", "same", "time", "area", "improvement", "both", "term", "image", "quality", "processing", "speed", "artifact", "from", "incorrect", "depth", "estimate", "along", "contour", "object", "close", "camera", "still", "possible", "depend", "scene", "content", "background", "texture", "correction", "artifact", "while", "focus", "paper", "remain", "important", "area", "continue", "research", "algorithm", "computationally", "intensive", "while", "efficiency", "be", "exploit", "allow", "pipeline", "scale", "mobile", "device", "remain", "active", "area", "work", "due", "constrain", "nature", "power", "compute", "availability", "form", "factor", "nevertheless", "we", "believe", "continued", "work", "both", "area", "architecture", "have", "potential", "remove", "some", "limitation", "camera", "design", "small", "form", "factor", "device", "enable", "new", "imaging", "application" ],
  "content" : "We developed the camera array as a 4x4 sensor array where each sensor supports 1000 ? 750 pixels in a 4:3 aspect ratio. The synthesized high resolution image output by our processing is an 8 megapixel image. The lens array consists of 3 types of lenses red, green, and bluewhere each has F-number 3.1, a diagonal field of view of 56 ? and a focal length of 2mm. The overall camera module height is less than 3.5mm as compared to a height of anywhere between 5.2mm and 6.0mm for a legacy camera module. A key  challenge in creating a robust imaging system is the estimation of accurate depth by the parallax stage and the resulting resolution of the depth map. The least count (this is the highest degree of accuracy of measurement) of the disparity between two cameras is a function of the system noise and blur and, in practice, we have found this to be 1 of an LR pixel. This puts a limit on the depth 3 map accuracy and how the depth resolution changes with distance. Since disparity is a function of depth, if we let d u?v (z 1 ) represent the disparity between two cameras, u and v, at a distance z 1 and d u?v (z 2 ) represent the disparity at distance z 2 (where z 2 > z 1 ), then d u?v (z 1 ) ? d u?v (z 2 ) ? 1 3 . This constraint can be used to determine how the estimated value of depth changes with increase in object distance. Figure 11 shows this variation of the accuracy of the depth estimate with object distance. Obviously a key aspect of how successful this approach is in being a reasonable alternative to conventional camera design lies in how effective the superresolution is at recovering the resolution encoded in the aliased signals of the LR images in the array, under all lighting and scene conditions. Figure 7 shows our system behavior in capturing high frequency images. The ability of the camera array to capture high frequency signal is fundamentally defined by the lens F-number (MTF), optical format of lens, pixel size (pixel MTF), and the superresolution factor. Figure 12 shows how the resolution of the final super-resolved image changes with varying values of these parameters by extrapolating from the current reference design (highlighted in red) using a F3.1 lens, and 1000 ? 750, 1.75? front-side illuminated (FSI) pixels per camera and using the information presented in Figure 6 . The table can be used to determine how much resolution is being traded off by the array camera in comparison with the legacy camera in gaining depth information. If we consider the sensor size (3264 ? 2448), pixel size (1.4?m), and F-number (F2.4) of the iPhone5, a corresponding array camera of similar specification would be a 4 ? 4 array with each sub-array having 800 ? 600, 1.4?m pixels and an F2.4 lens. The achievable resolution (MTF20) of such a comparable system would be 950 lw/ph (highlighted in blue). In comparison, the achievable resolution (MTF20) of the iPhone5 is 2000lw/ph ( Figure 6 ) that tells us we are trading resolution by a factor of 2 for depth information. In Figure 13 , we also illustrate the effects of not using some of the new developments discussed in Section 4.2 (namely the likelihood gradient formation and filtering, and the uncertainty processing), on the quality of restoration. This is akin to performing a more classical likelihood computation, and it basically translates into forming single likelihoods (no filtering) at fusion-populated HR grid positions, where we used a median filtering of any pixel stacks formed, and interpolating any holes on the HR grid. This degrades image quality, and may even interfere with the correct reconstruction of frequencies, as errors in the operations preceding the MAP processing start playing a larger role. Figure 15 shows a comparison of the noise performance of the camera array against that of the iPhone5 at 100Lux illumination. We offset the exposure time on the camera array to compensate for the faster lens on the iPhone5. The figure shows, in 3 zoomed out regions, the relative noise difference between the two cameras. Both visually and using the SNR metric (both measured YSNR of about 39dB) we see that our camera array performs at close to the noise performance of the iPhone5. It must be pointed out, however, that a smaller exposure time also leads to more motion blur and in the final analysis is not an adequate solution and one that can only be addressed by a corresponding faster lens for the PiCam. We have also compared our camera against iPhone5 both indoors and outdoors. All of these scenes were captured at the same time by the PiCam and by the iPhone5 under the same illumination conditions. Figure 14 , in the top two rows, shows a couple of examples of an indoor and outdoor shot, and the last row shows an example of a post capture refocus application. By virtue of having a relatively small optical format ( 1 ) and a shorter focal length compared 7 to a legacy 8MP camera in a mobile device, the hyperfocal distance of our imaging system is at 40cm. Thus, in addition to all objects from 20cm to ? being captured in focus, the computed depth map allows one to achieve a degree of post-capture refocus that provides creative flexibility to the photographer. The iPhone5 has a larger aperture and a correspondingly large hyperfocal distance (?100cm). In the top row image, the iPhone5 is focused on a near object (<50cm) and has a correspondingly short depth of field so that the background picture has defocus blur. By contrast, the PiCam has everything in focus and the background appears sharper than it does on the iPhone5. A second point to consider is that the degree of refocus ability is clearly dependent on the resolution of the depth map. Thus, an object at a given distance from the camera may be refocused against its background as long as the background object is at a distance larger than the depth resolution for that distance (see Figure 11 ). The last row of Figure 14 shows an example of an image being refocused, first with the foreground in focus and then with the background in focus. Our synthesized high resolution images show traces of chromatic fringing that could be improved with better color tuning and tone mapping and is an area for future work. Finally, PiCam is a 3D capable capture device given its ability to compute depth of textured surfaces. This should enable a handheld digitization device capable of creating point clouds that lend themselves to subsequent meshing. We captured an object (a Chinese dragon), shown in Figure 16(a) , on a tabletop at a distance of 50cm and converted the depth map from the object to a point cloud by filtering the depth map to reveal just the high confidence depth values. A total of 87000 points were rendered with texture and the resulting figure is shown in Figure 16(b) . In addition to the above applications, the PiCam architecture also enables view synthesis from any position on the array and also in front or behind the array. The synthesis procedure consists of three steps calculating the displacement of each image in the array to the virtual viewpoint, computing the depth map for the virtual viewpoint, and forming the color image at that viewpoint. The method enables one to showcase motion parallax and generate stereo left and right views. Being able to generate different viewpoints, when combined with real-time gyroscope readings on a mobile device, provides the viewer with a sense of scene depth and a rich interactive experience. We show examples in the accompanying video. Our approach to computational array cameras has shown robustness in generating high resolution color images under varying imaging conditions. In addition, PiCam provides a significant difference over the legacy camera in that it relaxes the z-height constraint considerably. The resolution of our system is a function of the optical format and F-number of the lens, the pixel size, and the number of cameras in the array. Depending on the application, an appropriate choice of the imaging system and processing parameters allows one to scale the resolution of the system without hitting the z-height constraint. Additionally, the potential for assembling systems with multiple distributed arrays allows for greater range imaging and view synthesis, which could benefit applications in security and automotive. Our system is also fault tolerant to an extent since the failure of 1 or 2 cameras in the array leads to a graceful degradation of system performance. At the same time, there are areas of improvement both in terms of image quality and processing speed. Artifacts from incorrect depth estimates, along the contours of objects close to the camera, are still possible depending on scene content and background texture. The correction of these artifacts, while not a focus of this paper, remains an important area of continuing research. The algorithms are computationally intensive and while efficiencies are being exploited to allow the pipeline to scale to mobile devices, this remains an active area of work due to the constrained nature of power and compute  availability in these form factors. Nevertheless, we believe that with continued work in both of these areas this architecture has the potential to remove some of the limitations to camera design for small form factor devices, and enable new imaging applications.",
  "resources" : [ ]
}