{
  "uri" : "sig2012-a46-lu_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2012/a46-lu_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "HelpingHand: Example-based Stroke Stylization",
    "published" : "2012",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Jingwan-Lu",
      "name" : "Jingwan",
      "surname" : "Lu"
    }, {
      "uri" : "http://drinventor/Fisher-Yu",
      "name" : "Fisher",
      "surname" : "Yu"
    }, {
      "uri" : "http://drinventor/Adam-Finkelstein",
      "name" : "Adam",
      "surname" : "Finkelstein"
    }, {
      "uri" : "http://drinventor/Stephen-DiVerdi",
      "name" : "Stephen",
      "surname" : "DiVerdi"
    } ]
  },
  "bagOfWords" : [ "paper", "present", "data-driven", "approach", "synthesize", "6d", "hand", "gesture", "datum", "user", "low-quality", "input", "device", "we", "algorithm", "output", "6d", "trajectory", "can", "feed", "any", "virtual", "brush", "stroke", "engine", "make", "expressive", "stroke", "novice", "user", "limited", "hardware", "appearance", "stroke", "govern", "only", "path", "instrument", "also", "pressure", "angle", "-lrb-", "see", "inset", "-rrb-", "perform", "interactive", "rate", "provide", "immediate", "feedback", "user", "during", "drawing", "make", "easy", "choose", "amongst", "different", "style", "finally", "while", "we", "have", "design", "system", "interactive", "use", "non-expert", "people", "without", "highquality", "tablet", "same", "method", "can", "apply", "stylization", "any", "source", "line", "art", "include", "output", "vector", "illustration", "software", "computer-generated", "line", "drawing", "base", "3d", "model", "finally", "we", "explore", "space", "candidate", "algorithm", "evaluate", "they", "quantitatively", "qualitatively", "conclude", "demonstration", "practical", "result", "technique", "work", "selectively", "copy", "portion", "library", "generate", "new", "datum", "maintain", "similar", "statistical", "distribution", "aesthetic", "property", "careful", "tailor", "particular", "requirement", "each", "domain", "optimal", "boundary", "placement", "2-d", "grid", "intractable", "however", "we", "show", "we", "1-d", "domain", "can", "solve", "via", "dynamic", "programming", "we", "also", "derive", "high-level", "inspiration", "from", "approach", "human", "motion", "synthesis", "Kovar", "et", "al.", "-lsb-", "2002", "-rsb-", "Hsu", "et", "al.", "-lsb-", "2004", "-rsb-", "both", "which", "synthesize", "high", "dimensional", "output", "from", "database", "low", "dimensional", "control", "input", "furthermore", "we", "separate", "concern", "pose", "stylization", "versus", "input", "trajectory", "stylization", "show", "how", "apply", "we", "algorithm", "either", "one", "individually", "both", "simultaneously", "stylization", "2d", "domain", "elasticurve", "-lsb-", "Thiel", "et", "al.", "2011", "-rsb-", "intelligently", "neaten", "input", "stroke", "base", "velocity", "datum", "only", "able", "produce", "single", "style", "smooth", "result", "curve", "analogy", "framework", "Hertzmann", "et", "al.", "-lsb-", "2002", "-rsb-", "could", "apply", "arbitrary", "stylization", "input", "curve", "learn", "variation", "from", "pre-existing", "input-output", "curve", "pair", "moreover", "we", "approach", "trajectory", "modification", "rely", "library", "output-only", "exemplar", "rather", "than", "input-output", "pair", "both", "approach", "depend", "explicitly", "narrowly", "define", "relationship", "between", "stroke", "shape", "width", "do", "support", "additional", "pose", "dof", "need", "virtual", "brush", "model", "specifically", "target", "towards", "digital", "painting", "Okabe", "et", "al.", "-lsb-", "2005", "-rsb-", "apply", "realistic", "brush", "stroke", "curve", "first", "acquire", "video", "change", "shape", "real", "brush", "during", "stroke", "train", "hmm", "generate", "appropriate", "footprint", "base", "user?s", "curve", "handwriting", "we", "approach", "learning", "reproduce", "brush", "pose", "style", "real", "artist", "also", "bear", "similarity", "branch", "biometric", "research", "concern", "handwriting", "verification", "synthesis", "extreme", "Plamondon", "-lsb-", "1995", "-rsb-", "develop", "kinematic", "theory", "rapid", "human", "movement", "use", "synthesize", "stroke", "trajectory", "property", "similar", "natural", "motion", "beyond", "2d", "trajectory", "Franke", "et", "al.", "-lsb-", "2005", "-rsb-", "create", "handwriting", "robot", "hold", "pen", "static", "orientation", "can", "vary", "pressure", "throughout", "stroke", "create", "very", "convincing", "signature", "forgery", "Yu", "et", "al.", "-lsb-", "2004", "-rsb-", "consider", "hardware", "acquire", "5d", "input", "include", "pressure", "2d", "tilt", "only", "purpose", "writer", "identification", "synthesis", "each", "6d", "sample", "contain", "2d", "position", "4d", "pose", "comprise", "pressure", "tilt", "rotation", "we", "refer", "trajectory", "sequence", "sample", "position", "-lcb-", "-rcb-", "pose", "corresponding", "hand", "pose", "sequence", "-lcb-", "-rcb-", "after", "capture", "we", "resample", "each", "stroke", "uniformly", "arc", "length", "-lrb-", "roughly", "pixel", "spacing", "2000x2000", "image", "-rrb-", "we", "system", "take", "those", "recording", "input", "build", "collection", "6d", "stroke", "we", "call", "library", "l.", "each", "library", "stroke", "consist", "set", "position", "pose", "sample", "-lcb-", "-rcb-", "project", "rely", "several", "assumption", "first", "shape", "stroke", "use", "handwriting", "-lrb-", "example", "-rrb-", "part", "style", "give", "artist", "different", "example", "similar", "shape", "like", "loop", "shape", "more", "consistent", "from", "same", "person", "compare", "example", "from", "other", "artist", "assumption", "widely", "accept", "example", "form", "basis", "forensic", "handwriting", "analysis", "we", "rely", "assumption", "trajectory", "synthesis", "method", "present", "section", "we", "also", "make", "second", "assumption", "less", "well", "studied?that", "artist", "hand", "pose", "determine", "target", "trajectory", "some", "variance", "artist", "draw", "same", "shape", "-lrb-", "same", "intention", "-rrb-", "multiple", "time", "tend", "select", "pose", "from", "same", "pool", "possible", "gesture", "imply", "give", "stroke", "trajectory", "we", "find", "other", "stroke", "similar", "trajectory", "pose", "should", "have", "similar", "statistics", "observation", "form", "underpinning", "example-based", "pose", "synthesis", "method", "present", "section", "therefore", "verify", "we", "pose", "assumption", "we", "conduct", "correlationbased", "analysis", "record", "library", "datum", "investigate", "how", "well", "pose", "attribute", "correlate", "between", "stroke", "patch", "similar", "shape", "each", "sample", "each", "stroke", "we", "construct", "patch", "center", "sample", "compose", "neighbor", "sample", "-lcb-", "-rcb-", "stroke", "sample", "we", "have", "total", "2n", "overlap", "patch", "each", "size", "2n", "size", "provide", "notion", "what", "we", "mean", "local", "through", "moderate", "trial", "error", "we", "find", "12", "work", "well", "we", "use", "value", "throughout", "we", "experiment", "each", "patch", "we", "construct", "simple", "feature", "vector", "vector", "local", "tangent", "every", "sample", "concatenate", "pair", "coordinate", "indicate", "whether", "sample", "near", "beginning", "end", "stroke", "-lrb-", "describe", "fully", "section", "4.1", "-rrb-", "next", "each", "patch", "we", "find", "most", "similar", "patch", "from", "different", "stroke", "within", "library", "measure", "distance", "we", "reject", "all", "pair", "patch", "whose", "distance", "larger", "than", "threshold", "-lrb-", "mean", "feature", "distance", "over", "all", "pair", "patch", "-rrb-", "aggregate", "across", "multiple", "patch", "pair", "multiple", "pose", "attribute", "we", "convert", "pearson?s", "coefficient", "fisher?s", "coefficient", "compute", "average", "convert", "result", "back", "pearson?s", "-lsb-", "silver", "Dunlap", "1987", "-rsb-", "baseline", "comparison", "we", "also", "find", "random", "pair", "patch", "same", "size", "2n", "within", "library", "calculate", "correlation", "among", "they", "Figure", "summarize", "we", "finding", "bar", "chart", "show", "within", "library", "write", "same", "person", "pose", "sequence", "random", "pair", "patch", "well", "correlate", "whereas", "pose", "from", "stroke", "similar", "trajectory", "have", "high", "correlation", "blue", "bar", "report", "aggregate", "correlation", "within", "library", "show", "Figure", "2b", "Red", "bar", "different", "library", "from", "same", "artist", "green", "show", "correlation", "between", "those", "two", "library", "matrix", "right", "show", "same", "correlation", "analysis", "describe", "above", "compare", "all", "pair", "from", "set", "nine", "library", "-lrb-", "three", "each", "three", "artist", "-rrb-", "block", "diagonal", "-lrb-", "same", "artist", "-rrb-", "exhibit", "obviously", "higher", "value", "than", "off-diagonal", "-lrb-", "different", "artist", "-rrb-", "course", "even", "within", "same", "library", "correlation", "perfect", "-lrb-", "-rrb-", "least", "three", "reason", "-lrb-", "-rrb-", "Pairs", "similar", "patch", "do", "have", "exactly", "same", "trajectory", "-lrb-", "-rrb-", "same", "artist", "exhibit", "some", "variation", "hand", "pose", "even", "when", "follow", "same", "path", "multiple", "time", "degree", "variance", "depend", "individual", "some", "extent", "artist?s", "skill", "pose", "datum", "from", "novice", "user", "tend", "exhibit", "less", "consistency", "three", "we", "five", "volunteer", "have", "more", "than", "two", "year", "experience", "stylus", "-lrb-", "artist", "a-c", "Figure", "-rrb-", "while", "other", "two", "less", "experienced", "have", "correlation", "statistics", "around", "0.5", "still", "higher", "than", "typical", "correlation", "between", "different", "artist", "-lrb-", "off-diagonal", "-rrb-", "observe", "same", "shape", "draw", "different", "moment", "different", "part", "tablet", "exhibit", "similar", "pressure", "progression", "although", "variation", "one", "prominent", "factor", "position", "stroke", "tablet", "expect", "base", "body", "kinematic", "because", "pen", "pose", "change", "when", "person", "move", "he", "hand", "from", "one", "position", "another", "factor", "can", "have", "observable", "effect", "extreme", "example", "Figure", "4b", "show", "rotation", "pose", "strongly", "related", "position", "stroke", "least", "library", "where", "range", "from", "blue", "red", "roughly", "50", "we", "model", "pose", "attribute", "sample", "example", "rotation", "sum", "two", "component", "-lrb-", "-rrb-", "local", "variation", "intend", "artist", "-lrb-", "-rrb-", "positional", "component", "-lrb-", "-rrb-", "we", "observe", "local", "variation", "fairly", "uniformly", "distribute", "may", "view", "noise", "relative", "more", "global", "positional", "signal", "therefore", "we", "approximate", "-lrb-", "-rrb-", "quadratic", "polynomial", "over", "coordinate", "perform", "simple", "least", "square", "fit", "find", "coefficient", "polynomial", "we", "can", "remove", "approximate", "positional", "influence", "simply", "subtract", "polynomial", "from", "add", "its", "place", "average", "value", "Figure", "4c", "show", "result", "range", "roughly", "20", "we", "find", "tilt", "tend", "vary", "position", "way", "rotation", "do", "pressure", "more", "consistent", "positional", "influence", "vary", "from", "library", "library", "nevertheless", "we", "have", "find", "effect", "have", "strong", "impact", "visual", "quality", "synthesis", "result", "therefore", "we", "library", "have", "be", "modify", "use", "regression", "fit", "any", "result", "follow", "here", "we", "note", "few", "general", "observation", "we", "find", "when", "study", "datum", "example", "library", "supply", "we", "artist", "continuity", "pose", "tend", "change", "smoothly", "along", "stroke", "directionality", "gravity", "endpoint", "special", "care", "must", "take", "beginning", "ending", "stroke", "because", "physical", "act", "draw", "make", "part", "look", "different", "from", "middle", "path", "datum", "analysis", "section", "3.1", "tell", "we", "stroke", "similar", "trajectory", "draw", "similar", "hand", "pose", "synthesis", "algorithm", "operate", "stroke", "stroke", "basis", "process", "each", "stroke", "isolation", "so", "inter-stroke", "effect", "consider", "interactive", "painting", "program", "mouse-up", "after", "stroke", "draw", "synthesis", "algorithm", "run", "new", "stroke", "replace", "what", "user", "draw", "-lrb-", "fraction", "second", "typical", "stroke", "-rrb-", "both", "handwriting", "line", "drawing", "hand", "pose", "attribute", "themselves", "do", "fully", "represent", "artist?s", "style", "give", "query", "trajectory", "might", "draw", "shaky", "hand", "amateur", "user", "we", "can", "find", "new", "trajectory", "follow", "user?s", "overall", "intention", "have", "style", "expertise", "artist", "who", "draw", "library", "application", "rely", "same", "algorithm", "develop", "pose", "hallucination", "we", "replace", "query", "trajectory", "similar", "identical", "patch", "from", "library", "-lrb-", "strike", "balance", "between", "follow", "query", "intent", "preserve", "library", "style", "-rrb-", "stage", "compute", "feature", "vector", "-lrb-", "section", "4.1", "-rrb-", "select", "approximate", "nearest", "neighbor", "-lrb-", "section", "4.2", "-rrb-", "post", "processing", "-lrb-", "section", "4.3", "-rrb-", "Figure", "offer", "concise", "overview", "stage", "implementation", "option", "we", "process", "begin", "offline", "step", "where", "each", "sample", "library", "we", "compute", "feature", "vector", "describe", "local", "shape", "use", "either", "shape", "context", "-lrb-", "section", "4.1.1", "-rrb-", "filter", "velocity", "-lrb-", "section", "4.1.2", "-rrb-", "online", "give", "query", "stroke", "synthesis", "Preprocess", "compute", "feature", "vector", "library", "sample", "-lrb-", "4.1", "-rrb-", "shape", "context", "-lrb-", "4.1.1", "-rrb-", "choice", "filter", "velocity", "-lrb-", "4.1.2", "-rrb-", "Online", "compute", "feature", "vector", "query", "above", "-lrb-", "4.1", "-rrb-", "find", "nearest", "neighbor", "-lrb-", "k-nn", "-rrb-", "each", "sample", "-lrb-", "4.2", "-rrb-", "Select", "neighbor", "from", "k-nn", "synthesis", "closest", "neighbor", "-lrb-", "4.2.1", "-rrb-", "choice", "weighted", "average", "-lrb-", "4.2.2", "-rrb-", "optimal", "sequence", "-lrb-", "4.2.3", "-rrb-", "Post", "process", "optimal", "transition", "blending", "-lrb-", "4.3.1", "-rrb-", "trajectory", "shape", "optimization", "-lrb-", "4.3.2", "-rrb-", "begin", "compute", "feature", "vector", "query", "sample", "search", "similar", "feature", "library", "pose", "attribute", "end", "stroke", "have", "different", "distribution", "than", "those", "middle", "-lrb-", "section", "3.3", "-rrb-", "we", "define", "scalar", "min", "-lrb-", "d/d", "-rrb-", "where", "arc", "length", "distance", "stroke", "size", "we", "recent", "history", "window", "likewise", "we", "have", "measure", "distance", "end", "stroke", "relative", "future", "window", "value", "clamp", "interior", "stroke", "undifferentiated", "put", "all", "together", "we", "have", "feature", "vector", "-lcb-", "-lcb-", "-rcb-", "-rcb-", "-lrb-", "-rrb-", "where", "-lcb-", "-rcb-", "set", "shape", "feature", "weight", "balance", "between", "relative", "importance", "shape", "feature", "versus", "end", "feature", "next", "two", "subsection", "consider", "alternative", "shape", "feature", "introduce", "Belongie", "et", "al.", "-lsb-", "2001", "-rsb-", "shape", "context", "logpolar", "histogram", "sample", "position", "curve", "relative", "current", "sample", "we", "have", "adapt", "variant", "perform", "well", "we", "application", "two", "modification", "second", "we", "further", "divide", "two", "separate", "histogram", "one", "history", "one", "future", "division", "allow", "we", "distinguish", "example", "stroke", "draw", "leave", "right", "versus", "right", "leave", "we", "experiment", "we", "have", "use", "from", "25", "40", "history", "future", "sample", "each", "depend", "datum", "set", "here", "we", "describe", "feature", "vector", "base", "velocity", "rather", "than", "shape", "we", "use", "sample", "velocity", "-lcb-", "-rcb-", "where", "na?ve", "implementation", "feature", "vector", "would", "have", "each", "tap", "correspond", "directly", "velocity", "sample", "from", "stroke", "instead", "each", "filter", "tap", "obtain", "history", "future", "apply", "discrete", "triangle", "filter", "-rcb-", "-rcb-", "velocity", "sample", "where", "-lrb-", "-rrb-", "triangle", "-lrb-", "filter", "-rrb-", "tap", "weight", "stroke", "path", "number", "history", "future", "tap", "respectively", "triangle", "filter", "overlap", "so", "index", "end", "index", "triangle", "center", "index", "adjacent", "triangle", "which", "ensure", "all", "weight", "apply", "single", "velocity", "sample", "feature", "vector", "sum", "one", "filter", "width", "increase", "exponentially", "distance", "from", "sample", "which", "mean", "individual", "sample", "distant", "contribute", "relatively", "less", "feature", "vector", "when", "synthesize", "query", "sample", "near", "end", "query", "stroke", "some", "feature", "tap", "cover", "hypothetical", "sample", "outside", "query", "stroke", "case", "we", "only", "average", "velocity", "sample", "valid", "all", "sample", "under", "triangle", "center", "located", "outside", "valid", "range", "we", "use", "use", "triangle", "filter", "reduce", "dimensionality", "feature", "vector", "need", "represent", "large", "local", "neighborhood", "filter", "out", "noise", "present", "raw", "sample", "result", "paper", "use", "triangle", "filter", "equal", "size", "history", "future", "window", "we", "also", "use", "weight", "0.3", "balance", "shape", "feature", "against", "endpoint", "feature", "we", "experiment", "we", "have", "find", "method", "relatively", "insensitive", "parameter", "robust", "through", "broad", "range", "section", "discuss", "relative", "merit", "two", "feature", "vector", "we", "investigate", "once", "we", "have", "compute", "feature", "vector", "each", "sample", "query", "stroke", "we", "find", "its", "nearest", "sample", "library", "potential", "sample", "synthesis", "therefore", "we", "resort", "algorithm", "find", "approximate", "nearest", "neighbor", "output", "which", "we", "have", "find", "acceptable", "stage", "follow", "we", "experiment", "two", "algorithm", "FLANN", "implementation", "Muja", "Lowe", "-lsb-", "2009", "-rsb-", "adaptation", "PatchMatch", "algorithm", "Barnes", "et", "al.", "-lsb-", "2011", "-rsb-", "PatchMatch", "approach", "require", "straightforward", "modification", "search", "over", "1-d", "domain", "sample", "we", "find", "we", "datum", "algorithm", "converge", "reasonable", "approximation", "pass", "-lrb-", "Barnes", "et", "al.", "find", "image", "patch", "-rrb-", "overall", "two", "approach", "offer", "roughly", "equivalent", "performance", "equivalent", "quality", "output", "major", "tradeoff", "between", "method", "FLANN", "expend", "time", "memory", "build", "auxiliary", "structure", "during", "offline", "library", "construction", "phase", "other", "hand", "patchmatch", "only", "efficient", "when", "process", "entire", "query", "stroke", "once", "therefore", "suitable", "on-the-fly", "synthesis", "during", "stroke", "input", "once", "we", "have", "neighbor", "-lrb-", "k-nn", "-rrb-", "each", "query", "sample", "next", "step", "synthesize", "new", "sample", "-lcb-", "-rcb-", "from", "they", "just", "use", "closest", "neighbor", "query", "sample", "suppose", "library", "sample", "1-nn", "query", "sample", "strong", "coherence", "we", "want", "+1", "1-nn", "+1", "which", "only", "sometimes", "true", "-lrb-", "become", "more", "rare", "library", "size", "grow", "-rrb-", "nevertheless", "we", "retain", "case", "comparison", "other", "method", "section", "moreover", "case", "may", "think", "stand-in", "general", "non-parametric", "texture", "synthesis", "approach", "follow", "Efros", "Leung", "-lsb-", "1999", "-rsb-", "particular", "we", "also", "experiment", "choose", "randomly", "among", "k-nn", "also", "variant", "propose", "ashikhmin", "-lsb-", "2001", "-rsb-", "-lrb-", "which", "probabilistically", "choose", "+1", "scenario", "above", "-rrb-", "however", "we", "experiment", "none", "lead", "result", "coherent", "those", "method", "follow", "give", "neighbor", "distance", "from", "query", "sample", "feature", "space", "we", "synthesize", "sample", "weighted", "average", "use", "weight", "1/d", "produce", "consecutive", "sample", "vary", "smoothly", "create", "continuous", "output", "stroke", "however", "library", "typically", "contain", "many", "similar", "stroke", "-lrb-", "say", "multiple", "version", "letter", "-rrb-", "each", "slightly", "different", "pose", "trajectory", "weighted", "average", "method", "therefore", "generate", "stroke", "compromise", "among", "distinctive", "feature", "library", "stroke", "quite", "reproduce", "any", "they", "well", "result", "method", "produce", "stroke", "tend", "smoother", "than", "artist?s", "style", "both", "closest", "neighbor", "weighted", "average", "local", "solution", "have", "difficulty", "reproduce", "smoothness", "distinctiveness", "artist", "style", "achieve", "both", "quality", "we", "propose", "-lrb-", "per-stroke", "-rrb-", "global", "optimize", "solution", "which", "we", "solve", "use", "dynamic", "programming", "efficient", "computation", "one", "goal", "optimization", "select", "few", "long", "segment", "library", "stroke", "-lrb-", "sequence", "near-consecutive", "sample", "-rrb-", "match", "segment", "query", "-lrb-", "figure", "-rrb-", "avoid", "many", "potential", "discontinuity", "we", "optimize", "sequence", "transition", "index", "-lcb-", "-rcb-", "minimize", "total", "synthesis", "cost", "over", "sample", "query", "stroke", "i-th", "query", "sample", "index", "select", "library", "stroke", "index", "select", "sample", "stroke", "we", "seek", "optimal", "sequence", "-lcb-", "-rcb-", "minimize", "sum", "four", "error", "term", "term", "address", "respectively", "match", "feature", "choose", "good", "transition", "between", "segment", "avoid", "short", "segment", "match", "stroke", "endpoints?discussed", "below", "match", "feature", "term", "simply", "sum", "-lrb-", "over", "all", "query", "sample", "-rrb-", "distance", "feature", "space", "select", "neighbor", "all", "other", "term", "optimization", "have", "impact", "term", "would", "drive", "solution", "closest", "neighbor", "selection", "method", "-lrb-", "section", "4.2.1", "-rrb-", "however", "typically", "different", "neighbor", "among", "k-nn", "almost", "good", "closest", "neighbor", "have", "other", "desirable", "property", "would", "cause", "select", "over", "closest", "neighbor", "base", "term", "follow", "transition", "penalty", "term", "encourage", "use", "fewer", "segment", "consecutive", "query", "sample", "we", "encourage", "select", "sample", "consecutive", "library", "stroke", "since", "have", "natural", "coherence", "hand", "pose", "attribute", "capture", "local", "style", "possible", "other", "reason", "we", "still", "encourage", "repeat", "same", "library", "sample", "once", "skip", "exactly", "one", "library", "sample?policies", "allow", "library", "segment", "stretch", "shrink", "match", "query", "otherwise", "we", "call", "transition", "jump", "assign", "penalty", "include", "both", "large", "constant", "cost", "cost", "base", "pose", "discontinuity", "jump", "location", "accord", "policy", "above", "four", "case", "consecutive", "+1", "+1", "one", "repeat", "+1", "+1", "cost", "stretch", "one", "skip", "+1", "+1", "cost", "shrink", "jump", "otherwise", "+1", "cost", "jump", "deeper", "penalty", "large", "pose", "discontinuity", "we", "use", "50", "10", "rather", "than", "penalize", "pose", "difference", "jump", "we", "penalize", "direction", "change", "term", "become", "4b", "Trajectory", "jump", "+1", "where", "normalize", "velocity", "sample", "library", "stroke", "short", "Segment", "Penalty", "we", "find", "short", "segment", "often", "lead", "visual", "discontinuity", "synthesize", "result", "avoid", "they", "we", "impose", "penalty", "take", "sum", "-lrb-", "-lrb-", "min", "-rrb-", "-rrb-", "over", "all", "segment", "length", "min", "we", "experiment", "we", "use", "min", "12", "sample", "Endpoint", "Penalty", "note", "section", "3.3", "end", "stroke", "have", "unique", "characteristic", "therefore", "we", "prefer", "where", "possible", "synthesize", "beginning", "query", "stroke", "beginning", "library", "stroke", "same", "end", "we", "impose", "penalty", "term", "-lrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-rrb-", "where", "index", "neighbor", "select", "first", "sample", "index", "last", "query", "number", "sample", "library", "stroke", "term", "essentially", "measure", "how", "far", "neighbor", "select", "end", "query", "from", "end", "respective", "stroke", "cost", "match", "endpoint", "which", "we", "set", "optimization", "we", "solve", "optimization", "dynamic", "programming", "over", "transition", "table", "row", "k-nn", "column", "stroke", "sample", "fill", "each", "entry", "column", "we", "consider", "all", "entry", "once", "full", "we", "recover", "optimal", "sequence", "select", "lowest", "cost", "path", "through", "table", "after", "select", "sequence", "neighbor", "sample", "we", "post-process", "they", "create", "final", "stroke", "datum", "case", "optimal", "neighbor", "selection", "we", "apply", "transition", "blending", "case", "trajectory", "synthesis", "we", "perform", "shape", "optimization", "both", "discuss", "below", "optimal", "sequence", "method", "-lrb-", "section", "4.2.3", "-rrb-", "can", "still", "have", "discontinuity", "jump", "location", "despite", "penalty", "term", "attempt", "minimize", "they", "therefore", "we", "employ", "blend", "remove", "remain", "artifact", "we", "gather", "many", "sample", "-lrb-", "exist", "-rrb-", "either", "side", "jump", "from", "both", "library", "stroke", "abut", "jump", "perform", "simple", "cross", "fade", "between", "attribute", "-lrb-", "pose", "and/or", "trajectory", "-rrb-", "overlap", "region", "when", "synthesize", "trajectory", "result", "can", "drift", "away", "from", "query", "shape", "so", "we", "correct", "use", "shape", "optimization", "suppose", "-lcb-", "-rcb-", "input", "query", "trajectory", "we", "simply", "integrate", "synthesize", "velocity", "-lcb-", "-rcb-", "start", "from", "position", "first", "sample", "we", "get", "new", "trajectory", "look", "like", "library", "deviate", "from", "query", "-lrb-", "figure", "7a", "black", "vs.", "blue", "-rrb-", "we", "therefore", "design", "simple", "linear", "optimization", "attempt", "simultaneously", "preserve", "synthesize", "shape", "while", "match", "few", "key", "feature", "query", "we", "place", "first", "type", "anchor", "point", "few", "sample", "from", "end", "location", "-lrb-", "blue", "dot", "Figure", "7b", "-rrb-", "second", "we", "add", "location", "very", "rapid", "change", "orientation", "follow", "each", "query", "sample", "we", "calculate", "stroke", "turn", "angle", "local", "window", "we", "find", "all", "local", "maximum", "above", "threshold", "angle", "-lrb-", "we", "use", "60", "-rrb-", "call", "they", "angle", "point", "-lrb-", "magenta", "dot", "-rrb-", "add", "vertex", "polyline", "third", "kind", "anchor", "point", "-lrb-", "green", "dot", "-rrb-", "next", "we", "set", "up", "system", "equation", "compose", "three", "constraint", "each", "which", "we", "wish", "satisfy", "least-squares", "sense", "order", "construct", "final", "curve", "-lrb-", "red", "Figure", "7c", "-rrb-", "first", "constraint", "attempt", "match", "final", "velocity", "synthesize", "velocity", "avoid", "second", "order", "discontinuity", "induce", "optimization", "anchor", "point", "third", "constraint", "attempt", "match", "local", "curvature", "result", "synthesize", "velocity", "near", "anchor", "know", "synthesis", "velocity", "query", "position", "we", "seek", "unknown", "position", "via", "system", "equation", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "i?a", "-lrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-rrb-", "-lrb-", "-rrb-", "i?a", "??", "handwriting", "pose", "synthesis", "Query", "stroke", "-lrb-", "-rrb-", "ground", "truth", "stroke", "-lrb-", "-rrb-", "without", "pose", "datum", "-lrb-", "-rrb-", "we", "synthesis", "result", "visually", "indistinguishable", "-lrb-", "-rrb-", "apply", "another", "artist?s", "style", "yield", "characteristically", "different", "visual", "appearance", "set", "contain", "index", "anchor", "point", "number", "surround", "sample", "involve", "second", "order", "constraint", "we", "experiment", "we", "use", "0.25", "output", "we", "synthesis", "process", "so", "far", "sequence", "pose", "and/or", "trajectory", "can", "drive", "virtual", "brush", "model", "however", "we", "pose", "synthesis", "framework", "use", "trajectory", "input", "both", "pose", "trajectory", "be", "synthesize", "algorithm", "can", "run", "either", "one", "two", "pass", "one", "pass", "version", "query", "trajectory", "use", "directly", "synthesize", "both", "pose", "new", "trajectory", "thus", "combined", "output", "do", "have", "ideal", "correlation", "two", "pass", "version", "first", "input", "stroke", "use", "synthesize", "new", "trajectory", "output", "trajectory", "use", "synthesize", "pose", "datum", "which", "create", "datum", "dependency", "produce", "better", "correlation", "another", "advantage", "two-pass", "version", "allow", "we", "use", "separate", "parameter", "synthesize", "trajectory", "pose", "example", "we", "generally", "tune", "fewer", "segment", "trajectory", "synthesis", "than", "pose", "synthesis", "two-pass", "case", "run", "time", "we", "synthesis", "algorithm", "sublinear", "number", "library", "sample", "due", "approximate", "k-nn", "search", "we", "find", "through", "experimentation", "150", "stroke", "sufficient", "generate", "plausible", "result", "confirm", "through", "correlation", "analysis", "similar", "section", "library", "average", "run", "time", "both", "pose", "trajectory", "synthesis", "0.08", "seconds", "per", "stroke", "we", "experiment", "enrich", "library", "up", "about", "1000", "stroke", "include", "same", "stroke", "scale", "different", "size", "-lrb-", "50", "-rrb-", "increase", "match", "scale-invariance", "do", "see", "significant", "improvement", "performance", "reduce", "we", "also", "try", "use", "very", "small", "-lrb-", "fewer", "than", "10", "-rrb-", "very", "large", "-lrb-", "more", "than", "500", "-rrb-", "library", "small", "library", "feature", "matching", "can", "find", "similar", "enough", "trajectory", "therefore", "pick", "random", "stroke", "copy", "since", "optimal", "sequence", "algorithm", "encourage", "long", "segment", "pose", "result", "still", "look", "plausible", "trajectory", "poor", "match", "may", "result", "complete", "loss", "semantics", "result", "large", "library", "do", "affect", "pose", "synthesis", "whereas", "trajectory", "modification", "more", "likely", "find", "very", "similar", "patch", "query", "reduce", "effect", "style", "transfer", "all", "result", "show", "here", "render", "use", "Adobe", "Photoshop?s", "bristle", "brush", "tool", "-lsb-", "DiVerdi", "et", "al.", "2010", "-rsb-", "same", "brush", "setting", "difference", "synthesize", "pose", "datum", "induce", "visibly", "different", "shape", "texture", "stroke", "Figure", "show", "plausibility", "pose", "synthesis", "handwriting", "artist?s", "6-dof", "stroke", "strip", "pose", "datum", "trajectory", "use", "query", "same", "artist?s", "library", "apply", "synthesize", "output", "visually", "indistinguishable", "from", "ground", "truth", "whereas", "apply", "another", "artist?s", "library", "create", "visually", "distinct", "result", "pose", "synthesis", "line", "drawing", "demonstrate", "Figure", "example", "trajectory", "stylization", "Figure", "15", "we", "show", "robustness", "noisy", "input", "utility", "trajectory", "stylization", "demonstrate", "how", "can", "neaten", "mouse-written", "text", "which", "have", "characteristic", "shakiness", "we", "algorithm", "can", "also", "apply", "stylistic", "flourish", "serif", "block", "lettering", "figure", "14", "15", "show", "two-pass", "algorithm", "stylize", "both", "pose", "trajectory", "remainder", "section", "describe", "study", "we", "conduct", "evaluate", "we", "result", "quantitative", "measure", "pose", "synthesis", "quality", "we", "compute", "correlation", "between", "synthesize", "result", "ground", "truth", "however", "equivalent", "measure", "trajectory", "synthesis", "ultimately", "we", "care", "most", "about", "how", "user", "judge", "we", "result", "therefore", "we", "also", "conduct", "user", "study", "both", "pose", "trajectory", "synthesis", "section", "3.1", "show", "artist", "exhibit", "some", "natural", "variation", "hand", "pose", "even", "when", "draw", "same", "path", "multiple", "time", "therefore", "gold", "standard", "we", "can", "compare", "we", "synthesis", "result", "against?l", "measurement", "reconstruction", "error", "against", "ground", "truth", "good", "indication", "success", "correlation", "other", "hand", "better", "evaluation", "metric", "case", "pose", "synthesis", "we", "can", "apply", "analysis", "similar", "section", "3.1", "evaluate", "we", "result", "style", "library", "successfully", "transfer", "onto", "query", "stroke", "every", "local", "patch", "output", "should", "have", "sim", "-lrb-", "-rrb-", "ground", "truth", "-lrb-", "-rrb-", "optimal", "-lrb-", "-rrb-", "weighted", "average", "-lrb-", "-rrb-", "closest", "-lrb-", "-rrb-", "transfer", "-lrb-", "-rrb-", "transfer", "ilar", "pose", "profile", "similar", "patch", "library", "we", "compare", "closest", "neighbor", "weighted", "average", "optimal", "sequence", "variant", "we", "algorithm", "-lrb-", "section", "4.2", "-rrb-", "Figure", "10", "contain", "correlation", "result", "show", "optimal", "algorithm", "achieve", "highest", "pose", "correlation", "both", "synthesis", "case", "furthermore", "since", "we", "have", "ground", "truth", "pose", "datum", "query", "stroke", "we", "compare", "they", "synthesis", "find", "well", "correlate", "expect", "note", "we", "have", "analogous", "quality", "measure", "trajectory", "synthesis", "because", "goal", "blend", "local", "feature", "global", "shape", "fair", "objective", "function", "more", "difficult", "formulate", "we", "conduct", "two", "user", "study", "goal", "evaluate", "whether", "user", "can", "distinguish", "between", "we", "result", "ground", "truth", "both", "study", "use", "same", "methodology", "only", "image", "different", "Study", "Design", "we", "show", "subject", "three", "line", "English", "text", "from", "artist?s", "library?the", "exemplar", "-lrb-", "we", "use", "two", "library", "from", "each", "artist", "show", "Figure", "2a", "-rrb-", "below", "exemplar", "appear", "two", "test", "image", "contain", "same", "-lrb-", "3-9", "letter", "-rrb-", "phrase?one", "ground", "truth", "originally", "write", "artist", "one", "forgery", "synthesize", "one", "we", "algorithm", "subject", "instruct", "one", "image", "original", "other", "forgery", "ask", "identify", "original", "compare", "both", "exemplar", "pose", "study", "ground", "truth", "forgery", "have", "same", "trajectory", "-lrb-", "figure", "11", "-rrb-", "trajectory", "study", "ground", "truth", "trajectory", "use", "synthesis", "pose", "datum", "omit", "from", "all", "image", "-lrb-", "figure", "12", "-rrb-", "one", "trial", "consist", "26", "task", "-lrb-", "each", "same", "exemplar", "-rrb-", "compare", "-lrb-", "-rrb-", "random", "ground", "truth", "phrase", "forgery", "select", "from", "one", "five", "condition", "-lrb-", "-rrb-", "optimal", "sequence", "-lrb-", "-rrb-", "weighted", "average", "-lrb-", "-rrb-", "closest", "neighbor", "-lrb-", "-rrb-", "style", "transfer", "-lrb-", "-rrb-", "style", "transfer", "validation", "condition", "-lrb-", "b-d", "-rrb-", "algorithm", "be", "test", "whereas", "-lrb-", "e-f", "-rrb-", "baseline", "synthesize", "forgery", "another", "artist?s", "library", "-lrb-", "so", "should", "very", "easy", "identify", "-rrb-", "26", "task", "four", "from", "each", "-lrb-", "b-e", "-rrb-", "ten", "from", "-lrb-", "-rrb-", "randomly", "shuffle", "any", "particular", "subject", "-lrb-", "e-f", "-rrb-", "select", "from", "two", "different", "library", "style", "randomly", "we", "only", "retain", "datum", "from", "trial", "correct", "count", "-lrb-", "-rrb-", "method", "pose", "study", "trajectory", "study", "average", "153", "322", "-lrb-", "48", "-rrb-", "96", "302", "-lrb-", "32", "-rrb-", "optimal", "169", "316", "-lrb-", "53", "-rrb-", "172", "305", "-lrb-", "56", "-rrb-", "closest", "269", "304", "-lrb-", "88", "-rrb-", "220", "292", "-lrb-", "75", "-rrb-", "transfer", "293", "301", "-lrb-", "97", "-rrb-", "274", "288", "-lrb-", "95", "-rrb-", "-lrb-", "-rrb-", "ground", "truth", "-lrb-", "-rrb-", "optimal", "-lrb-", "-rrb-", "weighted", "average", "-lrb-", "-rrb-", "closest", "-lrb-", "-rrb-", "transfer", "-lrb-", "-rrb-", "transfer", "when", "out", "10", "validation", "condition", "-lrb-", "-rrb-", "correct", "so", "we", "know", "user", "understand", "task", "actually", "try", "succeed", "-lrb-", "0.01", "-rrb-", "style", "transfer", "result", "only", "report", "-lrb-", "-rrb-", "we", "study", "be", "restricted", "us-only", "worker", "who", "be", "pay", "0.20", "per", "task", "-lrb-", "HIT", "contain", "26", "comparison", "which", "typically", "complete", "few", "minute", "-rrb-", "across", "two", "study", "70", "worker", "complete", "total", "214", "hit", "subject", "be", "allow", "complete", "many", "10", "hit", "per", "study", "most", "worker", "do", "just", "one", "case", "where", "particular", "pair", "repeat", "particular", "worker", "due", "randomize", "selection", "we", "only", "retain", "first", "response", "total", "4,170", "response", "Study", "result", "result", "report", "Table", "frequency", "which", "ground", "truth", "correctly", "identify", "Bonferroni", "correct", "randomize", "permutation", "test", "distribution", "each", "consecutive", "pair", "row", "table", "show", "different", "statistical", "significance", "-lrb-", "0.01", "-rrb-", "except", "case", "average", "optimal", "condition", "pose", "study", "-lrb-", "0.34", "-rrb-", "ideal", "forgery", "indistinguishable", "from", "ground", "truth", "so", "subject", "choose", "randomly", "result", "correct", "answer", "near", "50", "time", "when", "forgery", "easy", "identify", "-lrb-", "figure", "12e", "-rrb-", "we", "expect", "score", "near", "100", "transfer", "condition", "near", "100", "both", "study", "which", "show", "people", "can", "perform", "task", "easy", "case", "people", "tend", "identify", "closest", "method", "-lrb-", "88", "75", "-rrb-", "so", "generally", "implausible", "pose", "study", "average", "optimal", "both", "near", "50", "therefore", "plausibly", "synthesize", "pose", "datum", "optimal", "perform", "well", "trajectory", "study", "average", "significantly", "below", "50", "which", "mean", "subject", "tend", "incorrectly", "identify", "forgery", "original", "mention", "section", "4.2.2", "weighted", "average", "method", "produce", "very", "smooth", "output", "trajectory", "we", "believe", "people", "have", "bias", "towards", "smoother", "curve", "case", "people", "choose", "average", "over", "ground", "truth", "even", "though", "actually", "smoother", "than", "exemplar", "thus", "fail", "mimic", "exemplar?s", "style", "many", "we", "result", "handwriting", "sample", "though", "we", "do", "make", "special", "accommodation", "they", "because", "handwriting", "provide", "easy", "understand", "readily", "available", "source", "datum", "handwriting", "uniquely", "stylized", "writer?s", "hand", "pose", "local", "trajectory", "variation", "global", "feature", "slant", "angle", "handwriting", "also", "provide", "readily-evaluated", "test", "set", "contrast", "more", "difficult", "measure", "performance", "stroke", "drawing", "we", "consider", "pose", "local", "trajectory", "stylistic", "result", "motor", "reflex", "whereas", "global", "shape", "intentional", "we", "algorithm", "attempt", "transfer", "style", "maintain", "intent", "-lrb-", "via", "trajectory", "shape", "optimization", "-rrb-", "similarly", "while", "artist?s", "style", "may", "consistently", "place", "higher", "weight", "stroke", "drawing", "nearer", "viewpoint", "we", "do", "attempt", "model", "variation", "way", "we", "provide", "most", "general", "result", "possible", "we", "examine", "both", "shape", "context", "filter", "velocity", "feature", "vector", "we", "result", "use", "filter", "velocity", "though", "difficult", "say", "which", "absolutely", "better", "Figure", "13", "show", "limitation", "filter", "velocity", "tend", "perform", "very", "well", "can", "sometimes", "get", "confuse", "match", "letter", "different", "similar", "letter", "shape", "context", "have", "fewer", "error", "have", "difficulty", "balance", "local", "style", "transfer", "global", "shape", "result", "output", "appear", "less", "plausible", "noisy", "also", "generally", "more", "difficult", "select", "parameter", "shape", "context", "whereas", "filter", "velocity", "more", "robust", "through", "broader", "range", "setting", "finally", "get", "high", "quality", "result", "shape", "context", "need", "have", "more", "dimension", "-lrb-", "see", "Section", "4.1.2", "-rrb-", "impact", "performance", "we", "also", "compare", "strategy", "choose", "among", "nearest", "neighbor", "closest", "neighbor", "weighted", "average", "optimal", "sequence", "result", "we", "pose", "evaluation", "quantitatively", "optimal", "sequence", "best", "casual", "observer", "weighted", "average", "effective", "however", "careful", "inspection", "can", "reveal", "subtle", "difference", "between", "two", "-lrb-", "e.g.", "figure", "11b", "-rrb-", "trajectory", "synthesis", "weighted", "average", "obviously", "more", "smooth", "some", "case", "too", "smooth", "advantage", "weighted", "average", "have", "over", "optimal", "sequence", "do", "require", "query", "stroke", "complete", "before", "begin", "synthesize", "so", "can", "use", "on-the-fly", "implementation", "synthesize", "pose", "datum", "while", "user", "still", "create", "stroke", "otherwise", "optimal", "sequence", "result", "highest", "quality", "output", "finally", "we", "approach", "do", "require", "hand-drawn", "input", "method", "apply", "any", "kind", "2d", "path", "b?zier", "curve", "-lrb-", "see", "Figure", "14", "-rrb-", "path", "first", "sample", "uniformly", "arc", "length", "treat", "constant-velocity", "brush", "stroke", "we", "unmodified", "algorithm", "approach", "would", "also", "work", "line", "extract", "from", "3d", "model", "other", "automatic", "process", "Limitations", "Future", "Work", "we", "algorithm", "consider", "each", "stroke", "independently", "artistic", "style", "also", "include", "interaction", "among", "nearby", "stroke", "both", "temporally", "spatially", "which", "we", "hope", "model", "future", "work", "we", "result", "all", "render", "Adobe", "Photoshop?s", "bristle", "brush", "which", "use", "all", "6-dof", "stroke", "datum", "however", "visual", "impact", "each", "dof", "may", "obvious", "would", "real", "physical", "brush", "because", "we", "algorithm", "only", "generate", "stroke", "datum", "can", "use", "any", "digital", "paint", "engine", "so", "other", "brush", "simulation", "may", "able", "use", "datum", "more", "effectively", "Figure", "13", "highlight", "some", "trajectory", "synthesis", "failure", "where", "query", "shape", "poorly", "match", "we", "algorithm", "we", "approach", "local", "have", "higher-level", "notion", "intent", "part", "artist", "while", "cognitive", "process", "too", "complex", "model", "may", "some", "intermediate", "level", "could", "help", "moreover", "failure", "could", "address", "we", "current", "framework", "choose", "different", "parameter", "setting", "we", "approach", "work", "well", "especially", "pose", "synthesis", "broad", "range", "setting", "find", "ideal", "value", "arbitrary", "problem", "difficult", "finally", "we", "treat", "artist?s", "library", "single", "monolithic", "style", "practice", "artist", "may", "choose", "among", "multiple", "style", "even", "single", "drawing", "style", "really", "more", "multi-modal", "than", "characterize", "we", "process", "we", "can", "partially", "address", "issue", "offer", "user", "choice", "different", "style", "find", "effective", "interface", "remain", "interesting", "problem", "more", "challenging", "would", "try", "characterize", "multi-modal", "nature", "within", "library", "conclusion", "paper", "present", "data-driven", "approach", "synthesize", "plausible", "pose", "datum", "can", "use", "generate", "expressive", "handwriting", "line", "drawing", "same", "framework", "can", "also", "use", "transfer", "stroke", "trajectory", "style", "acknowledgement", "we", "thank", "anonymous", "volunteer", "who", "contribute", "both", "write", "sample", "drawing", "project", "research", "sponsor", "part", "Adobe", "Corporation", "conduct", "conjunction", "Intel", "Science", "Technology", "Center", "Visual", "Computing", "fro", "a.", "eung", "t.", "1999", "texture", "synthesis", "nonparametric", "sampling", "International", "Conference", "Computer", "Vision", "1033", "1038", "ranke", "K.", "chomaker", "L.", "OPPEN", "M.", "2005", "pen", "force", "emulate", "robotic", "write", "device", "its", "application", "Workshop", "Advanced", "Robotics", "its", "Social", "Impacts", "36", "46", "oodwin", "T.", "OLLICK", "I.", "ertzmann", "a.", "2007", "isophote", "distance", "shade", "approach", "artistic", "stroke", "thickness", "non-photorealistic", "animation", "rendering", "53", "62", "ertzmann", "a.", "liver", "N.", "URLESS", "B.", "EITZ", "S.", "2002", "curve", "analogy", "Eurographics", "Workshop", "Rendering", "233", "246", "inton", "G.", "AIR", "V.", "2005", "infer", "motor", "program", "from", "image", "handwritten", "digit", "advance", "Neural", "Information", "Processing", "515", "522", "ouse", "D.", "INGH", "M.", "2007", "Line", "draw", "dynamic", "process", "Pacific", "Graphics", "351", "360", "SU", "E.", "ENTRY", "S.", "opovus", "J.", "2004", "examplebased", "control", "human", "motion", "Symposium", "Computer", "Animation", "69", "77", "OVAR", "L.", "LEICHER", "M.", "ighin", "F.", "2002", "Motion", "graph", "SIGGRAPH", "473", "482", "ra", "J.", "INGH", "K.", "2009", "sketch", "piecewise", "clothoid", "curve", "sketch-based", "interface", "modeling", "ra", "J.", "INGH", "K.", "2011", "neaten", "sketched", "stroke", "use", "piecewise", "french", "curve", "sketch-based", "interface", "modeling", "141", "148", "uja", "m.", "owe", "D.", "G.", "2009", "fast", "approximate", "nearest", "neighbor", "automatic", "algorithm", "configuration", "Internat", "Vision", "Theory", "application", "331", "340", "kabe", "Y.", "AITO", "S.", "AKAJIMA", "M.", "2005", "paintbrush", "rendering", "line", "use", "hmm", "GRAPHITE", "91", "98", "lamondon", "R.", "1995", "kinematic", "theory", "rapid", "human", "movement", "biological", "cybernetics", "72", "295", "320", "aito", "S.", "ANI", "a.", "hang", "Y.", "AKAJIMA", "M.", "2007", "curvature-based", "stroke", "rendering", "visual", "Computing", "24", "-lrb-", "November", "-rrb-", "11", "ch", "odl", "a.", "zeliskus", "R.", "ALESIN", "D.", "H.", "ssa", "i.", "2000", "Video", "texture", "SIGGRAPH", "489", "498", "ilver", "N.", "UNLAP", "W.", "P.", "1987", "average", "correlation", "coefficient", "should", "fisher?s", "transformation", "use", "Journal", "app", "72", "-lrb-", "-rrb-", "146", "148", "hiel", "Y.", "ingh", "K.", "ALAKRISHNAN", "R.", "2011", "Elasticurves", "exploit", "stroke", "dynamics", "inertia", "real-time", "neatening", "sketched", "2d", "curve", "user", "Interface", "Software", "Technology", "383", "392", "andoren", "P.", "aerhoven", "T.", "LAESEN", "L.", "AELMAN", "J.", "AYMAEKERS", "C.", "eeth", "F.", "2008", "IntuPaint", "bridge", "gap", "between", "physical", "digital", "painting", "horizontal", "interactive", "human", "Computer", "Systems", "65", "72", "arga", "T.", "ILCHHOFER", "D.", "UNKE", "H.", "2005", "templatebased", "synthetic", "handwriting", "generation", "training", "recognition", "system", "conference", "International", "Graphonomics", "Society", "206", "211", "EI", "L.-Y.", "EFEBVRE", "S.", "WATRA", "V.", "urk", "G.", "2009", "state", "art", "example-based", "texture", "synthesis", "eurographic", "2009", "state", "Art", "Report", "K.", "ang", "Y.", "t.", "2004", "writer", "identification", "use", "dynamic", "feature", "Biometric", "Authentication", "D.", "Zhang", "A.", "Jain", "Eds", "3072", "Lec", "note", "Comp" ],
  "content" : "This paper presents a data-driven approach for synthesizing the 6D hand gesture data for users of low-quality input devices. Our algorithm outputs a 6D trajectory that can be fed into any virtual brush stroke engine to make expressive strokes for novices or users of limited hardware. The appearance of the strokes is governed not only by the path of the instrument but also the pressure and angle (see inset). It performs at interactive rates to provide immediate feedback to the user during drawing and to make it easy to choose amongst different styles. Finally, while we have designed the system for interactive use by non-experts or people without highquality tablets, the same method can apply stylization to any source of line art, including the output of vector illustration software or computer-generated line drawings based on 3D models. Finally, we explore the space of candidate algorithms and evaluate them quantitatively and qualitatively, concluding with a demonstration of practical results. These techniques work by selectively copying portions of a library to generate new  data that maintains a similar statistical distribution and aesthetic property, with careful tailoring to the particular requirements of each domain. Optimal boundary placement on the 2-D grid is intractable; however, we show that on our 1-D domain it can be solved via dynamic programming. We also derive high-level inspiration from the approach for human motion synthesis of Kovar et al. [2002] and Hsu et al. [2004], both of which synthesize high dimensional output from a database of low dimensional control input. Furthermore, we separate the concerns for pose stylization versus input trajectory stylization, and show how to apply our algorithm to either one individually or both simultaneously. Stylization. In the 2D domain, Elasticurves [Thiel et al. 2011] intelligently neaten input strokes based on velocity data, but are only able to produce a single style of smooth result. The curve analogies framework of Hertzmann et al. [2002] could apply arbitrary stylizations to input curves, by learning variations from pre-existing input-output curve pairs. Moreover, our approach for trajectory modification relies on a library of output-only exemplars, rather than input-output pairs. Both approaches depend on explicitly and narrowly defined relationships between stroke shape and width, and do not support additional pose DOFs as needed for a virtual brush model. Specifically targeted towards digital painting, Okabe et al. [2005] apply realistic brush strokes to curves, by first acquiring videos of the changing shape of real brushes during strokes, and then training an HMM to generate the appropriate footprint based on the user?s curves. Handwriting. Our approach of learning and then reproducing the brush pose styles of real artists also bears similarities to a branch of biometrics research concerned with handwriting verification and synthesis. In the extreme, Plamondon [1995] developed a kinematic theory of rapid human movements that was used to synthesize stroke trajectories with properties similar to natural motions. Beyond 2D trajectories, Franke et al. [2005] created a handwriting robot that holds a pen at a static orientation but can vary pressure throughout a stroke, to create very convincing signature forgeries. Yu et al. [2004] consider hardware that acquire 5D input including pressure and 2D tilt, but only for the purposes of writer identification, and not synthesis. Each 6D sample contains 2D position x = x, y and 4D pose h = ?, ?, ?, ? comprised of pressure ?, tilt ?, ? and rotation ?. We refer to trajectory T as a sequence of sample positions T = {x i }, and pose H as the corresponding hand pose sequence H = {h i }. After capture, we resample each stroke uniformly in arc length (roughly 1 pixel spacing in 2000x2000 images). Our system takes those recordings as input and builds a collection of 6D strokes that we call library L. Each library stroke L ? L consists of a set of position and pose samples, L = {x i , h i }. This project relies on several assumptions. The first is that shapes of strokes used in handwriting (for example) are part of the ?style? of a given artist; different examples of similar shapes like loops or ?v? shapes will be more consistent from the same person as compared with examples from other artists. This assumption is widely accepted. For example, it forms the basis for forensic handwriting analysis. We rely on this assumption for the trajectory synthesis method presented in Section 4. But we also make a second assumption that is less well studied?that artists? hand poses are determined by their target trajectories, with some variance. An artist drawing the same shapes (with the same intention) multiple times tends to select poses from the same pool of possible gestures. This implies that given a stroke L with trajectory T, if we find other strokes with similar trajectories their poses should have similar statistics as T. This observation forms the underpinnings of the example-based pose synthesis methods presented in Section 4. Therefore, to verify our pose assumption, we conduct a correlationbased analysis on the recorded library data, investigating how well the pose attributes are correlated between stroke patches with similar shapes. For each sample i in each stroke L ? L, we construct a patch t i centered at sample i and composed of neighboring samples t i = {x j | n ? |i ? j|}. For a stroke with m samples, we have a total of m ? 2n overlapping patches, each of size 2n + 1. The size n provides a notion of what we mean by ?local? and through moderate trial and error we found n = 12 to work well; we use this value throughout our experiments. For each patch t i ? L we construct a simple feature vector F i as the vector of local tangents at every sample, concatenated with a pair of coordinates x ? i , x + i that indicates whether the sample is near the beginning or end of the stroke (described fully in Section 4.1). Next for each patch t i we find the most similar patch t c from a different stroke within the library, measured by the L 2 distance F i ? F c . We reject all pairs of patches whose distance is larger than a threshold (the mean feature distance over all pairs of patches). To aggregate across multiple patch pairs and multiple pose attributes, we convert Pearson?s r coefficients into Fisher?s z coefficients, compute the average, and then convert the result back into Pearson?s r [Silver and Dunlap 1987]. As a baseline comparison, we also find random pairs of patches of the same size 2n + 1 within the library and calculate the correlation among them. Figure 3 summarizes our findings. The bar chart shows that within libraries written by the same person, pose sequences of random pairs of patches are not well correlated whereas pose from strokes with similar trajectories have high correlation. The blue bars report aggregate correlation within the library shown in Figure 2b . Red bars are for a different library from the same artist, and green shows correlation between those two libraries. The matrix on the right shows the same correlation analysis described above, comparing all pairs from a set of nine libraries (three by each of three artists). The block diagonal (same artist) exhibits obviously higher values than the off-diagonal (different artists). Of course even within the same library, correlation is not perfect (r < 1) for at least three reasons. (2) Pairs of similar patches do not have exactly the same trajectories. (3) The same artist exhibits some variation in hand pose, even when following the same path multiple times. The degree of variance depends on the individual and to some extent the artist?s skill. Pose data from novice users tends to exhibit less consistency. Three of our five volunteers have more than two years of experience with a stylus (Artists A-C in Figure 3 ) while the other two are less experienced and have correlation statistics around 0.5?still higher than typical correlation between different artists (off-diagonal). Observe that the same shapes drawn at different moments on different parts of the tablet exhibit similar pressure progressions, although there is variation. One of the prominent factors is the position of the stroke on the tablet. This is to be expected based on body kinematics, because the pen pose changes when the person moves his hand from one position to another. This factor can have an observable effect. As an extreme example, Figure 4b shows that the rotation of the pose is strongly related to the position of the stroke, at least in this library where the range from blue to red is roughly 50 ? . We model the pose attributes at sample i, for example rotation ? i , as a sum of two components: (1) local variation intended by the artist ? i , and (2) a positional component ?(x i ). We observe that the the local variations are fairly uniformly distributed and may be viewed as noise relative to the more global positional signal. Therefore we approximate ?(x i ) by a quadratic polynomial over the coordinates of x i , and perform a simple least squares fit to find the coefficients of the polynomial. Then we can remove the approximate positional influence simply by subtracting the polynomial from ? i , but adding in its place the average value. Figure 4c shows the result, with a range of roughly 20 ? . We find that tilt tends to vary by position the way rotation does, but pressure is more consistent. Positional influence varies from library to library. Nevertheless, we have not found these effects to have a strong impact on the visual quality of the synthesis results. Therefore, our libraries have not been modified using the regression fit for any of the results that follow. Here we note a few general observations we found when studying the data in the example libraries supplied by our artists: ? Continuity. Pose tends to change smoothly along strokes. ? Directionality. ? Gravity. ? Endpoints. Special care must be taken for the beginnings and endings of strokes because the physical act of drawing makes these parts look different from the middle of the path. Data analysis in Section 3.1 tells us strokes with similar trajectory are drawn with similar hand pose. The synthesis algorithm operates on a stroke by stroke basis, processing each stroke in isolation, so inter-stroke effects are not considered. In an interactive painting program, on mouse-up after a stroke is drawn, the synthesis algorithm is run and the new stroke replaces what the user drew (in a fraction of a second for typical strokes). In both handwriting and line drawings, the hand pose attributes themselves do not fully represent an artist?s style. Given a query trajectory that might be drawn with the shaky hand of an amateur user, we can find a new trajectory that follows the user?s overall intention but has the style and expertise of the artist who drew the library. This application relies on the same algorithm developed for pose hallucination. We replace the query trajectory with similar, but not identical, patches from the library (striking a balance between following query intent and preserving library style). These stages are: computing feature vectors (Section 4.1), selecting approximate nearest neighbors (Section 4.2), and post processing (Section 4.3). Figure 5 offers a concise overview of these stages and implementation options. Our process begins with an offline step, where for each sample in the library we compute a feature vector that describes the local shape, using either shape contexts (Section 4.1.1) or filtered velocities (Section 4.1.2). Then online, for a given query stroke, synthesis\n          Preprocess: ? Compute feature vectors for library samples: (?4.1) ? shape contexts (?4.1.1) choice ? filtered velocities (?4.1.2) Online: ? Compute feature vectors for queries, as above (?4.1) ? Find k nearest neighbors (k-NN) of each sample (?4.2) ? Select neighbors from k-NN for synthesis: ? closest neighbor (?4.2.1) choice ? weighted average (?4.2.2) ? optimal sequence (?4.2.3) ? Post process: ? for optimal: transition blending (?4.3.1) ? for trajectory: shape optimization (?4.3.2) begins by computing feature vectors for the query samples, and then searching for similar features in the library. The pose attributes at the start or end of a stroke have different distributions than those in the middle (Section 3.3). We define the scalar x ? i = min(1, d/d h ) where d is the arc length distance to the start of the stroke and d h is the size of our recent history window. Likewise we have x i + measuring distance to the end of the stroke relative to the future window. These values are clamped such that the interiors of the strokes are undifferentiated. Putting this all together we have feature vector F i : F i = {x ? i , x i + , W {f j } | j} (1) where {f j } is the set of shape features and W is a weight that balances between the relative importance of shape features versus end features. The next two subsections consider alternatives for the shape features. Introduced by Belongie et al. [2001], a shape context is a logpolar histogram of sample positions on the curve, relative to the current sample. We have adapted a variant that performs well for our application, with two modifications. Second, we further divide these into two separate histograms, one for history and one for future; this division allows us to distinguish, for example, a stroke drawn left to right versus right to left. In our experiments we have used from 25 to 40 history and future samples each, depending on the data set. Here we describe a feature vector that is based on velocity rather than shape. We use the sample velocities {v i }, where v i = x i ? x i?1 , v 0 = 0. A na?ve implementation of the feature vector would have each tap correspond directly to a velocity sample from the stroke: f j = v j . Instead, each filter tap is obtained by history f i future applying a discrete triangle filter to the } } velocity samples, f j = w k v k , where (i w k ? are N ) the ? j triangle ? (i + filter M ) taps. weights, N and for stroke path M are the number of history and future taps, respectively. The triangle filters overlap so that the start index and the end index of a triangle are the center indices of the adjacent triangles, which ensures that all the weights applied to a single velocity sample in a feature vector sum to one. The filter width increases exponentially with distance from sample i, which means individual samples that are distant contribute relatively less to the feature vector. When synthesizing the query samples near the start or the end of the query stroke, some of the feature taps will cover hypothetical samples that are outside of the query stroke. In that case, we only average the velocity of the samples that are valid. If all the samples under a triangle centered at j are located outside of the valid range, then we use f j = 0. Using triangle filters reduces the dimensionality of the feature vector needed to represent a large local neighborhood and filters out noise present in the raw samples. Results in this paper use triangle filters with equal sized history and future windows M = N = 7. We also use a weight W = 0.3 balancing shape features against endpoint features. In our experiments we have found the method to be relatively insensitive to these parameters, and robust through a broad range. Section 6 discusses the relative merits of the two feature vectors we investigated. Once we have computed a feature vector for each sample in a query stroke, we find its k nearest samples in the library as potential samples for synthesis. Therefore, we resort to algorithms for finding approximate k nearest neighbors, the output of which we have found acceptable in the stages that follow. We experimented with two algorithms, the FLANN implementation of Muja and Lowe [2009], and an adaptation of the PatchMatch algorithm of Barnes et al. [2011]. The PatchMatch approach requires a straightforward modification to search over the 1-D domain of samples, and we found that with our data the algorithm converges to a reasonable approximation in ? 5 passes (as Barnes et al. found for image patches). Overall, the two approaches offer roughly equivalent performance for equivalent quality of output. The major tradeoff between the methods is that FLANN expends time and memory to build auxiliary structures during the offline library construction phase; on the other hand PatchMatch is only efficient when processing the entire query stroke at once and therefore is not suitable for on-the-fly synthesis during stroke input. Once we have the k neighbors (k-NN) for each query sample i, the next step is to synthesize a new sample {x i , h i } from them. That is, just use the closest neighbor  to the query sample. Suppose library sample L j is the 1-NN of query sample Q i . For strong coherence we want L j+1 to be the 1-NN of Q i+1 , which is only sometimes true (and it becomes more rare as the library size grows). Nevertheless, we retain this case for comparison with the other methods in Section 5. Moreover, this case may be thought of as a stand-in for the general non-parametric texture synthesis approaches following that of Efros and Leung [1999]. In particular, we also experimented with choosing randomly among the k-NN, and also the variant proposed by Ashikhmin [2001] (which probabilistically chooses L j+1 in the scenario above). However, in our experiments, none of these led to results as coherent as those of the methods that follow. Given k neighbors n j , with distances d j from the query sample in feature space, we synthesize a sample as their weighted average using weights 1/d j . This produces consecutive samples that vary smoothly, creating a continuous output stroke. However, the library typically contains many similar strokes (say multiple versions of the letter ?a?), each with slightly different pose and trajectory. The weighted average method therefore generates a stroke that is a compromise among the distinctive features of the library strokes, not quite reproducing any of them well. The result is that this method produces strokes that tend to be smoother than the artist?s style. Both closest neighbor and weighted average are local solutions that have difficulty reproducing the smoothness and distinctiveness of the artists? style. To achieve both of these qualities, we propose a (per-stroke) global optimizing solution, which we solve using dynamic programming for efficient computation. One goal of the optimization is to select a few long segments of library strokes (sequences of near-consecutive samples) to be matched to segments of the query ( Figure 6 ), avoiding many potential discontinuities. We optimize for the sequence of transition indices {c i = a i , b i | i = 1, 2, ? ? ? , s} by minimizing a total synthesis cost over the s samples in the query stroke. For the i-th query sample: a i is the index of the selected library stroke, and b i is the index of the selected sample on stroke a i . We seek the optimal sequence {C i } that minimizes the sum of four error terms, e f , e t , e s , and e m . These terms address, respectively, matching features, choosing good transitions between segments, avoiding short segments, and matching stroke endpoints?discussed below. Matching Features. The term e f simply sums (over all query samples i) the distance in feature space to the selected neighbor c i . If all other terms in the optimization had no impact then this term would drive the solution to the closest neighbor selection method (Section 4.2.1). However there is typically a different neighbor among the k-NN that is almost as good as the closest neighbor and that has other desirable properties that would cause it to be selected over the closest neighbor, based on the terms that follow. Transition Penalty. The term e t encourages using fewer segments. For consecutive query samples, we encourage selecting samples that are consecutive on a library stroke, since they have natural coherence in the hand pose attributes and capture the local style. If that is not possible for other reasons, we still encourage repeating the same library sample once, or skipping exactly one library sample?policies that allow the library segment to be stretched or shrunk to match the query. Otherwise we call the transition a jump, and assign a penalty that includes both a large constant cost and a cost based on pose discontinuity at the jump location. According to the policies above there are four cases: 1. Consecutive: If a i = a i+1 and b i+1 = 1 + b i , then e i t = 0. One repeat: If a i = a i+1 and b i+1 = b i and b i = b i?1 , then e i t = C r , the cost of stretching. One skip: If a i = a i+1 and b i+1 = 2 + b i , then e i t = C s , the cost of shrinking. Jump: Otherwise, e i t = C t + C p h c i ? h c i+1 , the cost of a jump with deeper penalty for large pose discontinuities. We use C r = 3, C s = 3, C t = 50, and C p = 10. Rather than penalizing pose difference at the jumps, we penalize direction changes. The term e i t becomes: 4b. Trajectory jump: e i t = C t + C p 1 ? v c i ? v c i+1 where v c i is the normalized velocity of sample b i in library stroke a i . Short Segment Penalty. We find that short segments often lead to visual discontinuities in the synthesized result. To avoid them we impose a penalty e s taken as the sum of (C l + (L min ? l i )) 2 over all segments of length l i < L min . In our experiments, we use C l = 3 and L min = 12 samples. Endpoint Penalty. As noted in Section 3.3, ends of strokes have unique characteristics. Therefore we prefer where possible to synthesize the beginning of a query stroke with the beginning of of a library stroke, and the same for ends. We impose a penalty term e m = C e ((b 1 ? 1) + (s ? b s )) where b 1 is index of the neighbor selected for the first sample, b s is the index for the last query, and s is the number of samples in the library stroke a s . This term essentially measures how far the neighbors selected for the ends of the query are from the ends of their respective strokes. C e is the cost of not matching endpoints, which we set to C e = 3. Optimization. We solve the optimization with dynamic programming over a transition table with k rows for the k-NN by n columns for the stroke samples. To fill each entry in column i, we consider all the entries in i ? 1. Once full, we recover the optimal sequence by selecting the lowest cost path through the table. After selecting a sequence of neighbor samples, we post-process them to create the final stroke data. For the case of optimal neighbor selection we apply transition blending, and for the case of trajectory synthesis we perform shape optimization, both discussed below. The optimal sequence method (Section 4.2.3) can still have discontinuities at the jump locations, despite the penalty term e i t that  attempts to minimize them. Therefore, we employ blending to remove remaining artifacts. We gather as many as 6 samples (if they exist) on either side of the jump from both library strokes that abut the jump, and perform a simple cross fade between their attributes (pose and/or trajectory) in this overlap region. When synthesizing trajectories, the result can ?drift? away from the query shape, so we correct it using shape optimization. Suppose T = {x i } is the input query trajectory. If we simply integrate the synthesized velocity V = {v i } starting from the position of the first sample x 1 , we get a new trajectory that looks like the library, but deviates from the query ( Figure 7a black vs. blue). We therefore design a simple linear optimization that attempts to simultaneously preserve the synthesized shape while matching a few key features of the query. We place the first type of anchor point a few samples from the start and end locations (blue dots in Figure 7b ). Second, we add locations with very rapid change in orientation, as follows. For each query sample, we calculate the stroke turning angle in a local window. We find all local maxima above a threshold angle (we use 60 ? ) and call them angle points (magenta dots). The added vertices of the polylines are the third kind of anchor point (green dot). Next we set up a system of equations composed of three constraints, each of which we wish to satisfy in a least-squares sense, in order to construct the final curve (red in Figure 7c -d). The first constraint attempts to match the final velocities v i to the synthesized velocities v i . To avoid second order discontinuities induced by optimization at the anchor points, the third constraint attempts to match the local curvature of the result to that of the synthesized velocities, near the anchors. With known synthesis velocities v i and query positions x i we seek the unknown positions x i via a system of equations: s 0= ( v i ? v i ) 2 (2) i=1 0 = C a ( x i ? x i ) 2 (3) i?A j=i+? 0 = C k (?( x j ) ? ?(x j )) 2 (4) i?A j=i?? Handwriting pose synthesis. Query strokes (a) are ground truth strokes (b) without the pose data. (c) Our synthesis results are visually indistinguishable. (d) Applying another artist?s style yields characteristically different visual appearance. The set A contains the indices of the anchor points. ? is the number of surrounding samples involved in the second order constraints. In our experiments, we use ? = 2, C a = 0.25, and C k = 2. The output of our synthesis process so far is a sequence of poses and/or trajectories that can drive a virtual brush model. However, our pose synthesis framework uses trajectory as input. If both pose and trajectory are being synthesized, the algorithm can be run in either one or two passes. In the one pass version, the query trajectory is used to directly synthesize both the pose and new trajectory and thus the combined output does not have ideal correlation. In the two pass version, first the input stroke is used to synthesize a new trajectory, and then that output trajectory is used to synthesize pose data, which creates a data dependency but produces better correlation. Another advantage to the two-pass version is that it allows us to use separate parameters for synthesizing trajectory and pose. For example we generally tune for fewer segments in trajectory synthesis than in pose synthesis in the two-pass case. The running time of our synthesis algorithm is sublinear with the number of library samples, due to the approximate k-NN search. We found through experimentation that 150 strokes is sufficient for generating plausible results, and confirmed this through correlation analysis similar to that of Section 3. For such a library, the average running time for both pose and trajectory synthesis is 0.08 seconds per stroke. We experimented with ?enriching? the library up to about 1000 strokes by including the same strokes scaled to different sizes (?50%), to increase matching scale-invariance, but did not see a significant improvement, and performance was reduced. We also tried using very small (fewer than 10) and very large (more than 500) libraries. With small libraries, feature matching cannot find similar enough trajectories and therefore picks random strokes to copy. Since the optimal sequence algorithm encourages long segments, the pose results still look plausible, but for trajectories, poor matches may result in complete loss of semantics in the results. Large libraries do not affect pose synthesis, whereas  trajectory modification is more likely to find very similar patches to the query, reducing the effect of style transfer. All the results shown here are rendered using Adobe Photoshop?s bristle brush tool [DiVerdi et al. 2010] with the same brush settings. The differences in the synthesized pose data induce the visibly different shape and texture of the strokes. Figure 8 shows the plausibility of pose synthesis on handwriting. An artist?s 6-DOF strokes are stripped of their pose data and the trajectories are used as queries with the same artist?s library applied. The synthesized output is visually indistinguishable from the ground truth, whereas applying another artist?s library creates a visually distinct result. Pose synthesis on line drawings is demonstrated in Figure 9 . Examples of trajectory stylization are in Figure 15 . We show robustness to noisy input and the utility of trajectory stylization by demonstrating how it can neaten mouse-written text, which has characteristic shakiness. Our algorithm can also apply stylistic flourishes such as serifs or block lettering. Figures 1, 14, and 15 show the two-pass algorithm stylizing both pose and trajectory. The remainder of this section describes the studies we conducted to evaluate our results. As a quantitative measure of the pose synthesis quality, we computed the correlation between the synthesized results and ground truth. However, there is no equivalent measure for trajectory synthesis and ultimately we care most about how users judge our results. Therefore, we also conducted user studies on both pose and trajectory synthesis. Section 3.1 shows that an artist exhibits some natural variation in hand pose even when drawing the same path multiple times. Therefore, there is no ?gold standard? that we can compare our synthesis results against?L 2 measurement of reconstruction error against the ground truth is not a good indication of success. Correlation on the other hand is a better evaluation metric in this case. For pose synthesis, we can apply analysis similar to Section 3.1 to evaluate our results. If the style of the library is successfully transferred onto the query strokes, every local patch of the output should have a sim- (a) ground truth (b) optimal (c) weighted average (d) closest (e) transfer 1 (f) transfer 2 ilar pose profile to similar patches in the library. We compared the closest neighbor, weighted average, and optimal sequence variants of our algorithm (Section 4.2). Figure 10 contains the correlation results. It shows that the optimal algorithm achieves the highest pose correlation in both synthesis cases. Furthermore, since we have ground truth pose data for the query strokes, we compare them to the synthesis and find they are not well correlated, as expected. Note that we have no analogous quality measure for trajectory synthesis because the goal is a blend of local features with global shape, and a fair objective function is more difficult to formulate. We conducted two user studies with the goal of evaluating whether a user can distinguish between our results and ground truth. Both studies use the same methodology; only the images are different. Study Design. We show the subject three lines of English text from an artist?s library?the exemplar (we used two libraries from each of the artists shown in Figure 2a -b). Below the exemplar appear two test images containing the same (3-9 letter) phrase?one ground truth originally written by the artist, and one forgery synthesized by one of our algorithms. The subject is instructed that one image is an ?original? and the other is a ?forgery,? and is asked to identify the original by comparing both with the exemplar. In the pose study, the ground truth and forgery have the same trajectory ( Figure 11 ). In the trajectory study, the ground truth trajectory is used for synthesis, and pose data is omitted from all images ( Figure 12 ). One trial consists of 26 such tasks (each with the same exemplar) comparing (a) a random ground truth phrase, and a forgery selected from one of five conditions: (b) optimal sequence, (c) weighted average, (d) closest neighbor, (e) style transfer, and (f) style transfer for validation. Conditions (b-d) are the algorithms being tested, whereas (e-f) are baselines that synthesize the forgery with another artist?s library (so should be very easy to identify). Of the 26 tasks, four are from each of (b-e) and ten are from (f), randomly shuffled. For any particular subject, (e-f) are selected from two different library styles, randomly. We only retain data from a trial\n          correct / count (%) method pose study trajectory study average 153 / 322 (48%) 96 / 302 (32%) optimal 169 / 316 (53%) 172 / 305 (56%) closest 269 / 304 (88%) 220 / 292 (75%) transfer 293 / 301 (97%) 274 / 288 (95%) (a) ground truth (b) optimal (c) weighted average (d) closest (e) transfer 1 (f) transfer 2 when 9 out of 10 of the validation conditions (f) are correct, so we know the user understands the task and is actually trying to succeed (p = 0.01). Then style transfer results are only reported for (e). Our studies were restricted to US-only workers who were paid $0.20 per task (a ?HIT? containing the 26 comparisons, which they typically completed in a few minutes). Across the two studies, 70 workers completed a total of 214 HITs. Subjects were allowed to complete as many as 10 HITs per study, but most workers did just one. For cases where a particular pair was repeated by a particular worker due to the randomized selection, we only retained the first such response, for total of 4,170 responses. Study Results. The results are reported in Table 1 as the frequency with which the ground truth was correctly identified. A Bonferroni corrected, randomized permutation test on the distributions for each consecutive pair of rows in the table shows that they are different with statistical significance (p 0.01) except in the case of the average and optimal conditions in the pose study (p = 0.34). The ideal forgery is indistinguishable from ground truth so subjects will choose randomly, resulting in a correct answer near 50% of the time. When the forgery is easy to identify ( Figure 12e ), we expect scores near 100%. The transfer condition is near 100% in both studies, which shows people can perform the task in easy cases. People tend to identify the closest method (88% and 75%), so it is generally implausible. In the pose study, average and optimal are both near 50%, and therefore plausibly synthesize pose data. Optimal performs well in the trajectory study, but average is significantly below 50% which means subjects tend to incorrectly identify the forgery as the ?original. ? As mentioned in Section 4.2.2 the weighted average method produces a very smooth output trajectory, and we believe people have a bias towards smoother curves. In such cases people choose average over ground truth, even though it is actually smoother than the exemplar and thus fails to mimic the exemplar?s style. Many of our results are handwriting samples, though we do not make special accommodations for them, because handwriting provides an easy to understand and readily available source of data. Handwriting is uniquely stylized by the writer?s hand pose, the local trajectory variations, and the global features such as slant angle. Handwriting also provides readily-evaluated test sets; in contrast, it is more difficult to measure performance on strokes in a drawing. We consider that the pose and local trajectory are stylistic results of motor reflexes, whereas the global shape is intentional. Our algorithm attempts to transfer style but maintain intent (via the trajectory shape optimization). Similarly, while an artist?s style may consistently place higher weight on strokes in a drawing that are nearer to the viewpoint, we do not attempt to model these variations. In this way, we provide the most general result possible. We examined both shape contexts and filtered velocities for feature vectors. Our results use filtered velocities, though it is difficult to say which is absolutely better. Figure 13 shows their limitations. Filtered velocities tend to perform very well, but can sometimes get ?confused? and match a letter to a different but similar letter. Shape contexts have fewer of these errors, but have difficulty balancing local style transfer with global shape, resulting in output that appears less plausible and noisy. Also it is generally more difficult to select parameters for shape contexts, whereas filtered velocities are more robust through a broader range of settings. Finally, to get high quality results, the shape contexts need to have more dimensions (see Section 4.1.2) and this impacts performance. We also compared strategies for choosing among nearest neighbors: closest neighbor, weighted average, and optimal sequence. The result of our pose evaluations is that quantitatively, optimal sequence is best, but to the casual observer, weighted average is as effective. However, careful inspection can reveal subtle differences between the two (e.g. Figure 11b -c). For trajectory synthesis, weighted average is obviously more smooth, and in some cases too smooth. The advantage weighted average has over optimal sequence is that it does not require the query stroke be completed before it begins synthesizing, so it can be used in an ?on-the-fly? implementation that synthesizes pose data while the user is still creating the stroke. Otherwise, optimal sequence results in the highest quality output. Finally, our approach does not require hand-drawn input. The method applies to any kind of 2D path, such as B?zier curves (see Figure 14 ). The paths are first sampled uniformly in arc length and then treated as constant-velocity brush strokes by our unmodified algorithm. This approach would also work for lines extracted from 3D models or other automatic processes. Limitations and Future Work. Our algorithm considers each stroke independently, but artistic styles also include interactions among nearby strokes, both temporally and spatially, which we hope to model in future work. Our results are all rendered by Adobe Photoshop?s bristle brush, which uses all 6-DOF of the stroke data. However the visual impact of each DOF may not be as obvious as it would be with a real physical brush. Because our algorithm only generates stroke data, it can be used with any digital paint engine, so other brush simulations may be able to use the data more effectively. Figure 13 highlights some trajectory synthesis failures where the query shape was poorly matched by our algorithm. Our approach is local and has no higher-level notion of intent on the part of the artist. While the cognitive process is too complex to model there may be some intermediate levels that could help. Moreover, these failures could be addressed in our current framework by choosing different parameter settings. Our approach works well, especially for pose synthesis for a broad range of settings, but finding the ideal values for an arbitrary problem is difficult. Finally, we treat the artist?s library as a single monolithic style. In practice, artists may choose among multiple styles, even in a single drawing. A style is really more multi-modal than is characterized by our process. We can partially address this issue by offering the user the choice of different styles, but finding an effective interface for this remains an interesting problem. More challenging would be to try to characterize the multi-modal nature within a library. Conclusion. This paper presents a data-driven approach for synthesizing plausible pose data that can be used to generate expressive handwriting and line drawings. The same framework can also be used to transfer stroke trajectory style. Acknowledgements. We thank the anonymous volunteers who contributed both writing samples and drawings to this project. This research was sponsored in part by Adobe Corporation and conducted in conjunction with the Intel Science and Technology Center Visual Computing. E FROS , A., AND L EUNG , T. 1999. Texture synthesis by nonparametric sampling. In International Conference on Computer Vision, 1033?1038. F RANKE , K., S CHOMAKER , L., AND K OPPEN  ? , M. 2005. Pen force emulating robotic writing device and its application. In Workshop on Advanced Robotics and its Social Impacts, 36?46. G OODWIN , T., V OLLICK , I., AND H ERTZMANN , A. 2007. Isophote distance: a shading approach to artistic stroke thickness. In Non-Photorealistic Animation and Rendering, 53?62. H ERTZMANN , A., O LIVER , N., C URLESS , B., AND S EITZ , S. 2002. Curve analogies. In Eurographics Workshop on Rendering, 233?246. H INTON , G., AND N AIR , V. 2005. Inferring motor programs from images of handwritten digits. In Advances in Neural Information Processing, 515?522. H OUSE , D., AND S INGH , M. 2007. Line drawing as a dynamic process. In Pacific Graphics, 351?360. H SU , E., G ENTRY , S., AND P OPOVI C  ? , J. 2004. Examplebased control of human motion. In Symposium on Computer Animation, 69?77. K OVAR , L., G LEICHER , M., AND P IGHIN , F. 2002. Motion graphs. In SIGGRAPH, 473?482. M C C RAE , J., AND S INGH , K. 2009. Sketching piecewise clothoid curves. In Sketch-Based Interfaces and Modeling. M C C RAE , J., AND S INGH , K. 2011. Neatening sketched strokes using piecewise french curves. In Sketch-Based Interfaces and Modeling, 141?148. M UJA , M., AND L OWE , D. G. 2009. Fast approximate nearest neighbors with automatic algorithm configuration. In Internat. Vision Theory and Application, 331?340. O KABE , Y., S AITO , S., AND N AKAJIMA , M. 2005. Paintbrush rendering of lines using HMMs. In GRAPHITE, 91?98. P LAMONDON , R. 1995. A kinematic theory of rapid human movements. Biological Cybernetics 72, 295?320. S AITO , S., K ANI , A., C HANG , Y., AND N AKAJIMA , M. 2007. Curvature-based stroke rendering. Visual Computing 24 (November), 1?11. S CH ODL  ? , A., S ZELISKI , R., S ALESIN , D. H., AND E SSA , I. 2000. Video textures. In SIGGRAPH, 489?498. S ILVER , N., AND D UNLAP , W. P. 1987. Averaging correlation coefficients: Should fisher?s z transformation be used? Journal of App. 72(1), 146?148. T HIEL , Y., S INGH , K., AND B ALAKRISHNAN , R. 2011. Elasticurves: exploiting stroke dynamics and inertia for the real-time neatening of sketched 2D curves. In User Interface Software and Technology, 383?392. V ANDOREN , P., V AN L AERHOVEN , T., C LAESEN , L., T AELMAN , J., R AYMAEKERS , C., AND V AN R EETH , F. 2008. IntuPaint: Bridging the gap between physical and digital painting. In Horizontal Interactive Human Computer Systems, 65?72. V ARGA , T., K ILCHHOFER , D., AND B UNKE , H. 2005. Templatebased synthetic handwriting generation for the training of recognition systems. In Conference of the International Graphonomics Society, 206?211. W EI , L.-Y., L EFEBVRE , S., K WATRA , V., AND T URK , G. 2009. State of the art in example-based texture synthesis. In Eurographics 2009, State of the Art Report. Y U , K., W ANG , Y., AND T AN , T. 2004. Writer identification using dynamic features. In Biometric Authentication, D. Zhang and A. Jain, Eds. 3072 of Lec. Notes in Comp.",
  "resources" : [ ]
}