{
  "uri" : "sig2009-a25-vergne_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2009/a25-vergne_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Light Warping for Enhanced Surface Depiction",
    "published" : "2009",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Romain-Vergne",
      "name" : "Romain",
      "surname" : "Vergne"
    }, {
      "uri" : "http://drinventor/Romain-Pacanowski",
      "name" : "Romain",
      "surname" : "Pacanowski"
    }, {
      "uri" : "http://drinventor/Pascal-Barla",
      "name" : "Pascal",
      "surname" : "Barla"
    }, {
      "uri" : "http://drinventor/Xavier-Granier",
      "name" : "Xavier",
      "surname" : "Granier"
    }, {
      "uri" : "http://drinventor/Christophe-Schlick",
      "name" : "Christophe",
      "surname" : "Schlick"
    } ]
  },
  "bagOfWords" : [ "final", "stage", "we", "system", "render", "3d", "object", "arbitrary", "material", "illumination", "while", "take", "account", "way", "environment", "lighting", "must", "warped", "each", "surface", "point", "we", "illustrate", "approach", "photorealistic", "well", "nonphotorealistic", "scenario", "both", "real-time", "off-line", "renderer", "we", "first", "reformulate", "reflect", "radiance", "equation", "take", "light", "warping", "account", "where", "surface", "point", "viewpoint", "direction", "incoming", "lighting", "direction", "sphere", "direction", "brdf", "warping", "function", "define", "section", "we", "clamp", "light", "direction", "-lrb-", "both", "original", "warped", "-rrb-", "hemisphere", "direction", "around", "way", "similar", "clamp", "do", "when", "use", "bump", "normal", "map", "discretization", "equation", "may", "raise", "performance", "quality", "issue", "though", "indeed", "common", "sample", "light", "source", "pre-process", "reduce", "noise", "result", "-lrb-", "e.g.", "kriv?nek", "Colbert", "-lsb-", "2008", "-rsb-", "-rrb-", "however", "since", "light", "warping", "different", "every", "point", "approach", "become", "intractable", "equation", "enable", "pre-sampling", "light", "source", "we", "re-write", "substitute", "-lrb-", "-rrb-", "where", "jacobian", "-lrb-", "see", "supplemental", "material", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-lrb-", "-rrb-", "-rrb-", "we", "implement", "light", "warp", "approach", "different", "renderer", "both", "case", "we", "use", "ashikmin?s", "brdf", "model", "-lsb-", "ashikhmin", "et", "al.", "2000", "-rsb-", "we", "real-time", "rendering", "system", "evaluate", "equation", "use", "pre-sampled", "environment", "light", "however", "avoid", "compute", "visibility", "information", "ignore", "indirect", "illumination", "Figure", "show", "how", "shape", "input", "3d", "object", "enhance", "two", "different", "illumination", "setting", "system", "note", "how", "enhancement", "remain", "coherent", "while", "pattern", "reflect", "lighting", "completely", "different", "each", "image", "indeed", "only", "cue", "we", "provide", "here", "deformation", "pattern", "additional", "real-time", "capture", "use", "render", "system", "show", "supplemental", "video", "we", "off-line", "rendering", "system", "we", "compute", "full", "global", "illumination", "result", "equation", "indirect", "lighting", "equation", "direct", "lighting", "use", "we", "path", "tracer", "-lsb-", "dutr", "et", "al.", "2006", "-rsb-", "apply", "light", "warp", "only", "first", "ray", "bounce", "we", "also", "implement", "warped", "ambient", "occlusion", "use", "diffuse", "material", "after", "be", "warped", "light", "ray", "have", "different", "visibility", "change", "visibility", "enhance", "shape", "best", "see", "supplemental", "result", "rendering", "show", "Figure", "where", "shape", "same", "input", "3d", "object", "enhance", "each", "configuration", "again", "surface", "feature", "enhance", "matter", "material", "characteristic", "we", "also", "experiment", "purely", "reflective", "refractive", "material", "show", "supplemental", "material", "complexity", "we", "light", "warp", "approach", "linear", "number", "sample", "light", "direction", "practice", "apply", "warping", "function", "negligible", "global", "illumination", "decrease", "frame", "rate", "50", "direct", "illumination", "however", "we", "still", "get", "real-time", "frame", "rate", "practice", "instance", "result", "Figure", "obtain", "37", "fp", "800", "600", "use", "54", "light", "finally", "we", "experiment", "non-photorealistic", "rendering", "technique", "use", "we", "light", "warp", "approach", "order", "exaggerate", "enhancement", "obtain", "light", "warping", "we", "incorporate", "curvature-dependent", "contrast", "enhancement", "exaggerated", "reflect", "radiance", "give", "where", "-lsb-", "-rsb-", "contrast", "parameter", "when", "both", "other", "case", "contrast", "increase", "depend", "curvature", "warping", "magnitude", "when", "apply", "object", "diffuse", "material", "minimal", "illumination", "method", "come", "close", "mean", "curvature", "shade", "technique", "-lsb-", "Kindlmann", "et", "al.", "2003", "-rsb-", "Figure", "show", "effect", "use", "equation", "we", "real-time", "renderer", "both", "natural", "minimal", "illumination", "we", "also", "apply", "stylized", "quantization", "algorithm", "-lsb-", "winnem?ller", "et", "al.", "2006", "-rsb-", "both", "rendering", "show", "how", "very", "same", "warped", "lighting", "able", "enhance", "stylized", "shading", "end", "result", "compelling", "cartoon", "style", "work", "arbitrary", "material", "illumination", "we", "have", "present", "new", "approach", "surface", "shape", "enhancement", "call", "light", "warping", "preserve", "material", "illumination", "characteristic", "well", "stylistic", "choice", "also", "have", "number", "practical", "advantage", "over", "previous", "method", "flexibility", "respect", "input", "datum", "representation", "automatic", "well", "controllable", "levels-of-detail", "real-time", "rendering", "GPU", "future", "work", "we", "plan", "exploit", "property", "we", "local", "shape", "descriptor", "produce", "line-based", "rendering", "various", "style", "we", "believe", "exhibit", "most", "surface", "feature", "need", "create", "rich", "line", "drawing", "moreover", "we", "present", "one", "way", "perform", "light", "warping", "stereographic", "space", "we", "would", "like", "investigate", "other", "potential", "function", "particular", "we", "could", "imagine", "make", "use", "additional", "information", "explicit", "description", "environment", "illumination", "finally", "interesting", "direction", "research", "would", "study", "connection", "we", "local", "shape", "descriptor", "light", "warping", "technique", "visual", "perception" ],
  "content" : "The final stage in our system is to render 3D objects with arbitrary materials and illumination, while taking into account the way the environment lighting must be warped at each surface point. We illustrate this approach with photorealistic as well as nonphotorealistic scenarios, with both real-time and off-line renderers. We first reformulate the reflected radiance equation to take the light warping into account: where p is the surface point, e is the viewpoint direction, l is the incoming lighting direction, ? is the sphere of directions, ? is the BRDF and W is the warping function as defined in Section 5. We clamp light directions (both original and warped) to the hemisphere of directions around n, in a way similar to the clamping done when using bump or normal maps. The discretization of Equation 1 may raise performance and quality issues though. Indeed, it is common to sample light sources in pre-process to reduce noise in the results (e.g., Kriv?nek and Colbert [2008]). However, since the light warping is different at every point, such approaches become intractable with Equation 1. To enable pre-sampling of light sources, we re-write L ? by substituting l ? = W( l) to l: where J is the jacobian of W ?1 (see supplemental materials): J = 4 ? u 3 ? v 3 (1 + l z ? ) 2 ( ? u 2 ? v 2 (1 + l ? z ) 2 + ? v 2 l u ?2 + ? u 2 l ?2 v ) 2 We implemented the light warping approach in different renderers. In both cases, we used Ashikmin?s BRDF model [Ashikhmin et al. 2000]. Our real-time rendering system evaluates Equation 2 using pre-sampled environment lights; however, it avoids computing visibility information and ignores indirect illumination. Figure 1 shows how the shape of an input 3D object is enhanced in two different illumination settings with this system. Note how the enhancement remains coherent while the patterns of reflected lighting are completely different in each image; indeed, the only cue we provide here is the deformation of patterns. Additional real-time captures using this rendering system are shown in the supplemental video. In our off-line rendering system, we compute full global illumination results, with Equation 1 for indirect lighting and Equation 2 for direct lighting, using our path tracer [Dutr? et al. 2006], applying light warping only to the first ray bounce. We also implemented a warped ambient occlusion used with diffuse materials. After being warped, light rays have a different visibility; this change of visibility enhances shape as is best seen in supplemental results. Renderings are shown in Figure 8 , where the shape of the same input 3D object is enhanced in each configuration. Again, surface features are enhanced no matter the material characteristics. We also experimented with purely reflective and refractive materials as shown in supplemental materials. The complexity of our light warping approach is linear in the number of sampled light directions. In practice, applying the warping function is negligible with global illumination, but decreases frame rate by 50% with direct illumination. However, we still get real-time frame rates in practice: for instance, the results in Figure 1 are obtained at 37 fps in 800 ? 600 using 54 lights. Finally, we experimented with non-photorealistic rendering techniques using our light warping approach. In order to exaggerate the enhancement obtained by light warping, we incorporate a curvature-dependent contrast enhancement. The exaggerated reflected radiance is then given by where ? ? [?1, 1] is a contrast parameter. When both ? u = 0 and ? v = 0, L ? ? = L ? ; in other cases, contrast is increased depending on  curvature and warping magnitudes. When applied to an object with diffuse material and minimal illumination, this method comes close to the mean curvature shading technique [Kindlmann et al. 2003]. Figure 9 shows the effect of using Equation 3 in our real-time renderer with both natural and minimal illumination. We also applied a stylized quantization algorithm [Winnem?ller et al. 2006] to both renderings that shows how the very same warped lighting is able to enhance stylized shading. The end result is a compelling cartoon style that works with arbitrary materials and illumination. We have presented a new approach to surface shape enhancement called light warping that preserves material and illumination characteristics as well as stylistic choices. It also has a number of practical advantages over previous methods such as flexibility with respect to input data representations, automatic as well as controllable levels-of-detail, and real-time rendering on the GPU. In future work, we plan to exploit the properties of our local shape descriptor for producing line-based renderings in various styles, as we believe it exhibits most of the surface features needed to create rich line drawings. Moreover, we presented one way of performing light warping in stereographic space, but we would like to investigate other potential functions. In particular, we could imagine making use of additional information such as an explicit description of the environment illumination. Finally, an interesting direction of research would be to study the connections of our local shape descriptor and light warping technique with visual perception.",
  "resources" : [ ]
}