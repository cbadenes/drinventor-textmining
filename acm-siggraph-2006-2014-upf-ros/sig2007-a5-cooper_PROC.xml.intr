{
  "uri" : "sig2007-a5-cooper_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2007/a5-cooper_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Active Learning for Real-Time Motion Controllers",
    "published" : "2007",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Seth-Cooper",
      "name" : "Seth",
      "surname" : "Cooper"
    }, {
      "uri" : "http://drinventor/Aaron-Hertzmann",
      "name" : "Aaron",
      "surname" : "Hertzmann"
    }, {
      "uri" : "http://drinventor/Zoran-Popovic",
      "name" : "Zoran",
      "surname" : "Popovic"
    } ]
  },
  "bagOfWords" : [ "human", "motion", "capture", "datum", "provide", "effective", "basis", "create", "new", "animation", "example", "interpolate", "concatenate", "motion", "realistic", "new", "animation", "can", "generate", "real-time", "response", "user", "control", "other", "input", "paper", "we", "consider", "animation", "model", "we", "refer", "motion", "controller", "controller", "generate", "animation", "real-time", "base", "user-specified", "task", "-lrb-", "e.g.", "user", "might", "press", "forward", "game", "controller", "specify", "task", "walk", "forward", "-rrb-", "each", "task", "parameterize", "control", "vector", "continuous", "space", "-lrb-", "e.g.", "catch", "ball", "fly", "from", "specific", "direction", "velocity", "-rrb-", "paper", "controller", "essentially", "function", "from", "combined", "space", "state", "task", "space", "motion", "we", "controller", "kinematic", "produce", "character?s", "motion", "interpolate", "motion", "capture", "rather", "than", "produce", "motion", "dynamically", "through", "force", "torque", "Motion", "capture", "datum", "very", "time-consuming", "expensive", "acquire", "thus", "desirable", "capture", "little", "possible", "when", "build", "simplest", "controller", "designer", "can", "minimize", "common", "theme", "computer", "animation", "research", "create", "new", "motion", "from", "exist", "motion", "capture", "datum", "most", "method", "create", "animation", "off-line", "example", "interpolate", "similar", "set", "motion", "accord", "user-specified", "control", "parameter", "-lsb-", "Witkin", "Popovi", "1995", "Kovar", "Gleicher", "2004", "Mukai", "Kuriyama", "2005", "Rose", "et", "al.", "1998", "Wiley", "Hahn", "1997", "-rsb-", "optimize", "motion", "accord", "probabilistic", "time-series", "model", "-lsb-", "brand", "hertzmann", "2000", "Li", "et", "al.", "2002", "-rsb-", "concatenate", "blend", "example", "sequence", "-lsb-", "Arikan", "et", "al.", "2003", "Kovar", "et", "al.", "2002", "Torresani", "et", "al.", "2007", "-rsb-", "combine", "modeland", "data-driven", "technique", "-lsb-", "Yamane", "et", "al.", "2004", "Zordan", "et", "al.", "2005", "Liu", "Popovi", "2002", "Liu", "et", "al.", "2005", "-rsb-", "method", "generate", "motion", "off-line", "whereas", "we", "consider", "problem", "real-time", "synthesis", "worth", "note", "many", "method", "typically", "require", "large", "motion", "database", "need", "database", "could", "mitigate", "we", "active", "learning", "approach", "number", "real-time", "animation", "system", "build", "motion", "capture", "datum", "well", "one", "approach", "directly", "play", "transition", "between", "clip", "from", "motion", "database", "-lsb-", "Gleicher", "et", "al.", "2003", "Lee", "et", "al.", "2002", "Lee", "et", "al.", "2006", "-rsb-", "precomputation", "can", "use", "allow", "real-time", "planning", "which", "clip", "use", "-lsb-", "Lau", "Kuffner", "2006", "Lee", "Lee", "2006", "-rsb-", "Reitsma", "Pollard", "-lsb-", "2004", "-rsb-", "present", "method", "evaluate", "possible", "motion", "generate", "approach", "few", "author", "have", "describe", "method", "generate", "new", "pose", "response", "real-time", "input", "we", "motion", "controller", "model", "most", "similar", "method", "transition", "between", "interpolated", "sequence", "Park", "et", "al.", "-lsb-", "2004", "-rsb-", "Kwon", "Shin", "-lsb-", "2005", "-rsb-", "combine", "interpolation", "motion", "graph", "structure", "generate", "new", "locomotion", "sequence", "Shin", "oh", "-lsb-", "2006", "-rsb-", "perform", "interpolation", "graph", "edge", "simple", "model", "locomotion", "other", "repetitive", "motion", "previous", "work", "assume", "corpus", "motion", "datum", "available", "advance", "user", "manually", "select", "which", "motion", "capture", "paper", "we", "show", "how", "use", "adaptive", "selection", "motion", "sequence", "allow", "creation", "controller", "greater", "complexity", "while", "allow", "fine-scale", "parameterize", "control", "capture", "relatively", "few", "motion", "overall", "datum", "acquisition", "difficult", "expensive", "and/or", "time-consuming", "problem", "many", "discipline", "consequently", "automatic", "selection", "test", "case", "have", "be", "extensively", "study", "statistics", "optimal", "experimental", "design", "method", "seek", "most", "informative", "test", "point", "estimate", "unknown", "nonlinear", "function", "-lsb-", "Atkinson", "Donev", "1992", "Santner", "et", "al.", "2003", "-rsb-", "simplest", "method", "determine", "all", "test", "point", "advance", "e.g.", "via", "space-filling", "function", "optimize", "objective", "function", "however", "often", "possible", "determine", "advance", "which", "region", "input", "space", "need", "most", "datum", "active", "learning", "method", "select", "test", "datum", "sequentially", "after", "each", "datum", "point", "acquire", "next", "test", "point", "choose", "maximize", "objective", "function", "-lsb-", "Cohn", "et", "al.", "1994", "-rsb-", "active", "learning", "have", "be", "study", "most", "extensively", "classification", "problem", "-lrb-", "e.g.", "-lsb-", "Lindenbaum", "et", "al.", "2004", "-rsb-", "-rrb-", "paper", "we", "present", "active", "learning", "algorithm", "motion", "controller", "we", "approach", "distinct", "from", "exist", "active", "learning", "method", "two", "way", "first", "instead", "choose", "next", "sample", "capture", "we", "system", "identify", "set", "candidate", "from", "which", "user", "choose", "sample", "improve", "second", "we", "assume", "metric", "correctness", "provide", "which", "candidate", "may", "choose" ],
  "content" : "Human motion capture data provides an effective basis for creating new animations. For example, by interpolating and concatenating motions, realistic new animations can be generated in real-time in response to user control and other inputs. In this paper, we consider such an animation model that we refer to as a motion controller: a controller generates animation in real-time, based on user-specified tasks (e.g., a user might press forward on a game controller to specify the task ?walk forward,?). Each task is parameterized by a control vector in a continuous space (e.g., ?catch the ball flying from a specific direction and velocity?). In this paper, a controller is essentially a function from the combined space of states and tasks to the space of motions. Our controllers are kinematic: they produce the character?s motion by interpolating motion capture, rather than producing motion dynamically through forces and torques. Motion capture data is very time-consuming and expensive to acquire, and thus it is desirable to capture as little as possible. When building the simplest controllers, a designer can minimize A common theme in computer animation research is to create new motion from existing motion capture data. Most methods create animation off-line, for example, by interpolating a similar set of motions according to user-specified control parameters [Witkin and Popovi? 1995; Kovar and Gleicher 2004; Mukai and Kuriyama 2005; Rose et al. 1998; Wiley and Hahn 1997], by optimizing motion according to probabilistic time-series models [Brand and Hertzmann 2000; Li et al. 2002], by concatenating and blending example sequences [Arikan et al. 2003; Kovar et al. 2002; Torresani et al. 2007], or by combining modeland data-driven techniques [Yamane et al. 2004; Zordan et al. 2005; Liu and Popovi? 2002; Liu et al. 2005]. These methods generate motion off-line, whereas we consider the problem of real-time synthesis. It is worth noting that many of these methods typically require large motion databases; the need for such databases could be mitigated by our active learning approach. A number of real-time animation systems build on motion capture data as well. One approach is to directly play and transition between clips from a motion database [Gleicher et al. 2003; Lee et al. 2002; Lee et al. 2006]; precomputation can be used to allow real-time planning of which clips to use [Lau and Kuffner 2006; Lee and Lee 2006]. Reitsma and Pollard [2004] present a method for evaluating the possible motions generated by such approaches. A few authors have described methods that generate new poses in response to real-time input. Our motion controller model is most similar to methods that transition between interpolated sequences. Park et al. [2004] and Kwon and Shin [2005] combine interpolation of motions with a graph structure to generate new locomotion sequences. Shin and Oh [2006] perform interpolation on graph edges for simple models of locomotion and other repetitive motions. In previous work, it is assumed that a corpus of motion data is available in advance, or that a user will manually select which motions to capture. In this paper, we show how the use of adaptive selection of motion sequences allows the creation of controllers with greater complexity, while allowing fine-scale parameterized control and capturing relatively few motions overall. Data acquisition is difficult, expensive, and/or time-consuming for problems in many disciplines. Consequently, automatic selection of test cases has been extensively studied. In statistics, optimal experimental design methods seek the most informative test points to estimate unknown nonlinear functions [Atkinson and Donev 1992; Santner et al. 2003]. The simplest methods determine all test points in advance, e.g., via space-filling functions, or by optimizing an objective function. However, it is often not possible to determine in advance which regions of input space will need the most data. Active learning methods select test data sequentially: after each data point is acquired, the next test point is chosen to maximize an objective function [Cohn et al. 1994]. Active learning has been studied most extensively for classification problems  (e.g., [Lindenbaum et al. 2004]). In this paper, we present an active learning algorithm for motion controllers. Our approach is distinct from existing active learning methods in two ways: first, instead of choosing the next sample to capture, our system identifies a set of candidates, from which a user chooses a sample to improve; second, we assume that a metric of correctness is provided by which candidates may be chosen.",
  "resources" : [ ]
}