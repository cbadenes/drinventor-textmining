{
  "uri" : "sig2014-a35-xu_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2014/a35-xu_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Organizing Heterogeneous Scene Collections through Contextual Focal Points",
    "published" : "2014",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Kai Xu-null",
      "name" : "Kai Xu",
      "surname" : null
    }, {
      "uri" : "http://drinventor/Rui-Ma",
      "name" : "Rui",
      "surname" : "Ma"
    }, {
      "uri" : "http://drinventor/Hao Zhang-null",
      "name" : "Hao Zhang",
      "surname" : null
    }, {
      "uri" : "http://drinventor/Chenyang-Zhu",
      "name" : "Chenyang",
      "surname" : "Zhu"
    }, {
      "uri" : "http://drinventor/Ariel-Shamir",
      "name" : "Ariel",
      "surname" : "Shamir"
    }, {
      "uri" : "http://drinventor/Daniel-Cohen-Or",
      "name" : "Daniel",
      "surname" : "Cohen-Or"
    }, {
      "uri" : "http://drinventor/Hui Huang-null",
      "name" : "Hui Huang",
      "surname" : null
    } ]
  },
  "bagOfWords" : [ "we", "demonstrate", "advantage", "focal-centric", "scene", "comparison", "organization", "over", "exist", "approach", "particularly", "deal", "hybrid", "scene", "scene", "consist", "element", "which", "suggest", "membership", "different", "semantic", "category", "we", "represent", "indoor", "scene", "graph", "its", "constituent", "object", "focal", "point", "play", "key", "role", "we", "organization", "heterogeneous", "scene", "collection", "secondly", "scene", "organization", "give", "clustering", "scene", "base", "representative", "focal", "extract", "some", "scene", "may", "contain", "multiple", "focal", "thus", "belong", "multiple", "cluster", "scene", "typically", "hybrid", "nature", "provide", "linkage", "gateway", "between", "scene", "cluster", "allow", "exploration", "scene", "organization", "naturally", "transition", "between", "meaningful", "scene", "category", "illustrate", "Figure", "we", "show", "advantage", "focal-centric", "scene", "comparison", "organization", "over", "exist", "approach", "particularly", "deal", "hybrid", "scene", "we", "also", "demonstrate", "new", "capability", "offer", "new", "datum", "organization", "scene", "retrieval", "exploration", "conceptual", "level", "we", "work", "can", "see", "realization", "notion", "family", "resemblance", "from", "seminal", "work", "Wittgenstein", "-lsb-", "1953", "-rsb-", "we", "work", "present", "algorithm", "identify", "conceptual", "focal", "which", "serve", "reference", "point", "compare", "scene", "heterogeneous", "collection", "scene", "analysis", "we", "work", "recognize", "difficulty", "compare", "complex", "scene", "globally", "e.g.", "via", "classic", "graph", "kernel", "-lsb-", "Fisher", "et", "al.", "2011", "-rsb-", "relevance", "work", "which", "extract", "distinctive", "region", "-lsb-", "shilane", "Funkhouser", "2007", "Juneja", "et", "al.", "2013", "-rsb-", "representative", "semantic", "category", "we", "representation", "allow", "multiple", "view", "scene", "model", "each", "which", "may", "see", "from", "perspective", "particular", "focal", "point", "all", "work", "substructure", "scene", "provide", "context", "characterize", "individual", "object", "therein", "we", "treat", "substructure", "explicit", "scene", "feature", "i.e.", "potential", "focal", "perform", "contextual", "analysis", "larger", "scope", "furthermore", "group", "Xu", "et", "al.", "-lsb-", "2013", "-rsb-", "base", "frequency", "analysis", "only", "while", "we", "perform", "both", "frequent", "pattern", "mining", "subspace", "clustering", "focal", "point", "extraction", "we", "co-analysis", "unsupervised", "drive", "novel", "cluster", "compactness", "objective", "both", "focal", "selection", "focal-induced", "clustering", "frequent", "pattern", "mining", "most", "relevant", "work", "those", "design", "frequent", "subgraph", "mining", "e.g.", "-lsb-", "Yan", "Han", "2002", "-rsb-", "which", "primarily", "base", "subgraph", "isomorphism", "testing", "also", "worth", "note", "frequency", "occurrence", "only", "criterion", "focal", "point", "selection", "subspace", "clustering", "subspace", "clustering", "cluster", "highdimensional", "datum", "multiple", "subspace", "each", "model", "subset", "feature", "-lsb-", "Vidal", "2011", "-rsb-", "high", "level", "clustering", "problem", "we", "face", "have", "similar", "setting", "subspace", "clustering", "where", "focal", "act", "feature", "subset", "characterize", "subspace", "contain", "cluster", "scene", "we", "work", "we", "perform", "cluster", "attachment", "reveal", "cluster", "overlap", "base", "representative", "focal", "make", "obtain", "cluster", "better", "reflect", "complexity", "heterogeneity", "datum", "collection", "input", "we", "algorithm", "heterogeneous", "collection", "3d", "indoor", "scene", "collect", "from", "public", "repository", "we", "analysis", "use", "object", "label", "never", "scene", "label", "each", "scene", "structural", "graph", "construct", "which", "encode", "two", "type", "relationship", "between", "scene", "object", "support", "proximity", "we", "main", "algorithm", "consist", "couple", "optimization", "whose", "objective", "maximize", "overall", "compactness", "scene", "cluster", "while", "ensure", "focal", "represent", "respective", "cluster", "effectively", "key", "each", "representative", "focal", "sufficiently", "discriminative", "so", "frequent", "only", "within", "cluster", "represent", "characterize", "optimization", "iterative", "where", "each", "iteration", "interleave", "between", "cluster-guided", "focal", "point", "mining", "focal-induced", "subspace", "clustering", "scene", "see", "Figure", "first", "initial", "phase", "optimization", "extract", "frequent", "substructure", "focal", "from", "input", "structural", "graph", "via", "subgraph", "mining", "-lrb-", "section", "4.1", "-rrb-", "rather", "than", "rely", "subgraph", "isomorphism", "we", "perform", "inexact", "graph", "matching", "which", "insist", "consistency", "node", "labeling", "edge", "connection", "matching", "relation", "base", "layout", "similarity", "measure", "between", "spatial", "arrangement", "object", "matching", "confine", "scene", "group", "result", "from", "most", "recent", "clustering", "phase", "second", "phase", "base", "extract", "focal", "we", "perform", "subspace", "clustering", "-lrb-", "section", "4.2", "-rrb-", "scene", "structural", "graph", "cluster", "so", "each", "cluster", "characterize", "subset", "current", "focal", "maximization", "base", "iteratively", "reweight", "subspace", "clustering", "scheme", "we", "develop", "which", "gradually", "increase", "cluster", "compactness", "finally", "once", "cluster", "focal", "determine", "optimization", "we", "perform", "cluster", "attachment", "focal", "join", "-lrb-", "section", "4.3", "-rrb-", "some", "cluster", "share", "scene", "contain", "multiple", "focal", "each", "characterize", "different", "cluster", "cluster", "naturally", "attach", "shared", "scene", "within", "cluster", "multiple", "local", "substructure", "may", "occur", "concurrently", "across", "all", "most", "scene", "each", "input", "scene", "we", "construct", "structural", "graph", "-lrb-", "figure", "-lrb-", "-rrb-", "-rrb-", "whose", "node", "scene", "object", "edge", "encode", "spatial", "relationship", "support", "proximity", "between", "object", "see", "algorithm", "both", "node", "edge", "label", "object", "semantic", "label", "relationship", "type", "-lrb-", "support", "proximity", "-rrb-", "respectively", "second", "we", "add", "proximity", "edge", "from", "any", "object", "connect", "support", "edge", "object", "which", "have", "strongest", "connection", "where", "connection", "strength", "-lrb-", "equation", "-rrb-", "define", "part", "layout", "similarity", "Third", "we", "ensure", "any", "group", "symmetric", "object", "have", "symmetric", "connection", "other", "object", "any", "we", "detect", "all", "group", "mutually", "symmetric", "object", "examine", "each", "group", "all", "outside", "object", "connect", "group", "finally", "we", "detect", "connected", "component", "current", "graph", "connect", "component", "proximity", "edge", "make", "sure", "entire", "scene", "represent", "connected", "graph", "we", "co-analysis", "operate", "structural", "graph", "main", "algorithm", "involve", "couple", "optimization", "both", "focal", "point", "mining", "scene", "clustering", "objective", "optimization", "set", "cluster", "denote", "compactness", "cluster", "base", "FCGK", "size", "cluster", "we", "optimize", "iteratively", "iteration", "continue", "until", "overall", "compactness", "cluster", "converge", "specifically", "when", "change", "objective", "function", "less", "than", "1.0", "10", "follow", "section", "we", "detail", "we", "co-analysis", "algorithm", "substructure", "occur", "scene", "we", "say", "scene", "support", "substructure", "notion", "occurrence", "quickly", "relax", "inexact", "graph", "matching", "which", "enable", "similarity", "measure", "spatial", "layout", "between", "substructure", "scene", "layout", "similarity", "we", "define", "layout", "similarity", "between", "two", "substructure", "examine", "pair-wise", "spatial", "arrangement", "orient", "bound", "box", "-lrb-", "obb", "-rrb-", "object", "substructure", "suppose", "we", "give", "two", "substructure", "represent", "two", "subgraph", "structural", "graph", "two", "scene", "layout", "dissimilarity", "between", "they", "define", "where", "-lrb-", "-rrb-", "corresponding", "object", "correspondence", "can", "determine", "during", "subgraph", "mining", "describe", "below", "arr", "measure", "spatial", "arrangement", "dissimilarity", "between", "two", "pair", "object", "which", "define", "base", "two", "factor", "first", "connection", "strength", "between", "object", "where", "Hausdorff", "distance", "obb", "-lrb-", "-rrb-", "obb", "object", "dl", "-lrb-", "-rrb-", "diagonal", "length", "obb", "-lrb-", "-rrb-", "second", "factor", "angle", "between", "upright", "vector", "vector", "between", "where", "dir", "-lrb-", "-rrb-", "vector", "from", "larger", "object", "two", "smaller", "one", "upright", "upright", "vector", "??", "-lrb-", "??", "max", "-rrb-", "normalize", "connection", "strength", "where", "0.4", "maximum", "value", "max", "find", "all", "pair", "object", "normalize", "similarly", "we", "use", "0.6", "we", "implementation", "Figure", "-lrb-", "-rrb-", "show", "few", "example", "similar", "layout", "frequent", "substructure", "mining", "frequent", "subgraph", "mining", "extract", "from", "set", "input", "graph", "-lcb-", "-rcb-", "set", "subgraph", "-lcb-", "-rcb-", "which", "frequently", "occur", "-lrb-", "more", "than", "give", "threshold", "value", "min", "-rrb-", "input", "graph", "base", "subgraph", "isomorphism", "we", "define", "where", "ik", "-lrb-", "-rrb-", "indicator", "function", "subgraph", "isomorphism", "-lcb-", "ik", "-rcb-", "supporter", "set", "directly", "apply", "frequent", "subgraph", "mining", "structural", "graph", "ineffective", "since", "proximity", "relationship", "necessarily", "consistent", "across", "different", "scene", "e.g.", "see", "Figure", "-lrb-", "-rrb-", "one", "may", "resort", "inexact", "graph", "matching", "e.g.", "base", "graph", "edit", "distance", "-lsb-", "Riesen", "et", "al.", "2010", "-rsb-", "however", "large", "search", "space", "inexact", "subgraph", "mining", "make", "approach", "prohibitive", "we", "propose", "two-step", "scheme", "frequent", "substructure", "mining", "-lrb-", "algorithm", "-rrb-", "which", "carry", "out", "inexact", "graph", "match", "efficiently", "we", "first", "perform", "frequent", "subgraph", "mining", "base", "exact", "subgraph", "isomorphism", "use", "gspan", "-lsb-", "yan", "Han", "2002", "-rsb-", "relatively", "low", "minimal", "support", "threshold", "-lrb-", "line", "algorithm", "-rrb-", "second", "step", "we", "employ", "inexact", "subgraph", "matching", "-lsb-", "Riesen", "et", "al.", "2010", "-rsb-", "match", "frequent", "subgraph", "mine", "previous", "step", "against", "all", "graph", "set", "expand", "support", "-lrb-", "Lines", "2-6", "-rrb-", "note", "both", "step", "matching", "graph", "node", "exact", "base", "only", "node", "label", "edit", "cost", "each", "operation", "define", "spatial", "arrangement", "dissimilarity", "-lrb-", "equation", "-rrb-", "between", "two", "pair", "object", "involve", "total", "edit", "cost", "-lrb-", "-rrb-", "match", "less", "than", "0.1", "we", "add", "supporter", "set", "frequent", "subgraph", "we", "have", "obtain", "its", "embedding", "any", "its", "supporter", "graph", "during", "mining", "step", "denote", "-lrb-", "-rrb-", "specifically", "give", "supporter", "we", "compute", "average", "dissimilarity", "between", "its", "corresponding", "embedding", "those", "all", "other", "supporter", "filter", "out", "supporter", "value", "exceed", "threshold", "0.3", "finally", "we", "remove", "those", "subgraph", "whose", "number", "supporter", "fall", "below", "minimal", "support", "threshold", "min", "-lrb-", "line", "12", "-rrb-", "cluster-guided", "weighted", "mining", "therefore", "instead", "rely", "frequency", "criterion", "equation", "-lrb-", "-rrb-", "we", "base", "we", "substructure", "mining", "current", "cluster", "perform", "weighted", "subgraph", "mining", "-lsb-", "tsuda", "Kudo", "2006", "-rsb-", "each", "cluster", "we", "define", "support", "weight", "-lrb-", "-rrb-", "measure", "support", "any", "substructure", "use", "positive", "weight", "belong", "negative", "otherwise", "discriminant", "score", "favor", "substructure", "which", "frequent", "cluster", "penalize", "its", "frequency", "other", "cluster", "therefore", "mine", "substructure", "frequent", "mainly", "within", "cluster", "specifically", "we", "set", "1/n", "where", "-lrb-", "-rrb-", "n/n", "we", "fix", "0.1", "we", "algorithm", "final", "set", "focal", "point", "take", "union", "per-cluster", "discriminant", "substructure", "where", "number", "cluster", "achieve", "weighted", "mining", "we", "evaluate", "discriminant", "score", "individual", "substructure", "which", "efficiently", "enumerate", "gspan", "identify", "discriminative", "one", "base", "current", "cluster", "we", "perform", "support", "expand", "filter", "extract", "substructure", "first", "iteration", "when", "clustering", "miss", "we", "use", "unweighted", "frequent", "substructure", "mining", "focal", "extract", "we", "perform", "subspace", "clustering", "group", "input", "scene", "accord", "extract", "focal", "share", "i.e.", "scene", "contain", "support", "same", "focal", "each", "scene", "we", "build", "high-dimensional", "feature", "vector", "clustering", "feature", "define", "set", "all", "extract", "focal", "most", "current", "focal", "mining", "step", "-lrb-", "section", "4.1", "-rrb-", "each", "entry", "feature", "vector", "indicator", "support", "scene", "corresponding", "focal", "form", "Bag-of-Words", "-lrb-", "bow", "-rrb-", "feature", "-lrb-", "ik", "-rrb-", "subspace", "clustering", "perform", "over", "all", "input", "datum", "represent", "feature", "space", "-lsb-", "-rsb-", "d?n", "extract", "cluster", "characterize", "low-dimensional", "subspace", "subspace", "clustering", "we", "adopt", "method", "Wang", "et", "al.", "-lsb-", "2011a", "-rsb-", "subspace", "segmentation", "via", "quadratic", "programming", "-lrb-", "ssqp", "-rrb-", "state-of-the-art", "spectral", "clustering", "base", "approach", "algorithm", "iteratively", "reweight", "Subspace", "Clustering", "Input", "structural", "graph", "-lcb-", "-rcb-", "bow", "feature", "-lsb-", "-rsb-", "-lrb-", "-lrb-", "ik", "-rrb-", "-rrb-", "weight", "-lsb-", "-rsb-", "-lrb-", "-lrb-", "ik", "-rrb-", "-rrb-", "subspace", "cluster", "-lcb-", "-rcb-", "11", "do", "12", "13", "do", "14", "ik", "problem", "where", "Frobenius", "norm", "diag", "-lrb-", "-rrb-", "diagonal", "vector", "matrix", "regularization", "term", "enforce", "sparsity", "solution", "lead", "feature", "selection", "subspace", "clustering", "problem", "linear", "constrain", "quadratic", "programming", "which", "can", "solve", "efficiently", "result", "coefficient", "matrix", "form", "affinity", "matrix", "base", "which", "spectral", "clustering", "apply", "obtain", "clustering", "result", "practice", "cluster", "count", "relatively", "stable", "throughout", "iteration", "since", "structure", "bow", "feature", "matrix", "do", "change", "significantly", "besides", "clustering", "result", "we", "need", "identify", "representative", "focal", "which", "characterize", "cluster", "each", "cluster", "we", "identify", "set", "representative", "focal", "denote", "we", "rank", "importance", "all", "focal", "support", "any", "structural", "graph", "cluster", "base", "discriminant", "score", "see", "equation", "-lrb-", "-rrb-", "top", "rank", "focal", "select", "representative", "one", "we", "select", "top", "focal", "from", "list", "until", "i-th", "one", "when", "over", "80", "structural", "graph", "cluster", "which", "support", "top", "focals", "simultaneously", "we", "ultimate", "goal", "maximize", "compactness", "all", "cluster", "base", "scene-to-scene", "similarity", "emphasize", "representative", "focal", "point", "subspace", "clustering", "above", "base", "indicator", "feature", "which", "capture", "occurrence", "focal", "sufficiently", "informative", "reflect", "actual", "scene", "similarity", "directly", "incorporate", "focal-centric", "scene", "similarity", "subspace", "clustering", "infeasible", "since", "representative", "focal", "unknown", "before", "feature", "selective", "clustering", "perform", "therefore", "we", "propose", "iteratively", "reweight", "subspace", "clustering", "process", "gradually", "produce", "more", "compact", "cluster", "where", "compactness", "measure", "base", "focal-centric", "graph", "kernel", "-lrb-", "fcgk", "-rrb-", "appear", "across", "three", "cluster", "-lrb-", "-rrb-", "so", "-lrb-", "-rrb-", "corresponding", "weight", "set", "weight", "decrease", "due", "low", "compactness", "blue", "cluster", "next", "clustering", "group", "green", "cluster", "representative", "focal", "point", "-lrb-", "-rrb-", "focal-centric", "graph", "kernel", "give", "cluster", "its", "compactness", "define", "average", "distance", "between", "all", "pair", "structural", "graph", "belong", "measure", "FCGK", "where", "-lrb-", "-rrb-", "p-th", "order", "walk", "graph", "kernel", "-lrb-", "-rrb-", "p-th", "order", "rooted-walk", "graph", "kernel", "-lsb-", "Fisher", "et", "al.", "2011", "-rsb-", "which", "we", "briefly", "review", "below", "completeness", "compare", "node", "graph", "respectively", "compare", "all", "walk", "length", "whose", "first", "node", "against", "all", "walk", "length", "whose", "first", "node", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "r1", "...", "ep", "rp", "-rrb-", "gi", "-lrb-", "-rrb-", "-lrb-", "s1", "...", "fp", "sp", "-rrb-", "Gj", "-lrb-", "-rrb-", "where", "-lrb-", "-rrb-", "set", "all", "walk", "length", "originate", "from", "graph", "node", "kernel", "take", "both", "geometry", "label", "comparison", "account", "similar", "-lsb-", "Fisher", "et", "al.", "2011", "-rsb-", "except", "we", "use", "single", "label", "each", "object", "instead", "series", "semantic", "tag", "edge", "kernel", "we", "use", "similarity", "spatial", "arrangement", "-lrb-", "equation", "-rrb-", "instead", "binary", "comparison", "edge", "type", "walk", "kernel", "focal-centric", "we", "set", "higher", "weight", "those", "root", "walk", "which", "originate", "from", "node", "representative", "focal", "cluster", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "otherwise", "where", "scaling", "factor", "we", "algorithm", "we", "set", "100", "which", "fairly", "high", "emphasize", "more", "role", "focal", "scene", "characterization", "than", "overall", "scene", "similarity", "iteratively", "reweight", "subspace", "clustering", "structural", "graph", "we", "weight", "individual", "dimension", "its", "bow", "feature", "vector", "weight", "vector", "-lrb-", "ik", "-rrb-", "solve", "weigh", "subspace", "clustering", "which", "minimize", "error", "linear", "approximation", "equation", "-lrb-", "-rrb-", "under", "weighted", "Frobenius", "norm", "specifically", "we", "replace", "first", "term", "equation", "-lrb-", "-rrb-", "weight", "allow", "we", "tune", "importance", "individual", "dimension", "when", "seek", "subspace", "can", "utilize", "iteratively", "shift", "clustering", "result", "example", "one", "can", "increase", "weight", "correspond", "dimension", "span", "subspace", "cluster", "obtain", "last", "round", "reinforce", "cluster", "current", "clustering", "we", "case", "we", "encourage", "reoccurrence", "compact", "cluster", "next", "iteration", "increase", "weight", "dimension", "correspond", "its", "representative", "focal", "point", "deprecate", "incompact", "cluster", "decrease", "corresponding", "weight", "initially", "weight", "set", "uniformly", "each", "iteration", "we", "perform", "weighted", "subspace", "clustering", "update", "base", "compactness", "cluster", "which", "belong", "see", "Algorithm", "each", "member", "cluster", "we", "compute", "weight", "dimension", "correspond", "representative", "focal", "cluster", "base", "cluster", "compactness", "focal", "point", "discriminant", "score", "-lrb-", "line", "10", "-rrb-", "stop", "criterion", "iterative", "process", "same", "one", "use", "during", "interleave", "optimization", "i.e.", "change", "overall", "cluster", "compactness", "Figure", "demonstrate", "process", "reweight", "subspace", "clustering", "mini-experiment", "structural", "graph", "focal", "experiment", "after", "obtain", "subspace", "clustering", "along", "representative", "focal", "weight", "correspond", "focal", "point", "decrease", "due", "low", "discriminant", "score", "low", "cluster", "compactness", "respectively", "update", "weight", "which", "originally", "cluster", "blue", "cluster", "due", "now", "group", "green", "one", "characterize", "because", "play", "major", "role", "clustering", "after", "deprecate", "after", "reweight", "weighted", "feature", "vector", "some", "structural", "graph", "may", "decrease", "-lrb-", "close", "-rrb-", "vector", "-lrb-", "e.g.", "Figure", "-rrb-", "since", "clustering", "structural", "graph", "quite", "unpredictable", "we", "choose", "leave", "they", "out", "when", "weight", "vector", "vanish", "make", "iterative", "clustering", "converge", "faster", "structural", "graph", "later", "introduce", "back", "beginning", "next", "round", "interleave", "optimization", "cluster", "attachment", "spectral", "clustering", "produce", "partition", "input", "dataset", "which", "do", "reflect", "potential", "cluster", "overlap", "due", "scene", "which", "exist", "multiple", "cluster", "general", "structural", "graph", "input", "scene", "which", "support", "multiple", "focal", "may", "belong", "multiple", "cluster", "have", "other", "different", "representative", "focal", "we", "simply", "attach", "cluster", "respect", "shared", "scene", "which", "can", "easily", "identify", "reveal", "overlap", "focal", "join", "subgraph", "mining", "perform", "structural", "graph", "whose", "node", "connection", "only", "capture", "local", "proximity", "unable", "return", "large-scale", "non-local", "substructure", "we", "work", "frequent", "substructure", "detection", "couple", "subspace", "clustering", "enable", "we", "combine", "extract", "focal", "form", "larger", "non-local", "substructure", "through", "analyze", "cluster", "characterize", "suppose", "both", "representative", "focal", "some", "cluster", "supporter", "set", "denote", "overlap", "sufficiently", "i.e.", "0.9", "min", "-lcb-", "-rcb-", "we", "join", "they", "union", "node", "form", "larger", "substructure", "12", "representative", "focal", "we", "present", "result", "obtain", "we", "algorithm", "focal", "point", "drive", "analysis", "indoor", "scene", "collection", "scene", "retrieval", "we", "compare", "we", "result", "those", "obtain", "from", "state-of-the-art", "method", "both", "through", "precision-recall", "curve", "preliminary", "user", "study", "target", "hybrid", "scene", "more", "extensive", "result", "accompany", "video", "can", "find", "supplementary", "material", "dataset", "we", "experiment", "be", "provide", "Stanford", "repository", "-lsb-", "Fisher", "et", "al.", "2012", "-rsb-", "Tsinghua", "repository", "-lsb-", "xu", "et", "al.", "2013", "-rsb-", "both", "dataset", "contain", "semantic", "tag", "object", "originally", "collect", "from", "Google", "-lrb-", "now", "Trimble", "-rrb-", "3D", "Warehouse", "since", "tag", "from", "two", "dataset", "inconsistent", "we", "run", "we", "test", "each", "dataset", "separately", "each", "scene", "we", "remove", "wall", "focus", "only", "interior", "scene", "object", "Stanford", "collection", "consist", "132", "scene", "461", "object", "encompass", "78", "object", "category", "five", "labeled", "scene", "category", "Tsinghua", "dataset", "consist", "792", "scene", "13", "365", "object", "encompass", "119", "object", "category", "six", "labeled", "scene", "category", "Tsinghua", "dataset", "contain", "102", "hybrid", "scene", "which", "compose", "many", "subscene", "each", "represent", "room", "parameter", "statistics", "key", "parameter", "we", "algorithm", "include", "minimum", "support", "min", "use", "frequent", "substructure", "mining", "first", "iteration", "rooted", "path", "combination", "weight", "use", "compute", "graph", "kernel", "all", "result", "report", "paper", "be", "obtain", "same", "parameter", "setting", "min", "40", "Tsinghua", "dataset", "min", "20", "Stanford", "dataset", "parameter", "graph", "kernel", "use", "optimal", "one", "available", "from", "publish", "work", "Fisher", "et", "al.", "-lsb-", "2011", "-rsb-", "value", "all", "other", "parameter", "fix", "throughout", "describe", "section", "statistics", "timing", "Table", "show", "some", "statistics", "from", "focal", "point", "extraction", "scene", "clustering", "timing", "wise", "take", "10.5", "minute", "process", "whole", "Tsinghua", "dataset", "-lrb-", "792", "scene", "-rrb-", "3.2", "minute", "Stanford", "scene", "collection", "-lrb-", "132", "scene", "-rrb-", "over", "iteration", "compactness", "evaluation", "-lrb-", "include", "FCGK", "computation", "-rrb-", "take", "60", "time", "spectral", "clustering", "30", "inexact", "frequent", "pattern", "mining", "note", "first", "two", "part", "be", "both", "implement", "Matlab", "could", "see", "significant", "speed-up", "code", "c/c", "timing", "measure", "quad-core", "2.80", "GHz", "Intel", "Core", "CPU", "12gb", "RAM", "focal", "point", "extraction", "Figure", "show", "several", "cluster", "representative", "focal", "point", "extract", "from", "Tsinghua", "collection", "complete", "set", "result", "focal", "extraction", "can", "find", "supplementary", "material", "we", "can", "observe", "hybrid", "scene", "contain", "multiple", "focal", "point", "which", "fairly", "typical", "result", "cluster", "overlap", "also", "worth", "note", "extraction", "non-local", "focal", "which", "compose", "relatively", "distant", "object", "group", "e.g.", "-lcb-", "tv", "tv-stand", "table", "sofa", "-rcb-", "etc.", "Table", "give", "number", "non-local", "focal", "extract", "both", "dataset", "see", "also", "last", "two", "row", "Figure", "effect", "focal", "join", "iterative", "clustering", "Figure", "10", "plot", "how", "normalize", "compactness", "cluster", "change", "iterative", "clustering", "algorithm", "progress", "while", "change", "strictly", "monotone", "evident", "iteration", "generally", "improve", "cluster", "quality", "over", "time", "final", "cluster", "count", "two", "set", "respectively", "precision-recall", "scene", "retrieval", "Figure", "11", "compare", "we", "method", "two", "other", "method", "scene", "retrieval", "GK", "graph", "kernel", "Fisher", "et", "al.", "-lsb-", "2011", "-rsb-", "measure", "similarity", "between", "whole", "scene", "since", "we", "be", "unable", "obtain", "author", "code", "we", "code", "up", "we", "own", "implementation", "two", "major", "difference", "original", "work", "first", "we", "use", "we", "structural", "graph", "which", "only", "encode", "two", "type", "relationship", "-lrb-", "support", "proximity", "-rrb-", "do", "consider", "hierarchical", "scene", "graph", "second", "computation", "node", "edge", "kernel", "slightly", "different", "see", "section", "4.2", "both", "GK", "FCGK", "scheme", "node", "edge", "kernel", "estimation", "graph", "kernel", "normalization", "well", "all", "parameter", "same", "original", "work", "bow", "baseline", "method", "where", "we", "use", "bag-of-words", "feature", "focal", "point", "only", "scene-to-scene", "similarity", "fcgk", "-lrb-", "sg", "-rrb-", "Tsinghua", "dataset", "we", "also", "apply", "we", "fcgk", "similarity", "scene", "where", "focal", "we", "use", "212", "structural", "group", "detect", "Xu", "et", "al.", "-lsb-", "2013", "-rsb-", "when", "apply", "we", "method", "which", "use", "fcgk", "scene", "similarity", "we", "show", "result", "three", "setting", "-rrb-", "use", "initial", "set", "focal", "after", "only", "one", "step", "frequent", "pattern", "mining", "-rrb-", "use", "intermediate", "set", "focal", "-rrb-", "use", "final", "set", "focal", "extract", "Tsinghua", "dataset", "ground", "truth", "evaluate", "scene", "retrieval", "give", "scene", "labels/categories", "which", "come", "dataset", "since", "dataset", "contain", "many", "hybrid", "scene", "we", "separate", "subset", "simple", "scene", "remain", "hybrid", "-lrb-", "complex", "-rrb-", "scene", "report", "result", "each", "combination", "since", "Stanford", "collection", "do", "come", "scene", "label", "we", "provide", "we", "own", "label", "obtain", "manually", "which", "admittedly", "could", "introduce", "evaluation", "bias", "potentially", "more", "reliable", "method", "vote", "from", "multiple", "user", "could", "employ", "from", "precision-recall", "curve", "we", "see", "we", "focal-centric", "similarity", "base", "final", "set", "focal", "best", "all", "four", "case", "moreover", "performance", "gain", "more", "prominent", "hybrid", "scene", "result", "demonstrate", "only", "merit", "utilize", "focal", "scene", "comparison", "also", "merit", "we", "focal", "extraction", "scheme", "seem", "evident", "retrieval", "performance", "improve", "we", "iterative", "algorithm", "progress", "comparison", "GK", "Figure", "12", "show", "explicit", "comparison", "between", "GK", "FCGK", "scene", "similarity", "attest", "effectiveness", "utilize", "focal", "we", "experiment", "we", "also", "observe", "matching", "performance", "GK", "tend", "negatively", "affect", "presence", "many", "small/trivial", "object", "example", "when", "scene", "contain", "shelf", "support", "many", "small", "object", "GK", "count", "rooted", "walk", "from", "all", "object", "which", "would", "influence", "similarity", "between", "more", "prominent", "object", "fcgk", "more", "discriminative", "trivial", "object", "less", "likely", "have", "be", "choose", "focal", "user", "evaluation", "retrieval", "hybrid", "scene", "may", "difficult", "assign", "unambiguous", "category", "label", "ground", "truth", "use", "retrieval", "scene", "may", "unreliable", "thus", "instead", "rely", "scene", "category", "ground", "truth", "we", "let", "human", "user", "judge", "scene", "similarity", "base", "prior", "knowledge", "second", "comparative", "study", "scene", "retrieval", "we", "focus", "exclusively", "retrieval", "where", "query", "hybrid", "scene", "we", "present", "user", "10", "query", "each", "query", "top", "return", "from", "three", "compare", "method", "-lrb-", "gk", "bow", "fcgk", "-rrb-", "present", "user", "user", "ask", "choose", "which", "three", "most", "similar", "query", "we", "repeat", "total", "102", "query", "hybrid", "scene", "Tsinghua", "dataset", "against", "GK", "we", "obtain", "win", "percentage", "70.2", "against", "BOW", "we", "obtain", "73.9", "result", "statistically", "significant", "-lrb-", "0.01", "-rrb-", "study", "each", "scene", "have", "be", "render", "three", "random", "bird?s", "eye", "view", "image", "be", "present", "randomly", "among", "43", "participant", "80", "computer", "science", "researcher", "age", "20", "50", "rest", "frequent", "computer", "user", "vary", "background", "we", "scene", "organization", "allow", "classical", "scene", "query", "thus", "suitable", "any", "application", "which", "utilize", "retrieval", "result", "before", "e.g.", "-lsb-", "Fisher", "et", "al.", "2012", "Xu", "et", "al.", "2013", "-rsb-", "section", "we", "discuss", "several", "new", "capability", "afford", "we", "focal-based", "datum", "organization", "scene", "retrieval", "exploration", "Comprehensive", "retrieval", "classical", "retrieval", "single", "query", "would", "fetch", "single", "rank", "list", "datum", "item", "we", "focal-centric", "similarity", "pre-computed", "set", "focal", "we", "scene", "organization", "support", "classical", "query", "also", "support", "part-in-whole", "type", "query", "where", "user", "specify", "region", "interest", "-lrb-", "rous", "-rrb-", "query", "scene", "demonstrate", "exploration", "tool", "which", "we", "describe", "below", "interesting", "new", "feature", "enable", "we", "scene", "organization", "what", "we", "call", "comprehensive", "retrieval", "here", "query", "do", "have", "specify", "focal", "however", "available", "focal", "organization", "match", "query", "scene", "instead", "return", "single", "rank", "list", "scene", "comprehensive", "retrieval", "return", "multiple", "rank", "list", "each", "which", "correspond", "well-matched", "focal", "Figure", "13", "show", "result", "note", "vertical", "order", "table", "have", "clear", "meaning", "since", "three", "-lrb-", "horizontal", "-rrb-", "list", "retrieve", "base", "different", "set", "focal", "put", "all", "result", "together", "however", "one", "can", "expect", "those", "retrieve", "multiple", "focal", "should", "rank", "higher", "since", "have", "more", "focal", "substructure", "receive", "higher", "weight", "refer", "equation", "-lrb-", "-rrb-", "focal-to-scene", "matching", "we", "utilize", "efficient", "subgraph", "match", "approach", "describe", "-lsb-", "Riesen", "et", "al.", "2010", "-rsb-", "which", "focal", "subgraph", "pre-compile", "hierarchical", "representation", "accelerate", "online", "matching", "average", "query", "time", "960m", "Tsinghua", "collection", "140m", "Stanford", "set", "multi-query", "retrieval", "application", "example-based", "scene", "synthesis", "-lsb-", "Fisher", "et", "al.", "2012", "-rsb-", "one", "may", "form", "query", "consist", "multiple", "semantically", "related", "scene", "wish", "retrieve", "more", "scene", "same", "multi-query", "retrieval", "wellsupport", "we", "scene", "organization", "indeed", "since", "query", "scene", "related", "likely", "share", "meaningful", "substructure", "make", "they", "suitable", "focal-based", "scene", "comparison", "give", "query", "set", "we", "extract", "frequent", "substructure", "from", "set", "match", "they", "against", "extract", "focal", "scene", "organization", "we", "retrieve", "scene", "from", "organization", "use", "fcgk", "base", "match", "focal", "Figure", "14", "show", "one", "result", "query", "set", "four", "hybrid", "scene", "comparison", "we", "also", "show", "rank", "list", "return", "base", "gk", "similarity", "measure", "against", "any", "scene", "query", "set", "one", "would", "expect", "focal-based", "retrieval", "produce", "more", "discernable", "result", "more", "useful", "result", "user", "select", "four", "query", "scene", "all", "contain", "bednightstand", "combo", "desk-chair", "combo", "likely", "he/she", "seek", "scene", "contain", "similar", "substructure", "scene", "exploration", "we", "develop", "exploration", "tool", "base", "extract", "focal", "which", "enable", "user", "browse", "through", "heterogeneous", "scene", "collection", "focal", "point", "primary", "means", "search", "navigation", "Figure", "15", "show", "GUI", "we", "tool", "user", "can", "select", "few", "focal", "from", "focal", "point", "list", "panel", "-lrb-", "bottom", "-rrb-", "we", "tool", "automatically", "select", "set", "scene", "share", "similar", "focal", "list", "they", "scene", "list", "panel", "-lrb-", "right", "-rrb-", "user", "can", "browse", "list", "view", "scene", "main", "viewer", "-lrb-", "middle", "-rrb-", "any", "time", "user", "can", "click", "select", "focal", "view", "its", "embedding", "current", "scene", "term", "navigation", "show", "Figure", "user", "can", "traverse", "from", "one", "scene", "another", "one", "scene", "cluster", "another", "through", "focal", "which", "interlink", "they", "accompany", "video", "contain", "full", "session", "interactive", "exploration", "addition", "we", "provide", "interface", "user", "paint", "region", "interest", "-lrb-", "rous", "-rrb-", "search", "scene", "which", "contain", "sub-scene", "similar", "surroundings", "rous", "when", "user", "select", "rous", "scene", "we", "system", "first", "find", "focal", "point", "scene", "which", "overlap", "most", "rous", "add", "focal", "select", "list", "retrieve", "new", "list", "scene", "base", "update", "list", "select", "focal", "explore", "database", "focal", "point", "around", "rous", "instead", "only", "rous", "can", "provide", "more", "relevant", "result", "example", "user", "select", "only", "chair", "model", "rous", "naive", "partial", "matching", "would", "simply", "return", "all", "scene", "contain", "chair", "contrast", "we", "tool", "search", "scene", "share", "same", "fo", "cal", "around", "chair", "return", "result", "more", "context-aware", "note", "rooted", "walk", "graph", "kernel", "Fisher", "et", "al.", "-lsb-", "2011", "-rsb-", "could", "also", "support", "contextual", "part-in-whole", "query", "however", "perform", "subgraph", "search", "likely", "too", "time", "consume", "online", "retrieval", "pre-analysis", "result", "focal-based", "scene", "organization", "we", "tool", "can", "support", "efficient", "context-aware", "partial", "matching", "over", "large", "heterogeneous", "scene", "collection", "core", "datum", "organization", "problem", "mechanism", "compare", "datum", "traditional", "approach", "rely", "holistic", "datum", "view", "unique", "distance", "define", "between", "datum", "item", "group", "clustering", "however", "when", "datum", "become", "complex", "multifaceted", "fix", "global", "view", "datum", "similarity", "can", "hardly", "express", "rich", "characteristic", "datum", "we", "advocate", "use", "focal", "point", "compare", "organize", "complex", "heterogeneous", "datum", "use", "3d", "indoor", "scene", "prototype", "demonstrate", "its", "feasibility", "performance", "gain", "e.g.", "retrieval", "new", "approach", "seem", "particularly", "apt", "deal", "complex", "hybrid", "scene", "perhaps", "its", "most", "compelling", "feature", "ability", "process", "large", "heterogeneous", "collection", "scene", "organize", "they", "interlink", "well-connected", "cluster", "formation", "which", "facilitate", "scene", "exploration", "FCGK", "vs.", "GK", "while", "we", "retrieval", "experiment", "show", "superior", "performance", "fcgk", "over", "GK", "one", "should", "realize", "direct", "comparison", "between", "two", "exactly", "fair", "GK", "standalone", "graph", "similarity", "measure", "where", "only", "two", "graph", "compare", "need", "fcgk-based", "comparison", "come", "higher", "cost", "require", "set", "graph", "co-analysis", "focal", "extraction", "say", "scene", "collection", "available", "we", "would", "still", "suggest", "use", "fcgk", "its", "better", "performance", "modest", "processing", "cost", "comparison", "structural", "group", "we", "work", "focal", "point", "consist", "group", "scene", "object", "derive", "via", "structural", "scene", "analysis", "name", "alone", "suggest", "similarity", "structural", "group", "compute", "Xu", "et", "al.", "-lsb-", "2013", "-rsb-", "however", "major", "difference", "first", "structural", "group", "category", "group", "while", "we", "focal", "object", "group", "more", "importantly", "group", "extraction", "involve", "only", "frequent", "pattern", "mining", "through", "local", "proximity", "base", "search", "latter", "imply", "method", "unlikely", "return", "non-local", "structural", "group", "part", "evidence", "much", "higher", "number", "group", "-lrb-", "212", "-rrb-", "obtain", "vs.", "34", "focal", "we", "obtain", "same", "scene", "collection", "-lrb-", "tsinghua", "792", "scene", "-rrb-", "retrieval", "result", "Figure", "11", "seem", "suggest", "nonlocal", "focal", "extract", "via", "mining", "clustering", "provide", "better", "perspective", "meaningful", "scene", "comparison", "non-unique", "distance", "retrieval", "experiment", "use", "fcgk", "seem", "suggest", "we", "method", "assign", "unique", "distance", "between", "any", "two", "scene", "true", "once", "set", "focal", "fix", "fcgk", "compute", "base", "those", "focal", "clustering", "result", "however", "non-uniqueness", "focal-centric", "distance", "well", "utilize", "other", "setting", "include", "comprehensive", "retrieval", "multi-query", "retrieval", "roi-driven", "scene", "exploration", "where", "relevant", "focal", "query", "scene", "all", "determine", "on-demand", "Limitations", "we", "current", "algorithm", "depend", "semantic", "labeling", "scene", "object", "remain", "see", "whether", "work", "effectively", "noisy", "incomplete", "label", "base", "pure", "geometry", "analysis", "example", "interesting", "test", "we", "method", "input", "various", "level", "label", "noise", "however", "would", "hard", "quantitatively", "evaluate", "robustness", "against", "noisy", "label", "since", "may", "difficult", "reproduce", "realistic", "labeling", "noise", "introduce", "human", "nevertheless", "two", "dataset", "we", "use", "do", "contain", "some", "incorrect", "label", "which", "do", "seem", "affect", "overall", "performance", "perhaps", "more", "than", "desirable", "number", "parameter", "algorithm", "whose", "value", "be", "determine", "experimentally", "from", "technical", "stand", "point", "improvement", "possible", "various", "component", "algorithm", "example", "we", "layout", "similarity", "operate", "obb", "only", "which", "may", "unsuitable", "object", "complex", "geometry", "spatial", "arrangement", "structural", "graph", "model", "scene", "only", "flat", "arrangement", "object", "hierarchical", "organization", "may", "potentially", "advantageous", "one", "obvious", "pursuit", "apply", "we", "focal-driven", "approach", "other", "dataset", "e.g.", "large", "heterogeneous", "collection", "annotated", "image", "interesting", "technical", "question", "whether", "we", "scene", "organization", "can", "update", "additional", "set", "scene", "without", "recompute", "everything", "also", "rather", "than", "replace", "one", "object", "time", "scene", "synthesis", "like", "previous", "work", "we", "scene", "organization", "focal-based", "partial", "scene", "retrieval", "may", "allow", "substitute", "sub-scene", "synthesis", "task", "we", "conclude", "paper", "question", "what", "best", "way", "compare", "complex", "scene", "work", "along", "other", "before", "assume", "compare", "attribute", "graph", "define", "semantic", "tag", "object", "arrangement", "best", "way", "however", "we", "observe", "visually", "many", "retrieval", "result", "do", "look", "so", "compelling", "even", "best", "method", "date", "one", "take", "away", "coloring", "Figure", "14", "contrast", "between", "GK", "FCGK", "would", "salient", "hence", "focal-centric", "view", "we", "advocate", "offer", "perspective", "worth", "consider", "general", "question", "also", "one", "attribute", "complex", "datum", "beyond", "those", "indoor", "scene", "should", "perhaps", "answer", "user", "application", "intent", "mind", "we", "thank", "all", "reviewer", "comment", "feedback", "we", "grateful", "author", "-lsb-", "Fisher", "et", "al.", "2011", "-rsb-", "-lsb-", "Xu", "et", "al.", "2013", "-rsb-", "provide", "dataset", "work", "support", "part", "nsfc", "-lrb-", "61202333", "61379090", "61272327", "-rrb-", "NSERC", "Canada", "-lrb-", "611370", "-rrb-", "National", "863", "program", "China", "-lrb-", "2012aa011802", "-rrb-", "Shenzhen", "Innovation", "Program", "-lrb-", "CXB201104220029A", "kqcx20120807104901791" ],
  "content" : "We demonstrate advantages of focal-centric scene comparison and organization over existing approaches, particularly in dealing with hybrid scenes, scenes consisting of elements which suggest membership in different semantic categories. We represent an indoor scene by a graph of its constituent objects. Focal points play a key role in our organization of a heterogeneous scene collection. Secondly, the scene organization is given by the clustering of scenes based on the representative focals extracted. Some scenes may contain multiple focals, thus belong to multiple clusters. Such scenes, typically of a hybrid nature, provide linkages or gateways between scene clusters, allowing an exploration of the scene organization to naturally transition between meaningful scene categories, as illustrated in Figure 3 . We show advantages of focal-centric scene comparison and organization over existing approaches, particularly in dealing with hybrid scenes. We also demonstrate new capabilities offered by the new data organization for scene retrieval and exploration. At a conceptual level, our work can be seen as a realization of the notion of ?family resemblances? from the seminal work of Wittgenstein [1953]. Our work presents an algorithm for identifying conceptual focals which serve as reference points for comparing scenes in a heterogeneous collection. Scene analysis. Our work recognizes the difficulty in comparing complex scenes globally, e.g., via the classic graph kernels [Fisher et al. 2011]. Of relevance are works which extract distinctive regions [Shilane and Funkhouser 2007; Juneja et al. 2013] that are representative of a semantic category. Our representation allows multiple views of a scene model, each of which may be seen as from the perspective of a particular focal point. In all of these works, substructures in a scene provide the contexts for characterizing individual objects therein. We treat the substructures as explicit scene features, i.e., potential focals, and perform contextual analysis in a larger scope. Furthermore, the grouping in Xu et al. [2013] is based on frequency analysis only, while we perform both frequent pattern mining and subspace clustering for focal point extraction. Our co-analysis is unsupervised, driven by a novel cluster compactness objective for both focal selection and focal-induced clustering. Frequent pattern mining. The most relevant works are those designed for frequent subgraph mining, e.g., [Yan and Han 2002], which are primarily based on subgraph isomorphism testing. It is also worth noting that frequency of occurrence is not the only criterion for focal point selection. Subspace clustering. Subspace clustering clusters highdimensional data into multiple subspaces, each modeled by a subset of features [Vidal 2011]. At a high level, the clustering problem we face has a similar setting as subspace clustering, where focals act as the feature subsets and characterize the subspaces that contain the clusters of scenes. In our work, we perform cluster attachment to reveal cluster overlap based on their representative focals, making the obtained clusters better reflect the complexity and heterogeneity of the data collection. The input to our algorithm is a heterogeneous collection of 3D indoor scenes collected from public repositories. Our analysis uses the object labels but never the scene labels. For each scene, a structural graph is constructed which encodes two types of relationships between scene objects: support and proximity. Our main algorithm consists of a coupled optimization whose objective is to maximize the overall compactness of the scene clusters while ensuring that the focals represent their respective clusters effectively. A key is that each representative focal is sufficiently discriminative so that it is frequent only within the cluster it represents or characterizes. The optimization is iterative, where each iteration interleaves between cluster-guided focal point mining and focal-induced subspace clustering of the scenes; see Figure 5 . The first and initial phase of the optimization is to extract frequent substructures as focals from the input structural graphs, via subgraph mining (Section 4.1). Rather than relying on subgraph isomorphism, we perform inexact graph matching which insists on consistency of node labeling but not edge connection. The matching of such relations is based on a layout similarity measure between spatial arrangements of objects. This matching is confined by scene grouping resulting from the most recent clustering phase. In the second phase, based on the extracted focals, we perform subspace clustering (Section 4.2) on the scenes. The structural graphs are clustered so that each cluster is characterized by a subset of current focals. The maximization is based an iteratively reweighted subspace clustering scheme we develop, which gradually increases cluster compactness. Finally, once the clusters and focals are determined by the optimization, we perform cluster attachment and focal joining (Section 4.3). Some clusters share scenes containing multiple focals, each characterizing a different cluster. These clusters are naturally attached at the shared scenes. Within a cluster, multiple local substructures may occur concurrently across all or most scenes. For each input scene, we construct a structural graph ( Figure 6(b) ) whose nodes are scene objects and edges encode spatial relationship, support and proximity, between objects; see Algorithm 1. Both nodes and edges are labeled, by object semantic labels and relationship types (support or proximity), respectively. Second, we add a proximity edge from any object that is not connected by a support edge, to the object which has the strongest connection with it, where connection strength (Equation 3) is defined as a part of layout similarity. Third, we ensure that any group of symmetric objects has symmetric connections to other objects, if any. We detect all groups of mutually symmetric objects and examine for each group all outside objects connecting to that group. Finally, we detect the connected components in the current graph, and connect the components with proximity edges to make sure the entire scene is represented by a connected graph. Our co-analysis operates on these structural graphs. The main algorithm involves a coupled optimization for both focal point mining and scene clustering. The objective of the optimization is c the set of clusters. ? denotes the compactness of cluster C based on FCGK, and n is the size of cluster C . We optimize iteratively with the iterations continuing until the overall compactness of the clusters converges, specifically, when the change of the objective function is less than 1.0 ? 10 ?6 . In the following sections, we detail our co-analysis algorithm. If a substructure occurs in a scene, we say that the scene supports that substructure. The notion of occurrence will be quickly relaxed by inexact graph matching, which is enabled by a similarity measure of spatial layout between substructures of scenes. Layout similarity. We define a layout similarity between two substructures by examining the pair-wise spatial arrangement of oriented bounding boxes (OBBs) of the objects in the substructures. Suppose we are given two substructures represented by two subgraphs in the structural graphs of two scenes: S a ? G A and S b ? G B . The layout dissimilarity between them is defined as: where ?(p) ? G B is the corresponding object of p ? G A . Such correspondences can be determined during subgraph mining, as described below. d arr measures the spatial arrangement dissimilarity between two pairs of objects which is defined based on two factors. The first is the connection strength between objects p and q: where d H is Hausdorff distance, obb(p) the OBB of object p, and dl(p) the diagonal length of obb(p). The second factor is the angle between the upright vector and the vector between p and q: where v dir (p, q) is the vector from the larger object of the two to the smaller one and v upright the upright vector. ? = e ?? 2 /(?? max ) 2 is normalized connection strength where ? = 0.4 and the maximum value ? max is found for all pairs of objects. ? is normalized similarly. We use ? = 0.6 in our implementation. Figure 6(c) shows a few examples of similar layouts. Frequent substructure mining. Frequent subgraph mining extracts from a set of input graphs G = {G i } n i=1 , a set of subgraphs F = {F k } k=1 d , which frequently occur (more than a given threshold value s min ) in the input graphs based on subgraph isomorphism. We define: n where x ik = I(F k ? G i ) is an indicator function for subgraph isomorphism and S k = {G i | x ik = 1} is the supporter set of F k . Directly applying frequent subgraph mining to structural graphs is ineffective since the the proximity relationships are not necessarily consistent across different scenes, e.g., see Figure 7(a ,b). One may then resort to inexact graph matching, e.g., based on graph edit distance [Riesen et al. 2010]. However, the large search space of inexact subgraph mining makes such approaches prohibitive. We propose a two-step scheme for frequent substructure mining (Algorithm 2) which carries out inexact graph matching efficiently. We first perform frequent subgraph mining based on exact subgraph isomorphism, using gSpan [Yan and Han 2002], with a relatively low minimal support threshold (Line 1 in Algorithm 2). Then, in the second step, we employ inexact subgraph matching [Riesen et al. 2010] to match the frequent subgraphs mined in the previous step against all graphs in the set, to expand their support (Lines 2-6). Note that in both steps, the matching of graph nodes is exact and based only on node labels. The edit cost of each operation is defined as the spatial arrangement dissimilarity (Equation 5) between the two pairs of objects involved. If the total edit cost ?(G i , F k ) for matching F k and G i is less than ? t = 0.1, we add G i to F k ?s supporter set. For a frequent subgraph F k , we have obtained its embedding in any of its supporter graphs during the mining step, denoted as G i (F k ) ? G i , G i ? S k . Specifically, given a supporter G i ? S k of F k , we compute the average dissimilarity between its corresponding embedding and those in all other supporters, and filter out this supporter if the value exceeds a threshold ? t = 0.3|S k |. Finally, we remove those subgraphs whose number of supporters falls below the minimal support threshold s min (Line 12). Cluster-guided weighted mining. Therefore, instead of relying on the frequency criterion in Equation (6), we base our substructure mining on the current clusters and perform weighted subgraph mining [Tsuda and Kudo 2006]. For each cluster C , we define supporting weights ( i ) i=1 n as a measure of support of G i to any substructure. By using positive weights i , if G i belongs to C , and negative otherwise, the discriminant score favors a substructure which is frequent in cluster C and penalizes its frequency in other clusters. Therefore, the mined substructures in F are frequent mainly within cluster C . Specifically, we set i = x i /n ? 1/n, where x i = I(G i ? C ), and ? t = ?n/n . We fix ? = 0.1 in our algorithm. The final set of focal points takes the union of per-cluster discriminant substructures: F = c =1 F , where c is the number of clusters. To achieve weighted mining, we evaluate the discriminant score of the individual substructures, which are efficiently enumerated by gSpan, and identify the discriminative ones based on the current clusters. Then we perform support expanding and filtering for the extracted substructures. In the first iteration, when clustering is missing, we use unweighted frequent substructure mining. With the focals extracted, we perform subspace clustering to group the input scenes according to the extracted focals that they ?share?, i.e., the scenes contain and support the same focal. For each scene, we build a high-dimensional feature vector for clustering. The feature is defined by the set of all extracted focals in the most current focal mining step (Section 4.1). Each entry of the feature vector is an indicator of support of the scene to the corresponding focal, forming a Bag-of-Words (BoW) feature: x i = (x ik ) k=1 d . Subspace clustering is then performed over all input data represented in the feature space, X = [x i ] i=1 n ? R d?n , to extract clusters characterized by a low-dimensional subspace. For subspace clustering, we adopt the method of Wang et al. [2011a] on subspace segmentation via quadratic programming (SSQP), a state-of-the-art spectral clustering based approach. Algorithm 3: Iteratively Reweighted Subspace Clustering Input : structural graphs G = {G i } n i=1 , BoW features: X = [x i ] n i=1 , (x i = (x ik ) d k=1 ) weights: W = [w i ] i=1 n , (w i = (w ik ) k=1 d ) subspace clusters {C } c ; 11 for k = 1 to d do 12 if F k ? / c =1 R then 13 for i = 1 to n do 14 w ik ? 0; ; problem: where ? F is the Frobenius norm and diag(Z) the diagonal vector of matrix Z. The 1 -regularization term enforces sparsity of the solution, leading to feature selection for subspace clustering. The problem is a linear constrained quadratic programming which can be solved efficiently. The resulting coefficient matrix then forms an affinity matrix, |Z + Z T |/2, based on which spectral clustering is applied to obtain the clustering result. In practice, the cluster count is relatively stable throughout the iterations since the structure of the BOW feature matrix does not change significantly. Besides the clustering result, we need to identify the representative focals which characterize the clusters. For each cluster C , we identify a set of representative focals, denoted as R . We rank the importance of all focals supported by any structural graph in the cluster based on their discriminant score ? k ; see Equation (7). The top ranked focal is selected as the representative one. We select the top focals from the list until the i-th one, when there are over p c = 80% of the structural graphs in the cluster which support these top i focals simultaneously. Our ultimate goal is to maximize the compactness of all clusters based on a scene-to-scene similarity emphasizing their representative focal points. The subspace clustering above is based on indicator features, which capture the occurrence of the focals but are not sufficiently informative to reflect the actual scene similarity. Directly incorporating focal-centric scene similarity into the subspace clustering is infeasible since the representative focals are unknown before the feature selective clustering is performed. Therefore, we propose an iteratively reweighted subspace clustering process to gradually produce more compact clusters where the compactness is measured based on the focal-centric graph kernel (FCGK). as it appears across three clusters (b) so in (c) the corresponding weights are set to 0. The weights for F 4 are decreased due to the low compactness of the blue cluster. The next clustering groups G 2 into the green cluster with F 5 as the representative focal point (d). Focal-centric graph kernel. Given a cluster C , its compactness is defined as the average distance between all pairs of structural graphs belonging to it, measured by the FCGK: where k G p (?, ?) is the p-th order walk graph kernel: p k R (G i , G j , r, s) is the p-th order rooted-walk graph kernel [Fisher et al. 2011] which we briefly review below for completeness. It compares nodes r and s, in graphs G i and G j , respectively, by comparing all walks of length p whose first node is r against all walks of length p whose first node is s: p k R (G i , G j , r, s) = p?1 k n (r p , s p ) k n (r i , s i )k e (e i , f i ), (r1 ,e 1 ,... ,ep?1 ,rp )?W Gi p (r) i=1 p (s1 ,f 1 ,... ,fp?1 ,sp )?W Gj (s) p where W G (r) is the set of all walks of length p originated from r in graph G. The node kernel k n takes both geometry and label comparison into account, similar to [Fisher et al. 2011], except that we used a single label for each object, instead of a series of semantic tags. For edge kernel k e , we use the similarity of spatial arrangement (Equation 2), instead of a binary comparison of edge types. For the walk kernel ? to be focal-centric, we set higher weight for those rooted walks which originates from a node in a representative focal of cluster C :\n        1+ ? ? ? k if r ? G i (F k ), s ? G j (F k ) and F k ? R ? r,s = 1 otherwise\n        where ? is a scaling factor. In our algorithm, we set ? = 100 which is fairly high and emphasizes more the role of focals in scene characterization than the overall scene similarity. Iteratively reweighted subspace clustering. For a structural graph G i , we weight the individual dimensions of its BoW feature\n        vector by a weight vector w i = (w ik ) k=1 d and solve a weighed subspace clustering which minimizes the error of linear approximation in Equation (8) under a weighted Frobenius norm. Specifically, we replace the first term in Equation (8) by: The weights allow us to tune the importance of the individual dimensions when seeking subspaces and can be utilized to iteratively shift clustering results. For example, one can increase the weights corresponding to the dimensions spanning the subspace of a cluster obtained in the last round, to reinforce the cluster in the current clustering. In our case, we encourage the reoccurrence of the compact clusters in the next iteration by increasing the weights of the dimensions corresponding to its representative focal points, and deprecate incompact clusters by decreasing their corresponding weights. Initially, the weights in w i are set uniformly to 1. In each iteration, we perform the weighted subspace clustering and then update w i based on the compactness of the cluster to which G i belongs; see Algorithm 3. For each member of a cluster, we compute the weights of the dimensions corresponding to the representative focals of the cluster based on cluster compactness and focal point discriminant score (Line 10). The stopping criteria for this iterative process is the same as the one used during the interleaving optimization, i.e., the change of overall cluster compactness. Figure 8 demonstrates the process of reweighted subspace clustering with a mini-experiment on 8 structural graphs with 5 focals. In the experiment, after obtaining the subspace clustering along with the representative focals, the weights corresponding to focal point F 3 and F 4 are decreased, due to low discriminant score and low cluster compactness, respectively. With the updated weights, G 2 , which was originally clustered into the blue cluster due to F 4 , is now grouped into the green one characterized by F 5 . This is because F 5 plays the major role in clustering G 2 after F 4 is deprecated. After reweighting, the weighted feature vector of some structural graphs may decrease to (or close to) 0 vector (e.g., G 4 and G 7 in Figure 8 ). Since the clustering of these structural graphs is quite unpredictable, we choose to leave them out when their weight vector vanishes, to make the iterative clustering converge faster. These structural graphs are later introduced back in the beginning of the next round of interleaving optimization. Cluster attachment. Spectral clustering produces a partition of an input dataset, which does not reflect potential cluster overlapping due to scenes which exist in multiple clusters. In general, a structural graph for an input scene which support multiple focals may belong to multiple clusters that have other different representative focals. We simply attach such clusters with respect to the shared scenes, which can be easily identified, to reveal the overlap. Focal joining. As subgraph mining is performed on structural graphs whose node connections only capture local proximity, it is unable to return large-scale and non-local substructures. In our work, frequent substructure detection is coupled with subspace clustering. This enables us to combine the extracted focals to form a larger and non-local substructure, through analyzing the clusters they characterize. Suppose that F 1 and F 2 are both representative focals for some cluster C . If their supporter sets in C , denoted as S 1 and S 2 , overlap sufficiently, i.e., |S 1 ? S 2 | > 0.9 min{|S 1 |, |S 2 |}, we join them, by a union of their nodes, to form a larger substructure F 12 as a representative focal for C . We present results obtained by our algorithm for focal point driven analysis of indoor scene collections. For scene retrieval, we compare our results to those obtained from state-of-the-art methods both through precision-recall curves and a preliminary user study, targeted for hybrid scenes. More extensive results and an accompanying video can be found in the supplementary material. The datasets we experiment on were provided by the Stanford repository [Fisher et al. 2012] and the Tsinghua repository [Xu et al. 2013]. Both datasets contain semantic tags with the objects originally collected from Google (now Trimble) 3D Warehouse. Since the tags from the two datasets are inconsistent, we run our test on each dataset separately. For each scene, we remove the walls and focus only on the interior scene objects. The Stanford collection consists of 132 scenes and 3, 461 objects, encompassing 78 object categories and five labeled scene categories. The Tsinghua dataset consists of 792 scenes and 13, 365 objects, encompassing 119 object categories and six labeled scene categories. The Tsinghua dataset contains 102 hybrid scenes which is composed of many subscenes, each representing a room. Parameters and statistics. The key parameters of our algorithm include: the minimum support s min used for frequent substructure mining in the first iteration, and the rooted paths combination weights used in computing graph kernel. All the results reported in the paper were obtained with the same parameter setting: s min = 40 for Tsinghua dataset and s min = 20 for the Stanford dataset. The parameters for graph kernel use the optimal ones available from the published work of Fisher et al. [2011]. Values for all other parameters are fixed throughout and described in Section 4. Statistics and timing. Table 1 shows some statistics from focal point extraction and scene clustering. Timing wise, it took 10.5 minutes to process the whole Tsinghua dataset (792 scenes) and 3.2 minutes for the Stanford scene collection (132 scenes). Over an iteration, compactness evaluation (including FCGK computation) takes ~60% of the time, with spectral clustering ~30%, and inexact frequent pattern mining ~5%. Note that the first two parts were both implemented in Matlab and could see significant speed-up if coded in C/C++. Timing is measured on a 4 quad-core 2.80GHz Intel Core CPU with 12GB RAM. Focal point extraction. Figure 9 shows several clusters and their representative focal points extracted from the Tsinghua collection; the complete set of results for focal extraction can be found in the supplementary material. We can observe hybrid scenes containing multiple focal points, which is fairly typical and results in cluster overlap. Also worth noting is the extraction of non-local focals, which are composed of relatively distant object groups, e.g., {TV, TV-stand, table, sofa}, etc. Table 1 gives the number of non-local focals extracted for both datasets. See also the last two rows in Figure 9 for the effect of focal joining. Iterative clustering. Figure 10 plots how the normalized compactness of the clusters change as the iterative clustering algorithm progresses. While the change is not strictly monotone, it is evident that the iteration generally improves cluster quality over time. The final cluster counts for the two sets are 5 and 9, respectively. Precision-recall on scene retrieval. Figure 11 compares our method to two other methods for scene retrieval: GK: Graph kernels of Fisher et al. [2011] to measure similarity between whole scenes. Since we were unable to obtain the authors? code, we coded up our own implementation with two major differences to the original work. First, we use our structural graphs which only encode two types of relationships (support and proximity) and do not consider hierarchical scene graphs. Second, the computation of node and edge kernels are slightly different; see Section 4.2. For both GK and FCGK, the schemes for node and edge kernel estimation and graph kernel normalization, as well as all the parameters, are the same as the original work. BOW: A baseline method where we use bag-of-words features on the focal points only as a scene-to-scene similarity. FCGK (SG): On the Tsinghua dataset, we also apply our FCGK similarity on the scenes where as focals, we use the 212 structural groups detected by Xu et al. [2013]. When applying our method, which uses FCGK for scene similarity, we show results in three settings: 1) using the initial set of focals after only one step of frequent pattern mining; 2) using an intermediate set of focals; 3) using the final set of focals extracted. For the Tsinghua dataset, the ground truth for evaluating scene retrieval is given by the scene labels/categories which come with the dataset. Since this dataset contains many hybrid scenes, we separate it into a subset of simple scenes and the remaining hybrid (complex) scenes and report results on each and their combination. Since the Stanford collection does not come with scene labels, we provide our own labels obtained manually, which, admittedly, could introduce an evaluation bias. A potentially more reliable method, such as voting from multiple users, could be employed. From the precision-recall curves, we see that our focal-centric similarity based on the final set of focals is the best in all four cases. Moreover, the performance gain is more prominent for hybrid scenes. These results demonstrate not only the merit of utilizing focals for scene comparison but also the merit of our focal extraction scheme, as it seems evident that retrieval performance improves as our iterative algorithm progresses. Comparison to GK. Figure 12 shows an explicit comparison between GK and FCGK on scene similarity, attesting to the effectiveness of utilizing focals. In our experiment, we also observed that the matching performance of GK tends to be negatively affected by the presence of many small/trivial objects. For example, when a scene contains a shelf supporting many small objects, GK counts rooted walks from all these objects, which would influence the similarity between more prominent objects. FCGK is more discriminative and trivial objects are less likely to have been chosen as focals. User evaluation on retrieval. For a hybrid scene, it may be difficult to assign an unambiguous category label. The ground truth used for retrieval on such scenes may be unreliable. Thus instead of relying on scene categories as ground truth, we let human users judge scene similarity based on their prior knowledge. In this second comparative study on scene retrieval, we focus exclusively on retrieval where the query is a hybrid scene. We present a user with 10 queries. For each query, the top return from the three compared methods (GK, BOW and FCGK) are presented to the user and the user is asked to choose which of the three is most similar to the query. We repeat this for a total of 102 queries for the hybrid scenes in the Tsinghua dataset. Against GK, we obtain a winning percentage of 70.2% and against BOW, we obtain 73.9%. The results are statistically significant (with p = 0.01). In the studies, each scene has been rendered in three random bird?s eye views and the images were presented randomly. Among the 43 participants, 80% are computer science researchers, with ages 20 to 50. The rest are frequent computer users with varying backgrounds. Our scene organization allows classical scene queries and is thus suitable for any application which utilized retrieval results as before, e.g., [Fisher et al. 2012; Xu et al. 2013]. In this section, we discuss several new capabilities afforded by our focal-based data organization for scene retrieval and exploration. Comprehensive retrieval. In classical retrieval, a single query would fetch a single ranked list of data items. With our focal-centric similarity and pre-computed set of focals, our scene organization supports such classical queries. It also supports part-in-whole type of queries, where the user specifies a region of interest (ROI) in the query scene. This is demonstrated with the exploration tool which we describe below. The interesting new feature enabled by our scene organization is what we call comprehensive retrieval. Here the query does not have a specified focal. However, the available focals in the organization are matched with the query scene. Instead of returning a single ranked list of scenes, the comprehensive retrieval returns multiple ranked lists, each of which corresponds to a well-matched focal. Figure 13 shows such a result. Note that the vertical order in the table has no clear meaning since the three (horizontal) lists are retrieved based on different sets of focals. If putting all the results together, however, one can expect that those retrieved with multiple focals should be ranked higher since they have more focal substructures receiving higher weights; refer to Equation (9). For focal-to-scene matching, we utilize the efficient subgraph matching approach described in [Riesen et al. 2010], by which the focal subgraphs are pre-compiled into a hierarchical representation to accelerate the online matching. The average query time is 960ms for the Tsinghua collection and 140ms for the Stanford set. Multi-query retrieval. In applications such as example-based scene synthesis [Fisher et al. 2012], one may form queries consisting of multiple semantically related scenes and wish to retrieve more scenes ?of the same?. Such multi-query retrievals are wellsupported by our scene organization. Indeed, since the query scenes are related, they likely share meaningful substructures, making them suitable for focal-based scene comparisons. Given a query set, we extract frequent substructures from the set and match them against the extracted focals in the scene organization. We then retrieve scenes from the organization using FCGK based on the matched focals. Figure 14 shows one such result with a query set of four hybrid scenes. For comparison, we also show a ranked list of returns based on GK similarity measured against any scene in the query set. As one would expect, the focal-based retrieval produces more discernable results, and more useful results. If the user selected four query scenes all containing a bednightstand combo and a desk-chair combo, then it is likely that he/she was seeking scenes that contain similar substructures. Scene exploration. We develop an exploration tool, based on the extracted focals, which enables a user to browse through a heterogeneous scene collection. Focal points are the primary means for search and navigation. Figure 15 shows the GUI of our tool. The user can select a few focals from the focal point list panel (bottom), and our tool automatically selects a set of scenes sharing similar focals and lists them in the scene list panel (right). The user can browse the list and view the scenes in the main viewer (middle). At any time, the user can click on a selected focal to view its embedding in the current scene. In terms of navigation, as shown in Figure 3, the user can traverse from one scene to another, and one scene cluster to another, through focals which interlink them. The accompanying video contains full sessions of interactive exploration. In addition, we provide an interface for the user to paint a region of interest (ROI) and search for scenes which contain sub-scenes that are similar to the surroundings of the ROI. When the user selects an ROI in a scene, our system first finds a focal point in the scene which overlaps most with the ROI and adds the focal to the selected list. It then retrieves a new list of scenes based on the updated list of selected focals. Exploring the database with focal points around an ROI, instead of with only the ROI, can provide more relevant results. For example, if the user selects only a chair model as ROI, naive partial matching would simply return all scenes containing a chair. In contrast, our tool searches for scenes sharing the same fo- cal around the chair, returning results that are more context-aware. Note that the rooted walk graph kernels of Fisher et al. [2011] could also support contextual part-in-whole queries. However, performing subgraph search is likely too time consuming for online retrieval. With pre-analysis resulting a focal-based scene organization, our tool can support efficient context-aware partial matching over a large heterogeneous scene collection. At the core of the data organization problem is the mechanism for comparing data. Traditional approaches rely on holistic data views and unique distances defined between data items for grouping or clustering. However, when the data become complex and multifaceted, a fixed and global view on data similarity can hardly express the rich characteristics in the data. We advocate the use of focal points for comparing and organizing complex and heterogeneous data and use 3D indoor scenes as a prototype to demonstrate its feasibility and performance gains, e.g., in retrieval. The new approach seems particularly apt at dealing with complex and hybrid scenes. Perhaps its most compelling feature is the ability to process large and heterogeneous collections of scenes and to organize them into an interlinked and well-connected cluster formation, which facilitates scene exploration. FCGK vs. GK. While our retrieval experiment showed superior performance of FCGK over GK, one should realize that a direct comparison between the two is not exactly fair. GK is a standalone graph similarity measure, where only two graphs to compare are needed. FCGK-based comparison comes with a higher cost as it requires a set of graphs and a co-analysis for focal extraction. That said, if a scene collection is available, we would still suggest using FCGK for its better performance and modest processing costs. Comparison to structural groups. In our work, a focal point consists of a group of scene objects and it is derived via structural scene analysis. By name alone, this suggests similarity to the structural groups computed by Xu et al. [2013]. There are however major differences. First, their structural groups are category groups, while our focals are object groups. More importantly, their group extraction involves only frequent pattern mining through local proximity based search. The latter implies that their method is unlikely to return non-local structural groups. This is in part evidenced by the much higher number of groups (212) they obtain vs. the 34 focals we obtain, on the same scene collection (Tsinghua, 792 scenes). The retrieval results in Figure 11 seem to suggest that nonlocal focals extracted via mining and clustering provide the better perspectives for meaningful scene comparison. Non-unique distance. The retrieval experiment using FCGK seems to suggest that our method assigns a unique distance between any two scenes. This is true once the set of focals is fixed and FCGK is to be computed based on those focals and the clustering result. However, the non-uniqueness of focal-centric distances is well utilized in other settings including comprehensive retrieval, multi-query retrieval, and ROI-driven scene exploration, where the relevant focals in the query scenes are all determined on-demand. Limitations. Our current algorithm depends on semantic labeling of scene objects. It remains to be seen whether it works effectively with noisy or incomplete labels, based on pure geometry analysis. For example, it is interesting to test our method on inputs with various levels of label noise. However, it would be hard to quantitatively evaluate the robustness against noisy labels since it may be difficult to reproduce realistic labeling noise introduced by humans. Nevertheless, the two datasets we used do contain some incorrect labels, which did not seem to affect the overall performance. There are perhaps more than a desirable number of parameters in the algorithm, whose values were determined experimentally. From a technical stand point, improvements are possible in various components of the algorithm. For example, our layout similarity operates on OBBs only, which may be unsuitable for objects with complex geometry and spatial arrangements. The structural graphs model the scenes only as flat arrangements of objects. Hierarchical organization may be potentially advantageous. One obvious pursuit is to apply our focal-driven approach to other datasets, e.g., large and heterogeneous collections of annotated images. An interesting technical question is whether our scene organization can be updated with an additional set of scenes without recomputing everything. Also, rather than replacing one object at a time for scene synthesis like in previous works, our scene organization and focal-based partial scene retrieval, may allow for substituting sub-scenes for the synthesis task. We conclude the paper with a question: ?what is the best way to compare complex scenes? ? This work, along with others before it, assume that comparing attributed graphs defined by semantic tags and object arrangements is the best way. However, we observe that visually, many retrieval results do not look so compelling even with the best method to date. If one takes away the colorings in Figure 14, then the contrast between GK and FCGK would not be as salient. Hence, the focal-centric view we advocate offers a perspective worth considering. The general question, also one that is attributed to complex data beyond those of indoor scenes, should perhaps be answered with user and application intent in mind. We thank all the reviewers for their comments and feedback. We are grateful to the authors of [Fisher et al. 2011] and [Xu et al. 2013] for providing their datasets. This work was supported in part by NSFC (61202333, 61379090 and 61272327), NSERC Canada (611370), National 863 Program of China (2012AA011802), Shenzhen Innovation Program (CXB201104220029A, KQCX20120807104901791,",
  "resources" : [ ]
}