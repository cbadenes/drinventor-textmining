{
  "uri" : "sig2011-a27-lee_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2011/a27-lee_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "ShadowDraw: Real-Time User Guidance for Freehand Drawing",
    "published" : "2011",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Yong Jae-Lee",
      "name" : "Yong Jae",
      "surname" : "Lee"
    }, {
      "uri" : "http://drinventor/C. Lawrence-Zitnick",
      "name" : "C. Lawrence",
      "surname" : "Zitnick"
    }, {
      "uri" : "http://drinventor/Michael F.-Cohen",
      "name" : "Michael F.",
      "surname" : "Cohen"
    } ]
  },
  "bagOfWords" : [ "ask", "draw", "face", "result", "most", "we", "-lrb-", "those", "little", "practice", "drawing", "-rrb-", "might", "look", "like", "one", "those", "upper", "row", "Figure", "create", "subject", "we", "user", "study", "use", "standard", "drawing", "interface", "similarly", "ask", "draw", "bicycle", "most", "we", "would", "have", "difficult", "time", "depict", "how", "frame", "wheel", "relate", "each", "other", "one", "solution", "search", "image", "thing", "we", "want", "draw", "either", "trace", "use", "some", "other", "way", "reference", "however", "aside", "from", "difficulty", "find", "photo", "what", "we", "want", "draw", "simply", "trace", "object", "edge", "eliminate", "much", "essence", "drawing", "i.e.", "very", "little", "freedom", "trace", "stroke", "conversely", "draw", "blank", "paper", "only", "image", "mind?s", "eye", "give", "drawer", "lot", "freedom", "freehand", "drawing", "can", "frustrate", "without", "significant", "training", "address", "we", "present", "ShadowDraw", "drawing", "interface", "automatically", "infer", "what", "you", "draw", "dynamically", "depict", "relevant", "shadow", "-lrb-", "figure", "-rrb-", "underneath", "drawing", "shadow", "may", "either", "use", "ignore", "drawer", "ShadowDraw", "preserve", "essence", "drawing", "i.e.", "freedom", "expressiveness", "same", "time", "use", "visual", "reference", "shadow", "guide", "drawer", "furthermore", "shadow", "from", "real", "image", "can", "enlighten", "artist", "gist", "many", "image", "simultaneously", "creation", "become", "mix", "both", "human", "intuition", "computer", "intelligence", "computer", "essence", "partner", "draw", "process", "provide", "guidance", "like", "teacher", "instead", "actually", "produce", "final", "artwork", "drawing", "bottom", "row", "Figure", "be", "draw", "same", "subject", "time", "use", "ShadowDraw", "Notice", "how", "user", "own", "creative", "style", "remain", "consistent", "between", "drawing", "while", "overall", "shape", "spacing", "more", "realistic", "ShadowDraw", "consist", "two", "main", "computational", "step", "plus", "user", "interface", "first", "offline", "step", "consist", "build", "database", "from", "collection", "30,000", "image", "collect", "from", "web", "each", "image", "convert", "edge", "drawing", "use", "long", "edge", "detector", "technique", "develop", "-lsb-", "Bhat", "et", "al.", "2009", "-rsb-", "store", "overlapping", "window", "each", "edge", "image", "analyze", "code", "store", "each", "window", "convert", "edge", "descriptor", "further", "code", "sketch", "distinct", "hash", "key", "use", "min-hash", "-lsb-", "Chum", "et", "al.", "2008", "-rsb-", "second", "online", "step", "user", "draw", "ShadowDraw", "analyze", "stroke", "use", "similar", "encode", "determine", "hash", "key", "overlap", "window", "fast", "matching", "database", "image", "top", "100", "matching", "database", "edge", "image", "further", "align", "drawing", "set", "spatially", "vary", "weight", "blend", "edge", "image", "shadow", "image", "user", "interface", "stroke", "overlay", "top", "evolve", "shadow", "image", "provide", "guidance", "future", "stroke", "we", "main", "contribution", "interactive", "drawing", "system", "dynamically", "adapt", "user?s", "draw", "provide", "real-time", "feedback", "number", "technical", "contribution", "make", "ShadowDraw", "unique", "although", "portion", "ShadowDraw", "follow", "basic", "framework", "content", "base", "image", "retrieval", "technique", "partial", "spatial", "matching", "ShadowDraw", "employ", "novel", "allow", "multiple", "match", "image", "base", "different", "sub-region", "image", "addition", "verification", "stage", "method", "determine", "blend", "weight", "unique", "work", "while", "have", "be", "previous", "work", "help", "user", "draw", "basic", "shape", "-lsb-", "Igarashi", "et", "al.", "1999", "Arvo", "Novins", "2000", "Igarashi", "Hughes", "2001", "-rsb-", "we", "knowledge", "we", "first", "develop", "interactive", "user", "interface", "assist", "freeform", "drawing", "we", "test", "we", "approach", "human", "subject", "show", "comparison", "between", "drawing", "be", "produce", "without", "system", "result", "show", "we", "system", "produce", "more", "realistically", "proportion", "line", "drawing", "particularly", "those", "who", "possess", "some", "skill", "lack", "expertise", "we", "purposely", "avoid", "paper", "make", "any", "claim", "system", "help", "produce", "more", "skilled", "drawer", "more", "artistic", "drawing", "huge", "volume", "image", "video", "datum", "available", "web", "scientific", "database", "newspaper", "archive", "along", "recent", "advance", "efficient", "-lrb-", "approximate", "-rrb-", "nearest", "neighbor", "match", "scheme", "have", "open", "door", "number", "large", "scale", "match", "application", "general", "field", "content", "base", "image", "retrieval", "-lrb-", "cbir", "-rrb-", "use", "many", "different", "input", "modality", "search", "similar", "image", "database", "-lrb-", "see", "-lsb-", "Datta", "et", "al.", "2008", "-rsb-", "general", "survey", "field", "-rrb-", "here", "we", "briefly", "review", "related", "work", "large", "scale", "image", "retrieval", "technique", "especially", "those", "use", "line", "drawing", "query", "and/or", "aim", "construct", "new", "image", "drawing", "number", "system", "produce", "photographic-like", "result", "composit", "portion", "retrieve", "image", "sketch-tocollage", "system", "-lsb-", "Gavilan", "et", "al.", "2007", "-rsb-", "produce", "single", "composite", "collage", "match", "user", "provide", "color", "stroke", "database", "image", "segment", "out", "region", "interactively", "blend", "retrieve", "segment", "sketch2photo", "system", "-lsb-", "Chen", "et", "al.", "2009", "-rsb-", "produce", "composite", "image", "from", "user?s", "sketch", "scene", "text", "label", "annotated", "object", "candidate", "image", "region", "each", "object", "find", "web", "those", "produce", "best", "agreement", "put", "together", "form", "final", "composition", "PhotoSketch", "-lsb-", "Eitz", "et", "al.", "2009", "-rsb-", "progressively", "create", "image", "through", "sketch", "composit", "interface", "user", "interact", "system", "segment", "blend", "image", "retrieve", "from", "database", "1.5", "million", "image", "rather", "than", "start", "from", "blank", "page", "Scene", "Completion", "algorithm", "-lsb-", "Hays", "Efros", "2007", "-rsb-", "perform", "global", "scene", "match", "use", "query", "image", "which", "have", "hole", "system", "find", "best", "image", "complete", "scene", "object", "could", "have", "be", "miss", "region", "improve", "retrieval", "accuracy", "sketch-based", "system", "researcher", "have", "also", "design", "descriptor", "provide", "better", "match", "between", "human", "draw", "sketch", "natural", "image", "-lsb-", "Chalechale", "et", "al.", "2005", "Hu", "et", "al.", "2010", "-rsb-", "more", "general", "cbir", "effort", "include", "early", "SIGGRAPH", "work", "fast", "Multiresolution", "image", "query", "-lsb-", "Jacobs", "et", "al.", "1995", "-rsb-", "match", "user", "paint", "stroke", "underlie", "wavelet", "signature", "image", "database", "Blobworld", "approach", "-lsb-", "Carson", "et", "al.", "2002", "-rsb-", "query", "image", "region", "rather", "than", "entire", "image", "allow", "user", "specify", "which", "object", "image", "more", "relevant", "query", "-lsb-", "nister", "Stewenius", "2006", "-rsb-", "vocabulary", "tree", "create", "efficiently", "retrieve", "image", "from", "large", "database", "tree", "define", "hierarchical", "quantization", "local", "image", "feature", "provide", "multi-level", "scheme", "score", "match", "image", "-lsb-", "Chum", "et", "al.", "2007", "-rsb-", "idea", "query", "expansion", "text", "retrieval", "apply", "image", "domain", "where", "highest", "rank", "image", "from", "original", "query", "re-queried", "generate", "additional", "relevant", "image", "3d", "photorealistic", "virtual", "space", "create", "-lsb-", "Sivic", "et", "al.", "2008", "-rsb-", "allow", "user", "tour", "theme", "city", "street", "skyline", "similar", "image", "match", "stitch", "from", "large", "-lrb-", "few", "hundred", "thousand", "-rrb-", "image", "collection", "download", "from", "Flickr", "most", "recently", "mindfinder", "-lsb-", "Cao", "et", "al.", "2010", "-rsb-", "aim", "improve", "image", "retrieval", "allow", "user", "input", "text", "tag", "sketch", "color", "query", "system", "able", "retrieve", "image", "better", "match", "image", "user?s", "mind", "finally", "-lsb-", "Chaudhuri", "Koltun", "2010", "-rsb-", "data-driven", "suggestion", "make", "3d", "modeling", "system", "present", "suggestion", "match", "retrieve", "relevant", "shape", "database", "initial", "basic", "model", "ShadowDraw", "also", "leverage", "idea", "match", "large", "database", "image", "unlike", "previous", "method", "we", "end", "goal", "help", "user", "draw", "rather", "than", "perform", "image", "composition", "completion", "retrieval", "3d", "modeling", "furthermore", "ShadowDraw", "use", "only", "partial", "evolve", "draw", "query", "rather", "than", "other", "image", "and/or", "textual", "description", "we", "system", "require", "retrieval", "run", "real", "time", "we", "have", "see", "other", "system", "leverage", "image", "retrieval", "same", "kind", "application", "partial", "drawing", "input", "interactive", "draw", "interface", "Teddy", "-lsb-", "Igarashi", "et", "al.", "1999", "-rsb-", "fluid", "sketch", "-lsb-", "Arvo", "Novins", "2000", "-rsb-", "3d", "draw", "system", "-lsb-", "Igarashi", "Hughes", "2001", "-rsb-", "strive", "produce", "better", "drawing", "user", "method", "provide", "low-level", "information", "feedback", "form", "basic", "polygonal", "shape", "line", "curve", "more", "recently", "iCanDraw", "interface", "-lsb-", "Dixon", "et", "al.", "2010", "-rsb-", "provide", "step-by-step", "instruction", "corrective", "feedback", "guide", "user", "draw", "human", "face", "from", "reference", "image", "while", "similar", "motivation", "we", "approach", "provide", "guidance", "draw", "arbitrary", "high-level", "object", "use", "only", "example", "image", "recently", "-lsb-", "Cole", "et", "al.", "2008", "-rsb-", "author", "study", "artist", "line", "drawing", "3d", "shape", "analyze", "which", "line", "segment", "be", "be", "emphasize", "compute", "correlation", "between", "those", "segment", "contour", "produce", "use", "exist", "computer", "generate", "line", "drawing", "technique", "contour", "feature", "extractor", "while", "we", "work", "aim", "help", "user", "freeform", "drawing", "output", "we", "system", "can", "useful", "resource", "line", "work", "i.e.", "user", "drawing", "produce", "shadowdraw", "can", "use", "analyze", "contour", "more", "general", "object", "occur", "natural", "image" ],
  "content" : "If asked to draw a face, the result for most of us (those with little practice in drawing) might look like one of those in the upper row of Figure 1 , created by subjects in our user study using a standard drawing interface. Similarly, if asked to draw a bicycle, most of us would have a difficult time depicting how the frame and wheels relate to each other. One solution is to search for an image of the thing we want to draw, and to either trace it or to use it in some other way as a reference. However, aside from the difficulty of finding a photo of what we want to draw, simply tracing object edges eliminates much of the essence of drawing, i.e., there is very little freedom in tracing strokes. Conversely, drawing on a blank paper with only the image in the mind?s eye gives the drawer a lot of freedom, but freehand drawing can be frustrating without significant training. To address this, we present ShadowDraw, a drawing interface that automatically infers what you are drawing and then dynamically depicts relevant shadows (Figures 5 and 6) underneath the drawing. These shadows may be either used or ignored by the drawer. ShadowDraw preserves the essence of drawing, i.e., freedom and expressiveness, and at the same time uses visual references, shadows, to guide the drawer. Furthermore, shadows from real images can enlighten the artist with the gist of many images simultaneously. The creation becomes a mix of both human intuition and computer intelligence. The computer, in essence, is a partner in the drawing process, providing guidance like a teacher, instead of actually producing the final artwork. The drawings in the bottom row of Figure 1 were drawn by the same subjects, this time using ShadowDraw. Notice how the users? own creative styles remain consistent between the drawings, while the overall shapes and spacing are more realistic. ShadowDraw consists of two main computational steps plus the user interface. The first offline step consists of building a database from a collection of 30,000 images collected from the Web. Each image is converted to an edge drawing using the long edge detector technique developed by [Bhat et al. 2009] and stored. Overlapping windows in each edge image are analyzed, coded, and stored. Each window is converted to edge descriptors, and further coded as sketches with distinct hash keys using min-hash [Chum et al. 2008]. In the second online step, as the user draws, ShadowDraw analyzes the strokes using a similar encoding to determine hash keys for overlapping windows for fast matching with the database of images. The top 100 matching database edge images are further aligned to the drawing. A set of spatially varying weights blend the edge images into a shadow image. In the user interface, the strokes are overlaid on top of an evolving shadow image that provides guidance for future strokes. Our main contribution is an interactive drawing system that dynamically adapts to the user?s drawing and provides real-time feedback. A number of technical contributions make ShadowDraw unique. Although portions of ShadowDraw follow the basic framework of content based image retrieval, the technique of partial spatial matching that ShadowDraw employs is novel, in that it allows for multiple matching images based on different sub-regions of the image. In addition, the verification stage and methods for determining the blending weights are unique to this work. While there have been previous works that helps users draw basic shapes [Igarashi et al. 1999; Arvo and Novins 2000; Igarashi and Hughes 2001], to our knowledge, we are the first to develop an interactive user interface to assist freeform drawing. We test our approach with human subjects and show comparisons between the drawings that were produced with and without the system. The results show that our system produces more realistically proportioned line drawings, particularly for those who possess some skill but lack expertise. We purposely avoid in this paper, making any claims that the system helps produce more skilled drawers or more artistic drawings. The huge volume of image and video data available on the Web, scientific databases, and newspaper archives, along with recent advances in efficient (approximate) nearest neighbor matching schemes have opened the door for a number of large scale matching applications. The general field of content based image retrieval (CBIR) uses many different inputs modalities to search for similar images in a database (see [Datta et al. 2008] for a general survey of this field). Here, we briefly review related work in large scale image retrieval techniques, especially those that use line drawings for the query and/or are aimed at constructing new images and drawings. There are a number of systems that produce photographic-like results by compositing portions of retrieved images. The Sketch-toCollage system [Gavilan et al. 2007] produces a single composite collage by matching user provided color strokes to a database of images, segmenting out regions and interactively blending the retrieved segments. The Sketch2Photo system [Chen et al. 2009] produces a composite image from the user?s sketch of a scene with text label annotated objects. Candidate image regions for each object are found on the Web and those that produce the best agreement are put together to form the final composition. PhotoSketch [Eitz et al. 2009] progressively creates images through a sketching and compositing interface. The user interacts with the system to segment and blend the images retrieved from a database of 1.5 million images. Rather than starting from a blank page, the Scene Completion algorithm [Hays and Efros 2007] performs a global scene match using a query image, which has ?holes?. The system finds the best images for completing the scene with objects that could have been in the missing regions. To improve retrieval accuracy of these sketch-based systems, researchers have also designed descriptors that provide better matches between human drawn sketches and natural images [Chalechale et al. 2005; Hu et al. 2010]. More general CBIR efforts include the early SIGGRAPH work, Fast Multiresolution Image Querying [Jacobs et al. 1995], that matches user paint strokes to underlying wavelet signatures of images in the database. The ?Blobworld? approach [Carson et al.  2002] queries image regions rather than the entire image, to allow the user to specify which objects in the image are more relevant to the query. In [Nister and Stewenius 2006], a vocabulary tree is created to efficiently retrieve images from a large database. The tree defines a hierarchical quantization of the local image features and provides a multi-level scheme to score matching images. In [Chum et al. 2007], the idea of ?query expansion? in text retrieval is applied to the image domain, where the highest ranked images from the original query are re-queried to generate additional relevant images. A 3D photorealistic virtual space is created in [Sivic et al. 2008] to allow users to tour themes, such as city streets or skylines. Similar images are matched and stitched from a large (few hundred thousand) image collection downloaded from Flickr. Most recently, MindFinder [Cao et al. 2010] aims to improve image retrieval by allowing the user to input a text tag, a sketch, and a color as a query. The system is able to retrieve images that better match the image in the user?s mind. Finally, in [Chaudhuri and Koltun 2010], data-driven suggestions are made for 3D modeling. The system presents suggestions by matching and retrieving relevant shapes in the database to the initial basic model. ShadowDraw also leverages the idea of matching to a large database of images. Unlike previous methods, our end goal is to help the user draw rather than to perform an image composition, completion, retrieval, or 3D modeling. Furthermore, ShadowDraw uses only a partial and evolving drawing for the query rather than other images and/or textual descriptions. Our system requires the retrieval to run in real time. We have seen no other system that leverages image retrieval for the same kind of application or with partial drawings as the input. There are interactive drawing interfaces such as Teddy [Igarashi et al. 1999], Fluid Sketches [Arvo and Novins 2000], and the 3D drawing system of [Igarashi and Hughes 2001] that strive to produce better drawings for the user. These methods provide low-level information feedback in the form of basic polygonal shapes, lines, and curves. More recently, the iCanDraw interface [Dixon et al. 2010] provides step-by-step instructions and corrective feedback to guide a user to draw a human face from a reference image. While similar in motivation, our approach provides guidance for drawing arbitrary high-level objects using only example images. Recently, in [Cole et al. 2008], the authors studied artists? line drawings of 3D shapes to analyze which line segments were being emphasized, and to compute correlations between those segments and the contours produced using existing computer generated line drawing techniques and contour feature extractors. While our work aims to help users in freeform drawing, the outputs of our system can be a useful resource for this line of work, i.e., the user drawings produced with ShadowDraw can be used for analyzing the contours of more general objects occurring in natural images.",
  "resources" : [ ]
}