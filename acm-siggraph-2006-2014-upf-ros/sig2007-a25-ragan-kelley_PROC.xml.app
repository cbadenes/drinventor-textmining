{
  "uri" : "sig2007-a25-ragan-kelley_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2007/a25-ragan-kelley_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "The Lightspeed Automatic Interactive Lighting Preview System",
    "published" : "2007",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Jonathan-Ragan-Kelley",
      "name" : "Jonathan",
      "surname" : "Ragan-Kelley"
    }, {
      "uri" : "http://drinventor/Charlie-Kilpatrick",
      "name" : "Charlie",
      "surname" : "Kilpatrick"
    }, {
      "uri" : "http://drinventor/Brian W.-Smith",
      "name" : "Brian W.",
      "surname" : "Smith"
    }, {
      "uri" : "http://drinventor/Doug-Epps",
      "name" : "Doug",
      "surname" : "Epps"
    }, {
      "uri" : "http://drinventor/Paul-Green",
      "name" : "Paul",
      "surname" : "Green"
    }, {
      "uri" : "http://drinventor/Christophe-Hery",
      "name" : "Christophe",
      "surname" : "Hery"
    }, {
      "uri" : "http://drinventor/Fr?do-Durand",
      "name" : "Fr?do",
      "surname" : "Durand"
    } ]
  },
  "bagOfWords" : [ "we", "present", "automated", "approach", "high-quality", "preview", "feature-film", "rendering", "during", "lighting", "design", "similar", "previous", "work", "we", "use", "deep-framebuffer", "shaded", "GPU", "achieve", "interactive", "performance", "we", "first", "contribution", "generate", "deep-framebuffer", "corresponding", "shader", "automatically", "through", "data-flow", "analysis", "compilation", "original", "scene", "cache", "compression", "reduce", "automatically-generated", "deep-framebuffer", "reasonable", "size", "complex", "production", "scene", "shader", "we", "also", "propose", "new", "structure", "indirect", "framebuffer", "decouple", "shade", "sample", "from", "final", "pixel", "allow", "deepframebuffer", "handle", "antialiasing", "motion", "blur", "transparency", "efficiently", "progressive", "refinement", "enable", "fast", "feedback", "coarser", "resolution", "we", "demonstrate", "we", "approach", "real-world", "production", "keyword", "Lighting", "Preview", "Interactive", "Rendering", "Data-flow", "Analysis", "RenderMan", "Programmable", "Shading", "GPUs", "Software", "renderer", "can", "optimize", "repetitive", "re-rendering", "cache", "intermediate", "result", "various", "stage", "render", "process", "pioneer", "TDI", "1980s", "-lsb-", "Alias", "1999", "Pixar", "2001", "Nvidia", "2005", "Tabellion", "Lamorlette", "2004", "-rsb-", "however", "optimization", "must", "integrate", "core", "system", "still", "far", "from", "interactive", "film", "scene", "s?quin", "smyrl", "-lsb-", "1989", "-rsb-", "introduce", "parameterized", "version", "ray", "trace", "enable", "modification", "some", "material", "light", "property", "after", "precomputation", "-lrb-", "although", "light", "direction", "position", "-rrb-", "system", "require", "manual", "segmentation", "shader", "light-dependent", "light-independent", "component", "manual", "translation", "preview", "shader", "we", "choose", "potentially", "sacrifice", "performance", "tremendously", "improve", "integration", "maintainability", "automate", "segmentation", "translation", "shader", "finally", "we", "approach", "also", "automatically", "support", "editing", "many", "-lrb-", "user-selected", "-rrb-", "surface", "property", "because", "employ", "data-flow", "analysis", "respect", "arbitrary", "parameter", "however", "technique", "only", "cache", "shade", "computation?not", "tessellation", "displacement", "etc.", "require", "manual", "shader", "segmentation", "Guenter", "Knoblock", "Ruf", "develop", "datum", "specialization", "reduce", "cost", "recomputation", "when", "only", "certain", "shade", "parameter", "vary", "automatically", "segment", "shader", "parameterdependent", "independent", "component", "-lsb-", "1995", "1996", "-rsb-", "we", "leverage", "approach", "context", "lighting", "design", "extend", "analysis", "global", "data-flow", "through", "exist", "real-world", "RenderMan", "shader", "allow", "we", "only", "specialize", "respect", "dynamic", "parameter", "also", "perform", "dead-code", "elimination", "other", "analysis", "all", "from", "single", "dependence", "analysis", "we", "too", "exploit", "fact", "large", "subset", "RenderMan", "Shading", "language", "-lrb-", "rsl", "-rrb-", "can", "compile", "GPU", "we", "interest", "however", "use", "RSL", "GPU", "shade", "language", "automatically", "specialize", "final-frame", "shader", "create", "appropriate", "deep", "framebuffer", "interactive", "relighting", "example", "lpic", "system", "deploy", "Pixar", "-lsb-", "Pellacini", "et", "al.", "2005", "-rsb-", "least", "two", "version", "each", "shader", "need", "write", "place", "just", "one", "usual", "RenderMan", "shader", "use", "final", "rendering", "-lrb-", "additional", "code", "path", "cache", "datum", "-rrb-", "cg", "version", "use", "real-time", "preview", "we", "alleviate", "need", "author", "multiple", "version", "shader", "automatically", "translate", "unmodified", "RenderMan", "shader", "realtime", "shader", "precomputation", "shader", "cache", "compression", "effectively", "reduce", "automaticallygenerated", "deep-framebuffer", "reasonable", "size", "complex", "production", "shader", "addition", "transparency", "motion", "blur", "antialiasing", "can", "critical", "judge", "appearance", "we", "introduce", "indirect", "framebuffer", "which", "enable", "effect", "without", "linearly", "scale", "render", "time", "we", "use", "computation", "graph", "directly", "express", "dependency", "data-flow", "between", "pass", "implement", "shadow", "translucency", "however", "later", "become", "apparent", "we", "approach", "can", "also", "enable", "modification", "many", "all", "material", "appearance", "parameter", "we", "have", "seek", "facilitate", "although", "only", "secondary", "objective", "order", "receive", "widespread", "adoption", "production", "lighting", "design", "system", "must", "meet", "follow", "three", "major", "design", "goal", "specifically", "we", "wish", "provide", "low-latency", "feedback", "when", "user", "modify", "light", "parameter", "image", "refresh", "must", "instantaneous", "we", "seek", "keep", "initial", "preprocessing", "time", "short", "render", "one", "frame", "offline", "renderer", "high", "absolute", "render", "speed", "though", "secondary", "latency", "startup", "time", "absolute", "render", "speed", "must", "optimize", "we", "system", "must", "achieve", "effective", "reuse", "we", "system", "seek", "reuse", "exist", "pipeline", "wherever", "possible", "offload", "most", "precomputation", "directly", "exist", "offline", "pipeline", "flexibility", "we", "system", "develop", "two", "independent", "studio", "different", "pipeline", "toolset", "so", "we", "wish", "reuse", "much", "possible", "between", "two", "environment", "Automatic", "specialization", "First", "we", "automatically", "slice", "all", "surface", "shader", "static", "component", "can", "cache", "dynamic", "component", "execute", "real-time", "engine", "-lrb-", "section", "-rrb-", "we", "directly", "translate", "light", "shader", "execute", "together", "rerender", "surface", "shader", "GPU", "first", "encode", "dependence", "between", "different", "element", "real-time", "rendering", "which", "particularly", "critical", "progressive", "refinement", "multipass", "effect", "important", "we", "design", "goal", "integrate", "seamlessly", "multiple", "different", "workflow", "we", "wish", "automatically", "generate", "deep-framebuffer", "realtime", "preview", "main", "challenge", "specialization", "lie", "number", "value", "need", "cache", "large", "shader", "static", "code", "analysis", "challenging", "tend", "conservative", "identical", "other", "channel", "non-unique", "term", "replace", "reference", "single", "common", "channel", "many", "most", "commonly", "tune", "parameter", "gain", "factor", "specular", "roughness", "can", "dynamically", "edit", "direct", "extension", "would", "use", "supersampling", "greatly", "increase", "storage", "shade", "cost", "scale", "poorly", "variable", "depth", "complexity", "introduce", "transparency", "even", "transparency", "which", "traditionally", "present", "challenge", "due", "order-dependence", "ultimately", "factor", "single", "weight", "because", "we", "assume", "fix", "view", "configuration", "we", "directly", "exploit", "static", "linearity", "while", "decouple", "shading", "final", "pixel", "value", "simply", "normalize", "subpixel", "weight", "SRC", "ALPHA", "one", "minus", "SRC", "ALPHA", "instead", "additive", "blending", "we", "maintain", "appropriate", "brightness", "because", "we", "wish", "provide", "initial", "feedback", "user", "quickly", "possible", "common", "lowest", "refinement", "level", "light", "cache", "valid", "while", "higher", "refinement", "level", "various", "invalid", "state", "we", "therefore", "choose", "abstract", "individual", "algorithm", "from", "overall", "data-flow", "through", "real-time", "rendering", "pipeline", "-lrb-", "fig.", "11", "-rrb-", "use", "dependency", "graph", "structure", "which", "individual", "computation", "encapsulate", "node", "cache", "time", "Robot", "significantly", "less", "than", "even", "single", "offline", "render", "-lrb-", "common", "most", "complex", "shot", "-rrb-", "because", "we", "cache", "light", "turn", "off", "some", "technically", "straightforward", "significant", "aspect", "we", "implementation", "shadow", "map", "rendering", "currently", "lack", "extensive", "optimization", "while", "significant", "effort", "have", "be", "pay", "ensure", "fidelity", "scalability", "core", "compiler", "preprocessing", "real-time", "shading", "component", "complex", "scene" ],
  "content" : "We present an automated approach for high-quality preview of feature-film rendering during lighting design. Similar to previous work, we use a deep-framebuffer shaded on the GPU to achieve interactive performance. Our first contribution is to generate the deep-framebuffer and corresponding shaders automatically through data-flow analysis and compilation of the original scene. Cache compression reduces automatically-generated deep-framebuffers to reasonable size for complex production scenes and shaders. We also propose a new structure, the indirect framebuffer, that decouples shading samples from final pixels and allows a deepframebuffer to handle antialiasing, motion blur and transparency efficiently. Progressive refinement enables fast feedback at coarser resolution. We demonstrate our approach in real-world production. Keywords: Lighting Preview, Interactive Rendering, Data-flow Analysis, RenderMan, Programmable Shading, GPUs Software renderers can be optimized for repetitive re-rendering by caching intermediate results at various stages of the rendering process as pioneered by TDI in the 1980s [Alias 1999; Pixar 2001; Nvidia 2005; Tabellion and Lamorlette 2004]. However, such optimizations must be integrated at the core of a system and are still far from interactive for film scenes. S?quin and Smyrl [1989] introduced a parameterized version of ray tracing that enables the modification of some material and light properties after precomputation (although not the light direction or position). These systems require manual segmentation of shaders into light-dependent and light-independent components, and manual translation of preview shaders. We chose to potentially sacrifice performance but tremendously improve integration and maintainability by automating the segmentation and translation of shaders. Finally, our approach also automatically supports editing many (user-selected) surface properties because it employs data-flow analysis with respect to arbitrary parameters. However, their technique only cached shading computation?not tessellation, displacement, etc.?and required manual shader segmentation. Guenter, Knoblock & Ruf developed data specialization to reduce the cost of recomputation when only certain shading parameters vary, by automatically segmenting shaders into parameterdependent and -independent components [1995; 1996]. We leverage their approach in the context of lighting design and extend their analyses to global data-flow through existing real-world RenderMan shaders. This allows us to not only specialize with respect to dynamic parameters, but also to perform dead-code elimination and other analyses, all from a single dependence analysis. We, too, exploit the fact that a large subset of the RenderMan Shading Language (RSL) can be compiled to a GPU. Our interest, however, is not in using RSL as a GPU shading language, but in automatically specializing final-frame shaders and creating an appropriate deep framebuffer for interactive relighting. For example, in the lpics system deployed at Pixar [Pellacini et al. 2005], at least two versions of each shader need to be written in place of just one: the usual RenderMan shader used for the final rendering (with additional code paths to cache data), and a Cg version used for real-time preview. We alleviate the need to author multiple versions of a shader by automatically translating unmodified RenderMan shaders into realtime shaders and precomputation shaders. Cache compression effectively reduces automaticallygenerated deep-framebuffers to reasonable size for complex production shaders. In addition, transparency, motion blur and antialiasing can be critical to judge appearance. We introduce the indirect framebuffer, which enables these effects without linearly scaling rendering time. We use a computation graph that directly expresses the dependencies and data-flow between passes to implement shadows and translucency. However, it later became apparent that our approach can also enable the modification of many, but not all, material appearance parameters, and we have sought to facilitate this, although only as a secondary objective. In order to receive widespread adoption in production, a lighting design system must meet the following three major design goals. Specifically, we wish to provide: ? Low-latency feedback ? When the user modifies a light parameter, image refresh must be instantaneous. We seek to keep the initial preprocessing time as short as rendering one frame with the offline renderer. ? High absolute rendering speed ? Though secondary to latency and startup time, absolute rendering speed must be optimized. Our system must achieve effective: ? Reuse ? Our system seeks to reuse the existing pipeline wherever possible, offloading most precomputation directly to the existing offline pipeline. ? Flexibility ? Our system is developed for two independent studios, with different pipelines and toolsets, so we wish to reuse as much as possible between these two environments. Automatic specialization First, we automatically slice all surface shaders into a static component that can be cached and a dynamic component that will be executed by the real-time engine (Section 3). We directly translate light shaders to execute together with the rerendering surface shaders on the GPU. First, it encodes dependences between different elements of real-time rendering, which is particularly critical for progressive refinement and multipass effects. This is important to our design goal of integrating seamlessly with multiple different workflows. We wish to automatically generate a deep-framebuffer and realtime preview. The main challenge for specialization lies in the number of values that need to be cached for large shaders. Static code analysis is challenging and tends to be conservative. ? Identical to other channels ? non-unique terms are replaced with references to a single common channel. Many of the most commonly tuned parameters, such as gain factors and specular roughness can be dynamically edited. A direct extension would use supersampling, but this greatly increases storage and shading cost and scales poorly with variable depth complexity introduced by transparency. Even transparency, which traditionally presents challenges due to order-dependence, ultimately factors into a single weight because we assume a fixed viewing configuration. We directly exploit this static linearity while decoupling shading and final pixel value. By simply normalizing subpixel weights for SRC ALPHA,ONE MINUS SRC ALPHA instead of additive blending, we maintain appropriate brightness. Because we wish to provide initial feedback to the user as quickly as possible, it is common for the lowest refinement level of the light cache to be valid, while higher refinement levels are in various invalid states. We therefore chose to abstract individual algorithms from the overall data-flow through the real-time rendering pipeline ( Fig. 11 ) by using a dependency graph structure in which individual computations are encapsulated as nodes. Caching time for Robot is significantly less than even a single offline render (common for most complex shots), because we cache with lights turned off. As such, some technically straightforward but significant aspects of our implementation, such as shadow map rendering, currently lack extensive optimization, while significant effort has been paid to ensure the fidelity and scalability of the core compiler, preprocessing, and real-time shading components on complex scenes.",
  "resources" : [ ]
}