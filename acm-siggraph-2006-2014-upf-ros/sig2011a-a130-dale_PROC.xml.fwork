{
  "uri" : "sig2011a-a130-dale_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2011a/a130-dale_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Video Face Replacement",
    "published" : "2011",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Mahmoud-Afifi",
      "name" : "Mahmoud",
      "surname" : "Afifi"
    }, {
      "uri" : "http://drinventor/Khaled F.-Hussain",
      "name" : "Khaled F.",
      "surname" : "Hussain"
    }, {
      "uri" : "http://drinventor/Hosny M.-Ibrahim",
      "name" : "Hosny M.",
      "surname" : "Ibrahim"
    }, {
      "uri" : "http://drinventor/Nagwa M.-Omar",
      "name" : "Nagwa M.",
      "surname" : "Omar"
    } ]
  },
  "bagOfWords" : [ "cr", "category", "i.", "4.3", "-lsb-", "image", "processing", "computer", "Vision", "-rsb-", "enhancement?filtering", "i.", "3.7", "-lsb-", "Computer", "Graphics", "-rsb-", "ThreeDimensional", "Graphics", "Realism?Animation", "Keywords", "face", "replacement", "facial", "animation", "video", "compositing", "result", "current", "system", "require", "complex", "hardware", "significant", "user", "intervention", "achieve", "sufficient", "level", "realism", "-lrb-", "e.g.", "-lsb-", "Alexander", "et", "al.", "2009", "-rsb-", "-rrb-", "can", "contain", "similar", "performance", "two", "very", "different", "performance", "related", "scenario", "dub", "where", "source", "target", "subject", "same", "source", "video", "depict", "actor", "studio", "record", "foreign", "language", "track", "target", "footage", "shot", "location", "another", "useful", "scenario", "involve", "retargeting", "exist", "footage", "produce", "sequence", "combine", "exist", "backdrop", "new", "face", "place", "exist", "actor?s", "facial", "performance", "new", "footage", "Video", "face", "replacement", "have", "advantage", "over", "replace", "entire", "body", "head", "video", "full", "body", "replacement", "typically", "require", "chroma", "key", "compositing", "-lrb-", "i.e.", "green", "screening", "-rrb-", "rotoscoping", "separate", "body", "from", "video", "exist", "method", "both", "body", "head", "replacement", "require", "expensive", "equipment", "significant", "manual", "work", "both", "-lsb-", "Alexander", "et", "al.", "2009", "-rsb-", "work", "best", "when", "illumination", "source", "target", "video", "similar", "assumption", "could", "waive", "employ", "user", "assistance", "during", "tracking", "Face", "replacement", "image", "video", "have", "be", "consider", "variety", "scenario", "include", "animation", "expression", "transfer", "online", "privacy", "edit", "face", "image", "Face", "editing", "replacement", "image", "have", "be", "subject", "extensive", "research", "wellknown", "photomontage", "-lsb-", "Agarwala", "et", "al.", "2004", "-rsb-", "instant", "cloning", "system", "-lsb-", "Farbman", "et", "al.", "2009", "-rsb-", "allow", "replace", "face", "photograph", "use", "seamless", "blending", "-lsb-", "p?rez", "et", "al.", "2003", "-rsb-", "Bitouk", "et", "al.", "-lsb-", "2008", "-rsb-", "describe", "system", "automatic", "face", "swap", "use", "large", "database", "face", "use", "system", "conceal", "identity", "face", "target", "image", "Face", "image", "have", "be", "also", "use", "prior", "enhance", "face", "attractiveness", "use", "global", "face", "warping", "-lsb-", "Leyvand", "et", "al.", "2008", "-rsb-", "adjust", "tone", "sharpness", "lighting", "face", "-lsb-", "Joshi", "et", "al.", "2010", "-rsb-", "system", "Sunkavalli", "et", "al.", "-lsb-", "2010", "-rsb-", "model", "texture", "noise", "contrast", "blur", "target", "face", "improve", "appearance", "composite", "more", "recently", "Yang", "et", "al.", "-lsb-", "2011", "-rsb-", "use", "optical", "flow", "replace", "face", "expression", "between", "two", "photograph", "3d", "face", "model", "actor", "can", "capture", "use", "marker-based", "-lsb-", "Williams", "1990", "Guenter", "et", "al.", "1998", "Bickel", "et", "al.", "2007", "-rsb-", "structured", "light", "-lsb-", "Zhang", "et", "al.", "2004", "Ma", "et", "al.", "2008", "Li", "et", "al.", "2009", "Weise", "et", "al.", "2009", "-rsb-", "passive", "multi-view", "stereo", "approach", "-lsb-", "Jones", "et", "al.", "2006", "Bradley", "et", "al.", "2010", "Beeler", "et", "al.", "2011", "-lrb-", "appear", "-rrb-", "-rsb-", "model-based", "face", "replacement", "can", "achieve", "remarkable", "realism", "Video-to-Video", "Face", "Replacement", "purely", "image-based", "method", "do", "construct", "3d", "model", "actor", "Flagg", "et", "al.", "-lsb-", "2009", "-rsb-", "use", "video-texture", "synthesize", "plausible", "articulated", "body", "motion", "approach", "build", "morphable", "3d", "face", "model", "from", "source", "image", "without", "marker", "special", "face", "scanning", "equipment", "exist", "approach", "use", "estimate", "model", "parameter", "generate", "drive", "detailed", "3d", "textured", "face", "mesh", "target", "identity", "which", "can", "seamlessly", "render", "back", "target", "footage", "general", "system", "assume", "source", "actor?s", "performance", "face", "desire", "newly", "synthesize", "output", "video", "method", "estimate", "multilinear", "model", "from", "3d", "face", "scan", "different", "identity", "expression", "speech", "articulation", "-lrb-", "i.e.", "viseme", "-rrb-", "while", "gradient", "domain", "compositing", "can", "produce", "realistic", "seamless", "result", "quality", "composite", "often", "tie", "seam", "along", "which", "blend", "compute", "use", "arbitrary", "seam", "know", "lead", "bleed", "artifact", "result", "show", "paper", "each", "which", "about", "10", "seconds", "processing", "require", "about", "20", "minute", "multilinear", "face", "model", "mode", "tensor", "total", "3k", "element", "-lrb-", "where", "number", "vertex", "single", "face", "mesh", "-rrb-", "obtain", "via", "mode", "singular", "value", "decomposition", "-lrb-", "mode", "svd", "-rrb-", "from", "mode", "datum", "tensor", "contain", "vertex", "position", "original", "scan", "datum", "-lrb-", "cartesian", "product", "over", "expression", "viseme", "identity", "-rrb-", "least", "square", "solution", "eq", "while", "multilinear", "tracking", "do", "well", "tracking", "expression", "viseme", "which", "vary", "from", "frame", "frame", "we", "find", "identity", "which", "compute", "over", "full", "sequence", "hold", "constant", "cause", "significant", "problem", "when", "track", "full", "face", "model", "where", "critical", "mesh", "cover", "subject?s", "entire", "face", "only", "face", "-lrb-", "background", "-rrb-", "over", "entire", "sequence", "solve", "best-fit", "identity", "parameter", "per-frame", "pose", "consist", "scale", "rotation", "matrix", "translation", "vector", "together", "transform", "face", "mesh", "track", "position", "image", "space", "coordinate", "example", "when", "subject", "talk", "vertex", "correspond", "he", "lip", "remain", "same", "while", "position", "change", "do", "set", "weight", "spatial", "edge", "graph", "between", "neighbor", "vertex", "-lrb-", "-rrb-", "where", "use", "control", "influence", "temporal", "coherence", "unlike", "spatial", "weight", "weight", "construct", "have", "high", "value", "when", "appearance", "vertex", "doesn?t", "change", "much", "over", "time" ],
  "content" : "CR Categories: I.4.3 [Image Processing and Computer Vision]: Enhancement?Filtering; I.3.7 [Computer Graphics]: ThreeDimensional Graphics and Realism?Animation Keywords: face replacement, facial animation, video compositing As a result, current systems require complex hardware and significant user intervention to achieve a sufficient level of realism (e.g., [Alexander et al. 2009]). They can contain similar performances or two very different performances. A related scenario is dubbing, where the source and target subject are the same, and the source video depicts an actor in a studio recording a foreign language track for the target footage shot on location. Another useful scenario involves retargeting existing footage to produce a sequence that combines an existing backdrop with a new face or places an existing actor?s facial performance into new footage. Video face replacement has advantages over replacing the entire body or the head in video. Full body replacement typically requires chroma key compositing (i.e., green screening) or rotoscoping to separate the body from the video. Existing methods for both body and head replacement require expensive equipment, significant manual work, or both [Alexander et al. 2009]. It works best when the illumination in the source and target videos is similar. This assumption could be waived by employing user assistance during tracking. Face replacement in images and video has been considered in a variety of scenarios, including animation, expression transfer, and online privacy. Editing Faces in Images Face editing and replacement in images has been a subject of an extensive research. The wellknown photomontage [Agarwala et al. 2004] and instant cloning systems [Farbman et al. 2009] allow for replacing faces in photographs using seamless blending [P?rez et al. 2003]. Bitouk et al. [2008] describe a system for automatic face swapping using a large database of faces. They use this system to conceal the identity of the face in the target image. Face images have been also used as priors to enhance face attractiveness using global face warping [Leyvand et al. 2008] or to adjust tone, sharpness, and lighting of faces [Joshi et al. 2010]. The system of Sunkavalli et al. [2010] models the texture, noise, contrast and blur of the target face to improve the appearance of the composite. More recently, Yang et al. [2011] use optical flow to replace face expressions between two photographs. The 3D face model of the actor can be captured using marker-based [Williams 1990; Guenter et al. 1998; Bickel et al. 2007], structured light [Zhang et al. 2004; Ma et al. 2008; Li et al. 2009; Weise et al. 2009], or passive multi-view stereo approaches [Jones et al. 2006; Bradley et al. 2010; Beeler et al. 2011 (to appear)]. Model-based face replacement can achieve remarkable realism. Video-to-Video Face Replacement Purely image-based methods do not construct a 3D model of the actor. Flagg et al. [2009] use video-textures to synthesize plausible articulated body motion. These approaches build a morphable 3D face model from source images without markers or special face scanning equipment. Existing approaches use the estimated model parameters to generate and drive a detailed 3D textured face mesh for a target identity, which can be seamlessly rendered back into target footage. In general, these systems assume the source actor?s performance, but not their face, is desired in the newly synthesized output video. Their method estimates a multilinear model from 3D face scans of different identities, expressions, and speech articulations (i.e., visemes). While gradient domain compositing can produce realistic seamless results, the quality of the composite is often tied to the seam along which the blend is computed. Using an arbitrary seam is known to lead to bleeding artifacts. For the results shown in the paper, each of which is about 10 seconds, processing requires about 20 minutes. The multilinear face model M , an N -mode tensor with a total of 3K ?D 2 ?. ?D N elements (where K is the number of vertices in a single face mesh), is obtained via N -mode singular value decomposition (N -mode SVD) from the N -mode data tensor containing the vertex positions of the original scan data (the Cartesian product over expression, viseme, and identity). The least squares solution to Eq. While multilinear tracking does well at tracking expression and viseme, which vary from frame to frame, we found that identity, which is computed over the full sequence and held constant, was not. This caused significant problems when tracking with a full face model, where it is critical that the mesh covers the subject?s entire face, and only their face (no background) over the entire sequence. 3 and 4 to solve for the best-fit identity parameters. Per-frame pose consists of a scale s, 3 ? 3 rotation matrix R, and a translation vector t that together transform the face meshes into their tracked positions in image space coordinates. For example, when a subject talks, the vertices corresponding to his lips remain the same, while their positions change. This is done by setting the weights on the spatial edges in the graph between neighboring vertices f i (t) where ? is used to control the influence of the temporal coherence. Unlike the spatial weights, these weights are constructed to have high values when the appearance of the vertices doesn?t change much over time.",
  "resources" : [ ]
}