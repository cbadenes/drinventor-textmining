{
  "uri" : "sig2012-a46-lu_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2012/a46-lu_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "HelpingHand: Example-based Stroke Stylization",
    "published" : "2012",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Jingwan-Lu",
      "name" : "Jingwan",
      "surname" : "Lu"
    }, {
      "uri" : "http://drinventor/Fisher-Yu",
      "name" : "Fisher",
      "surname" : "Yu"
    }, {
      "uri" : "http://drinventor/Adam-Finkelstein",
      "name" : "Adam",
      "surname" : "Finkelstein"
    }, {
      "uri" : "http://drinventor/Stephen-DiVerdi",
      "name" : "Stephen",
      "surname" : "DiVerdi"
    } ]
  },
  "bagOfWords" : [ "run", "time", "we", "synthesis", "algorithm", "sublinear", "number", "library", "sample", "due", "approximate", "k-nn", "search", "we", "find", "through", "experimentation", "150", "stroke", "sufficient", "generate", "plausible", "result", "confirm", "through", "correlation", "analysis", "similar", "section", "library", "average", "run", "time", "both", "pose", "trajectory", "synthesis", "0.08", "seconds", "per", "stroke", "we", "experiment", "enrich", "library", "up", "about", "1000", "stroke", "include", "same", "stroke", "scale", "different", "size", "-lrb-", "50", "-rrb-", "increase", "match", "scale-invariance", "do", "see", "significant", "improvement", "performance", "reduce", "we", "also", "try", "use", "very", "small", "-lrb-", "fewer", "than", "10", "-rrb-", "very", "large", "-lrb-", "more", "than", "500", "-rrb-", "library", "small", "library", "feature", "matching", "can", "find", "similar", "enough", "trajectory", "therefore", "pick", "random", "stroke", "copy", "since", "optimal", "sequence", "algorithm", "encourage", "long", "segment", "pose", "result", "still", "look", "plausible", "trajectory", "poor", "match", "may", "result", "complete", "loss", "semantics", "result", "large", "library", "do", "affect", "pose", "synthesis", "whereas", "trajectory", "modification", "more", "likely", "find", "very", "similar", "patch", "query", "reduce", "effect", "style", "transfer", "all", "result", "show", "here", "render", "use", "Adobe", "Photoshop?s", "bristle", "brush", "tool", "-lsb-", "DiVerdi", "et", "al.", "2010", "-rsb-", "same", "brush", "setting", "difference", "synthesize", "pose", "datum", "induce", "visibly", "different", "shape", "texture", "stroke", "Figure", "show", "plausibility", "pose", "synthesis", "handwriting", "artist?s", "6-dof", "stroke", "strip", "pose", "datum", "trajectory", "use", "query", "same", "artist?s", "library", "apply", "synthesize", "output", "visually", "indistinguishable", "from", "ground", "truth", "whereas", "apply", "another", "artist?s", "library", "create", "visually", "distinct", "result", "pose", "synthesis", "line", "drawing", "demonstrate", "Figure", "example", "trajectory", "stylization", "Figure", "15", "we", "show", "robustness", "noisy", "input", "utility", "trajectory", "stylization", "demonstrate", "how", "can", "neaten", "mouse-written", "text", "which", "have", "characteristic", "shakiness", "similarly", "line", "drawing", "make", "artist", "unsure", "hand", "can", "make", "have", "more", "confident", "stroke", "we", "algorithm", "can", "also", "apply", "stylistic", "flourish", "serif", "block", "lettering", "figure", "14", "15", "show", "two-pass", "algorithm", "stylize", "both", "pose", "trajectory", "remainder", "section", "describe", "study", "we", "conduct", "evaluate", "we", "result", "quantitative", "measure", "pose", "synthesis", "quality", "we", "compute", "correlation", "between", "synthesize", "result", "ground", "truth", "however", "equivalent", "measure", "trajectory", "synthesis", "ultimately", "we", "care", "most", "about", "how", "user", "judge", "we", "result", "therefore", "we", "also", "conduct", "user", "study", "both", "pose", "trajectory", "synthesis", "section", "3.1", "show", "artist", "exhibit", "some", "natural", "variation", "hand", "pose", "even", "when", "draw", "same", "path", "multiple", "time", "therefore", "gold", "standard", "we", "can", "compare", "we", "synthesis", "result", "against?l", "measurement", "reconstruction", "error", "against", "ground", "truth", "good", "indication", "success", "correlation", "other", "hand", "better", "evaluation", "metric", "case", "pose", "synthesis", "we", "can", "apply", "analysis", "similar", "section", "3.1", "evaluate", "we", "result", "style", "library", "successfully", "transfer", "onto", "query", "stroke", "every", "local", "patch", "output", "should", "have", "sim", "-lrb-", "-rrb-", "ground", "truth", "-lrb-", "-rrb-", "optimal", "-lrb-", "-rrb-", "weighted", "average", "-lrb-", "-rrb-", "closest", "-lrb-", "-rrb-", "transfer", "-lrb-", "-rrb-", "transfer", "ilar", "pose", "profile", "similar", "patch", "library", "we", "compare", "closest", "neighbor", "weighted", "average", "optimal", "sequence", "variant", "we", "algorithm", "-lrb-", "section", "4.2", "-rrb-", "Figure", "10", "contain", "correlation", "result", "show", "optimal", "algorithm", "achieve", "highest", "pose", "correlation", "both", "synthesis", "case", "furthermore", "since", "we", "have", "ground", "truth", "pose", "datum", "query", "stroke", "we", "compare", "they", "synthesis", "find", "well", "correlate", "expect", "note", "we", "have", "analogous", "quality", "measure", "trajectory", "synthesis", "because", "goal", "blend", "local", "feature", "global", "shape", "fair", "objective", "function", "more", "difficult", "formulate", "we", "conduct", "two", "user", "study", "goal", "evaluate", "whether", "user", "can", "distinguish", "between", "we", "result", "ground", "truth", "pose", "trajectory", "study", "separately", "because", "user", "overwhelmingly", "sensitive", "trajectory", "over", "pose", "which", "would", "make", "pose", "evaluation", "difficult", "combine", "both", "study", "use", "same", "methodology", "only", "image", "different", "Study", "Design", "we", "show", "subject", "three", "line", "English", "text", "from", "artist?s", "library?the", "exemplar", "-lrb-", "we", "use", "two", "library", "from", "each", "artist", "show", "Figure", "2a", "-rrb-", "below", "exemplar", "appear", "two", "test", "image", "contain", "same", "-lrb-", "3-9", "letter", "-rrb-", "phrase?one", "ground", "truth", "originally", "write", "artist", "one", "forgery", "synthesize", "one", "we", "algorithm", "subject", "instruct", "one", "image", "original", "other", "forgery", "ask", "identify", "original", "compare", "both", "exemplar", "pose", "study", "ground", "truth", "forgery", "have", "same", "trajectory", "-lrb-", "figure", "11", "-rrb-", "trajectory", "study", "ground", "truth", "trajectory", "use", "synthesis", "pose", "datum", "omit", "from", "all", "image", "-lrb-", "figure", "12", "-rrb-", "one", "trial", "consist", "26", "task", "-lrb-", "each", "same", "exemplar", "-rrb-", "compare", "-lrb-", "-rrb-", "random", "ground", "truth", "phrase", "forgery", "select", "from", "one", "five", "condition", "-lrb-", "-rrb-", "optimal", "sequence", "-lrb-", "-rrb-", "weighted", "average", "-lrb-", "-rrb-", "closest", "neighbor", "-lrb-", "-rrb-", "style", "transfer", "-lrb-", "-rrb-", "style", "transfer", "validation", "condition", "-lrb-", "b-d", "-rrb-", "algorithm", "be", "test", "whereas", "-lrb-", "e-f", "-rrb-", "baseline", "synthesize", "forgery", "another", "artist?s", "library", "-lrb-", "so", "should", "very", "easy", "identify", "-rrb-", "26", "task", "four", "from", "each", "-lrb-", "b-e", "-rrb-", "ten", "from", "-lrb-", "-rrb-", "randomly", "shuffle", "any", "particular", "subject", "-lrb-", "e-f", "-rrb-", "select", "from", "two", "different", "library", "style", "randomly", "we", "only", "retain", "datum", "from", "trial", "correct", "count", "-lrb-", "-rrb-", "method", "pose", "study", "trajectory", "study", "average", "153", "322", "-lrb-", "48", "-rrb-", "96", "302", "-lrb-", "32", "-rrb-", "optimal", "169", "316", "-lrb-", "53", "-rrb-", "172", "305", "-lrb-", "56", "-rrb-", "closest", "269", "304", "-lrb-", "88", "-rrb-", "220", "292", "-lrb-", "75", "-rrb-", "transfer", "293", "301", "-lrb-", "97", "-rrb-", "274", "288", "-lrb-", "95", "-rrb-", "-lrb-", "-rrb-", "ground", "truth", "-lrb-", "-rrb-", "optimal", "-lrb-", "-rrb-", "weighted", "average", "-lrb-", "-rrb-", "closest", "-lrb-", "-rrb-", "transfer", "-lrb-", "-rrb-", "transfer", "when", "out", "10", "validation", "condition", "-lrb-", "-rrb-", "correct", "so", "we", "know", "user", "understand", "task", "actually", "try", "succeed", "-lrb-", "0.01", "-rrb-", "style", "transfer", "result", "only", "report", "-lrb-", "-rrb-", "subject", "be", "worker", "Amazon", "mechanical", "Turk", "microjob", "marketplace", "have", "be", "use", "grow", "variety", "study", "-lsb-", "Cole", "et", "al.", "2009", "-rsb-", "we", "study", "be", "restricted", "us-only", "worker", "who", "be", "pay", "0.20", "per", "task", "-lrb-", "HIT", "contain", "26", "comparison", "which", "typically", "complete", "few", "minute", "-rrb-", "across", "two", "study", "70", "worker", "complete", "total", "214", "hit", "subject", "be", "allow", "complete", "many", "10", "hit", "per", "study", "most", "worker", "do", "just", "one", "case", "where", "particular", "pair", "repeat", "particular", "worker", "due", "randomize", "selection", "we", "only", "retain", "first", "response", "total", "4,170", "response", "Study", "result", "result", "report", "Table", "frequency", "which", "ground", "truth", "correctly", "identify", "Bonferroni", "correct", "randomize", "permutation", "test", "distribution", "each", "consecutive", "pair", "row", "table", "show", "different", "statistical", "significance", "-lrb-", "0.01", "-rrb-", "except", "case", "average", "optimal", "condition", "pose", "study", "-lrb-", "0.34", "-rrb-", "ideal", "forgery", "indistinguishable", "from", "ground", "truth", "so", "subject", "choose", "randomly", "result", "correct", "answer", "near", "50", "time", "when", "forgery", "easy", "identify", "-lrb-", "figure", "12e", "-rrb-", "we", "expect", "score", "near", "100", "transfer", "condition", "near", "100", "both", "study", "which", "show", "people", "can", "perform", "task", "easy", "case", "people", "tend", "identify", "closest", "method", "-lrb-", "88", "75", "-rrb-", "so", "generally", "implausible", "pose", "study", "average", "optimal", "both", "near", "50", "therefore", "plausibly", "synthesize", "pose", "datum", "optimal", "perform", "well", "trajectory", "study", "average", "significantly", "below", "50", "which", "mean", "subject", "tend", "incorrectly", "identify", "forgery", "original", "mention", "section", "4.2.2", "weighted", "average", "method", "produce", "very", "smooth", "output", "trajectory", "we", "believe", "people", "have", "bias", "towards", "smoother", "curve", "case", "people", "choose", "average", "over", "ground", "truth", "even", "though", "actually", "smoother", "than", "exemplar", "thus", "fail", "mimic", "exemplar?s", "style", "section", "3.1", "show", "artist", "exhibit", "some", "natural", "variation", "hand", "pose", "even", "when", "draw", "same", "path", "multiple", "time", "therefore", "gold", "standard", "we", "can", "compare", "we", "synthesis", "result", "against?l", "measurement", "reconstruction", "error", "against", "ground", "truth", "good", "indication", "success", "correlation", "other", "hand", "better", "evaluation", "metric", "case", "pose", "synthesis", "we", "can", "apply", "analysis", "similar", "section", "3.1", "evaluate", "we", "result", "style", "library", "successfully", "transfer", "onto", "query", "stroke", "every", "local", "patch", "output", "should", "have", "sim", "-lrb-", "-rrb-", "ground", "truth", "-lrb-", "-rrb-", "optimal", "-lrb-", "-rrb-", "weighted", "average", "-lrb-", "-rrb-", "closest", "-lrb-", "-rrb-", "transfer", "-lrb-", "-rrb-", "transfer", "ilar", "pose", "profile", "similar", "patch", "library", "we", "compare", "closest", "neighbor", "weighted", "average", "optimal", "sequence", "variant", "we", "algorithm", "-lrb-", "section", "4.2", "-rrb-", "Figure", "10", "contain", "correlation", "result", "show", "optimal", "algorithm", "achieve", "highest", "pose", "correlation", "both", "synthesis", "case", "furthermore", "since", "we", "have", "ground", "truth", "pose", "datum", "query", "stroke", "we", "compare", "they", "synthesis", "find", "well", "correlate", "expect", "note", "we", "have", "analogous", "quality", "measure", "trajectory", "synthesis", "because", "goal", "blend", "local", "feature", "global", "shape", "fair", "objective", "function", "more", "difficult", "formulate", "we", "conduct", "two", "user", "study", "goal", "evaluate", "whether", "user", "can", "distinguish", "between", "we", "result", "ground", "truth", "pose", "trajectory", "study", "separately", "because", "user", "overwhelmingly", "sensitive", "trajectory", "over", "pose", "which", "would", "make", "pose", "evaluation", "difficult", "combine", "both", "study", "use", "same", "methodology", "only", "image", "different", "Study", "Design", "we", "show", "subject", "three", "line", "English", "text", "from", "artist?s", "library?the", "exemplar", "-lrb-", "we", "use", "two", "library", "from", "each", "artist", "show", "Figure", "2a", "-rrb-", "below", "exemplar", "appear", "two", "test", "image", "contain", "same", "-lrb-", "3-9", "letter", "-rrb-", "phrase?one", "ground", "truth", "originally", "write", "artist", "one", "forgery", "synthesize", "one", "we", "algorithm", "subject", "instruct", "one", "image", "original", "other", "forgery", "ask", "identify", "original", "compare", "both", "exemplar", "pose", "study", "ground", "truth", "forgery", "have", "same", "trajectory", "-lrb-", "figure", "11", "-rrb-", "trajectory", "study", "ground", "truth", "trajectory", "use", "synthesis", "pose", "datum", "omit", "from", "all", "image", "-lrb-", "figure", "12", "-rrb-", "one", "trial", "consist", "26", "task", "-lrb-", "each", "same", "exemplar", "-rrb-", "compare", "-lrb-", "-rrb-", "random", "ground", "truth", "phrase", "forgery", "select", "from", "one", "five", "condition", "-lrb-", "-rrb-", "optimal", "sequence", "-lrb-", "-rrb-", "weighted", "average", "-lrb-", "-rrb-", "closest", "neighbor", "-lrb-", "-rrb-", "style", "transfer", "-lrb-", "-rrb-", "style", "transfer", "validation", "condition", "-lrb-", "b-d", "-rrb-", "algorithm", "be", "test", "whereas", "-lrb-", "e-f", "-rrb-", "baseline", "synthesize", "forgery", "another", "artist?s", "library", "-lrb-", "so", "should", "very", "easy", "identify", "-rrb-", "26", "task", "four", "from", "each", "-lrb-", "b-e", "-rrb-", "ten", "from", "-lrb-", "-rrb-", "randomly", "shuffle", "any", "particular", "subject", "-lrb-", "e-f", "-rrb-", "select", "from", "two", "different", "library", "style", "randomly", "we", "only", "retain", "datum", "from", "trial", "correct", "count", "-lrb-", "-rrb-", "method", "pose", "study", "trajectory", "study", "average", "153", "322", "-lrb-", "48", "-rrb-", "96", "302", "-lrb-", "32", "-rrb-", "optimal", "169", "316", "-lrb-", "53", "-rrb-", "172", "305", "-lrb-", "56", "-rrb-", "closest", "269", "304", "-lrb-", "88", "-rrb-", "220", "292", "-lrb-", "75", "-rrb-", "transfer", "293", "301", "-lrb-", "97", "-rrb-", "274", "288", "-lrb-", "95", "-rrb-", "-lrb-", "-rrb-", "ground", "truth", "-lrb-", "-rrb-", "optimal", "-lrb-", "-rrb-", "weighted", "average", "-lrb-", "-rrb-", "closest", "-lrb-", "-rrb-", "transfer", "-lrb-", "-rrb-", "transfer", "when", "out", "10", "validation", "condition", "-lrb-", "-rrb-", "correct", "so", "we", "know", "user", "understand", "task", "actually", "try", "succeed", "-lrb-", "0.01", "-rrb-", "style", "transfer", "result", "only", "report", "-lrb-", "-rrb-", "subject", "be", "worker", "Amazon", "mechanical", "Turk", "microjob", "marketplace", "have", "be", "use", "grow", "variety", "study", "-lsb-", "Cole", "et", "al.", "2009", "-rsb-", "we", "study", "be", "restricted", "us-only", "worker", "who", "be", "pay", "0.20", "per", "task", "-lrb-", "HIT", "contain", "26", "comparison", "which", "typically", "complete", "few", "minute", "-rrb-", "across", "two", "study", "70", "worker", "complete", "total", "214", "hit", "subject", "be", "allow", "complete", "many", "10", "hit", "per", "study", "most", "worker", "do", "just", "one", "case", "where", "particular", "pair", "repeat", "particular", "worker", "due", "randomize", "selection", "we", "only", "retain", "first", "response", "total", "4,170", "response", "Study", "result", "result", "report", "Table", "frequency", "which", "ground", "truth", "correctly", "identify", "Bonferroni", "correct", "randomize", "permutation", "test", "distribution", "each", "consecutive", "pair", "row", "table", "show", "different", "statistical", "significance", "-lrb-", "0.01", "-rrb-", "except", "case", "average", "optimal", "condition", "pose", "study", "-lrb-", "0.34", "-rrb-", "ideal", "forgery", "indistinguishable", "from", "ground", "truth", "so", "subject", "choose", "randomly", "result", "correct", "answer", "near", "50", "time", "when", "forgery", "easy", "identify", "-lrb-", "figure", "12e", "-rrb-", "we", "expect", "score", "near", "100", "transfer", "condition", "near", "100", "both", "study", "which", "show", "people", "can", "perform", "task", "easy", "case", "people", "tend", "identify", "closest", "method", "-lrb-", "88", "75", "-rrb-", "so", "generally", "implausible", "pose", "study", "average", "optimal", "both", "near", "50", "therefore", "plausibly", "synthesize", "pose", "datum", "optimal", "perform", "well", "trajectory", "study", "average", "significantly", "below", "50", "which", "mean", "subject", "tend", "incorrectly", "identify", "forgery", "original", "mention", "section", "4.2.2", "weighted", "average", "method", "produce", "very", "smooth", "output", "trajectory", "we", "believe", "people", "have", "bias", "towards", "smoother", "curve", "case", "people", "choose", "average", "over", "ground", "truth", "even", "though", "actually", "smoother", "than", "exemplar", "thus", "fail", "mimic", "exemplar?s", "style" ],
  "content" : "The running time of our synthesis algorithm is sublinear with the number of library samples, due to the approximate k-NN search. We found through experimentation that 150 strokes is sufficient for generating plausible results, and confirmed this through correlation analysis similar to that of Section 3. For such a library, the average running time for both pose and trajectory synthesis is 0.08 seconds per stroke. We experimented with ?enriching? the library up to about 1000 strokes by including the same strokes scaled to different sizes (?50%), to increase matching scale-invariance, but did not see a significant improvement, and performance was reduced. We also tried using very small (fewer than 10) and very large (more than 500) libraries. With small libraries, feature matching cannot find similar enough trajectories and therefore picks random strokes to copy. Since the optimal sequence algorithm encourages long segments, the pose results still look plausible, but for trajectories, poor matches may result in complete loss of semantics in the results. Large libraries do not affect pose synthesis, whereas  trajectory modification is more likely to find very similar patches to the query, reducing the effect of style transfer. All the results shown here are rendered using Adobe Photoshop?s bristle brush tool [DiVerdi et al. 2010] with the same brush settings. The differences in the synthesized pose data induce the visibly different shape and texture of the strokes. Figure 8 shows the plausibility of pose synthesis on handwriting. An artist?s 6-DOF strokes are stripped of their pose data and the trajectories are used as queries with the same artist?s library applied. The synthesized output is visually indistinguishable from the ground truth, whereas applying another artist?s library creates a visually distinct result. Pose synthesis on line drawings is demonstrated in Figure 9 . Examples of trajectory stylization are in Figure 15 . We show robustness to noisy input and the utility of trajectory stylization by demonstrating how it can neaten mouse-written text, which has characteristic shakiness. Similarly, a line drawing made by an artist with an unsure hand can be made to have more confident strokes. Our algorithm can also apply stylistic flourishes such as serifs or block lettering. Figures 1, 14, and 15 show the two-pass algorithm stylizing both pose and trajectory. The remainder of this section describes the studies we conducted to evaluate our results. As a quantitative measure of the pose synthesis quality, we computed the correlation between the synthesized results and ground truth. However, there is no equivalent measure for trajectory synthesis and ultimately we care most about how users judge our results. Therefore, we also conducted user studies on both pose and trajectory synthesis. Section 3.1 shows that an artist exhibits some natural variation in hand pose even when drawing the same path multiple times. Therefore, there is no ?gold standard? that we can compare our synthesis results against?L 2 measurement of reconstruction error against the ground truth is not a good indication of success. Correlation on the other hand is a better evaluation metric in this case. For pose synthesis, we can apply analysis similar to Section 3.1 to evaluate our results. If the style of the library is successfully transferred onto the query strokes, every local patch of the output should have a sim- (a) ground truth (b) optimal (c) weighted average (d) closest (e) transfer 1 (f) transfer 2 ilar pose profile to similar patches in the library. We compared the closest neighbor, weighted average, and optimal sequence variants of our algorithm (Section 4.2). Figure 10 contains the correlation results. It shows that the optimal algorithm achieves the highest pose correlation in both synthesis cases. Furthermore, since we have ground truth pose data for the query strokes, we compare them to the synthesis and find they are not well correlated, as expected. Note that we have no analogous quality measure for trajectory synthesis because the goal is a blend of local features with global shape, and a fair objective function is more difficult to formulate. We conducted two user studies with the goal of evaluating whether a user can distinguish between our results and ground truth. Pose and trajectory are studied separately because users are overwhelmingly sensitive to trajectory over pose, which would make pose evaluation difficult if combined. Both studies use the same methodology; only the images are different. Study Design. We show the subject three lines of English text from an artist?s library?the exemplar (we used two libraries from each of the artists shown in Figure 2a -b). Below the exemplar appear two test images containing the same (3-9 letter) phrase?one ground truth originally written by the artist, and one forgery synthesized by one of our algorithms. The subject is instructed that one image is an ?original? and the other is a ?forgery,? and is asked to identify the original by comparing both with the exemplar. In the pose study, the ground truth and forgery have the same trajectory ( Figure 11 ). In the trajectory study, the ground truth trajectory is used for synthesis, and pose data is omitted from all images ( Figure 12 ). One trial consists of 26 such tasks (each with the same exemplar) comparing (a) a random ground truth phrase, and a forgery selected from one of five conditions: (b) optimal sequence, (c) weighted average, (d) closest neighbor, (e) style transfer, and (f) style transfer for validation. Conditions (b-d) are the algorithms being tested, whereas (e-f) are baselines that synthesize the forgery with another artist?s library (so should be very easy to identify). Of the 26 tasks, four are from each of (b-e) and ten are from (f), randomly shuffled. For any particular subject, (e-f) are selected from two different library styles, randomly. We only retain data from a trial\n          correct / count (%) method pose study trajectory study average 153 / 322 (48%) 96 / 302 (32%) optimal 169 / 316 (53%) 172 / 305 (56%) closest 269 / 304 (88%) 220 / 292 (75%) transfer 293 / 301 (97%) 274 / 288 (95%) (a) ground truth (b) optimal (c) weighted average (d) closest (e) transfer 1 (f) transfer 2 when 9 out of 10 of the validation conditions (f) are correct, so we know the user understands the task and is actually trying to succeed (p = 0.01). Then style transfer results are only reported for (e). Subjects were ?workers? on the Amazon Mechanical Turk, a microjob marketplace that has been used for a growing variety of such studies [Cole et al. 2009]. Our studies were restricted to US-only workers who were paid $0.20 per task (a ?HIT? containing the 26 comparisons, which they typically completed in a few minutes). Across the two studies, 70 workers completed a total of 214 HITs. Subjects were allowed to complete as many as 10 HITs per study, but most workers did just one. For cases where a particular pair was repeated by a particular worker due to the randomized selection, we only retained the first such response, for total of 4,170 responses. Study Results. The results are reported in Table 1 as the frequency with which the ground truth was correctly identified. A Bonferroni corrected, randomized permutation test on the distributions for each consecutive pair of rows in the table shows that they are different with statistical significance (p 0.01) except in the case of the average and optimal conditions in the pose study (p = 0.34). The ideal forgery is indistinguishable from ground truth so subjects will choose randomly, resulting in a correct answer near 50% of the time. When the forgery is easy to identify ( Figure 12e ), we expect scores near 100%. The transfer condition is near 100% in both studies, which shows people can perform the task in easy cases. People tend to identify the closest method (88% and 75%), so it is generally implausible. In the pose study, average and optimal are both near 50%, and therefore plausibly synthesize pose data. Optimal performs well in the trajectory study, but average is significantly below 50% which means subjects tend to incorrectly identify the forgery as the ?original. ? As mentioned in Section 4.2.2 the weighted average method produces a very smooth output trajectory, and we believe people have a bias towards smoother curves. In such cases people choose average over ground truth, even though it is actually smoother than the exemplar and thus fails to mimic the exemplar?s style. Section 3.1 shows that an artist exhibits some natural variation in hand pose even when drawing the same path multiple times. Therefore, there is no ?gold standard? that we can compare our synthesis results against?L 2 measurement of reconstruction error against the ground truth is not a good indication of success. Correlation on the other hand is a better evaluation metric in this case. For pose synthesis, we can apply analysis similar to Section 3.1 to evaluate our results. If the style of the library is successfully transferred onto the query strokes, every local patch of the output should have a sim- (a) ground truth (b) optimal (c) weighted average (d) closest (e) transfer 1 (f) transfer 2 ilar pose profile to similar patches in the library. We compared the closest neighbor, weighted average, and optimal sequence variants of our algorithm (Section 4.2). Figure 10 contains the correlation results. It shows that the optimal algorithm achieves the highest pose correlation in both synthesis cases. Furthermore, since we have ground truth pose data for the query strokes, we compare them to the synthesis and find they are not well correlated, as expected. Note that we have no analogous quality measure for trajectory synthesis because the goal is a blend of local features with global shape, and a fair objective function is more difficult to formulate. We conducted two user studies with the goal of evaluating whether a user can distinguish between our results and ground truth. Pose and trajectory are studied separately because users are overwhelmingly sensitive to trajectory over pose, which would make pose evaluation difficult if combined. Both studies use the same methodology; only the images are different. Study Design. We show the subject three lines of English text from an artist?s library?the exemplar (we used two libraries from each of the artists shown in Figure 2a -b). Below the exemplar appear two test images containing the same (3-9 letter) phrase?one ground truth originally written by the artist, and one forgery synthesized by one of our algorithms. The subject is instructed that one image is an ?original? and the other is a ?forgery,? and is asked to identify the original by comparing both with the exemplar. In the pose study, the ground truth and forgery have the same trajectory ( Figure 11 ). In the trajectory study, the ground truth trajectory is used for synthesis, and pose data is omitted from all images ( Figure 12 ). One trial consists of 26 such tasks (each with the same exemplar) comparing (a) a random ground truth phrase, and a forgery selected from one of five conditions: (b) optimal sequence, (c) weighted average, (d) closest neighbor, (e) style transfer, and (f) style transfer for validation. Conditions (b-d) are the algorithms being tested, whereas (e-f) are baselines that synthesize the forgery with another artist?s library (so should be very easy to identify). Of the 26 tasks, four are from each of (b-e) and ten are from (f), randomly shuffled. For any particular subject, (e-f) are selected from two different library styles, randomly. We only retain data from a trial\n          correct / count (%) method pose study trajectory study average 153 / 322 (48%) 96 / 302 (32%) optimal 169 / 316 (53%) 172 / 305 (56%) closest 269 / 304 (88%) 220 / 292 (75%) transfer 293 / 301 (97%) 274 / 288 (95%) (a) ground truth (b) optimal (c) weighted average (d) closest (e) transfer 1 (f) transfer 2 when 9 out of 10 of the validation conditions (f) are correct, so we know the user understands the task and is actually trying to succeed (p = 0.01). Then style transfer results are only reported for (e). Subjects were ?workers? on the Amazon Mechanical Turk, a microjob marketplace that has been used for a growing variety of such studies [Cole et al. 2009]. Our studies were restricted to US-only workers who were paid $0.20 per task (a ?HIT? containing the 26 comparisons, which they typically completed in a few minutes). Across the two studies, 70 workers completed a total of 214 HITs. Subjects were allowed to complete as many as 10 HITs per study, but most workers did just one. For cases where a particular pair was repeated by a particular worker due to the randomized selection, we only retained the first such response, for total of 4,170 responses. Study Results. The results are reported in Table 1 as the frequency with which the ground truth was correctly identified. A Bonferroni corrected, randomized permutation test on the distributions for each consecutive pair of rows in the table shows that they are different with statistical significance (p 0.01) except in the case of the average and optimal conditions in the pose study (p = 0.34). The ideal forgery is indistinguishable from ground truth so subjects will choose randomly, resulting in a correct answer near 50% of the time. When the forgery is easy to identify ( Figure 12e ), we expect scores near 100%. The transfer condition is near 100% in both studies, which shows people can perform the task in easy cases. People tend to identify the closest method (88% and 75%), so it is generally implausible. In the pose study, average and optimal are both near 50%, and therefore plausibly synthesize pose data. Optimal performs well in the trajectory study, but average is significantly below 50% which means subjects tend to incorrectly identify the forgery as the ?original. ? As mentioned in Section 4.2.2 the weighted average method produces a very smooth output trajectory, and we believe people have a bias towards smoother curves. In such cases people choose average over ground truth, even though it is actually smoother than the exemplar and thus fails to mimic the exemplar?s style.",
  "resources" : [ ]
}