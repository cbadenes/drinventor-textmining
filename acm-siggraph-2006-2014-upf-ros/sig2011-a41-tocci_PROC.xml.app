{
  "uri" : "sig2011-a41-tocci_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2011/a41-tocci_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "A Versatile HDR Video Production System",
    "published" : "2011",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Michael D.-Tocci",
      "name" : "Michael D.",
      "surname" : "Tocci"
    }, {
      "uri" : "http://drinventor/Chris-Kiser",
      "name" : "Chris",
      "surname" : "Kiser"
    }, {
      "uri" : "http://drinventor/Nora-Tocci",
      "name" : "Nora",
      "surname" : "Tocci"
    }, {
      "uri" : "http://drinventor/Pradeep-Sen",
      "name" : "Pradeep",
      "surname" : "Sen"
    } ]
  },
  "bagOfWords" : [ "work", "we", "present", "optical", "architecture", "HDR", "imaging", "allow", "simultaneous", "capture", "high", "medium", "low-exposure", "image", "three", "sensor", "high", "fidelity", "efficient", "use", "available", "light", "we", "also", "present", "hdr", "merge", "algorithm", "complement", "architecture", "which", "avoid", "undesired", "artifact", "when", "large", "exposure", "difference", "between", "image", "we", "implement", "prototype", "high-definition", "hdr-video", "system", "we", "present", "still", "frame", "from", "acquire", "HDR", "video", "tonemapp", "various", "technique", "cr", "category", "i.", "4.1", "-lsb-", "image", "processing", "computer", "Vision", "-rsb-", "digitization", "image", "capture?radiometry", "keyword", "hdr", "video", "merge", "hdr", "image", "Links", "dl", "pdf", "paper", "we", "describe", "end-to-end", "system", "capture", "HDR", "video", "high", "pixel", "fidelity", "use", "lightefficient", "optical", "architecture", "fit", "single", "hand-held", "unit", "we", "demonstrate", "work", "prototype", "present", "image", "video", "acquire", "system", "during", "merging", "process", "algorithm", "combine", "value", "from", "every", "exposure", "weighting", "each", "contribution", "triangle", "filter", "fall", "off", "pixel", "value", "approach", "cutoff", "saturation", "peak", "middle", "idea", "give", "more", "weight", "pixel", "work", "range", "camera", "less", "one", "near", "extrema", "camera?s", "operate", "range", "however", "approach", "can", "suffer", "from", "undesirable", "artifact", "when", "apply", "widely-separated", "ldr", "image", "due", "blending", "between", "exposure", "method", "do", "produce", "true", "radiometrically-correct", "hdr", "image", "so", "result", "can", "incorporate", "hdr", "production", "workflow", "simplest", "approach", "HDR", "imaging", "involve", "take", "series", "image", "different", "exposure", "time", "-lrb-", "e.g.", "-lsb-", "Mann", "Picard", "1995", "Debevec", "Malik", "1997", "-rsb-", "-rrb-", "approach", "require", "image", "manipulation", "register", "image", "which", "also", "introduce", "artifact", "although", "commercial-scale", "production", "sensor", "may", "someday", "realize", "currently", "expensive", "manufacture", "render", "method", "unusable", "most", "researcher", "today", "Aggarwal", "Ahuja", "-lsb-", "2004", "-rsb-", "point", "out", "possible", "vary", "amount", "light", "each", "sensor", "move", "beamsplitt", "prism", "away", "from", "optical", "axis", "instead", "use", "filter", "effectively", "change", "size", "shape", "aperture", "stop", "each", "sensor", "exacerbate", "problem", "each", "sensor", "get", "different", "view", "scene", "furthermore", "shiftedoptical-axis", "spatial-beamsplitting", "method", "easily", "integrate", "standard", "camera", "lens", "require", "either", "custom", "lens", "manufacture", "lens", "modification", "work", "correctly", "another", "option", "split", "incoming", "light", "beamsplitter", "prior", "lens", "two", "lens", "must", "perfectly", "match", "however", "zoom", "focus", "iris-tracking", "can", "difficult", "maintain", "between", "they", "addition", "put", "beamsplitter", "front", "camera", "lens", "place", "limit", "field", "view", "goal", "work", "present", "system", "simplify", "discussion", "paper", "however", "we", "simply", "state", "single", "average", "value", "transmittance", "therefore", "variation", "transmittance", "across", "sensor", "major", "issue", "we", "system", "course", "when", "ldr", "image", "very", "close", "exposure", "artifact", "considerably", "reduce", "method", "like", "Debevec", "Malik?s", "work", "quite", "well", "however", "hdr", "video", "system", "small", "set", "sensor", "become", "more", "widely", "use", "issue", "become", "more", "important", "although", "Debevec", "Malik?s", "algorithm", "blend", "value", "together", "we", "propose", "instead", "use", "pixel", "value", "from", "only", "longest-exposure", "sensor", "-lrb-", "which", "less", "noisy", "-rrb-", "wherever", "possible", "blend", "next", "darker", "exposure", "when", "pixel", "approach", "saturation", "instead", "we", "propose", "gracefully", "transition", "from", "one", "sensor", "next", "spatially", "blend", "pixel", "value", "between", "two", "sensor", "example", "bright", "orange", "section", "scene", "might", "have", "red", "pixel", "saturate", "while", "green", "blue", "pixel", "only", "way", "avoid", "artifact", "perform", "hdr-merging", "prior", "demosaicing", "we", "case", "we", "can", "factor", "out", "exposure", "time", "-lrb-", "since", "constant", "all", "three", "image", "-rrb-", "produce", "curve", "map", "pixel", "value", "directly", "scene", "irradiance", "interpolation", "coefficient", "can", "compute", "he", "which", "represent", "fraction", "unsaturated", "pixel", "neighborhood", "case", "we", "simply", "use", "me", "image", "set", "hdr", "-lrb-", "-rrb-", "me", "-lrb-", "-rrb-", "first", "two", "image", "Fig.", "13", "now", "og", "ash", "be", "capture", "snow", "direct", "sunlight", "second", "hdr", "imaging", "would", "arguably", "benefit", "consumer", "more", "than", "professional", "cinematographer", "because", "typical", "consumer", "do", "have", "lighting", "rig", "training", "need", "achieve", "HDR", "effect", "ldr", "system" ],
  "content" : "In this work, we present an optical architecture for HDR imaging that allows simultaneous capture of high, medium, and low-exposure images on three sensors at high fidelity with efficient use of the available light. We also present an HDR merging algorithm to complement this architecture, which avoids undesired artifacts when there is a large exposure difference between the images. We implemented a prototype high-definition HDR-video system and we present still frames from the acquired HDR video, tonemapped with various techniques. CR Categories: I.4.1 [Image Processing and Computer Vision]: Digitization and Image capture?Radiometry Keywords: HDR video, merging HDR images Links: DL PDF In this paper, we describe an end-to-end system for capturing HDR video with high pixel fidelity, using a lightefficient optical architecture that fits into a single hand-held unit. We demonstrate a working prototype and present images and video acquired with this system. During the merging process, the algorithm combines values from every exposure by weighting each contribution by a triangle filter that falls off as the pixel value approaches cutoff or saturation and peaks in the middle. The idea is to give more weight to pixels in the ?working range? of the camera, and less to the ones near the extrema of the camera?s operating range. 4, however, this approach can suffer from undesirable artifacts when applied to widely-separated LDR images due to the blending between exposures. These methods do not produce a true, radiometrically-correct HDR image, so the results cannot be incorporated into an HDR production workflow. The simplest approach for HDR imaging involves taking a series of images with different exposure times (e.g., [Mann and Picard 1995; Debevec and Malik 1997]). These approaches require image manipulation to register the images, which also introduces artifacts. Although commercial-scale production of these sensors may someday be realized, they are currently expensive to manufacture, rendering these methods unusable by most researchers today. As Aggarwal and Ahuja [2004] point out, it is possible to vary the amount of light to each sensor by moving the beamsplitting prism away from the optical axis instead of using filters. This effectively changes the size and shape of the aperture stop for each sensor, exacerbating the problem of each sensor getting different views of the scene. Furthermore, these shiftedoptical-axis spatial-beamsplitting methods are not easily integrated with standard camera lenses, and require either custom lens manufacture or lens modification to work correctly. Another option is to split the incoming light with beamsplitters prior to the lens. The two lenses must be perfectly matched, however, and zoom-, focus-, and iris-tracking can be difficult to maintain between them. In addition, putting the beamsplitter in front of the camera lens places a limit on the field of view. The goal of this work is to present such a system. To simplify the discussion in this paper, however, we simply state a single average value of transmittance. Therefore variation in transmittance across the sensor is not a major issue in our system. Of course, when the LDR images are very close in exposure, these artifacts are considerably reduced and methods like Debevec and Malik?s work quite well. However, as HDR video systems with a small set of sensors become more widely used, this issue will become more important. Although Debevec and Malik?s algorithm blends these values together, we propose instead to use pixel values from only the longest-exposure sensor (which is less noisy) wherever possible, and blend in the next darker exposure when pixels approach saturation. Instead, we propose to gracefully transition from one sensor to the next by spatially blending pixel values between the two sensors. For example, a bright orange section of a scene might have red pixels that are saturated while the green and blue pixels are not. The only way to avoid these artifacts is to perform HDR-merging prior to demosaicing. In our case, we can factor out the exposure time (since it is constant for all three images) and produce a curve that maps pixel value directly to scene irradiance. An interpolation coefficient ? can be computed as ? = |U |/|N HE |, which represents the fraction of unsaturated pixels in the neighborhood. In this case, we simply use the ME image and set I HDR (x, y) = I ME (x, y). The first two images of Fig. 13 , S NOW D OG and W ASH M E , were captured in the snow in direct sunlight. Second, HDR imaging would arguably benefit consumers more than professional cinematographers because the typical consumer does not have the lighting rigs or training needed to achieve HDR effects with LDR systems.",
  "resources" : [ ]
}