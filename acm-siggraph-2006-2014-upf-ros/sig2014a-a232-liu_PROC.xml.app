{
  "uri" : "sig2014a-a232-liu_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2014a/a232-liu_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Fast Burst Images Denoising",
    "published" : null,
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ ]
  },
  "bagOfWords" : [ "we", "accelerate", "alignment", "image", "introduce", "lightweight", "camera", "motion", "representation", "call", "homography", "flow", "handle", "scene", "motion", "during", "capture", "mechanism", "select", "consistent", "pixel", "temporal", "fusion", "propose", "synthesize", "clean", "ghost-free", "image", "which", "can", "largely", "reduce", "computation", "track", "motion", "between", "frame", "combine", "efficient", "solution", "we", "method", "run", "several", "order", "magnitude", "faster", "than", "previous", "work", "while", "denoising", "quality", "comparable", "smartphone", "prototype", "demonstrate", "we", "method", "practical", "work", "well", "large", "variety", "real", "example", "cr", "category", "i.", "4.3", "-lsb-", "image", "processing", "computer", "Vision", "-rsb-", "enhancement?smoothing", "keyword", "denoising", "burst", "image", "homography", "flow", "ghost-free", "design", "allow", "selection", "best", "shot", "record", "motion", "burst", "mode", "have", "be", "successfully", "exploit", "computation", "photography", "reduce", "blur", "-lsb-", "Cai", "et", "al.", "2009", "-rsb-", "improve", "shadow/highlight", "detail", "-lsb-", "Reinhard", "et", "al.", "2010", "-rsb-", "increase", "resolution", "-lsb-", "Farsiu", "et", "al.", "2004", "-rsb-", "clarity", "-lsb-", "Joshi", "Cohen", "2010", "-rsb-", "depth", "field", "-lsb-", "Jacobs", "et", "al.", "2012", "-rsb-", "paper", "we", "present", "practical", "solution", "burst", "image", "denoise", "turn", "burst", "noisy", "image", "-lrb-", "typically", "capture", "low-light", "condition", "-rrb-", "single", "clean", "image", "show", "Figure", "problem", "new", "have", "be", "study", "context", "multiple", "images/video", "denoising", "-lsb-", "buade", "et", "al.", "2010", "Liu", "Freeman", "2010", "Zhang", "et", "al.", "2009", "-rsb-", "we", "focus", "practicality", "we", "goal", "design", "highly", "efficient", "method", "while", "produce", "high-quality", "result", "so", "algorithm", "can", "run", "mobile", "device", "limited", "computational", "resource", "practical", "approach", "need", "tackle", "two", "challenge", "First", "efficiency", "Second", "quality", "moreover", "even", "some", "complicated", "method", "also", "fragile", "presence", "strong", "noise", "complex", "dynamic", "motion", "second", "step", "we", "handle", "scene", "motion", "identify", "consistent", "pixel", "-lrb-", "i.e.", "pixel", "similar", "color", "-rrb-", "along", "temporal", "axis", "from", "all", "align", "image", "-lrb-", "first", "step", "-rrb-", "per", "pixel", "location", "thus", "we", "can", "generate", "ghostfree", "result", "while", "avoid", "complex", "motion", "tracking", "dynamic", "object", "which", "too", "slow", "too", "difficult", "we", "extend", "idea", "find", "many", "consistent", "pixel", "possible", "every", "pixel", "location", "purpose", "better", "denoising", "third", "step", "we", "apply", "temporal", "multiscale", "pixel", "fusion", "succession", "obtain", "denoised", "result", "temporal", "fusion", "base", "simple", "optimal", "linear", "estimator", "multiscale", "fusion", "complementary", "temporal", "fusion", "further", "enable", "significant", "denoising", "meanwhile", "whole", "step", "also", "very", "efficient", "design", "because", "only", "involve", "pixel-wise", "operation", "furthermore", "we", "algorithm", "two", "three", "order", "magnitude", "faster", "Figure", "show", "comparison", "Representative", "method", "include", "bilateral", "filter", "-lsb-", "Tomasi", "Manduchi", "1998", "-rsb-", "wavelet", "-lrb-", "gsm", "-rrb-", "-lsb-", "Portilla", "et", "al.", "2003", "-rsb-", "field-ofexpert", "-lsb-", "Roth", "Black", "2005", "-rsb-", "non-local", "means", "-lsb-", "buade", "et", "al.", "2005", "-rsb-", "bm3d", "-lsb-", "Dabov", "et", "al.", "2007b", "-rsb-", "so", "most", "recently", "Levin", "et", "al.", "-lsb-", "2011", "-rsb-", "point", "out", "single", "image", "denoising", "may", "approach", "its", "performance", "limit", "multiple", "image", "denoising", "superior", "single", "image", "denoising", "because", "its", "use", "more", "information", "some", "denoise", "technique", "have", "be", "successfully", "use", "burst", "image", "-lsb-", "Tico", "2008", "Buades", "et", "al.", "2009", "Joshi", "Cohen", "2010", "-rsb-", "video", "-lsb-", "Bennett", "McMillan", "2005", "Liu", "Freeman", "2010", "Dabov", "et", "al.", "2007a", "Chen", "Tang", "2007", "-rsb-", "multiple-view", "image", "-lsb-", "Zhang", "et", "al.", "2009", "-rsb-", "volumetric", "MRI", "datum", "-lsb-", "maggionus", "et", "al.", "2013", "-rsb-", "work", "we", "use", "similar", "more", "lightweight", "parametric", "motion", "representation", "homography", "flow", "we", "first", "build", "gaussian", "pyramid", "all", "noisy", "image", "set", "midmost", "frame", "reference", "frame", "default", "across", "align", "image", "-lrb-", "homography", "flow", "-rrb-", "every", "pixel", "location", "we", "select", "set", "consistent", "pixel", "handle", "scene", "motion", "-lrb-", "section", "3.2", "-rrb-", "possible", "small", "misalignment", "cause", "homography", "flow", "note", "independently", "estimate", "homography", "each", "node", "unreliable", "because", "some", "node", "may", "have", "insufficient", "match", "feature", "basic", "idea", "use", "backup", "when", "we", "can", "reliably", "compute", "since", "pyramid", "homography", "graph", "parametric", "representation", "we", "require", "image", "warping", "coordinate", "transformation", "later", "denoising", "step", "operation", "all", "pixel", "-lrb-", "all", "frame", "all", "scale", "-rrb-", "very", "expensive", "address", "critical", "issue", "we", "application", "we", "discretize", "homography", "shear", "homography", "1.25", "modulus", "perspective", "0.1", "compare", "originalscale", "implementation", "time", "cost", "greatly", "reduce", "-lrb-", "factor", "average", "-rrb-", "psnr", "-lrb-", "measure", "registration", "error", "-rrb-", "improve", "0.005", "db", "0.045", "db", "various", "noise", "sigma", "-lrb-", "from", "20", "60", "-rrb-", "every", "pixel", "location", "-lrb-", "reference", "frame", "-rrb-", "we", "identify", "set", "consistent", "pixel", "1d", "profile", "-lrb-", "trace", "estimate", "homography", "flow", "-rrb-", "across", "all", "image", "temporal", "pixel", "fusion", "different", "from", "hdr", "deghosting", "purpose", "select", "consistent", "pixel", "only", "avoid", "ghost", "artifact", "-lrb-", "cause", "dynamic", "motion", "small", "frame", "misalignment", "-rrb-", "also", "find", "many", "consistent", "pixel", "possible", "denoise", "one", "reference-based", "we", "bi-directionally", "trace", "profile", "from", "pixel", "reference", "frame", "collect", "consistent", "pixel", "until", "accumulate", "pixel", "difference", "exceed", "threshold", "above", "fusion", "do", "exploit", "spatial", "information", "which", "play", "central", "role", "single", "image", "denoising", "algorithm", "-lsb-", "Zontak", "et", "al.", "2013", "-rsb-", "addition", "patch-based", "lmmse", "estimator", "provide", "overlap", "estimate", "every", "pixel", "which", "need", "patch", "aggregation", "-lrb-", "along", "temporal", "axis", "spatial", "edge", "direction", "-rrb-", "get", "final", "fusion", "result", "simulate", "camera", "motion", "we", "reuse", "estimate", "global", "homography", "from", "real", "datum", "-lrb-", "figure", "-rrb-", "randomly", "apply", "they", "one", "clean", "image", "generate", "burst", "image", "-lrb-", "10", "frame", "-rrb-", "challenge", "case", "how", "remove", "strong", "noise", "sky", "recover", "building", "structure" ],
  "content" : "We accelerate alignment of the images by introducing a lightweight camera motion representation called homography flow. To handle scene motion during the capture, a mechanism of selecting consistent pixels for temporal fusion is proposed to ?synthesize? a clean, ghost-free image, which can largely reduce the computation of tracking motion between frames. Combined with these efficient solutions, our method runs several orders of magnitude faster than previous work, while the denoising quality is comparable. A smartphone prototype demonstrates that our method is practical and works well on a large variety of real examples. CR Categories: I.4.3 [Image Processing and Computer Vision]: Enhancement?Smoothing Keywords: denoising, burst images, homography flow, ghost-free It is designed to allow selection of the best shot or record the motion. The burst mode has been successfully exploited in computation photography for reducing blur [Cai et al. 2009], or improving shadow/highlight details [Reinhard et al. 2010], or increasing resolution [Farsiu et al. 2004], or clarity [Joshi and Cohen 2010], or depth of the field [Jacobs et al. 2012]. In this paper, we present a practical solution for ?burst images denoising? turning a burst of noisy images (typically captured in a low-light condition) into a single clean image, as shown in Figure 1 . This problem is not new. It has been studied in the context of multiple images/video denoising [Buades et al. 2010; Liu and Freeman 2010; Zhang et al. 2009]. But we focus on practicality our goal is to design a highly efficient method while producing a high-quality result so that the algorithm can be run on a mobile device with limited computational resources. A practical approach needs to tackle two challenges. First is efficiency. Second is quality. Moreover, even some complicated methods are also fragile in the presence of strong noise or complex dynamic motion. In the second step, we handle the scene motion by identifying consistent pixels (i.e., pixels with similar colors) along the temporal axis from all aligned images (by the first step) per pixel location. Thus, we can generate ghostfree results while avoiding complex motion tracking on dynamic objects, which is too slow or too difficult. We extend this idea to find as many consistent pixels as possible at every pixel location for the purpose of better denoising. In the third step, we apply temporal and multiscale pixel fusions in succession to obtain the denoised result. The temporal fusion is based on a simple, optimal linear estimator. The multiscale fusion is complementary to temporal fusion and further enables significant denoising. Meanwhile, the whole step is also very efficient by design because it only involves pixel-wise operations. Furthermore, our algorithm is two or three orders of magnitude faster. Figure 1 shows a comparison. Representative methods include bilateral filtering [Tomasi and Manduchi 1998], wavelet (GSM) [Portilla et al. 2003], Field-OfExpert [Roth and Black 2005], non-local means [Buades et al. 2005], BM3D [Dabov et al. 2007b] and so on. Most recently, Levin et al. [2011] pointed out that single image denoising may be approaching its performance limit. Multiple image denoising is superior to single image denoising because of its use of more information. Some denoising techniques have been successfully used on burst images [Tico 2008; Buades et al. 2009; Joshi and Cohen 2010], videos [Bennett and McMillan 2005; Liu and Freeman 2010; Dabov et al. 2007a; Chen and Tang 2007], multiple-view images [Zhang et al. 2009], and volumetric MRI data [Maggioni et al. 2013]. In this work, we use a similar but more lightweight parametric motion representation homography flow. We first build Gaussian pyramids 1 of all noisy images and set the midmost frame as the reference frame by default. Across the aligned images (by homography flow), at every pixel location, we select a set of consistent pixels to handle scene motions (in Section 3.2) or possible small misalignment caused by the homography flow. Note that independently estimating the homography at each node is unreliable because some nodes may have insufficient matched features. The basic idea is to use H ? i l?1 as backup when we cannot reliably compute F i l . Since the pyramid homography graph is a parametric representation, we require an image warping or coordinate transformation in the later denoising step. But such operations for all pixels (in all frames, at all scales) are very expensive. To address this critical issue in our application, we discretized the homography\n          2 Shear of homography > 1.25 or modulus of perspective > 0.1. Compared with originalscale implementation, the time cost is greatly reduced (by a factor of 6, on average) and the PSNR (for measuring registration error) is improved by 0.005dB to 0.045dB for various noise sigma (from 20 to 60). At every pixel location (on a reference frame), we identify a set of consistent pixels on a 1D profile (traced by the estimated homography flow) across all images for temporal pixel fusion. Different from HDR deghosting, the purpose of selecting consistent pixels is not only avoiding ghost artifacts (caused by dynamic motion and small frame misalignment), but also finding as many consistent pixels as possible for denoising. One is reference-based: we bi-directionally trace the profile from the pixel at the reference frame and collect consistent pixels until the accumulated pixel difference exceeds a threshold ? . The above fusion does not exploit spatial information which plays a central role in single image denoising algorithms [Zontak et al. 2013]. In addition, the patch-based LMMSE estimator provides overlapping estimates for every pixel, which need patch aggregation (along the temporal axis or spatial edge direction) to get the final fusion result. To simulate the camera motion, we reuse the estimated global homographies from the real data ( Figure 4 ) and randomly apply them on one of the clean images to generate a burst of images (10 frames). The challenges in this case are on how to remove strong noise in the sky and recover building structures.",
  "resources" : [ ]
}