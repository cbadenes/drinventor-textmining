{
  "uri" : "sig2014-a145-templin_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2014/a145-templin_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Modeling and Optimizing Eye Vergence Response to Stereoscopic Cuts",
    "published" : "2014",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Krzysztof-Templin",
      "name" : "Krzysztof",
      "surname" : "Templin"
    }, {
      "uri" : "http://drinventor/Piotr-Didyk",
      "name" : "Piotr",
      "surname" : "Didyk"
    }, {
      "uri" : "http://drinventor/Karol-Myszkowski",
      "name" : "Karol",
      "surname" : "Myszkowski"
    }, {
      "uri" : "http://drinventor/Mohamed-Hefeeda",
      "name" : "Mohamed",
      "surname" : "Hefeeda"
    }, {
      "uri" : "http://drinventor/Hans-Peter-Seidel",
      "name" : "Hans-Peter",
      "surname" : "Seidel"
    }, {
      "uri" : "http://drinventor/Wojciech-Matusik",
      "name" : "Wojciech",
      "surname" : "Matusik"
    } ]
  },
  "bagOfWords" : [ "over", "past", "few", "year", "stereoscopic", "3d", "-lrb-", "s3d", "-rrb-", "technology", "have", "be", "constantly", "develop", "now", "have", "become", "ubiquitous", "however", "despite", "significant", "improvement", "only", "display", "device", "also", "image", "generation", "capture", "post-processing", "technique", "many", "consumer", "still", "skeptical", "about", "quality", "current", "s3d", "content", "future", "technology", "itself", "concern", "usually", "relate", "naturalness", "effortlessness", "overall", "appearance", "s3d", "effect", "should", "distraction", "difficulty", "s3d", "production", "sufficient", "produce", "two", "good", "image", "place", "one", "arrive", "good", "stereoscopic", "effect", "-lsb-", "Zilly", "et", "al.", "2011", "-rsb-", "s3d", "strong", "illusion", "since", "isolate", "only", "one", "real-world", "phenomenon", "fail", "reproduce", "many", "other", "prominent", "example", "be", "accommodation", "cue", "impose", "numerous", "restriction", "production", "process", "depth", "range", "variation", "must", "too", "large", "view-dependent", "effect", "need", "handle", "correctly", "image", "carefully", "register", "so", "work", "we", "concern", "rapid", "temporal", "change", "disparity", "human", "have", "good", "understanding", "environment", "observe", "move", "through", "so-called", "mental", "image", "which", "enhance", "capability", "focus", "different", "object", "-lsb-", "finke", "1989", "-rsb-", "however", "when", "scene", "merely", "sequence", "shot", "show", "flat", "screen", "easy", "get", "confused", "lose", "track", "point", "interest", "due", "among", "other", "thing", "unexpected", "change", "location", "camera", "angle", "although", "less", "problematic", "2d", "can", "challenge", "stereoscopic", "3d", "context", "unpredictable", "large", "change", "disparity", "mean", "binocular", "fusion", "lose", "confusing", "double", "image", "see", "-lrb-", "diplopium", "-rrb-", "moreover", "vergence", "system", "need", "quickly", "adapt", "new", "condition", "spite", "conflict", "goal", "interconnected", "accommodation", "system", "have", "be", "identify", "one", "source", "discomfort", "stereoscopic", "viewing", "-lsb-", "Hoffman", "et", "al.", "2008", "Lambooij", "et", "al.", "2009", "-rsb-", "Hollywood", "style", "combine", "shot", "develop", "set", "formal", "convention", "obey", "dynamics", "visual", "attention", "control", "continuity", "space", "time", "action", "modern", "movie", "cut", "play", "most", "important", "role", "-lrb-", "99", "all", "edit", "-rrb-", "while", "dissolve", "wipe", "have", "vanish", "almost", "completely", "extensive", "analysis", "cut", "et", "al.", "-lsb-", "2011", "-rsb-", "show", "average", "shot", "duration", "over", "past", "75", "year", "have", "decline", "from", "ca.", "15", "can", "clearly", "short", "shot", "increase", "viewer", "engagement", "force", "eye", "quickly", "follow", "newly", "appear", "content", "however", "accumulation", "sharp", "cut", "challenge", "visual", "system", "require", "seamless", "adjustment", "vergence", "between", "many", "shot", "over", "possibly", "wide", "range", "depths", "require", "different", "approach", "editing", "e.", "ultra-short", "mtvstyle", "shot", "need", "replace", "more", "slow-paced", "edit", "nevertheless", "modern", "movie", "often", "simultaneously", "release", "2d", "s3d", "one", "should", "expect", "director", "cinematographer", "editor", "entirely", "give", "up", "artistic", "vision", "style", "merely", "sake", "s3d", "medium", "limitation", "instead", "apply", "different", "s3d", "post-production", "technique", "make", "depth", "transition", "natural", "effortless", "viewer", "manipulation", "range", "from", "simple", "depth", "manipulation", "cross-dissolve", "type", "cut", "more", "sophisticated", "transition", "where", "multiple", "sequence", "gradually", "change", "depth", "combine", "-lsb-", "Owens", "2013", "-rsb-", "all", "manipulation", "time-consuming", "expensive", "perform", "manually", "example", "Owens", "-lsb-", "2013", "-rsb-", "point", "out", "editing", "transition", "one", "most", "challenging", "step", "post-production", "u2", "concert", "record", "stereoscopic", "3d", "abrupt", "depth", "change", "well", "beyond", "real-world", "experience", "should", "also", "expect", "action", "computer", "game", "address", "problem", "rapid", "depth", "change", "we", "propose", "relate", "transition", "quality", "vergence", "adaptation", "time", "instead", "simpler", "disparity", "difference", "we", "present", "series", "experiment", "human", "observer", "which", "vergence", "response", "be", "measure", "use", "consumer", "s3d", "equipment", "high-framerate", "eye-tracker", "lead", "simple", "model", "describe", "vergence", "adaptation", "curve", "give", "initial", "target", "disparity", "model", "allow", "prediction", "adaptation", "time", "after", "cut", "which", "facilitate", "its", "visualization", "minimization", "impact", "optimization", "visual", "quality", "s3d", "content", "demonstrate", "separate", "experiment", "we", "knowledge", "we", "first", "apply", "principled", "approach", "problem", "summary", "we", "make", "follow", "contribution", "measurement", "vergence", "response", "rapid", "disparity", "change", "define", "initial", "target", "disparity", "derivation", "evaluation", "model", "relate", "disparity", "change", "vergence", "adaptation", "curve", "along", "average", "observer", "parameter", "interactive", "tool", "visualization", "minimization", "adaptation", "time", "here", "we", "overview", "basic", "finding", "eye", "vergence", "mechanism", "main", "focus", "s3d", "display", "condition", "we", "refer", "reader", "survey", "Meesters", "et", "al.", "-lsb-", "2004", "-rsb-", "in-depth", "discussion", "other", "aspect", "s3d", "display", "perception", "vergence", "Dynamic", "process", "eye", "vergence", "drive", "depth", "change", "target", "object", "can", "perform", "high", "accuracy", "-lrb-", "error", "below", "10", "arcmin", "-rrb-", "both", "real", "world", "s3d", "display", "observation", "condition", "-lsb-", "Okuyama", "1998", "-rsb-", "other", "factor", "blur", "proximity", "target", "size", "luminance", "might", "affect", "vergence", "lesser", "extent", "-lsb-", "Campbell", "Westheimer", "1959", "-rsb-", "Vergence", "relatively", "slow", "process", "when", "compare", "other", "eye", "movement", "e.", "saccade", "-lrb-", "below", "60", "m", "-rrb-", "require", "about", "195", "750", "m", "convergence", "240", "1000", "m", "divergence", "vergence", "latency", "also", "demonstrate", "similar", "asymmetric", "behavior", "180", "250", "m", "convergence", "200", "210", "m", "divergence", "-lsb-", "Krishnan", "et", "al.", "1973", "Krishnan", "et", "al.", "1977", "Semmlow", "Wetzel", "1979", "-rsb-", "Vergence", "two-stage", "process", "where", "first", "fast", "transient", "-lrb-", "a.k.a.", "phasic", "-rrb-", "mechanism", "-lrb-", "react", "even", "brief", "200", "m", "flash", "-rrb-", "bring", "vergence", "proximity", "target", "depth", "slower", "sustained", "-lrb-", "a.k.a.", "tonic", "-rrb-", "mechanism", "responsible", "precise", "verge", "target", "well", "further", "tracking", "slower", "depth", "change", "Semmlow", "et", "al.", "-lsb-", "1986", "-rsb-", "find", "less", "dynamic", "depth", "change", "ramp", "velocity", "below", "deg/s", "only", "sustained", "mechanism", "active", "above", "deg/s", "transient", "mechanism", "dominate", "otherwise", "both", "mechanism", "active", "Vergence", "adaptation", "-lrb-", "similar", "luminance", "adaptation", "-rrb-", "have", "be", "observe", "which", "sustained", "mechanism", "support", "give", "eye", "vergence", "angle", "comfort", "state", "achieve", "during", "binocular", "vision", "-lsb-", "Hung", "1992", "-rsb-", "small", "depth", "change", "within", "panum?s", "fusional", "area", "motoric", "vergence", "activate", "sensoric", "fusion", "image", "retina", "sufficient", "Vergence", "vs.", "Accommodation", "while", "vergence", "drive", "depth", "accommodation", "drive", "mostly", "retinal", "blur", "both", "system", "reflexively", "couple", "interact", "each", "other", "through", "accommodative", "vergence", "vergence", "accommodation", "-lsb-", "Hung", "2001", "-rsb-", "accommodative", "vergence", "quantify", "ac/a", "ratio", "which", "relate", "change", "vergence", "cause", "change", "accommodation", "absence", "disparity", "analogous", "way", "vergence", "accommodation", "quantify", "CA/C", "ratio", "absence", "blur", "since", "range", "accommodation", "while", "view", "s3d", "display", "determine", "distance", "screen", "unnatural", "decoupling", "vergence", "accommodation", "require", "which", "may", "cause", "visual", "discomfort", "increase", "binocular", "fusion", "time", "-lsb-", "Hoffman", "et", "al.", "2008", "Lambooij", "et", "al.", "2009", "-rsb-", "when", "screen", "disparity", "increase", "beyond", "panum?s", "fusional", "area", "vergence", "eye", "movement", "bring", "disparity", "back", "area", "which", "shift", "accommodation", "away", "from", "screen", "when", "shift", "beyond", "depth", "focus", "-lrb-", "dof", "-rrb-", "zone", "accommodative-vergence", "feedback", "activate", "counteract", "loss", "sharp", "vision", "which", "turn", "direct", "vergence", "back", "towards", "display", "-lsb-", "Lambooij", "et", "al.", "2009", "-rsb-", "range", "vergence", "angle", "assure", "clear", "single", "binocular", "vision", "know", "comfort", "zone", "-lsb-", "Shibata", "et", "al.", "2011", "Zilly", "et", "al.", "2011", "-rsb-", "real", "world", "object", "away", "from", "fixation", "point", "perceive", "blur", "which", "reduce", "visibility", "diplopium", "because", "limit", "fusion", "higher", "low", "spatial", "frequency", "thus", "both", "accommodation", "vergence", "response", "can", "improve", "manipulation", "convergence", "local", "image", "defocus", "respectively", "-lsb-", "Ukai", "Kato", "2002", "Zwicker", "et", "al.", "2006", "-rsb-", "many", "practical", "s3d", "application", "comfort", "zone", "determine", "disparity", "range", "70", "arcmin", "-lsb-", "Lambooij", "et", "al.", "2009", "Zilly", "et", "al.", "2011", "-rsb-", "since", "rather", "conservative", "bind", "work", "we", "assume", "wider", "range", "2.5", "deg", "out-of-screen", "effect", "even", "beyond", "range", "use", "cinematography", "object", "interest", "typically", "move", "steadily", "off", "screen", "case", "so", "viewer", "can", "adapt", "its", "extreme", "position", "-lsb-", "Zilly", "et", "al.", "2011", "-rsb-", "achieve", "extreme", "disparity", "would", "possible", "through", "sudden", "jump", "case", "scene", "cut", "Vergence", "Measurements", "large", "body", "research", "measurement", "vergence", "dynamics", "response", "pulse", "step", "ramp", "sinusoidal", "disparity", "change", "we", "step-like", "change", "most", "relevant", "most", "experiment", "use", "physical", "target", "passively-shifted", "screen", "-lsb-", "erkelen", "et", "al.", "1989", "Hung", "et", "al.", "1994", "-rsb-", "simple", "stimulus", "vertical", "line", "be", "use", "eliminate", "other", "cue", "could", "affect", "vergence", "special", "care", "take", "suppress", "accommodation", "use", "pinhole", "aperture", "blur-free", "viewing", "wide", "range", "disparity", "35", "deg", "have", "be", "consider", "-lsb-", "Erkelens", "et", "al.", "1989", "-rsb-", "typical", "range", "below", "10", "deg", "relatively", "large", "step", "amplitude", "typically", "larger", "than", "deg", "-lsb-", "Hung", "2001", "-rsb-", "work", "we", "focus", "disparity", "range", "2.5", "deg", "lower", "disparity", "step", "amplitude", "which", "important", "comfortable", "experience", "while", "view", "s3d", "display", "assume", "disparity", "range", "correspond", "approximately", "comfort", "zone", "desktop", "viewing", "condition", "give", "Shibata", "et", "al.", "-lsb-", "2011", "Fig.", "23", "-rsb-", "use", "off-the-shelf", "s3d", "display", "we", "experiment", "deal", "real-world", "image", "validation", "step", "we", "ensure", "condition", "possibly", "similar", "one", "expect", "application", "where", "accommodation", "pictorial", "cue", "may", "affect", "vergence", "also", "initial", "disparity", "magnitude", "important", "we", "measurement", "both", "convergence", "divergence", "case", "Vergence", "Modeling", "Schor", "-lsb-", "1979", "-rsb-", "Hung", "-lsb-", "1998", "-rsb-", "propose", "sophisticated", "model", "eye", "vergence", "dynamics", "which", "employ", "concept", "control", "engineering", "simulate", "transient", "sustained", "-lrb-", "negative", "feedback", "loop", "-rrb-", "mechanism", "model", "have", "be", "extend", "handle", "accommodation", "well", "ac/a", "ca/c", "cross-link", "gain", "-lsb-", "Schor", "1992", "Schor", "1999", "Hung", "2001", "-rsb-", "extensive", "validation", "model", "against", "measurement", "datum", "have", "be", "perform", "however", "disparity", "step", "interesting", "we", "have", "be", "treat", "marginally", "furthermore", "viewing", "condition", "do", "force", "decoupling", "accommodation", "vergence", "while", "s3d", "display", "have", "be", "consider", "some", "computational", "model", "main", "goal", "artificially", "alter", "link", "between", "accommodation", "vergence", "system", "study", "change", "pre-task", "post-task", "measure", "ac/a", "ca/c", "-lsb-", "Eadie", "et", "al.", "2000", "-rsb-", "investigate", "developmental", "plasticity", "child", "expose", "s3d", "game", "-lsb-", "Rushton", "Riddell", "1999", "-rsb-", "Alvarez", "et", "al.", "-lsb-", "2005", "-rsb-", "experiment", "constant-sized", "deg", "step", "find", "case", "divergent", "step", "vergence", "dynamics", "dependent", "initial", "disparity", "work", "we", "propose", "simple", "data-driven", "model", "eye", "vergence", "tune", "step-like", "disparity", "change", "we", "emphasize", "here", "vergence", "dynamics", "function", "initial", "target", "disparity", "we", "goal", "minimization", "vergence", "adaptation", "time", "scene", "cut", "through", "disparity", "editing", "temporal", "change", "vs.", "Comfort", "Yano", "et", "al.", "-lsb-", "2004", "-rsb-", "report", "visual", "discomfort", "induce", "image", "be", "move", "depth", "accord", "step", "pulse", "function", "even", "image", "be", "display", "within", "depth", "focus", "related", "work", "Tam", "et", "al.", "-lsb-", "2012", "-rsb-", "influence", "disparity", "velocity", "visual", "comfort", "investigate", "significant", "interaction", "between", "velocity", "disparity", "show", "negative", "effect", "object", "velocity", "visual", "comfort", "apparent", "even", "when", "object", "be", "display", "within", "generally", "accept", "visual", "comfort", "zone", "less", "than", "deg", "horizontal", "disparity", "result", "obtain", "Lambooij", "et", "al.", "-lsb-", "2011", "-rsb-", "show", "rapidly", "move", "object", "change", "screen", "disparity", "indeed", "have", "significant", "effect", "visual", "comfort", "however", "dominant", "role", "confirm", "s3d", "content", "processing", "problem", "scene", "transition", "challenge", "context", "stereoscopic", "content", "since", "scene", "transition", "often", "create", "large", "temporal", "disparity", "discontinuity", "lead", "visual", "discomfort", "solve", "problem", "disparity", "adjustment", "technique", "require", "perform", "either", "during", "acquisition", "step", "modify", "camera", "parameter", "post-processing", "step", "use", "example", "horizontal", "image", "translation", "-lsb-", "Mendiburu", "2009", "-rsb-", "however", "only", "few", "technique", "can", "deal", "temporal", "effect", "disparity", "velocity", "consider", "one", "important", "factor", "disparity", "adjustment", "-lsb-", "Lang", "et", "al.", "2010", "-rsb-", "author", "propose", "interpolate", "between", "different", "disparity", "range", "scene", "cut", "reduce", "large", "discontinuity", "disparity", "end", "different", "disparity", "mapping", "operator", "can", "use", "make", "adjustment", "however", "decision", "how", "interpolation", "define", "leave", "user", "simpler", "technique", "have", "be", "propose", "koppal", "-lsb-", "2011", "-rsb-", "he", "suggest", "solve", "problem", "transition", "cross-fade", "horizontal", "image", "translation", "zero", "cut", "Bernhard", "et", "al.", "-lsb-", "2014", "-rsb-", "show", "how", "binocular", "fusion", "time", "can", "reduce", "means", "active", "manipulation", "convergence", "plane", "object", "interest", "bring", "back", "zero-disparity", "plane", "once", "change", "gaze", "have", "be", "detect", "before", "vergence", "adaptation", "complete", "contrast", "Bernhard", "et", "al.", "active", "approach", "we", "propose", "cut", "optimization", "process", "keep", "disparity", "constant", "during", "vergence", "adaptation", "improvement", "we", "case", "come", "from", "more", "informed", "choice", "initial", "target", "disparity", "nevertheless", "both", "approach", "could", "potentially", "combine", "Heinzle", "et", "al.", "-lsb-", "2011", "-rsb-", "propose", "computational", "camera", "rig", "which", "enable", "intuitive", "control", "over", "camera", "parameter", "artist?s", "involvement", "still", "need", "though", "design", "transition", "manually", "without", "any", "feedback", "human", "ability", "adapt", "rapid", "disparity", "change", "Automatic", "control", "over", "camera", "parameter", "propose", "context", "real-time", "system", "-lrb-", "e.", "game", "-rrb-", "-lsb-", "Oskam", "et", "al.", "2011", "-rsb-", "however", "primary", "goal", "maintain", "scene", "disparity", "range", "within", "give", "limit", "equivalent", "minimize", "vergence", "adaptation", "time", "which", "depend", "only", "disparity", "difference", "also", "initial", "disparity", "value", "we", "approach", "we", "take", "those", "two", "factor", "account", "more", "recently", "metric", "visual", "comfort", "have", "be", "propose", "-lsb-", "Du", "et", "al.", "2013", "-rsb-", "which", "directly", "address", "problem", "temporal", "disparity", "change", "author", "also", "suggest", "can", "use", "optimize", "stereoscopic", "parameter", "however", "metric", "deal", "motion", "unclear", "how", "apply", "technique", "context", "rapid", "disparity", "change", "those", "create", "during", "scene", "transition" ],
  "content" : "Over the past few years, stereoscopic 3D (S3D) technology has been constantly developing, and by now it has become ubiquitous. However, despite the significant improvements, not only in display devices, but also in image generation, capture and post-processing techniques, many consumers are still skeptical about the quality of current S3D content and the future of the technology itself. These concerns are usually related to naturalness, effortlessness, and overall appearance: S3D effect should not be a distraction. The difficulty in S3D production is that it is not sufficient to produce two good images in place of one to arrive at a good stereoscopic effect [Zilly et al. 2011]. S3D is a strong illusion, since it isolates only one real-world phenomenon, failing to reproduce many others, a prominent example being the accommodation cue. This imposes numerous restrictions on the production process: the depth range and variation must not be too large, view-dependent effects need to be handled correctly, images carefully registered, and so on. In this work, we are concerned with rapid temporal changes of disparity. Humans have a good understanding of the environment they observe and move through, a so-called ?mental image?, which enhances their capabilities in focusing on different objects [Finke 1989]. However, when the scene is merely a sequence of shots shown on a flat screen, it is easy to get confused or lose track of the point of interest, due to, among other things, unexpected changes of the location or the camera angle. Although less problematic in 2D, this can be challenging in stereoscopic 3D. In this context, an unpredictable and large change in disparity means that binocular fusion is lost, and a confusing double image is seen (diplopia). Moreover, the vergence system needs to quickly adapt to new conditions, in spite of the conflicting goal of the interconnected accommodation system. This has been identified as one of the sources of discomfort in stereoscopic viewing [Hoffman et al. 2008; Lambooij et al. 2009]. The Hollywood style of combining shots developed into a set of formal conventions that obey the dynamics of visual attention and control the continuity of space, time, and action. In modern movies cuts play the most important role (99% of all edits), while dissolves  and wipes have vanished almost completely. An extensive analysis by Cutting et al. [2011] shows that average shot duration over past 75 years has declined from ca. 15 s to ca. Clearly, short shots increase the viewer engagement by forcing eyes to quickly follow newly appearing content. However, such accumulation of sharp cuts challenges the visual system by requiring seamless adjustment of vergence between many shots over a possibly wide range of depths. This requires a different approach to editing, e. , ultra-short ?MTVstyle? shots need to be replaced by more slow-paced edits. Nevertheless, modern movies are often simultaneously released in 2D and S3D, and one should not expect that directors, cinematographers, and editors will entirely give up on their artistic visions and style merely for the sake of S3D medium limitations. Instead, they apply different S3D post-production techniques to make depth transitions natural and effortless for viewers. Such manipulations range from simple depth manipulations and cross-dissolve types of cuts to more sophisticated transitions, where multiple sequences with gradually changing depth are combined [Owens 2013]. All these manipulations are time-consuming and expensive, as they are performed manually. For example, Owens [2013] pointed out that the editing of transitions was one of the most challenging steps in the post-production of the U2 concert recorded in stereoscopic 3D. Abrupt depth changes, well beyond the real-world experience, should be also expected in action computer games. To address the problem of rapid depth changes, we propose to relate the transition quality to vergence adaptation time, instead of simpler disparity difference. We present a series of experiments with human observers, in which vergence responses were measured using consumer S3D equipment and a high-framerate eye-tracker. This leads to a simple model describing the vergence adaptation curve, given the initial and target disparities. The model allows for prediction of adaptation time after cuts, which facilitates its visualization and minimization. Impact of the optimization on the visual quality of S3D content is demonstrated in a separate experiment. To our knowledge, we are the first to apply such a principled approach to this problem. In summary, we make the following contributions: ? measurements of vergence response to rapid disparity changes defined by initial and target disparities; ? derivation and evaluation of a model relating disparity change to vergence adaptation curve, along with average observer parameters; ? interactive tool for visualization and minimization of adaptation time. Here we overview basic findings on the eye vergence mechanisms, with the main focus on S3D display conditions. We refer the reader to a survey by Meesters et al. [2004] for an in-depth discussion of other aspects of S3D display perception. Vergence as a Dynamic Process The eye vergence is driven by the depth changes of a target object, and can be performed with high accuracy (error below 10 arcmin) both in the real world and S3D display observation conditions [Okuyama 1998]. Other factors, such as blur, proximity, target size, and luminance might affect vergence, but to a lesser extent [Campbell and Westheimer 1959]. Vergence is a relatively slow process when compared to other eye movements, e. , saccades (below 60 ms), and requires about 195?750 ms for convergence and 240?1000 ms for divergence. Vergence latency also demonstrates a similar asymmetric behavior with 180?250 ms for convergence and 200?210 ms for divergence [Krishnan et al. 1973; Krishnan et al. 1977; Semmlow and Wetzel 1979]. Vergence is a two-stage process, where at first the fast transient (a.k.a. phasic) mechanism (reacts even for brief 200 ms flashes) brings the vergence in the proximity of the target depth, and then the slower sustained (a.k.a. tonic) mechanism is responsible for the precise verging on the target, as well as further tracking of slower depth changes. Semmlow et al. [1986] found that for less dynamic depth changes, with the ramp velocity below 2 deg/s, only the sustained mechanism is active, above 9 deg/s the transient mechanism dominates, and otherwise both mechanisms are active. Vergence adaptation (similar to luminance adaptation) has been observed in which the sustained mechanism supports a given eye vergence angle, and comfort state is achieved during binocular vision [Hung 1992]. For small depth changes within Panum?s fusional area, the motoric vergence is not activated, and sensoric fusion of images on the retina is sufficient. Vergence vs. Accommodation While vergence is driven by depth, and accommodation is driven mostly by retinal blur, both systems are reflexively coupled, and they interact with each other through accommodative vergence and vergence accommodation [Hung 2001]. The accommodative vergence is quantified by the AC/A ratio, which relates the change of vergence caused by the change of accommodation in the absence of disparity. In an analogous way, the vergence accommodation is quantified by the CA/C ratio in the absence of blur. Since the range of accommodation while viewing the S3D display is determined by the distance to the screen, unnatural decoupling of vergence and accommodation is required, which may cause visual discomfort and increase binocular fusion times [Hoffman et al. 2008; Lambooij et al. 2009]. When the screen disparity increases beyond Panum?s fusional area, vergence eye movements bring the disparity back to this area, which shifts accommodation away from the screen. When such a shift is beyond the depth of focus (DOF) zone, the accommodative-vergence feedback is activated to counteract the loss of sharp vision, which in turn directs vergence back towards the display [Lambooij et al. 2009]. The range of vergence angles that assure clear and single binocular vision is known as the ?comfort zone? [Shibata et al. 2011; Zilly et al. 2011]. In the real world, objects away from the fixation point are perceived as blurred, which reduces the visibility of diplopia, because the limits of fusion are higher for low spatial frequencies. Thus, both accommodation and vergence response can be improved by manipulation of convergence and local image defocus, respectively [Ukai and Kato 2002; Zwicker et al. 2006]. In many practical S3D applications, the comfort zone is determined by the disparity range of 70 arcmin [Lambooij et al. 2009; Zilly et al. 2011]. Since it is a rather conservative bound, in this work we assume a wider range of ?2.5 deg. Out-of-screen effects even beyond this range are used in cinematography, but the object of interest typically moves steadily off the screen in such cases, so that the viewer can adapt to its extreme position [Zilly et al. 2011]. Achieving such extreme disparities would not be possible through sudden jumps as in the case of scene cuts. Vergence Measurements There is a large body of research on measurements of vergence dynamics in response to pulse, step, ramp, and sinusoidal disparity changes. For us, the step-like changes are the most relevant. Most experiments used physical targets or passively-shifted screens [Erkelens et al. 1989; Hung et al. 1994]. Simple stimuli, such as vertical lines, were used to eliminate other cues that could affect vergence. Special care was taken to suppress accommodation by using pinhole apertures for blur-free viewing. A wide range of disparities ?35 deg have been considered [Erkelens et al. 1989], but a typical range was below ?10 deg with relatively large step amplitudes, typically larger than 2 deg [Hung 2001]. In this work we focus on the disparity range ?2.5 deg and lower disparity step amplitudes, which are important for comfortable experience while viewing S3D displays. The assumed disparity range corresponds approximately to the comfort zone in desktop viewing conditions given by Shibata et al. [2011, Fig. 23]. By using an off-the-shelf S3D display in our experiments, and dealing with real-world images in the validation step, we ensure that the conditions are possibly similar to the ones in expected applications, where accommodation and pictorial cues may affect the vergence. Also, the initial disparity magnitude is important in our measurements, both for the convergence and divergence case. Vergence Modeling Schor [1979] and Hung [1998] proposed sophisticated models of the eye vergence dynamics, which employ the concepts of control engineering to simulate the transient and sustained (a negative feedback loop) mechanisms. The models have been extended to handle accommodation as well as the AC/A and CA/C cross-link gains [Schor 1992; Schor 1999; Hung 2001]. An extensive validation of such models against measurement data has been performed; however, disparity steps interesting for us have been treated marginally. Furthermore, the viewing conditions did not force decoupling of accommodation and vergence. While S3D displays have been considered in some computational models, the main goal was to artificially alter the link between the accommodation and vergence systems to study the change in pre-task and post-task measures of AC/A and CA/C [Eadie et al. 2000], or to investigate developmental plasticity in children exposed to S3D games [Rushton and Riddell 1999]. Alvarez et al. [2005] experimented with constant-sized, 4 deg steps, and found that in case of divergent steps, vergence dynamics are dependent on the initial disparity. In this work, we propose a simple data-driven model of eye vergence that is tuned to step-like disparity changes. We emphasize here on vergence dynamics as a function of the initial and target disparities, and our goal is minimization of the vergence adaptation time at scene cuts through disparity editing. Temporal Changes vs. Comfort Yano et al. [2004] report that visual discomfort was induced if images were moved in depth according to a step pulse function, even if the images were displayed within the depth of focus. In a related work by Tam et al. [2012], influence of disparity and velocity on visual comfort was investigated, and a significant interaction between velocity and disparity was shown. The negative effect of object velocity on visual comfort was apparent even when the objects were displayed within the generally accepted visual comfort zone of less than 1 deg of horizontal disparity. Results obtained by Lambooij et al. [2011] show that rapidly moving objects and changing screen disparity indeed have a significant effect on visual comfort; however, their dominant role was not confirmed. S3D Content Processing The problem of scene transitions is challenging in the context of stereoscopic content, since scene transitions often create large temporal disparity discontinuities leading to visual discomfort. To solve this problem, disparity adjustment techniques are required. They are performed either during the acquisition step by modifying camera parameters or in the post-processing step using, for example, horizontal image translation [Mendiburu 2009]. However, only few techniques can deal with temporal effects. Disparity velocity was considered one of the important factors for disparity adjustment [Lang et al. 2010]. The authors proposed to interpolate between different disparity ranges at scene cuts to reduce large discontinuities in disparity. To this end, different disparity mapping operators can be used to make this adjustment; however, the decision of how this interpolation is defined was left to the user. A simpler technique has been proposed by Koppal [2011]. He suggested to solve the problem of transitions by cross-fading the horizontal image translation to zero at the cut. Bernhard et al. [2014] showed how binocular fusion times can be reduced by means of active manipulation of the convergence plane. The object of interest is brought back to the zero-disparity plane once the change in gaze has been detected, but before the vergence adaptation is complete. In contrast to Bernhard et al.?s active approach, we propose a cut optimization process that keeps the disparities constant during the vergence adaptation. The improvement in our case comes from more informed choice of the initial and target disparities. Nevertheless, both approaches could be potentially combined. Heinzle et al. [2011] proposed a computational camera rig, which enables intuitive control over camera parameters. The artist?s involvement is still needed, though, to design the transitions manually, without any feedback on human abilities to adapt to rapid disparity changes. Automatic control over camera parameters was proposed in the context of real-time systems (e. , games) [Oskam et al. 2011]. However, their primary goal was to maintain the scene disparity range within given limits. This is not equivalent to minimizing the vergence adaptation time, which depends not only on disparity difference but also the initial disparity value. In our approach, we take those two factors into account. More recently, a metric of visual comfort has been proposed [Du et al. 2013], which directly addresses the problem of temporal disparity changes. The authors also suggest that it can be used for optimizing stereoscopic parameters. However, their metric deals with motion, and it is unclear how to apply their technique in the context of rapid disparity changes such as those created during scene transitions.",
  "resources" : [ ]
}