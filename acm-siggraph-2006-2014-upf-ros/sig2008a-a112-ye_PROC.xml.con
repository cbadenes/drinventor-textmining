{
  "uri" : "sig2008a-a112-ye_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2008a/a112-ye_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Animating Responsive Characters with Dynamic Constraints in Near-Unactuated Coordinates",
    "published" : "2008",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Yuting-Ye",
      "name" : "Yuting",
      "surname" : "Ye"
    }, {
      "uri" : "http://drinventor/C. Karen-Liu",
      "name" : "C. Karen",
      "surname" : "Liu"
    } ]
  },
  "bagOfWords" : [ "we", "apply", "we", "method", "variety", "cyclic", "motion", "different", "style", "perform", "different", "subject", "one", "complete", "cycle", "each", "motion", "sufficient", "compute", "near-unacutated", "coordinate", "upper", "body", "simulation", "run", "20", "frame", "per", "second", "single", "core", "2.8", "GHz", "Intel", "Core", "duo", "processor", "we", "use", "snopt", "-lsb-", "Gill", "et", "al.", "1996", "-rsb-", "solve", "optimization", "problem", "each", "time", "step", "we", "result", "reveal", "dynamic", "constraint", "near-unactuated", "coordinate", "produce", "compliant", "response", "unexpected", "perturbation", "coordinate", "recovery", "motion", "customize", "input", "motion", "all", "example", "be", "generate", "use", "identical", "set", "weight", "describe", "section", "experiment", "show", "wide", "range", "weight", "produce", "similar", "result", "please", "see", "supplemental", "video", "all", "example", "describe", "below", "eigenvector", "analysis", "demonstrate", "importance", "joint", "actuation", "space", "we", "conduct", "several", "experiment", "normal", "walk", "different", "choice", "coordinate", "which", "dynamic", "constraint", "enforce", "we", "first", "simulated", "same", "input", "motion", "different", "value", "number", "dynamic", "constraint", "nearunactuated", "coordinate", "character", "appear", "more", "responsive", "number", "dynamic", "constraint", "increase", "however", "character", "able", "completely", "recover", "from", "perturbation", "when", "more", "than", "12", "dynamic", "constraint", "when", "number", "dynamic", "constraint", "increase", "16", "character", "simply", "fail", "track", "input", "motion", "second", "experiment", "simulated", "motion", "dynamic", "constraint", "coordinate", "correspond", "higher", "eigenvalue", "result", "show", "character", "able", "maintain", "original", "motion", "without", "actuation", "those", "coordinate", "perturbation", "we", "first", "experiment", "apply", "same", "external", "force", "different", "body", "part", "1.7", "80kg", "male", "character", "during", "different", "phase", "normal", "walking", "sequence", "result", "show", "same", "push", "incur", "larger", "response", "during", "single", "support", "than", "double", "support", "moreover", "character", "exhibit", "more", "stability", "when", "push", "apply", "same", "side", "support", "leg", "when", "push", "arm", "character", "react", "more", "compliantly", "than", "when", "push", "head", "shoulder", "-lrb-", "figure", "-rrb-", "second", "experiment", "test", "effect", "different", "external", "force", "direction", "character", "have", "harder", "time", "recover", "from", "backward", "push", "than", "forward", "one", "indicate", "he", "torso", "actuation", "asymmetric", "along", "sagittal", "direction", "addition", "produce", "highly", "coordinate", "reaction", "we", "method", "also", "preserve", "individual", "style", "we", "demonstrate", "large-scale", "arm", "movement", "female", "character", "-lrb-", "1.5", "40kg", "-rrb-", "preserve", "she", "reactive", "motion", "we", "scale", "magnitude", "external", "force", "proportionally", "female", "subject?s", "weight", "we", "method", "also", "allow", "user", "interact", "character", "perturb", "root", "movement", "illustrate", "we", "simulated", "reaction", "character", "step", "fast", "move", "platform", "root", "accelerate", "abruptly", "character?s", "upper", "body", "react", "passively", "gradually", "recover", "original", "motion", "pattern", "style", "coordinate", "actuation", "space", "encode", "muscle", "usage", "coordination", "specific", "input", "motion", "consequently", "each", "motion", "sequence", "react", "unexpected", "perturbation", "unique", "style", "we", "apply", "same", "set", "external", "force", "normal", "walk", "backward", "walk", "sneaky", "walk", "perform", "same", "male", "character", "-lrb-", "figure", "-rrb-", "comparison", "other", "motion", "normal", "walk", "exhibit", "higher", "coordination", "among", "upper", "body", "counteract", "disturbance", "use", "torso", "both", "arm", "simultaneously", "backward", "walk", "motion", "exhibit", "higher", "stability", "against", "forward", "push", "response", "compliantly", "backward", "push", "sneaky", "walk", "character", "maintain", "more", "stable", "posture", "center", "mass", "position", "lower", "than", "other", "motion", "result", "show", "same", "amount", "force", "induce", "smaller", "response", "sneaky", "walk", "compare", "actuation", "among", "style", "individual", "we", "extract", "near", "unactuated", "coordinate", "one", "individual", "perform", "normal", "walk", "apply", "they", "simulate", "another", "individual?s", "normal", "walk", "under", "perturbation", "result", "show", "plausible", "reactive", "motion", "can", "generate", "only", "when", "two", "individual", "have", "similar", "weight", "height", "we", "also", "conduct", "similar", "experiment", "different", "action", "style", "actuation", "sneaky", "walk", "reproduce", "normal", "walk", "faithfully", "without", "disturbance", "generate", "unrealistic", "response", "when", "perturb", "additional", "objective", "we", "formulation", "allow", "animator", "include", "additional", "objective", "enforce", "kinematic", "property", "input", "motion", "example", "we", "capture", "walking", "sequence", "subject", "hold", "cup", "he", "right", "hand", "during", "motion", "synthesis", "additional", "objective", "add", "keep", "cup", "upright", "orientation", "asymmetrical", "muscle", "usage", "left", "right", "arm", "result", "many", "interesting", "behavior", "when", "character", "push", "right", "arm", "he", "maintain", "orientation", "cup", "rotate", "he", "torso", "compensate", "movement", "he", "right", "arm", "contrast", "when", "left", "arm", "push", "same", "force", "he", "stiffen", "he", "torso", "reduce", "its", "movement", "impact", "right", "arm", "similarly", "we", "add", "objective", "repel", "character", "from", "obstacle", "environment", "character", "fail", "completely", "avoid", "obstacle", "external", "force", "apply", "site", "collision", "non-locomotion", "we", "method", "also", "work", "other", "periodic", "motion", "Tai", "Chi", "form", "although", "Tai", "Chi", "motion", "require", "higher", "overall", "internal", "torque", "than", "other", "locomotion", "sequence", "-lrb-", "-rrb-", "highly", "actuated", "coordinate", "mostly", "lie", "frontal", "plane", "moreover", "torque", "usage", "arm", "Tai", "Chi", "motion", "highly", "correlate", "result", "character", "react", "perturbation", "sagittal", "plane", "both", "arm", "move", "fluidly", "we", "have", "present", "technique", "synthesize", "generic", "class", "dynamic", "response", "small-scale", "perturbation", "enforce", "dynamic", "constraint", "actuation", "space", "virtual", "character", "respond", "arbitrary", "unexpected", "perturbation", "specific", "style", "encode", "input", "motion", "we", "have", "demonstrate", "simplicity", "robustness", "we", "technique", "show", "variety", "example", "generate", "same", "set", "parameter", "we", "method", "can", "readily", "augmented", "any", "kinematic", "technique", "character", "animation", "motion", "graph", "motion", "blending", "without", "modification", "exist", "implementation", "nor", "additional", "datum", "main", "assumption", "we", "approach", "only", "small", "set", "coordinate", "muscle", "group", "activate", "perform", "rhythmic", "motion", "biomechanic", "researcher", "have", "also", "hypothesize", "postural", "response", "under", "perturbation", "can", "activate", "few", "muscle", "synergy", "-lsb-", "Torres-Oviedo", "Ting", "2007", "-rsb-", "we", "result", "suggest", "same", "muscle", "synergy", "use", "input", "motion", "can", "also", "produce", "reasonable", "recovery", "motion", "from", "small", "perturbation", "thereby", "lend", "support", "hypothesis", "muscle", "synergy", "building", "block", "construct", "motor", "output", "pattern", "however", "we", "method", "robust", "against", "steady", "perturbation", "clear", "whether", "human", "body", "switch", "different", "muscle", "synergy", "when", "present", "sustained", "disturbance", "we", "technique", "focus", "only", "upper", "body", "response", "suitable", "large", "perturbation", "incur", "loss", "balance", "change", "high-level", "behavior", "we", "anticipate", "technique", "can", "apply", "whole", "body", "motion", "we", "can", "accurately", "measure", "ground", "contact", "force", "one", "possibility", "estimate", "ground", "contact", "force", "from", "motion", "capture", "datum", "use", "method", "describe", "Liu", "et", "al.", "-lsb-", "2005", "-rsb-", "another", "promising", "future", "direction", "combine", "we", "technique", "sophisticated", "balance", "controller", "determine", "lower", "body", "root", "movement", "-lsb-", "da", "Silva", "et", "al.", "2008", "Yin", "et", "al.", "2007", "-rsb-", "we", "approach", "use", "inverse", "dynamics", "method", "principle", "component", "analysis", "both", "which", "know", "sensitive", "input", "noise", "fortunately", "we", "method", "do", "directly", "apply", "computed", "torque", "simulate", "motion", "only", "use", "they", "derive", "eigenbasis", "input", "activity", "we", "test", "robustness", "we", "method", "against", "datum", "noise", "randomly", "select", "different", "cycle", "from", "input", "motion", "result", "show", "sporadic", "noise", "motion", "have", "negligible", "effect", "long", "input", "motion", "contain", "sufficient", "clean", "datum" ],
  "content" : "We applied our method to a variety of cyclic motions with different styles performed by different subjects. One complete cycle of each motion is sufficient to compute the near-unacutated coordinates for the upper body. The simulation runs at 20 frames per second on a single core of a 2.8 GHz Intel Core 2 Duo processor. We use SNOPT [Gill et al. 1996] to solve the optimization problem at each time step. Our results reveal that dynamic constraints in the near-unactuated coordinates produce compliant responses to unexpected perturbations and coordinated recovery motions customized to the input motion. All the examples were generated using an identical set of weights described in Section 4. Experiments show that a wide range of weights produce similar results. Please see the supplemental video for all the examples described below. Eigenvector analysis To demonstrate the importance of the joint actuation space, we conducted several experiments of a normal walk with different choices of coordinates in which dynamic constraints are enforced. We first simulated the same input motion with different values of k, the number of dynamic constraints in the nearunactuated coordinates. The character appears more responsive as the number of dynamic constraints increases. However, the character is not able to completely recover from a perturbation when there are more than 12 dynamic constraints. When the number of dynamic constraints increases to 16, the character simply fails to track the input motion. The second experiment simulated the motion with dynamic constraints in the coordinates corresponding to higher eigenvalues. The result shows that the character is not able to maintain the original motion without actuations in those coordinates. Perturbation Our first experiment applied the same external force on different body parts of a 1.7m, 80kg male character during different phases of a normal walking sequence. The results show that the same push incurs a larger response during the single support than the double support. Moreover, the character exhibits more stability when the push is applied on the same side of the supporting leg. When pushed on the arms, the character reacts more compliantly than when pushed on the head or shoulder ( Figure 2 ). The second experiment tested the effect of different external force directions. The character has a harder time recovering from a backward push than a forward one, indicating that his torso actuation is asymmetric along the sagittal direction. In addition to producing highly coordinated reactions, our method also preserves individual styles. We demonstrated that the large-scale arm movement of a female character (1.5m, 40kg) is preserved in her reactive motions. We scaled the magnitude of the external forces proportionally to the female subject?s weight. Our method also allows the user to interact with the character by perturbing the root movement. To illustrate this, we simulated the reaction of the character stepping on a fast moving platform. As the root accelerates abruptly, the character?s upper body reacts passively and gradually recovers to the original motion pattern. Style The coordinates in the actuation space encode muscle usage and coordination specific to the input motion. Consequently, each motion sequence reacts to the unexpected perturbations with a unique style. We applied the same set of external forces to normal walk, backward walk, and sneaky walk performed by the same male character ( Figure 3 ). In comparison to other motions, the normal walk exhibits higher coordination among the upper body as it counteracts the disturbance using the torso and both arms simultaneously. The backward walking motion exhibits higher stability against a forward push but responses compliantly to a backward push. In the sneaky walk, the character maintains a more stable posture with the center of mass position lower than other motions. The results show that the same amount of force induces smaller responses on a sneaky walk. To compare the actuation among styles of individuals, we extracted the near unactuated coordinates of one individual performing a normal walk, and applied them to simulate another individual?s normal walk under perturbations. The results show that plausible reactive motions can be generated only when the two individuals have similar weight and height. We also conducted similar experiments for different action styles. The actuation of a sneaky walk reproduces a normal walk faithfully without disturbances, but generates unrealistic response when perturbed. Additional objectives Our formulation allows the animator to include additional objectives to enforce kinematic properties of the input motion. For example, we captured a walking sequence with the subject holding a cup in his right hand. During motion synthesis, an additional objective was added to keep the cup in an upright orientation. The asymmetrical muscle usage in the left and the right arms results in many interesting behaviors. When the character is pushed on the right arm, he maintains the orientation of the cup by rotating his torso to compensate for the movement of his right arm. In contrast, when the left arm is pushed by the same force, he stiffens his torso to reduce its movement and the impact on the right arm. Similarly, we added an objective that repels the character from the obstacles in the environment. If the character fails to completely avoid the obstacles, an external force is applied at the site of collision. Non-locomotion Our method also works on other periodic motions such as Tai Chi forms. Although the Tai Chi motion requires higher overall internal torques than other locomotion sequences (k = 5), the highly actuated coordinates mostly lie on the frontal plane. Moreover, the torque usage of arms in the Tai Chi motion are highly correlated. As a result, the character reacts to perturbations on the sagittal plane with both arms moving fluidly. We have presented a technique that synthesizes a generic class of dynamic responses to small-scale perturbations. By enforcing the dynamic constraints in the actuation space, the virtual character responds to arbitrary unexpected perturbations in a specific style encoded in the input motion. We have demonstrated the simplicity and robustness of our technique by showing a variety of examples generated with the same set of parameters. Our method can be readily augmented to any kinematic technique for character animation, such as motion graphs or motion blending, without modification to the existing implementation nor additional data. The main assumption of our approach is that only a small set of coordinated muscle groups are activated for performing rhythmic motion. Biomechanics researchers have also hypothesized that postural responses under perturbations can be activated by a few muscle synergies [Torres-Oviedo and Ting 2007]. Our results suggest that the same muscle synergies used for the input motion can also produce reasonable recovery motion from a small perturbation, thereby lending support to the hypothesis of muscle synergies as building blocks for constructing motor output patterns. However, our method is not as robust against steady perturbations. It is not clear whether the human body will switch to different muscle synergies when presented with sustained disturbances. Our technique focuses only on the upper body response and is not suitable for large perturbations that incur the loss of balance or changes of high-level behaviors. We anticipate that the technique can be applied to the whole body motion if we can accurately measure the ground contact forces. One possibility is to estimate the ground contact forces from motion capture data using the method described by Liu et al. [2005]. Another promising future direction is to combine our technique with sophisticated balance controllers that determine the lower body and root movements [da Silva et al. 2008; Yin et al. 2007]. Our approach uses inverse dynamics methods and principle component analysis, both of which are known to be sensitive to input noise. Fortunately, our method does not directly apply the computed torques to simulate motion but only uses them to derive the  eigenbasis of the input activity. We tested the robustness of our method against data noise by randomly selecting different cycles from the input motion. The results show that sporadic noise in the motion has negligible effect as long as the input motion contains sufficient clean data.",
  "resources" : [ ]
}