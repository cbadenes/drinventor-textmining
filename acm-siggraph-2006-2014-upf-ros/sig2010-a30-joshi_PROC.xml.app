{
  "uri" : "sig2010-a30-joshi_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2010/a30-joshi_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Image Deblurring using Inertial Measurement Sensors",
    "published" : "2013",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Ondrej-Sindelar",
      "name" : "Ondrej",
      "surname" : "Sindelar"
    }, {
      "uri" : "http://drinventor/Filip-Sroubek",
      "name" : "Filip",
      "surname" : "Sroubek"
    } ]
  },
  "bagOfWords" : [ "we", "present", "deblurr", "algorithm", "use", "hardware", "attachment", "couple", "natural", "image", "prior", "deblur", "image", "from", "consumer", "camera", "best", "we", "knowledge", "first", "work", "use", "dof", "inertial", "sensor", "dense", "per-pixel", "spatially-varying", "image", "deblurring", "first", "work", "gather", "dense", "ground-truth", "measurement", "camera-shake", "blur", "intentional", "blur", "can", "use", "great", "artistic", "effect", "photography", "however", "many", "common", "imaging", "situation", "blur", "nuisance", "camera", "motion", "blur", "often", "occur", "light-limited", "situation", "one", "most", "common", "reason", "discard", "photograph", "blur", "function", "know", "image", "can", "improve", "deblurr", "non-blind", "deconvolution", "method", "however", "most", "image", "blur", "function", "unknown", "must", "recov", "recover", "both", "blur", "point-spread", "function", "-lrb-", "psf", "-rrb-", "desire", "deblurred", "image", "from", "single", "blur", "input", "-lrb-", "know", "blind-deconvolution", "problem", "-rrb-", "inherently", "ill-posed", "observe", "blur", "image", "provide", "only", "partial", "constraint", "solution", "prior", "knowledge", "about", "image", "kernel", "can", "disambiguate", "potential", "solution", "make", "deblurr", "more", "tractable", "-lsb-", "Fergus", "et", "al.", "2006", "-rsb-", "while", "approach", "have", "show", "some", "promise", "have", "some", "limitation", "generally", "assume", "spatially", "invariant", "blur", "have", "long", "run", "time", "can", "run", "highresolution", "image", "often", "fail", "large", "image", "blur", "can", "depth-dependent", "due", "camera", "translation", "depthindependent", "due", "camera", "rotation", "many", "method", "treat", "all", "type", "blur", "equally", "intentional", "defocus", "blur", "may", "remove", "create", "oversharpen", "image", "we", "address", "some", "limitation", "combined", "hardware", "software-based", "approach", "device", "use", "inexpensive", "gyroscope", "accelerometer", "measure", "camera?s", "acceleration", "angular", "velocity", "during", "exposure", "datum", "use", "input", "novel", "aid", "blind-deconvolution", "algorithm", "compute", "spatially-varying", "image", "blur", "latent", "deblurred", "image", "instrument", "camera", "inertial", "measurement", "sensor", "we", "can", "obtain", "relevant", "information", "about", "camera", "motion", "thus", "camera-shake", "blur", "however", "many", "challenge", "use", "information", "effectively", "error", "know", "drift", "occur", "due", "integration", "noisy", "measurement", "which", "lead", "increase", "inaccuracy", "track", "position", "over", "time", "we", "show", "we", "experiment", "use", "inertial", "sensor", "directly", "sufficient", "camera", "tracking", "deblurring", "instead", "we", "use", "inertial", "datum", "record", "blurry", "image", "together", "image", "prior", "novel", "aid", "blind-deconvolution", "method", "compute", "camera-induced", "motion", "blur", "latent", "deblurred", "image", "use", "energy", "minimization", "framework", "we", "consider", "algorithm", "aid", "blind-deconvolution", "since", "only", "give", "estimate", "psf", "from", "sensor", "method", "use", "high-end", "lens", "now", "appear", "lower-end", "point", "shoot", "camera", "use", "mechanical", "means", "dampen", "camera", "motion", "offset", "lens", "element", "translate", "sensor", "fundamentally", "try", "dampen", "motion", "assume", "past", "motion", "predict", "future", "motion", "-lsb-", "Canon", "1993", "-rsb-", "however", "do", "counteract", "actual", "camera", "motion", "during", "exposure", "nor", "do", "actively", "remove", "blur", "only", "reduce", "blur", "we", "work", "similar", "since", "we", "also", "track", "motion", "during", "exposure", "window", "however", "we", "use", "inexpensive", "small", "lightweight", "sensor", "instead", "second", "camera", "main", "difference", "between", "we", "work", "theirs", "we", "additionally", "measure", "axis", "rotational", "velocity", "we", "work", "complementary", "hardware-based", "deblurring", "work", "Levin", "el", "al.", "-lsb-", "2008", "-rsb-", "who", "show", "move", "camera", "along", "parabolic", "arc", "one", "can", "create", "image", "1d", "blur", "due", "object", "scene", "can", "remove", "regardless", "speed", "direction", "motion", "we", "first", "review", "image", "blur", "process", "from", "perspective", "six", "degree", "motion", "camera", "spatially", "invariant", "image", "blur", "model", "convolution", "latent", "sharp", "image", "shift-invariant", "kernel", "plus", "noise", "which", "typically", "consider", "additive", "white", "gaussian", "noise", "work", "we", "goal", "handle", "only", "camera", "induce", "motion", "blur", "i.e.", "spatiallyvary", "blur", "due", "last", "three", "factor", "integration", "project", "observation", "create", "blur", "image", "project", "trajectory", "each", "point", "image", "plane", "point?s", "point-spread", "function", "-lrb-", "psf", "-rrb-", "each", "row", "-lrb-", "-rrb-", "contain", "weight", "compute", "value", "pixel", "-lrb-", "-rrb-", "interpolation", "point", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "we", "use", "bilinear", "interpolation", "thus", "four", "value", "per", "row", "we", "can", "now", "define", "alternative", "formulation", "image", "blur", "integration", "apply", "homography", "over", "time", "value", "know", "image", "can", "deblurr", "use", "nonblind", "deconvolution", "problem", "deconvolution", "now", "reduce", "minimize", "negative", "log", "likelihood", "term", "-rsb-", "scene", "depths", "camera", "intrinsic", "section", "we", "discuss", "how", "recover", "camera", "rotation", "translation", "section", "4.2", "we", "address", "recover", "camera", "intrinsic", "any", "motion", "rigid", "body", "any", "point", "body", "can", "parameterize", "function", "six", "unknown", "three", "rotation", "three", "translation", "we", "now", "describe", "how", "recover", "quantity", "give", "inertial", "measurement", "from", "accelerometer", "gyroscope", "accelerometer", "current", "frame", "position", "accelerometer", "initial", "frame", "Vector", "from", "accelerometer", "center", "rotation", "gravity", "camera?s", "initial", "coordinate", "frame", "rigid", "body", "camera", "three", "axis", "accelerometer", "three", "axis", "gyroscope", "-lrb-", "three", "accelerometer", "gyroscope", "mount", "along", "single", "chip", "respectively", "-rrb-", "measure", "follow", "acceleration", "angular", "velocity", "measure", "angular", "velocity", "camera?s", "angular", "velocity", "also", "rotate", "current", "frame", "camera", "accelerometer", "translation", "-lrb-", "its", "position", "relative", "initial", "frame", "-rrb-", "term", "rigid", "body", "rotation", "translation", "give", "we", "relative", "rotation", "translation", "over", "time", "which", "use", "compute", "spatially-varying", "psf", "matrix", "equation", "10", "measurement", "noise-free", "rotation", "motion", "information", "sufficient", "deblurr", "however", "practice", "sensor", "noise", "introduce", "significant", "error", "get", "high-quality", "deblurring", "result", "we", "must", "overcome", "drift", "final", "camera", "position", "course", "unknown", "however", "we", "know", "drift", "bound", "thus", "correct", "final", "position", "should", "lie", "close", "we", "estimate", "from", "sensor", "datum", "thus", "we", "prototype", "hardware", "system", "show", "Figure", "minimal", "configuration", "consist", "three-axis", "1.5", "mem", "accelerometer", "package", "three", "single", "axis", "150", "mem", "gyroscope", "wire", "Arduino", "controller", "board", "Bluetooth", "radio", "we", "would", "like", "thank", "anonymous", "SIGGRAPH", "reviewer" ],
  "content" : "We present a deblurring algorithm that uses a hardware attachment coupled with a natural image prior to deblur images from consumer cameras. To the best of our knowledge, this is the first work that uses 6 DOF inertial sensors for dense, per-pixel spatially-varying image deblurring and the first work to gather dense ground-truth measurements for camera-shake blur. Intentional blur can be used to great artistic effect in photography. However, in many common imaging situations, blur is a nuisance. Camera motion blur often occurs in light-limited situations and is one of the most common reason for discarding a photograph. If the blur function is known, the image can be improved by deblurring it with a non-blind deconvolution method. However, for most images, the blur function is unknown and must be recov- Recovering both the blur or ?point-spread function? (PSF) and the desired deblurred image from a single blurred input (known as the blind-deconvolution problem) is inherently ill-posed, as the observed blurred image provides only a partial constraint on the solution. Prior knowledge about the image or kernel can disambiguate the potential solutions and make deblurring more tractable [Fergus et al. 2006]. While these approaches have shown some promise, they have some limitations: they generally assume spatially invariant blur, have long run times, cannot be run on highresolution images, and often fail for large image blurs. This can be depth-dependent due to camera translation, or depthindependent, due to camera rotation. As many methods treat all types of blur equally, intentional defocus blur may be removed, creating an oversharpened image. We address some of these limitations with a combined hardware and software-based approach. The device uses inexpensive gyroscopes and accelerometers to measure a camera?s acceleration and angular velocity during an exposure. This data is used as an input to a novel ?aided blind-deconvolution? algorithm that computes the spatially-varying image blur and latent deblurred image. By instrumenting a camera with inertial measurement sensors, we can obtain relevant information about the camera motion and thus the camera-shake blur; however, there are many challenges in using this information effectively. This error, known as ?drift?, occurs due to the integration of the noisy measurements, which leads to increasing inaccuracy in the tracked position over time. As we will show in our experiments, using inertial sensors directly is not sufficient for camera tracking and deblurring. Instead, we use the inertial data and the recorded blurry image together with an image prior in a novel ?aided blind-deconvolution? method that computes the camera-induced motion blur and the latent deblurred image using an energy minimization framework. We consider the algorithm to be ?aided blind-deconvolution?, since it is only given an estimate of the PSF from the sensors. These methods, used in high-end lenses and now appearing in lower-end point and shoot cameras, use mechanical means to dampen camera motion by offsetting lens elements or translating the sensor. Fundamentally, IS tries to dampen motion by assuming that the past motion predicts the future motion [Canon 1993]; however, it does not counteract the actual camera motion during an exposure nor does it actively remove blur ? it only reduces blur. Our work is similar, since we also track motion during the exposure window; however, we use inexpensive, small, and lightweight sensors instead of a second camera. The main difference between our work and theirs is that we additionally measure 3 axes of rotational velocity. Our work is complementary to the hardware-based deblurring work of Levin el al.?s [2008], who show that by moving a camera along a parabolic arc, one can create an image such that 1D blur due to objects in the scene can be removed regardless of the speed or direction of motion. We first review the image blur process from the perspective of the six degree motion of a camera. Spatially invariant image blur is modeled as the convolution of a latent sharp image with a shift-invariant kernel plus noise, which is typically considered to be additive white Gaussian noise. In this work, our goal is to handle only camera induced motion blur, i.e., spatiallyvarying blur due to the last three factors. The integration of these projected observations creates a blurred image, and the projected trajectory of each point on the image plane is that point?s point-spread function (PSF). Each row of A t (d) contains the weights to compute the value at pixel (u t , v t ) as the interpolation of the point (u 0 , v 0 , 1) T = H t (d) ?1 (u t , v t , 1) T ? we use bilinear interpolation, thus there are four values per row. We can now define an alternative formulation for image blur as the integration of applying these homographies over time: If these values are known, the image can be deblurred using nonblind deconvolution. The problem of deconvolution is now reduced to minimizing the negative log likelihood terms. t], the scene depths d, and camera intrinsics K. In this section, we discuss how to recover the camera rotations and translations, and in Section 4.2 we address recovering camera intrinsics. Any motion of a rigid body and any point on that body can be parameterized as a function of six unknowns, three for rotation and three for translation. We now describe how to recover these quantities given inertial measurements from accelerometers and gyroscopes. of the accelerometer in the current frame x i p Position of the accelerometer in the initial frame r p q Vector from the accelerometer to center of rotation g i Gravity in the camera?s initial coordinate frame A rigid body, such as a camera, with a three axis accelerometer and three axis gyroscope (three accelerometers and gyroscopes mounted along x, y, and z in a single chip, respectively) measures the following accelerations and angular velocities: The measured angular velocity is the camera?s angular velocity also rotated in the current frame of the camera. The accelerometers? translation (its position relative to the initial frame) in terms of the rigid body rotation and translation is: This gives us the relative rotation and translation over time, which is used to compute the spatially-varying PSF matrix in Equation 10. If the measurements are noise-free, this rotation and motion information is sufficient for deblurring; however, in practice, the sensor noise introduces significant errors. To get a high-quality deblurring results, we must overcome the drift. The final camera position is, of course, unknown; however, we know the drift is bounded and thus the correct final position should lie close to our estimate from the sensor data. Thus our prototype hardware system, shown in Figure 1 , is a minimal configuration consisting of a three-axis ?1.5g MEMS accelerometer package and three single axis ?150 ? /s MEMS gyroscopes wired to an Arduino controller board with a Bluetooth radio. We would like to thank the anonymous SIGGRAPH reviewers.",
  "resources" : [ ]
}