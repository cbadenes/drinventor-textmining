{
  "uri" : "sig2014a-a232-liu_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2014a/a232-liu_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Fast Burst Images Denoising",
    "published" : null,
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ ]
  },
  "bagOfWords" : [ "burst", "shooting", "mode", "most", "camera", "allow", "multiple", "shot", "capture", "quick", "succession", "either", "press", "hold", "shutter", "button", "design", "allow", "selection", "best", "shot", "record", "motion", "recently", "burst", "capture", "have", "become", "ubiquitous", "many", "hand-held", "imaging", "device", "-lrb-", "e.g.", "smartphone", "compact", "dslr", "camera", "-rrb-", "example", "iPhone", "5", "support", "burst", "up", "10", "shot", "per", "second", "burst", "mode", "have", "be", "successfully", "exploit", "computation", "photography", "reduce", "blur", "-lsb-", "Cai", "et", "al.", "2009", "-rsb-", "improve", "shadow/highlight", "detail", "-lsb-", "Reinhard", "et", "al.", "2010", "-rsb-", "increase", "resolution", "-lsb-", "Farsiu", "et", "al.", "2004", "-rsb-", "clarity", "-lsb-", "Joshi", "Cohen", "2010", "-rsb-", "depth", "field", "-lsb-", "Jacobs", "et", "al.", "2012", "-rsb-", "paper", "we", "present", "practical", "solution", "burst", "image", "denoise", "turn", "burst", "noisy", "image", "-lrb-", "typically", "capture", "low-light", "condition", "-rrb-", "single", "clean", "image", "show", "Figure", "problem", "new", "have", "be", "study", "context", "multiple", "images/video", "denoising", "-lsb-", "buade", "et", "al.", "2010", "Liu", "Freeman", "2010", "Zhang", "et", "al.", "2009", "-rsb-", "we", "focus", "practicality", "we", "goal", "design", "highly", "efficient", "method", "while", "produce", "high-quality", "result", "so", "algorithm", "can", "run", "mobile", "device", "limited", "computational", "resource", "practical", "approach", "need", "tackle", "two", "challenge", "First", "efficiency", "state-of-the-art", "method", "heavily", "rely", "optical", "flow", "patch", "matching", "establish", "temporal", "spatial", "correspondence", "which", "unacceptably", "slow", "Second", "quality", "fast", "method", "like", "average", "filter", "-lsb-", "Tomasi", "Manduchi", "1998", "-rsb-", "insufficient", "both", "noise", "reduction", "avoid", "ghost", "artifact", "cause", "either", "camera", "motion", "-lrb-", "hand", "shake", "-rrb-", "scene", "motion", "-lrb-", "dynamic", "object", "-rrb-", "moreover", "even", "some", "complicated", "method", "also", "fragile", "presence", "strong", "noise", "complex", "dynamic", "motion", "we", "propose", "fast", "noise", "reduction", "method", "produce", "clean", "image", "from", "burst", "image", "high", "speed", "we", "method", "enable", "introduce", "three", "accelerate", "step", "first", "step", "we", "use", "lightweight", "parametric", "motion", "representation", "homog", "raphy", "flow", "model", "motion", "cause", "camera", "movement", "representation", "inspire", "recent", "multiple", "homography", "model", "-lsb-", "Grundmann", "et", "al.", "2012", "Liu", "et", "al.", "2013", "-rsb-", "video", "stabilization", "since", "estimate", "homography", "flow", "only", "require", "spare", "feature", "matching", "step", "both", "efficient", "robust", "noise", "second", "step", "we", "handle", "scene", "motion", "identify", "consistent", "pixel", "-lrb-", "i.e.", "pixel", "similar", "color", "-rrb-", "along", "temporal", "axis", "from", "all", "align", "image", "-lrb-", "first", "step", "-rrb-", "per", "pixel", "location", "select", "consistent", "pixel", "use", "we", "temporal", "pixel", "fusion", "-lrb-", "third", "step", "-rrb-", "average", "thus", "we", "can", "generate", "ghostfree", "result", "while", "avoid", "complex", "motion", "tracking", "dynamic", "object", "which", "too", "slow", "too", "difficult", "idea", "successfully", "apply", "recent", "hdr", "deghosting", "-lsb-", "Granados", "et", "al.", "2013", "-rsb-", "we", "extend", "idea", "find", "many", "consistent", "pixel", "possible", "every", "pixel", "location", "purpose", "better", "denoising", "third", "step", "we", "apply", "temporal", "multiscale", "pixel", "fusion", "succession", "obtain", "denoised", "result", "temporal", "fusion", "base", "simple", "optimal", "linear", "estimator", "multiscale", "fusion", "complementary", "temporal", "fusion", "further", "enable", "significant", "denoising", "meanwhile", "whole", "step", "also", "very", "efficient", "design", "because", "only", "involve", "pixel-wise", "operation", "we", "have", "evaluate", "we", "algorithm", "variety", "real", "datum", "presence", "moderate", "strong", "noise", "we", "algorithm", "perform", "par", "state-of-the-art", "multi-image", "denoising", "method", "-lrb-", "e.g.", "vbm3d", "-lsb-", "Dabov", "et", "al.", "2007a", "-rsb-", "bm4d", "-lsb-", "Maggioni", "et", "al.", "2013", "-rsb-", "-rrb-", "furthermore", "we", "algorithm", "two", "three", "order", "magnitude", "faster", "Figure", "show", "comparison", "single", "image", "denoising", "have", "great", "progress", "recent", "decade", "Representative", "method", "include", "bilateral", "filter", "-lsb-", "Tomasi", "Manduchi", "1998", "-rsb-", "wavelet", "-lrb-", "gsm", "-rrb-", "-lsb-", "Portilla", "et", "al.", "2003", "-rsb-", "field-ofexpert", "-lsb-", "Roth", "Black", "2005", "-rsb-", "non-local", "means", "-lsb-", "buade", "et", "al.", "2005", "-rsb-", "bm3d", "-lsb-", "Dabov", "et", "al.", "2007b", "-rsb-", "so", "improve", "efficiency", "few", "fast", "variant", "have", "be", "propose", "fast", "bilateral", "filter", "-lsb-", "Paris", "Durand", "2009", "-rsb-", "gaussian", "kd-tree", "-lsb-", "Adams", "et", "al.", "2009", "-rsb-", "geodesic", "path", "-lsb-", "Chen", "et", "al.", "2013", "-rsb-", "most", "recently", "Levin", "et", "al.", "-lsb-", "2011", "-rsb-", "point", "out", "single", "image", "denoising", "may", "approach", "its", "performance", "limit", "noisebrush", "-lsb-", "Chen", "et", "al.", "2009", "-rsb-", "provide", "interactive", "way", "further", "quality", "improvement", "multiple", "image", "denoising", "superior", "single", "image", "denoising", "because", "its", "use", "more", "information", "some", "denoise", "technique", "have", "be", "successfully", "use", "burst", "image", "-lsb-", "Tico", "2008", "Buades", "et", "al.", "2009", "Joshi", "Cohen", "2010", "-rsb-", "video", "-lsb-", "Bennett", "McMillan", "2005", "Liu", "Freeman", "2010", "Dabov", "et", "al.", "2007a", "Chen", "Tang", "2007", "-rsb-", "multiple-view", "image", "-lsb-", "Zhang", "et", "al.", "2009", "-rsb-", "volumetric", "MRI", "datum", "-lsb-", "maggionus", "et", "al.", "2013", "-rsb-", "estimate", "camera", "motion", "Optical", "flow", "-lsb-", "Brox", "et", "al.", "2004", "-rsb-", "most", "general", "representation", "establish", "correspondence", "between", "frame", "recent", "work", "-lsb-", "Liu", "Freeman", "2010", "-rsb-", "show", "its", "importance", "video", "denoising", "optical", "flow", "itself", "have", "difficulty", "occlusion/large", "displacement", "fragile", "noise", "Patch", "matching", "more", "robust", "noise", "have", "be", "widely", "use", "multiple", "image", "processing", "-lsb-", "Tico", "2008", "Buades", "et", "al.", "2009", "Zhang", "et", "al.", "2009", "Maggioni", "et", "al.", "2013", "Sen", "et", "al.", "2012", "Kalantari", "et", "al.", "2013", "-rsb-", "however", "presence", "strong", "noise", "both", "nonparametric", "method", "degrade", "rapidly", "camera", "motion", "burst", "mode", "similar", "motion", "study", "video", "stabilization", "recent", "work", "-lsb-", "Grundmann", "et", "al.", "2012", "Liu", "et", "al.", "2013", "-rsb-", "demonstrate", "success", "use", "spatially-variant", "homography", "camera", "motion", "work", "we", "use", "similar", "more", "lightweight", "parametric", "motion", "representation", "homography", "flow", "handle", "scene", "motion", "since", "optical", "flow", "patch", "matching", "intrinsically", "hard", "problem", "recent", "work", "-lsb-", "Gallo", "et", "al.", "2009", "Granados", "et", "al.", "2013", "-rsb-", "hdr", "reconstruction", "bypass", "motion", "estimation", "find", "consistent", "subset", "color", "every", "pixel", "reconstruct", "ghost-free", "image", "Granados", "et", "al.", "-lsb-", "2013", "-rsb-", "consistency", "test", "rely", "accurate", "estimation", "noise", "distribution", "which", "may", "require", "complex", "calibration", "super-pixels", "computation", "we", "be", "inspire", "idea", "extend", "image", "denoising", "multiscale", "denoising", "effective", "way", "exploit", "cross-scale", "similarity", "noise", "reduction", "recently", "Zontak", "et", "al.", "-lsb-", "2013", "-rsb-", "propose", "directional", "pyramid", "technique", "find", "corresponding", "patch", "across", "scale", "which", "produce", "state-of-the-art", "result", "Zhang", "Gunturk", "-lsb-", "2008", "-rsb-", "extend", "bilateral", "filter", "multiscale", "framework", "we", "use", "pyramid-based", "pixel", "fusion", "method", "improve", "result", "quality" ],
  "content" : "Burst, a shooting mode in most cameras, allows multiple shots to be captured in a quick succession by either pressing or holding the shutter button. It is designed to allow selection of the best shot or record the motion. Recently, burst capturing has become ubiquitous in many hand-held imaging devices (e.g., smartphone, compact and DSLR cameras). For example, iPhone 5s supports a burst of up to 10 shots per second. The burst mode has been successfully exploited in computation photography for reducing blur [Cai et al. 2009], or improving shadow/highlight details [Reinhard et al. 2010], or increasing resolution [Farsiu et al. 2004], or clarity [Joshi and Cohen 2010], or depth of the field [Jacobs et al. 2012]. In this paper, we present a practical solution for ?burst images denoising? turning a burst of noisy images (typically captured in a low-light condition) into a single clean image, as shown in Figure 1 . This problem is not new. It has been studied in the context of multiple images/video denoising [Buades et al. 2010; Liu and Freeman 2010; Zhang et al. 2009]. But we focus on practicality our goal is to design a highly efficient method while producing a high-quality result so that the algorithm can be run on a mobile device with limited computational resources. A practical approach needs to tackle two challenges. First is efficiency. The state-of-the-art methods heavily rely on optical flow or patch matching to establish temporal and spatial correspondence, which is unacceptably slow. Second is quality. Fast methods like averaging or filtering [Tomasi and Manduchi 1998] are insufficient on both noise reduction and avoiding ?ghost? artifacts caused by either camera motion (by hand shake) or scene motion (by dynamic objects). Moreover, even some complicated methods are also fragile in the presence of strong noise or complex dynamic motion. We propose a fast noise reduction method that produces a clean image from a burst of images. The high speed of our method is enabled by introducing three accelerating steps. In the first step, we use a lightweight, parametric motion representation homog- raphy flow to model the motion caused by camera movements. This representation is inspired by the recent multiple homographies model [Grundmann et al. 2012; Liu et al. 2013] for video stabilization. Since estimating homography flow only requires spare feature matching, this step is both efficient and robust to noise. In the second step, we handle the scene motion by identifying consistent pixels (i.e., pixels with similar colors) along the temporal axis from all aligned images (by the first step) per pixel location. These selected consistent pixels are used in our temporal pixel fusion (in the third step) by averaging. Thus, we can generate ghostfree results while avoiding complex motion tracking on dynamic objects, which is too slow or too difficult. The idea was successfully applied in recent HDR deghosting [Granados et al. 2013]. We extend this idea to find as many consistent pixels as possible at every pixel location for the purpose of better denoising. In the third step, we apply temporal and multiscale pixel fusions in succession to obtain the denoised result. The temporal fusion is based on a simple, optimal linear estimator. The multiscale fusion is complementary to temporal fusion and further enables significant denoising. Meanwhile, the whole step is also very efficient by design because it only involves pixel-wise operations. We have evaluated our algorithm on a variety of real data. In the presence of moderate or strong noise, our algorithm performs on par with state-of-the-art multi-image denoising methods (e.g., VBM3D [Dabov et al. 2007a], BM4D [Maggioni et al. 2013]). Furthermore, our algorithm is two or three orders of magnitude faster. Figure 1 shows a comparison. Single image denoising has great progresses in recent decades. Representative methods include bilateral filtering [Tomasi and Manduchi 1998], wavelet (GSM) [Portilla et al. 2003], Field-OfExpert [Roth and Black 2005], non-local means [Buades et al. 2005], BM3D [Dabov et al. 2007b] and so on. To improve the efficiency, a few fast variants have been proposed, such as fast bilateral filtering [Paris and Durand 2009], Gaussian kd-trees [Adams et al. 2009], and geodesic paths [Chen et al. 2013]. Most recently, Levin et al. [2011] pointed out that single image denoising may be approaching its performance limit. NoiseBrush [Chen et al. 2009] provided a interactive way for further quality improvement. Multiple image denoising is superior to single image denoising because of its use of more information. Some denoising techniques have been successfully used on burst images [Tico 2008; Buades et al. 2009; Joshi and Cohen 2010], videos [Bennett and McMillan 2005; Liu and Freeman 2010; Dabov et al. 2007a; Chen and Tang 2007], multiple-view images [Zhang et al. 2009], and volumetric MRI data [Maggioni et al. 2013]. Estimating camera motion. Optical flow [Brox et al. 2004] is the most general representation for establishing correspondences between frames. Recent work [Liu and Freeman 2010] showed its importance in video denoising. But optical flow itself has difficulties with occlusion/large displacement, and is fragile to noise. Patch matching is more robust to noise and has been widely used in multiple image processing [Tico 2008; Buades et al. 2009; Zhang et al. 2009; Maggioni et al. 2013; Sen et al. 2012; Kalantari et al. 2013]. However, in the presence of strong noise, both nonparametric methods degrade rapidly. Camera motion in burst mode is similar to the motion studied in video stabilization. Recent work [Grundmann et al. 2012; Liu et al. 2013] demonstrated the success of using a spatially-variant homography for the camera motion. In this work, we use a similar but more lightweight parametric motion representation homography flow. Handling scene motion. Since optical flow or patch matching is an intrinsically hard problem, recent work [Gallo et al. 2009; Granados et al. 2013] in HDR reconstruction bypasses the motion estimation by finding a consistent subset of colors for every pixel to reconstruct a ghost-free image. Granados et al. [2013]?s consistency test relies on accurate estimation of the noise distribution, which may require complex calibration and super-pixels computation. We were inspired by this idea and extend it for image denoising. Multiscale denoising is an effective way to exploit cross-scale similarity for noise reduction. Recently, Zontak et al. [2013] proposed a directional pyramid technique to find corresponding patches across scales, which produces state-of-the-art results. Zhang and Gunturk [2008] extended the bilateral filter in a multiscale framework. We use a pyramid-based pixel fusion method to improve the result quality.",
  "resources" : [ ]
}