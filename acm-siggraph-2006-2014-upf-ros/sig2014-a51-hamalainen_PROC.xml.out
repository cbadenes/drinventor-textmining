{
  "uri" : "sig2014-a51-hamalainen_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2014/a51-hamalainen_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Online Motion Synthesis Using Sequential Monte Carlo",
    "published" : null,
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ ]
  },
  "bagOfWords" : [ "we", "present", "Model-Predictive", "Control", "-lrb-", "MPC", "-rrb-", "system", "online", "synthesis", "interactive", "physically", "valid", "character", "motion", "we", "system", "enable", "complex", "-lrb-", "36-dof", "-rrb-", "3d", "human", "character", "model", "balance", "give", "pose", "dodge", "projectile", "improvise", "get", "up", "strategy", "force", "lose", "balance", "all", "dynamic", "unpredictable", "environment", "contact-rich", "predictive", "reactive", "motion", "have", "previously", "only", "be", "generate", "offline", "use", "handcrafted", "state", "machine", "dataset", "reference", "motion", "which", "we", "system", "do", "require", "follow", "seminal", "work", "e.g.", "Witkin", "Kass", "-lsb-", "1988", "-rsb-", "sim", "-lsb-", "1994", "-rsb-", "basic", "behavior", "balancing", "locomotion", "can", "now", "generate", "real-time", "offline", "system", "exist", "synthesize", "more", "complex", "motion", "-lsb-", "Geijtenbeek", "et", "al.", "2011", "Al", "Borno", "et", "al.", "2013", "Erez", "et", "al.", "2013", "-rsb-", "output", "we", "system", "time-varying", "control", "strategy", "drive", "character", "towards", "specify", "goal", "while", "account", "change", "environment", "formally", "treat", "each", "control", "strategy", "point", "high-dimensional", "space", "-lrb-", "make", "explicit", "below", "-rrb-", "we", "evolve", "population", "sample", "use", "sequential", "Monte", "Carlo", "sampling", "so", "ensemble", "remain", "well-distributed", "even", "when", "fitness", "landscape", "change", "we", "formulation", "also", "allow", "straightforward", "parallelization", "objective", "function", "value", "sample", "can", "compute", "arbitrary", "order", "we", "contribution", "introduction", "smc", "online", "synthesis", "physically", "valid", "character", "motion", "novel", "sequential", "sampling", "method", "allow", "easy", "integration", "machine", "learning", "example", "motion", "generate", "we", "system", "show", "Figure", "figure", "give", "overview", "main", "component", "we", "system", "include", "multimodal", "sampler/optimizer", "generate", "motion", "plan", "parallelized", "physics", "engine", "use", "simulate", "movement", "result", "from", "each", "motion", "plan", "optional", "machine", "learn", "system", "generate", "one", "more", "prediction", "use", "seed", "adaptive", "sampling", "each", "frame", "however", "synthesize", "motion", "have", "be", "limit", "need", "prior", "knowledge", "contact", "information", "what", "frame", "character", "should", "touch", "ground", "which", "body", "part", "limitation", "overcome", "Mordatch", "et", "al.", "-lsb-", "2012", "-rsb-", "who", "introduce", "auxiliary", "optimize", "variable", "specify", "contact", "information", "who", "use", "l-bfg", "optimization", "Motion", "synthesis", "control", "Problem", "Spacetime", "optimization", "can", "also", "approach", "control", "problem", "dynamics", "simulation", "evaluate", "each", "sample", "control", "vector", "costly", "straightforward", "parallelize", "light", "recent", "work", "Mordatch", "et", "al.", "-lsb-", "2012", "-rsb-", "Al", "Borno", "et", "al.", "-lsb-", "2013", "-rsb-", "both", "deterministic", "spacetime", "optimization", "stochastic", "derivative-free", "control", "optimization", "appear", "equally", "suitable", "offline", "synthesis", "contact-rich", "complex", "acrobatic", "motion", "Online", "Optimization", "Control", "use", "prior", "datum", "consider", "online", "synthesis", "physically", "valid", "motion", "interactive", "frame", "rate", "various", "approach", "offline", "optimization", "have", "be", "use", "learn", "parameter", "neural", "network", "other", "controller", "type", "can", "use", "real-time", "physics", "simulation", "-lsb-", "sim", "1994", "Reil", "Husbands", "2002", "Geijtenbeek", "et", "al.", "2013", "-rsb-", "we", "work", "fall", "category", "we", "draw", "inspiration", "from", "two", "main", "prior", "system", "Jain", "et", "al.", "-lsb-", "2009", "-rsb-", "have", "implement", "balancing", "step", "other", "behavior", "use", "frame-by-frame", "qp", "optimizer", "augment", "state", "machine", "break", "movement", "down", "subgoal", "can", "implement", "planning", "horizon", "single", "frame", "raise", "concern", "about", "robustness", "e.g.", "obstacle", "foot", "placement", "decrease", "probability", "creative", "emergent", "movement", "we", "system", "do", "need", "motion", "datum", "we", "optimizer", "automatically", "generate", "balancing", "footstep", "without", "predefined", "state", "thanks", "planning", "horizon", "up", "seconds", "which", "enough", "complete", "rebalance", "step", "even", "roll", "ground", "bounce", "back", "up", "we", "approach", "also", "inherently", "predictive", "character", "can", "anticipate", "event", "without", "hand-coded", "prediction", "algorithm", "we", "extend", "approach", "three", "key", "area", "we", "use", "longer", "planning", "horizon", "-lrb-", "up", "seconds", "vs.", "0.5", "-rrb-", "simultaneously", "track", "multiple", "mode", "fitness", "function", "-lrb-", "ilqg", "method", "unimodal", "-rrb-", "use", "more", "complex", "character", "model", "include", "3-dof", "joint", "result", "we", "system", "add", "ability", "plan", "movement", "several", "phase", "e.g.", "get", "up", "plant", "hand", "push", "hand", "allow", "move", "foot", "closer", "shift", "weight", "foot", "show", "Figure", "14", "later", "work", "problem", "spring", "straight", "up", "solve", "design", "state", "machine", "explicitly", "break", "down", "task", "sequence", "subtask", "-lsb-", "Erez", "et", "al.", "2013", "-rsb-", "sequential", "Monte", "Carlo", "Sampling", "SMC", "have", "be", "use", "widely", "various", "tracking", "problem", "-lsb-", "Arulampalam", "et", "al.", "2002", "Doucet", "Johansen", "2009", "-rsb-", "body", "tracking", "use", "computer", "vision", "especially", "close", "we", "work", "many", "tracking", "system", "feature", "both", "particle", "filter", "-lrb-", "form", "smc", "-rrb-", "articulate", "human", "body", "model", "-lsb-", "Deutscher", "et", "al.", "2000", "Schmidt", "et", "al.", "2006", "-rsb-", "although", "we", "sampler", "bear", "similarity", "e.g.", "particle", "filter", "variant", "discuss", "Arulampalam", "et", "al.", "-lsb-", "2002", "-rsb-", "more", "precisely", "sequential", "version", "mutate", "kd-tree", "importance", "sampling", "H?m?l?inen", "et", "al.", "-lsb-", "2006", "-rsb-", "which", "turn", "base", "hierarchical", "subdivision", "sampling", "Kajiya", "-lsb-", "1986", "-rsb-", "illustration", "basic", "principle", "smc", "sampling", "step", "new", "sample", "draw", "from", "proposal", "density", "base", "previous", "sample", "during", "resampling", "step", "sample", "peak", "-lrb-", "-rrb-", "produce", "more", "offspring", "while", "other", "may", "die", "out", "we", "formulate", "find", "global", "maximum", "real-valued", "non-negative", "objective", "function", "-lrb-", "fitness", "function", "-rrb-", "-lrb-", "-rrb-", "where", "vector", "define", "control", "strategy", "represent", "timevary", "target", "joint", "angle", "other", "parameter", "explain", "detail", "section", "4.2", "Time", "parameter", "rather", "than", "domain", "variable", "account", "dynamic", "environment", "search", "space", "consist", "approximation", "all", "possible", "way", "drive", "actuator", "over", "couple", "seconds", "easy", "appreciate", "objective", "function", "multimodal", "mode", "shift", "appear", "vanish", "time", "core", "idea", "smc", "method", "sequence", "target", "probability", "density", "approximate", "use", "evolve", "set", "weighted", "sample", "illustrate", "Figure", "sample", "set", "can", "use", "estimate", "mode", "density", "function", "thorough", "mathematical", "treatment", "can", "find", "e.g.", "-lsb-", "Arulampalam", "et", "al.", "2002", "Doucet", "Johansen", "2009", "-rsb-", "we", "sampler", "avoid", "requirement", "allow", "insertion", "additional", "arbitrarily", "obtain", "candidate", "sample", "e.g.", "initial", "guess", "from", "machine", "learn", "component", "figure", "provide", "unified", "way", "weighting", "random", "sample", "known", "proposal", "density", "initial", "guess", "proposal", "density", "additionally", "kd-tree", "provide", "means", "adapt", "search", "variance", "so", "sample", "low", "fitness", "region", "perturb", "more", "Algorithm", "Overview", "we", "maintain", "population", "-lcb-", "-lrb-", "-rrb-", "-rcb-", "sample", "associate", "fitness", "evolve", "over", "time", "each", "frame", "algorithm", "perform", "follow", "step", "prune", "sample", "set", "keep", "only", "best", "draw", "set", "new", "sample", "optional", "heuristic", "machine", "learning", "prediction", "may", "depend", "current", "state", "construct", "sampling", "prior", "-lrb-", "-rrb-", "base", "sample", "insert", "sample", "kd-tree", "construct", "adaptive", "pdf", "until", "budget", "sample", "reach", "draw", "new", "sample", "from", "-lrb-", "-rrb-", "use", "each", "new", "sample", "adaptively", "update", "prior", "-lrb-", "-rrb-", "pick", "best", "sample", "use", "drive", "simulation", "forward", "current", "time", "step", "construction", "sampling", "prior", "-lrb-", "-rrb-", "its", "adaptive", "refinement", "describe", "section", "3.3", "detail", "outer", "loop", "present", "section", "3.4", "heuristic", "machine", "learning", "component", "detail", "section", "4.5", "provide", "visualization", "intuition", "we", "sampler", "apply", "motion", "optimization", "we", "present", "2d", "problem", "nonlinearity", "multimodality", "arise", "from", "physical", "contact", "optimize", "parameter", "-lsb-", "-rsb-", "where", "throw", "speed", "throw", "angle", "aim", "get", "ball", "close", "specify", "target", "possible", "Figure", "4A", "illustrate", "physical", "setup", "show", "two", "trajectory", "result", "from", "different", "target", "show", "black", "circle", "we", "illustrate", "two", "different", "objective", "function", "first", "illustrated", "Figure", "4B", "compute", "closest", "point", "-lrb-", "-rrb-", "trajectory", "target", "without", "regard", "timing", "i.e.", "-lrb-", "-rrb-", "exp", "-lcb-", "-lrb-", "-rrb-", "-rcb-", "produce", "landscape", "ridge", "each", "iteration", "sampling", "from", "model", "update", "model", "base", "sample", "also", "central", "some", "other", "optimization", "method", "Covariance", "Matrix", "Adaptation", "Evolution", "Strategy", "-lrb-", "cma-e", "-rrb-", "which", "have", "be", "gain", "popularity", "motion", "synthesis", "literature", "however", "whereas", "cma-e", "update", "unimodal", "model", "-lrb-", "single", "gaussian", "-rrb-", "we", "model", "multimodal", "algorithm", "Adaptive", "Importance", "sample", "use", "kd-tree", "draw", "uniformly", "parameter", "space", "evaluate", "-lrb-", "-rrb-", "root", "-lcb-", "-lrb-", "-rrb-", "-rcb-", "repeat", "randomly", "select", "leaf", "node", "probability", "draw", "sample", "new", "-lrb-", "-rrb-", "evaluate", "-lrb-", "new", "-rrb-", "-lcb-", "-rcb-", "nsert", "ree", "-lrb-", "new", "-rrb-", "new", "leaf", "-lrb-", "new", "-rrb-", "where", "new", "end", "up", "-lrb-", "-rrb-", "contain", "previous", "sample", "10", "until", "#samples", "ridge", "correspond", "e.g.", "different", "number", "bounce", "two", "example", "trajectory", "mark", "red", "green", "circle", "second", "goal", "illustrate", "Figure", "4C", "aim", "hit", "target", "specify", "point", "time", "corresponding", "objective", "function", "simply", "evaluate", "distance", "target", "time", "trajectory", "now", "some", "ridge", "become", "peak", "landscape", "still", "multimodal", "ball", "can", "still", "reach", "target", "use", "variety", "different", "bounce", "sequence", "Figure", "4d", "illustrate", "adaptive", "kd-tree", "define", "sampling", "prior", "-lrb-", "-rrb-", "whose", "construction", "detail", "next", "section", "we", "first", "describe", "adaptive", "importance", "sampler", "timeinvariant", "multimodal", "unnormalized", "objective", "function", "-lrb-", "-rrb-", "method", "propose", "-lsb-", "h?m?l?inen", "et", "al.", "2006", "-rsb-", "we", "repeat", "completeness", "extend", "sequential", "timevarying", "case", "process", "outline", "algorithm", "illustrate", "Figure", "Figure", "process", "draw", "sample", "approximately", "follow", "-lrb-", "-rrb-", "allocate", "more", "sample", "region", "where", "-lrb-", "-rrb-", "high", "approximation", "-lrb-", "-rrb-", "gradually", "improve", "each", "sample", "tree", "adaptively", "subdivide", "parameter", "space", "hypercube", "weight", "give", "single-sample", "estimate", "integral", "-lrb-", "-rrb-", "over", "leaf", "hypercube", "one", "can", "interpret", "tree", "piecewise", "constant", "approximation", "-lrb-", "-rrb-", "from", "which", "one", "may", "draw", "sample", "first", "randomly", "select", "hypercube", "selection", "probability", "generate", "sample", "uniformly", "inside", "hypercube", "solution", "treat", "kd-tree", "mixture", "Gaussians", "illustrate", "Figure", "select", "hypercube", "sample", "draw", "from", "-lrb-", "-rrb-", "gaussian", "tail", "overlap", "neighbor", "hypercube", "which", "make", "more", "likely", "sampling", "cross", "valley", "recover", "from", "bias", "until", "sampling", "budget", "meet", "we", "draw", "new", "sample", "from", "mixture", "add", "sample", "tree", "split", "leaf", "node", "where", "new", "sample", "land", "between", "new", "old", "sample", "recompute", "weight", "two", "new", "leaf", "-lrb-", "equation", "-rrb-", "mixture", "component", "show", "black", "curve", "step", "Gaussians", "center", "sample", "standard", "deviation", "proportional", "hypercube", "width", "each", "dimension", "blur", "distribution", "model", "adaptively", "less", "blur", "where", "sample", "densely", "concentrated", "increase", "chance", "sample", "cross", "valley", "illustrate", "step", "we", "application", "fitness", "landscape", "vary", "from", "frame", "frame", "environment", "change", "phenomenon", "illustrate", "Figure", "where", "change", "throw", "target", "change", "objective", "build", "sampling", "distribution", "out", "sample", "take", "during", "previous", "frame", "allow", "we", "exploit", "temporal", "coherence", "frame", "set", "sample", "from", "previous", "frame", "first", "prune", "sample", "retain", "sample", "whose", "leaf", "node", "have", "largest", "weight", "-lrb-", "line", "2-5", "-rrb-", "large", "mean", "old", "sample", "get", "select", "re-evaluate", "often", "which", "may", "affect", "convergence", "rapidly", "change", "situation", "whereas", "low", "value", "make", "track", "multiple", "mode", "difficult", "little", "information", "retain", "between", "frame", "we", "use", "0.1", "all", "we", "result", "after", "pruning", "tree", "rebuild", "insert", "remain", "sample", "random", "order", "-lrb-", "line", "6-10", "-rrb-", "however", "randomization", "average", "bias", "out", "temporally", "figure", "show", "function", "sample", "three", "different", "kd-tree", "model", "build", "from", "same", "set", "sample", "average", "100", "tree", "we", "have", "also", "experiment", "build", "ensemble", "tree", "each", "time", "step", "further", "reduce", "variance", "volume", "estimate", "each", "sample", "we", "do", "so", "far", "have", "conclusive", "evidence", "benefit", "after", "rebuild", "we", "introduce", "new", "sample", "draw", "from", "set", "heuristic", "-lrb-", "line", "11-15", "see", "section", "4.5", "-rrb-", "after", "sampling", "prior", "complete", "tree", "contain", "best", "sample", "from", "algorithm", "kD-Tree", "Sequential", "Importance", "sample", "each", "time", "step", "do", "prune", "tree", "sample", "while", "#samples", "do", "find", "leaf", "minimum", "emove", "ree", "-lrb-", "-rrb-", "end", "while", "randomly", "shuffle", "rebuild", "tree", "use", "old", "fitness", "lear", "ree", "-lrb-", "-rrb-", "-lcb-", "...", "-rcb-", "andom", "ermute", "-lrb-", "-lcb-", "...", "-rcb-", "-rrb-", "do", "nsert", "ree", "-lrb-", "-rrb-", "10", "end", "draw", "guess", "from", "heuristic", "ml", "predictor", "11", "do", "12", "raw", "uess", "-lrb-", "-rrb-", "13", "evaluate", "-lrb-", "-rrb-", "14", "nsert", "ree", "-lrb-", "-rrb-", "15", "end", "16", "-lcb-", "...", "-rcb-", "PDATE", "EAF", "EIGHTS", "-lrb-", "-rrb-", "perform", "adaptive", "sampling", "17", "repeat", "18", "randomly", "select", "leaf", "node", "probability", "19", "node", "contain", "old", "fitness", "-lrb-", "-rrb-", "20", "compute", "current", "fitness", "-lrb-", "-rrb-", "21", "-lrb-", "-rrb-", "update", "weight", "22", "else", "Sample", "algorithm", "23", "draw", "sample", "new", "-lrb-", "-rrb-", "24", "evaluate", "-lrb-", "new", "-rrb-", "25", "-lcb-", "-rcb-", "nsert", "ree", "-lrb-", "new", "-rrb-", "26", "-lrb-", "new", "-rrb-", "27", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "known", "28", "end", "29", "until", "#samples", "30", "end", "previous", "frame", "along", "new", "sample", "generate", "heuristic", "remainder", "algorithm", "perform", "adaptive", "sampling", "much", "like", "algorithm", "-lrb-", "line", "17-29", "-rrb-", "only", "difference", "when", "leaf", "contain", "stale", "fitness", "value", "from", "previous", "frame", "select", "recompute", "weight", "update", "new", "sample", "generate", "-lrb-", "line", "20-21", "-rrb-", "when", "node", "up-to-date", "fitness", "select", "refinement", "sampling", "proceeds", "algorithm", "-lrb-", "line", "23-27", "-rrb-", "when", "budget", "sample", "reach", "current", "sample", "set", "approximately", "distribute", "accord", "new", "fitness", "-lrb-", "-rrb-", "Figure", "show", "how", "algorithm", "track", "objective", "function", "mode", "2d", "example", "when", "ball", "throw", "target", "move", "after", "nearly", "exhausting", "we", "sample", "budget", "we", "further", "opportunistically", "explore", "region", "around", "current", "best", "sample", "we", "modify", "algorithm", "so", "last", "sample", "time", "step", "selection", "-lrb-", "line", "18", "-rrb-", "always", "choose", "leaf", "best", "sample", "so", "far", "lower", "scaling", "factor", "use", "computing", "adjust", "allow", "one", "tune", "balance", "between", "local", "global", "search", "we", "use", "0.005", "section", "present", "result", "from", "we", "character", "motion", "synthesis", "different", "value", "Figure", "show", "we", "character", "physics", "model", "we", "test", "we", "use", "two", "physics", "model", "one", "light-boned", "another", "considerably", "heavier", "torso", "thus", "higher", "center", "mass", "-lrb-", "com", "-rrb-", "which", "make", "balancing", "acrobatics", "more", "difficult", "physics", "object", "have", "constant", "density", "character", "have", "30", "actuate", "dof", "unactuated", "root", "dof", "physics", "model", "consist", "15", "bone", "-lrb-", "rigid", "body", "-rrb-", "connect", "use", "3-dof", "ball", "1-dof", "hinge", "joint", "latter", "use", "elbow", "knee", "ankle", "we", "do", "model", "clavicle", "toe", "finger", "simulation", "we", "use", "Open", "Dynamics", "Engine", "-lrb-", "ODE", "-rrb-", "0.12", "use", "ode?s", "direct", "big", "matrix", "lcp", "solver", "time", "step", "1/30", "seconds", "CFM", "erp", "parameter", "10", "0.2", "respectively", "note", "ode", "also", "have", "iterative", "solver", "which", "faster", "less", "stable", "approximately", "similar", "quality", "iterative", "solver", "require", "timestep", "1/120s", "which", "result", "slower", "operation", "we", "case", "direct", "solver", "only", "take", "approximately", "much", "CPU", "time", "collision", "handling", "we", "represent", "control", "strategy", "time-varying", "target", "joint", "angle", "encode", "sequence", "control", "point", "interpolate", "cubic", "spline", "we", "use", "control", "point", "all", "we", "experiment", "we", "spline", "non-uniform", "i.e.", "position", "control", "point", "along", "temporal", "axis", "-lrb-", "knot", "-rrb-", "subject", "optimization", "specifically", "where", "denote", "30", "target", "joint", "angle", "time", "limit", "maximum", "allowable", "torque", "actuated", "joint", "allow", "they", "vary", "instead", "use", "fix", "maximum", "allow", "character", "e.g.", "soften", "landing", "from", "high", "jump", "we", "use", "sampling", "bound", "50n", "150n", "lightweight", "model", "50n", "200n", "heavier", "one", "torque", "limit", "specify", "three", "group", "bone", "torso", "arm", "leg", "non-uniform", "knot", "sequence", "allow", "fine-grained", "control", "fast", "movement", "jump", "total", "number", "optimize", "variable", "136", "-lrb-", "i.e.", "136", "-rrb-", "consist", "30", "target", "angle", "torque", "limit", "time", "coordinate", "each", "control", "point", "spline", "define", "give", "continuous-time", "target", "joint", "angle", "-lrb-", "-rrb-", "limit", "maximum", "torque", "-lrb-", "-rrb-", "evaluate", "objective", "function", "we", "feed", "target", "physics", "simulation", "record", "what", "happen", "total", "duration", "simulation", "each", "sample", "vary", "depend", "control", "point", "however", "we", "only", "run", "simulation", "up", "predefined", "planning", "horizon", "section", "present", "result", "different", "planning", "horizon", "default", "use", "supplementary", "video", "seconds", "each", "time", "step", "we", "evaluate", "target", "angle", "-lrb-", "-rrb-", "torque", "limit", "-lrb-", "-rrb-", "feed", "they", "ODE", "physics", "simulator", "ODE", "motor", "control", "target", "velocity", "ode", "try", "make", "motor", "reach", "we", "compute", "target", "velocity", "ith", "motor", "from", "target", "pose", "-lrb-", "target", "current", "-rrb-", "denote", "joint", "angle", "see", "motor", "simulator", "step", "forward", "time", "step", "internally", "drive", "motor", "try", "match", "target", "velocity", "while", "respect", "torque", "limit", "simulation", "produce", "time", "series", "realize", "3d", "position", "velocity", "all", "15", "rigid", "body", "skeleton", "represent", "what", "happen", "when", "we", "try", "control", "character", "use", "strategy", "we", "denote", "series", "-lrb-", "-rrb-", "-lcb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-rcb-", "-lrb-", "-rrb-", "where", "-lrb-", "-rrb-", "number", "simulated", "time", "step", "sample", "denote", "current", "time", "step", "we", "also", "use", "shorthand", "notation", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "time", "index", "-lrb-", "-rrb-", "from", "-1", "we", "also", "include", "history", "past", "two", "frame", "evaluation", "which", "allow", "objective", "function", "evaluation", "prefer", "continuity", "previously", "select", "control", "strategy", "reduce", "movement", "jitter", "which", "could", "otherwise", "problem", "stochastic", "sampling", "system", "like", "ours", "note", "lcp", "solver", "adapt", "torque", "base", "e.g.", "contact", "force", "we", "scheme", "provide", "slightly", "higher", "level", "control", "than", "use", "pd", "controller", "human", "motor", "system", "comprise", "both", "motion-inducing", "stabilizer", "muscle", "stabilize", "character", "give", "pose", "easier", "motor", "than", "pd", "controller", "especially", "large", "we", "use", "appendix", "describe", "important", "implementation", "detail", "relate", "obtain", "causal", "reproducible", "simulation", "objective", "function", "drive", "character", "towards", "desire", "goal", "corresponding", "objective", "function", "formulate", "where", "denote", "damage", "avoidance", "smoothness", "balancing", "get", "up", "objective", "respectively", "adjust", "priority", "get", "up", "objective", "we", "use", "0.0001", "all", "component", "objective", "function", "function", "follow", "we", "omit", "dependence", "brevity", "damage", "avoidance", "damage", "avoidance", "objective", "try", "avoid", "high-velocity", "impact", "important", "body", "part", "we", "include", "head", "pelvis", "objective", "allow", "versatile", "movement", "prevent", "character", "from", "fall", "its", "head", "bottom", "where", "number", "all", "important", "body", "contact", "during", "realize", "plan", "relative", "velocity", "contact", "normal", "ith", "contact", "respectively", "we", "use", "2.2", "2.5", "smoothness", "smoothness", "objective", "consist", "minimize", "acceleration", "jerk", "-lrb-", "time-derivative", "acceleration", "-rrb-", "which", "have", "be", "find", "help", "produce", "natural", "movement", "-lsb-", "Van", "Welbergen", "et", "al.", "2010", "-rsb-", "objective", "give", "where", "mean", "square", "acceleration", "jerk", "respectively", "compute", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "+1", "-rrb-", "...", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "+1", "-rrb-", "-lrb-", "-rrb-", "we", "use", "value", "5.0", "13.7", "jerk", "term", "affect", "history", "last", "two", "frame", "-lrb-", "-rrb-", "avoid", "acceleration", "jitter", "from", "frame", "frame", "balance", "balance", "objective", "most", "complex", "one", "comprise", "desire", "target", "pose", "desire", "up-vector", "direction", "velocity", "minimization", "com", "displacement", "minimization", "penalization", "base", "other", "body", "part", "than", "foot", "touch", "ground", "we", "define", "where", "denote", "jth", "frame", "here", "penalize", "term", "get", "value", "any", "body", "part", "other", "than", "foot", "touch", "ground", "otherwise", "vector", "define", "velocity", "minimization", "do", "follow", "term", "-lrb-", "-rrb-", "velocity", "center", "mass", "project", "ground", "plane", "-lrb-", "-rrb-", "concatenation", "velocity", "all", "body", "-lrb-", "-rrb-", "com", "displacement", "com", "compute", "relative", "com", "target", "balancing", "pose", "character-centric", "coordinate", "system", "define", "global", "up", "vector", "character", "face", "direction", "vector", "project", "ground", "plane", "origin", "midway", "-lrb-", "-rrb-", "tween", "foot", "similarly", "up", "vector", "difference", "up", "compute", "character", "centric", "coordinate", "up", "root", "balanced", "where", "root", "up-vector", "root", "bone", "balanced", "corresponding", "vector", "target", "balancing", "pose", "finally", "denote", "difference", "between", "local", "joint", "angle", "simulated", "target", "pose", "use", "angle", "see", "ODE", "motor", "value", "we", "use", "scale", "multiplier", "vel1", "0.05", "m/s", "vel2", "0.75", "m/s", "disp", "0.05", "up", "0.1", "pose", "15.0", "degree", "balance", "objective", "compute", "each", "frame", "between", "specify", "minimum", "time", "length", "planning", "horizon", "best", "score", "frame", "use", "evaluate", "whole", "sample", "we", "use", "0.5", "minimum", "many", "MPC", "system", "objective", "function", "partition", "run", "cost", "terminal", "cost", "terminal", "cost", "only", "evaluate", "fix", "planning", "horizon", "contrast", "we", "system", "allow", "optimizer", "some", "slack", "term", "when", "reach", "goal", "which", "should", "make", "objective", "function", "mode", "larger", "thus", "easier", "find", "track", "get-up", "get", "up", "objective", "same", "balance", "objective", "omit", "pose", "term", "have", "less", "strict", "velocity", "multiplier", "vel1", "1.0", "m/s", "vel2", "15.0", "m/s", "where", "jth", "frame", "where", "term", "compute", "similar", "COM", "displacement", "term", "also", "include", "y-component", "clamp", "min", "-lrb-", "-lrb-", "target", "-rrb-", "-rrb-", "where", "0.1", "denote", "offset", "COM", "higher", "than", "target", "balancing", "pose", "penalize", "motion", "where", "COM", "temporarily", "above", "balancing", "pose", "e.g.", "when", "take", "step", "leap", "main", "difference", "previous", "work", "objective", "function", "formulation", "multimodal", "due", "max", "function", "practice", "we", "have", "find", "when", "character", "have", "fall", "down", "sampler", "have", "difficulty", "maximize", "all", "component", "balance", "objective", "however", "maximize", "much", "easier", "very", "often", "lead", "situation", "where", "consequence", "easier", "maximize", "effect", "similar", "how", "Jain", "et", "al.", "-lsb-", "2009", "-rsb-", "define", "balancing", "sequence", "state", "include", "balancing", "take", "step", "component", "also", "allow", "character", "take", "step", "regain", "balance", "dodge", "projectile", "do", "penalize", "deviation", "from", "target", "pose", "Roll", "heavier", "model", "middle", "Figure", "even", "get", "up", "strategy", "sometimes", "difficult", "find", "when", "character", "have", "fall", "its", "back", "case", "we", "add", "third", "alternative", "objective", "inside", "max", "function", "equation", "make", "character", "roll", "away", "from", "its", "back", "heuristic", "each", "frame", "we", "generate", "20", "sample", "uniformly", "within", "parameter", "space", "we", "also", "add", "guess", "where", "each", "control", "point", "spline", "equal", "target", "balancing", "pose", "where", "joint", "torque", "limit", "constant", "finally", "we", "add", "best", "sample", "previous", "frame", "after", "step", "its", "parameter", "one", "time", "step", "forward", "i.e.", "shift", "spline", "backward", "time", "when", "evaluate", "last", "heuristic", "important", "ensure", "interpolate", "result", "from", "original", "shift", "spline", "match", "machine", "precision", "over", "entire", "horizon", "machine", "Learning", "we", "system", "support", "optional", "generation", "guess", "-lrb-", "line", "11-15", "algorithm", "-rrb-", "from", "arbitrary", "machine", "learn", "component", "idea", "draw", "previous", "experience", "infer", "good", "strategy", "current", "situation", "feature", "vector", "consist", "current", "pose", "angle", "up", "direction", "root", "node", "rotation", "velocity", "root", "node", "optionally", "relative", "position", "velocity", "closest", "projectile", "dodge", "training", "set", "normalize", "respect", "norm", "feature", "variable", "we", "train", "mapping", "during", "online", "optimization", "-lrb-", "ball", "evade", "test", "explain", "section", "-rrb-", "store", "feature", "vector", "best", "sample", "all", "frame", "where", "-lrb-", "-rrb-", "10", "10", "while", "simple", "ANN", "search", "probably", "optimal", "machine", "learning", "method", "we", "case", "section", "5.2", "show", "few", "approximate", "nearest", "neighbor", "improve", "get-up", "performance", "considerably", "we", "have", "test", "we", "method", "three", "way", "-rrb-", "throw", "sphere", "character", "-rrb-", "add", "sudden", "impulse", "body", "part", "disturb", "balance", "throw", "character", "around", "-rrb-", "trigger", "simulated", "explosion", "add", "impulse", "all", "body", "part", "figure", "10", "11", "14", "illustrate", "test", "test", "character", "able", "avoid", "sphere", "avoidance", "behavior", "implicitly", "cause", "jerk", "minimization", "goal", "recover", "lose", "balance", "creative", "way", "roll", "over", "shoulder", "land", "back", "its", "foot", "get", "up", "when", "throw", "ground", "we", "describe", "result", "both", "qualitatively", "-lrb-", "section", "5.1", "-rrb-", "quantitatively", "-lrb-", "section", "5.2", "-rrb-", "follow", "we", "refer", "supplemental", "video", "use", "time", "parenthesis", "-lrb-", "mm", "ss", "-rrb-", "Performance", "supplemental", "video", "capture", "real-time", "-lrb-", "use", "Fraps", "www.fraps.com", "-rrb-", "Windows", "pc", "Intel", "Core", "i7-4930k", "3.40", "GHz", "CPU", "-lrb-", "12", "logical", "core", "-rrb-", "NVIDIA", "GeForce", "GTX", "480", "GPU", "computer", "optimizer", "run", "approximately", "20", "fp", "1/30s", "physics", "time", "step", "25", "sample", "per", "frame", "planning", "horizon", "seconds", "2012", "MacBook", "pro", "laptop", "2.4", "GHz", "processor", "same", "setting", "yield", "6-10", "fp", "enough", "interactive", "experiment", "parameter", "tuning", "which", "we", "consider", "one", "best", "aspect", "system", "show", "video", "25", "sample", "enough", "synthesize", "variety", "movement", "whereas", "use", "100", "sample", "-lrb-", "01:39", "-rrb-", "slow", "simulation", "down", "considerably", "other", "hand", "use", "fewer", "sample", "per", "frame", "shorter", "planning", "horizon", "yield", "fully", "real-time", "unreliable", "result", "-lrb-", "01:21", "-rrb-", "system", "show", "considerable", "creativity", "adapt", "surprising", "situation", "utilize", "environment", "example", "character", "dodge", "sphere", "use", "pirouette", "jump", "-lrb-", "02:22", "-rrb-", "slide", "dodge", "rolling", "sphere", "use", "hand", "keep", "sphere", "away", "-lrb-", "00:32", "-rrb-", "when", "character?s", "head", "punch", "ground", "continue", "movement", "cartwheel", "sort", "rise", "up", "-lrb-", "00:49", "-rrb-", "character", "also", "often", "land", "its", "foot", "when", "throw", "air", "-lrb-", "00:00", "00:38", "-rrb-", "top", "left", "corner", "video", "show", "which", "alternative", "objective", "function", "component", "give", "highest", "score", "best", "score", "sample", "balance", "correspond", "get", "up", "use", "2", "plan", "horizon", "sampler", "often", "able", "find", "balancing", "strategy", "while", "still", "roll", "ground", "after", "impact", "-lrb-", "01:02", "01:12", "-rrb-", "main", "drawback", "system", "movement", "sometimes", "stiff", "have", "unnecessary", "joint", "contortion", "-lrb-", "02:18", "-rrb-", "stiffness", "probably", "cause", "we", "parameterization", "use", "target", "angle", "instead", "joint", "torque", "character", "also", "often", "keep", "hand", "greedily", "close", "target", "pose", "even", "when", "nearly", "balanced", "we", "experiment", "shoulder", "elbow", "torque", "minimization", "goal", "easily", "lead", "other", "extreme", "hand", "hang", "limp", "which", "do", "look", "natural", "we", "fighter", "character", "sometimes", "appear", "almost", "unphysical", "character", "uncannily", "know", "although", "sway", "ultimately", "end", "up", "balanced", "without", "heuristic", "machine", "learning", "guess", "however", "character", "keep", "hower", "about", "target", "pose", "illustrate", "typically", "slow", "final", "convergence", "global", "sampling", "method", "we", "have", "also", "test", "two", "other", "balance", "pose", "asymmetric", "Taido", "-lrb-", "martial", "art", "-rrb-", "ready", "stance", "regular", "standing", "position", "both", "pose", "work", "although", "regular", "standing", "appear", "more", "difficult", "less", "stable", "support", "polygon", "smaller", "COM", "higher", "system", "stochastic", "hence", "may", "occasionally", "provide", "good", "result", "even", "just", "few", "sample", "ensure", "we", "result", "representative", "we", "have", "run", "quantitative", "balancing", "avoidance", "test", "vary", "parameter", "each", "test", "100", "sphere", "throw", "character", "from", "random", "direction", "sphere", "3x", "heavier", "than", "character", "i.e.", "failure", "avoid", "ball", "almost", "certainly", "lead", "character", "fall", "down", "we", "measure", "percentage", "time", "character", "balanced", "seconds", "after", "ball", "throw", "determine", "threshold", "objective", "function", "value", "succeed", "character", "could", "either", "dodge", "ball", "get", "successfully", "up", "after", "fail", "dodge", "test", "also", "save", "screenshot", "each", "failure", "case", "most", "typical", "case", "wide", "split", "lie", "back", "supplementary", "video", "show", "difficult", "situation", "-lrb-", "01:33", "01:48", "-rrb-", "left", "side", "Figure", "12", "show", "success", "percentage", "function", "optimizer", "sample", "per", "frame", "four", "condition", "st", "denote", "standard", "setup", "use", "capture", "supplemental", "video", "-lrb-", "2s", "planning", "horizon", "lightweight", "character", "model", "-rrb-", "st+ml", "FLANN", "prediction", "be", "generate", "each", "frame", "from", "dataset", "100k", "training", "vector", "which", "yield", "better", "result", "low", "sample", "budget", "indicate", "we", "system", "can", "utilize", "machine", "learning", "intend", "hv", "curve", "denote", "heavier", "character", "model", "change", "compare", "st", "which", "yield", "abysmal", "success", "rate", "low", "sample", "budget", "Performance", "better", "hv2", "case", "where", "we", "activate", "roll", "away", "from", "back", "goal", "use", "3.5", "plan", "horizon", "measure", "success", "after", "longer", "seconds", "after", "each", "ball", "throw", "right", "side", "Figure", "12", "show", "successful", "attempt", "function", "greedy", "sampling", "parameter", "appear", "sweet", "spot", "25-50", "greedy", "sample", "all", "we", "test", "supplemental", "video", "capture", "use", "25", "Figure", "13", "show", "successful", "attempt", "function", "number", "sample", "length", "planning", "horizon", "one", "can", "see", "2", "horizon", "use", "supplementary", "video", "reasonable", "default", "longer", "horizon", "do", "produce", "considerable", "benefit", "we", "have", "demonstrate", "Sequential", "Monte", "Carlo", "-lrb-", "SMC", "-rrb-", "sampling", "viable", "approach", "online", "synthesis", "complex", "human", "movement", "without", "reliance", "animation", "motion", "capture", "datum", "central", "feature", "system", "use", "kd-tree", "sampling", "non-uniform", "spline", "pose", "interpolation", "rigid", "body", "physics", "engine", "custom", "modification", "ensure", "reproducible", "simulation", "while", "key", "component", "adaptive", "sequential", "sampling", "method", "allow", "easy", "integration", "machine", "learn", "draw", "previous", "experience", "we", "surprise", "performance", "sampler", "even", "without", "machine", "learning", "use", "dimensionality", "reduction", "method", "constrain", "search", "space", "we", "have", "integrate", "we", "system", "unity3d", "state-of-the-art", "commercial", "game", "engine", "result", "release", "open", "source", "however", "we", "believe", "we", "sampler", "simple", "enough", "also", "implement", "from", "scratch", "we", "expect", "both", "can", "address", "precompute", "suitable", "prior", "sampling", "and/or", "develop", "interactive", "training", "application", "where", "user", "may", "instruct", "machine", "learning", "system", "learn", "most", "interesting", "movement", "have", "emerge", "we", "parameterization", "also", "allow", "pose-space", "dimensionality", "reduction", "accord", "we", "initial", "experiment", "do", "make", "abnormal", "pose", "less", "frequent", "however", "heavy", "dimensionality", "reduction", "use", "small", "training", "set", "easily", "overconstrain", "movement", "while", "larger", "training", "set", "allow", "character", "use", "pose", "abnormal", "context", "e.g.", "kick", "while", "balancing", "Contextual", "temporal", "information", "could", "incorporate", "e.g.", "use", "offline", "optimization", "generate", "training", "set", "control", "spline", "follow", "motion", "capture", "trajectory", "similar", "-lsb-", "Muico", "et", "al.", "2009", "-rsb-", "we", "thank", "all", "reviewer", "valuable", "comment", "research", "have", "be", "support", "Skene", "Games", "Refueled", "program", "finnish", "Funding", "Agency", "Innovation", "we", "end", "up", "use", "ODE", "its", "direct", "lcp", "solver", "iterative", "solver", "ODE", "Bullet", "physics", "physx", "engine", "be", "stable", "enough", "active", "character", "except", "very", "small", "time", "step", "be", "computationally", "efficient", "3-dof", "hip", "shoulder", "joint", "be", "especially", "unstable", "although", "previous", "study", "have", "successfully", "use", "2-dof", "joint", "-lsb-", "Tassa", "et", "al.", "2012", "-rsb-", "3-dof", "joint", "need", "realistic", "character", "skin", "mesh", "appear", "current", "mainstream", "physics", "engine", "optimize", "passive", "object", "ragdoll", "although", "new", "version", "Bullet", "have", "just", "appear", "new", "solver", "gear", "towards", "robotic", "we", "have", "make", "two", "important", "change", "ODE", "firstly", "original", "implementation", "ODE", "causal", "due", "some", "internal", "implementation", "detail", "reordering", "array", "optimization", "purpose", "due", "way", "random", "number", "generate", "we", "have", "solve", "issue", "remove", "non-deterministic", "optimization", "store", "random", "number", "generator", "seed", "thread", "context", "level", "ensure", "run", "two", "simulation", "different", "thread", "same", "control", "parameter", "achieve", "exactly", "same", "motion", "simulation", "fully", "causal", "sampler", "sometimes", "forget", "choose", "control", "strategy", "before", "have", "be", "completely", "execute", "secondly", "ode", "implement", "joint", "motor", "limit", "way", "might", "cause", "too", "much", "force", "apply", "when", "motor", "move", "away", "from", "limit", "cause", "instability", "ODE", "have", "solve", "introduce", "hand-tuned", "fudge", "factor", "scale", "force", "get", "maximum", "available", "force", "fudge", "factor", "correct", "each", "body", "part", "delicate", "difficult", "solve", "we", "use", "fudgefree", "patch", "from", "official", "ODE", "issue", "tracker", "instead", "add", "motor", "limit", "constraint", "row", "LCP", "formulation", "make", "simulation", "more", "robust", "we", "threading", "use", "pool", "worker", "thread", "which", "each", "obtain", "sample", "from", "sampler", "simulate", "physics", "forward", "compute", "-lrb-", "-rrb-", "store", "computed", "value", "sampler", "access", "sampler", "synchronize", "which", "mean", "we", "implementation", "optimal", "massively", "parallel", "computing", "however", "we", "current", "computer", "up", "12", "logical", "core", "we", "have", "achieve", "decent", "75-80", "core", "utilization" ],
  "content" : "We present a Model-Predictive Control (MPC) system for online synthesis of interactive and physically valid character motion. Our system enables a complex (36-DOF) 3D human character model to balance in a given pose, dodge projectiles, and improvise a get up strategy if forced to lose balance, all in a dynamic and unpredictable environment. Such contact-rich, predictive and reactive motions have previously only been generated offline or using a handcrafted state machine or a dataset of reference motions, which our system does not require. Following the seminal work of, e.g., Witkin and Kass [1988] and Sims [1994], basic behaviors such as balancing and locomotion can now be generated in real-time, and offline systems exist for synthesizing more complex motions [Geijtenbeek et al. 2011; Al Borno et al. 2013; Erez et al. 2013]. The output of our system is a time-varying control strategy that drives the character towards the specified goals, while accounting for changes in the environment. Formally, treating each control strategy as a point in a high-dimensional space (to be made explicit below), we evolve a population of samples using Sequential Monte Carlo sampling so that the ensemble remains well-distributed even when the fitness landscape changes. Our formulation also allows straightforward parallelization: the objective function values for the samples can be computed in an arbitrary order. Our contributions are ? the introduction of SMC to online synthesis of physically valid character motion; ? a novel sequential sampling method that allows easy integration of machine learning. An example of the motion generated by our system is shown in Figure 1 . Figure 2 gives an overview of the main components of our system, including the multimodal sampler/optimizer that generates motion plans, a parallelized physics engine that is used to simulate the movement resulting from each motion plan, and an optional machine learning system that generates one or more predictions used for seeding the adaptive sampling in each frame. However, the synthesized motions have been limited by the need for prior knowledge of contact information, such as in what frames the character should touch the ground and with which body parts. This limitation was overcome by Mordatch et al. [2012], who introduced auxiliary optimized variables that specify the contact information, and who used L-BFGS for optimization. Motion Synthesis as a Control Problem Spacetime optimization can also be approached as a control problem. The dynamics simulations for evaluating each sampled control vector are costly but straightforward to parallelize. In light of the recent work by Mordatch et al. [2012] and Al Borno et al. [2013], both deterministic spacetime optimization and stochastic derivative-free control optimization appear equally suitable for offline synthesis of contact-rich, complex and acrobatic motions. Online Optimization and Control using Prior Data Considering online synthesis of physically valid motion at interactive frame rates, there are various approaches. Offline optimization has been used to learn the parameters of neural networks and other controller types that can be used in real-time physics simulation [Sims 1994; Reil and Husbands 2002; Geijtenbeek et al. 2013]. Our work falls into this category, and we draw inspiration from two main prior systems. Jain et al. [2009] have implemented balancing, stepping and other behaviors using a frame-by-frame QP optimizer augmented with a state machine that breaks movement down into subgoals that can be implemented with a planning horizon of a single frame. This raises concerns about robustness, e.g., to obstacles for foot placement, and decreases the probability of creative, emergent movements. Our system does not need motion data, and our optimizer automatically generates balancing and footsteps without predefined states thanks to a planning horizon of up to 4 seconds, which is enough for completing a rebalancing step, or even rolling on the ground and bouncing back up. Our approach is also inherently predictive ? characters can anticipate events without hand-coded prediction algorithms. We extend their approach in three key areas: we use a longer planning horizon (up to 4 seconds vs. their 0.5s), simultaneously track multiple modes of the fitness function (their iLQG method is unimodal), and use a more complex character model, including 3-DOF joints. As a result, our system adds the ability to plan movements with several phases ? e.g. getting up by planting a hand, pushing with the hand to allow moving a foot closer, and then shifting weight on the foot, as shown in Figure 14 . In later work, the problem of springing straight up was solved by designing a state machine that explicitly breaks down the task into a sequence of subtasks [Erez et al. 2013]. Sequential Monte Carlo Sampling SMC has been used widely in various tracking problems [Arulampalam et al. 2002; Doucet and Johansen 2009]. Body tracking using computer vision is especially close to our work, as many tracking systems feature both particle filters (a form of SMC) and articulated human body models [Deutscher et al. 2000; Schmidt et al. 2006]. Although our sampler bears similarities, e.g., to the particle filter variants discussed by Arulampalam et al. [2002], it is more precisely a sequential version of the mutated kD-tree importance sampling of H?m?l?inen et al. [2006], which in turn is based on the hierarchical subdivision sampling of Kajiya [1986]. An illustration of the basic principles of SMC. In the sampling step, new samples are drawn from proposal densities based on the previous samples. During the resampling step, the samples at the peaks of f(x) produce more ?offspring?, while others may die out. We formulate this as finding the global maximum of a real-valued non-negative objective function (fitness function) f (x; t), where the vector x ? R k defines a control strategy represented as timevarying target joint angles and other parameters, explained in detail in Section 4.2 1 . Time t is a parameter rather than a domain variable, and it accounts for a dynamic environment. As the search space consists of an approximation to all the possible ways to drive the actuators over a couple of seconds, it is easy to appreciate that the objective function is multimodal, and that the modes shift, appear and vanish with time. The core idea of SMC methods is that a sequence of target probability densities is approximated using an evolving set of weighted samples, as illustrated in Figure 3 . The sample set can then be used for estimating the modes of the density function. A thorough mathematical treatment can be found, e.g., in [Arulampalam et al. 2002; Doucet and Johansen 2009]. Our sampler avoids this requirement, allowing the insertion of additional arbitrarily obtained candidate samples, e.g., initial guesses from the machine learning component in Figure 2 . This provides a unified way of weighting random samples with known proposal densities and initial guesses with no proposal density. Additionally, the kD-tree provides means for adapting the search variance so that samples at low fitness regions are perturbed more. Algorithm Overview We maintain a population {x i , f (x i ; t)} of N samples and their associated fitnesses that evolve over time. For each frame, the algorithm performs the following steps:\n          1. Prune the sample set. Keep only the best M . Draw a set of K new samples by optional heuristics and machine learning predictions that may depend on the current state. Construct a sampling prior q(x) based on the M + K samples by inserting the samples in a kD-tree and constructing an adaptive PDF. Until the budget of N samples is reached, draw new samples from q(x). Use each new sample to adaptively update the prior q(x). Pick the best sample and use it for driving the simulation forward for the current time step. The construction of the sampling prior q(x) and its adaptive refinement are described in Section 3.3. Details on the outer loop are presented in Section 3.4. The heuristics and machine learning component are detailed in Section 4.5. To provide visualizations and intuition on our sampler applied to motion optimization, we present a 2D problem with nonlinearities and multimodality arising from physical contacts. The optimized parameters are x = [s, ?] T , where s is the throwing speed, ? is the throwing angle, and the aim is to get the ball as close to a specified target g as possible. Figure 4A illustrates the physical setup and shows two trajectories resulting from different x. The target g is shown as a black circle. We illustrate two different objective functions: the first, illustrated in Figure 4B , computes the closest point c(x) of the trajectory and the target without regard for timing, i.e., f (x) = exp {? c(x) ? g 2 }. This produces a landscape with ridges, each\n          2 This iteration of sampling from a model and updating the model based on the samples is also central to some other optimization methods, such as the Covariance Matrix Adaptation Evolution Strategy (CMA-ES), which has been gaining popularity in the motion synthesis literature. However, whereas CMA-ES updates a unimodal model (a single Gaussian), our model is multimodal. Algorithm 1 Adaptive Importance Sampling using a kD-tree. 1: Draw x 0 uniformly in parameter space, evaluate f (x 0 ) 2: root ? {x 0 , f (x 0 )} 3: repeat 4: Randomly select leaf node i with probability ? w i 5: Draw a sample x new ? N (x i , C i ) 6: Evaluate f (x new ) 7: {n 1 , n 2 } ? I NSERT T REE ( x new ) n 1 , n 2 are new leaves 8: w n 1 ? V n 1 f (x new ) n 1 is where x new ends up 9: w n 2 ? V n 2 f (x n 2 ) n 2 contains previous sample 10: until #samples = N\n          ridge corresponding to, e.g., different number of bounces. The two example trajectories are marked by the red and green circles. The second goal, illustrated in Figure 4C , aims to hit the target at a specified point in time. The corresponding objective function simply evaluates the distance to the target at this time in the trajectory. Now, some of the ridges become peaks, but the landscape is still multimodal, as the ball can still reach the target using a variety of different bounce sequences. Figure 4D illustrates the adaptive kD-tree that defines the sampling prior q(x), whose construction is detailed in the next section. We first describe an adaptive importance sampler for a timeinvariant, multimodal, unnormalized objective function f (x). The method was proposed in [H?m?l?inen et al. 2006], but we repeat it for completeness, and then extend it for the sequential, timevarying case. The process is outlined in Algorithm 1 and illustrated in Figure 5 and Figure 6 . The process draws samples approximately following f (x), allocating more samples at regions where f (x) is high, with the approximation of f (x) gradually improving with each sample. The tree adaptively subdivides the parameter space into hypercubes. The weight gives a single-sample estimate of the integral of f (x) over the leaf hypercube. One can interpret the tree as a piecewise constant approximation of f (x), from which one may draw samples by first randomly selecting a hypercube with the selection probabilities ? w i , and then generating a sample uniformly inside the hypercube. The solution is to treat the kD-tree as a mixture of Gaussians, illustrated in Figure 6 . For the selected hypercube i, the sample is drawn from N (x i ; C i ). The Gaussian tails overlap the neighboring hypercubes, which makes it more likely for the sampling to cross valleys and recover from the biases. Until a sampling budget is met, we draw a new sample from the mixture, add the sample to the tree, split the leaf node where the new sample lands between the new and old samples, and recompute the weights for the two new leaves (Equation 1). The mixture components are shown as the black curves in step A. The Gaussians are centered at the samples, with standard deviations proportional to the hypercube widths in each dimension. This blurs the distribution model adaptively, with less blurring where samples are densely concentrated, and increases the chance of samples crossing valleys, illustrated in step B. In our application, the fitness landscape varies from frame to frame as the environment changes. The phenomenon is illustrated in Figure 8, where changing the throw target changes the objective. Building a sampling distribution out of the samples taken during the previous frame allows us to exploit temporal coherence. At frame t j , the set of samples from the previous frame t j?1 is first pruned to M < N samples by retaining the M samples whose leaf nodes have the largest weights (lines 2-5). A large M means that old samples get selected and re-evaluated often, which may affect convergence in rapidly changing situations, whereas a low value makes tracking multiple modes difficult as little information is retained between frames. We use M = 0.1N in all our results. After pruning, the tree is rebuilt by inserting the remaining M samples in random order (lines 6-10). However, the randomization averages the biases out temporally. Figure 7 shows a function with samples, three different kD-tree models built from the same set of samples, and an average of 100 trees. We have also experimented with building an ensemble of trees for each time step to further reduce the variance of the volume estimates for each sample, but we do not so far have conclusive evidence of the benefits. After rebuilding we introduce new samples drawn from a set of heuristics (lines 11-15, see Section 4.5). After this, the sampling prior is complete: the tree contains the M best samples from the Algorithm 2 kD-Tree Sequential Importance Sampling 1: for each time step t j do // Prune tree to M samples 2: while #samples > M do 3: find leaf i with minimum w i 4: R EMOVE T REE (x i ) 5: end while // Randomly shuffle and rebuild tree using old fitnesses 6: C LEAR T REE () 7: {x 1 , . . . , x M } ? R ANDOM P ERMUTE ({x 1 , . . . , x M }) 8: for i = 1 . M do 9: I NSERT T REE (x i ) 10: end for // Draw guesses from heuristics and ML predictors 11: for i = 1 . K do 12: x g ? D RAW G UESS () 13: evaluate f (x g ; t j ) 14: I NSERT T REE (x g ) 15: end for 16: {w 1 , . . . , w M +K } ? U PDATE L EAF W EIGHTS () // Then, perform adaptive sampling 17: repeat 18: Randomly select leaf node i with probability ? w i 19: if node contains old fitness f (x i ; t j?1 ) then 20: compute current fitness f (x i ; t j ) 21: w i ? V i f (x i ; t j ) update weight 22: else // Sample as in Algorithm 1 23: draw a sample x new ? N (x i , C i ) 24: Evaluate f (x new ; t j ) 25: {n 1 , n 2 } ? I NSERT T REE ( x new ) 26: w n 1 ? V n 1 f (x new ; t j ) 27: w n 2 ? V n 2 f (x n 2 ; t j ) f (x n 2 ; t j ) known 28: end if 29: until #samples = N 30: end for\n          previous frame, along with new samples generated by heuristics. The remainder of the algorithm performs adaptive sampling much like Algorithm 1 (lines 17-29). The only difference is that when a leaf that contains a stale fitness value from the previous frame is selected, it is recomputed and the weight updated, but a new sample is not generated (lines 20-21). When a node with an up-to-date fitness is selected for refinement, sampling proceeds as in Algorithm 1 (lines 23-27). When the budget of N samples is reached, the current sample set is approximately distributed according to the new fitness f (x; t j ). Figure 8 shows how Algorithm 2 tracks the objective function modes in the 2D example when the ball throw target is moving. After nearly exhausting our sample budget, we further opportunistically explore the region around the current best sample x b . We modify Algorithm 2 so that for the last N g samples of a time step, the selection (line 18) always chooses the leaf with the best sample so far, and a lower scaling factor ? g is used for computing C i . Adjusting N g and ? g allows one to tune the balance between local and global search. We use ? g = 0.005. Section 5 presents the results from our character motion synthesis with different values of N g . Figure 9 shows our character and physics models. In our tests, we use two physics models: one light-boned, and another with a considerably heavier torso and thus a higher center of mass (COM), which makes balancing and acrobatics more difficult. The physics objects have constant densities. The character has 30 actuated DOF and 6 unactuated root DOF. The physics model consists of 15 bones (rigid bodies) connected using 3-DOF ball and 1-DOF hinge joints, the latter used for elbows, knees and ankles. We do not model clavicles, toes, and fingers. For simulation, we use Open Dynamics Engine (ODE) 0.12, using ODE?s direct ?big matrix? LCP solver, a time step of ?t = 1/30 seconds, and CFM and ERP parameters as 10 ?5 and 0.2, respectively. Note that ODE also has an iterative solver, which is faster but less stable. For approximately similar quality, the iterative solver requires a timestep of 1/120s, which results in slower operation. In our case, the direct solver only takes approximately as much CPU time as collision handling. We represent control strategies as time-varying target joint angles that are encoded as a sequence of control points of an interpolating cubic spline. We use n = 4 control points in all our experiments. Our spline is non-uniform, i.e., the positions of the control points along the temporal axis (the knots) are subject to optimization. Specifically, where the q i denote the 30 target joint angles at time t i . The l i are limits on the maximum allowable torques for the actuated joints; allowing them to vary instead of using fixed maximums allows the character, e.g., to soften landings from high jumps. We use the sampling bounds 50N m < l i < 150N m for the lightweight model and 50N m < l i < 200N m for the heavier one. The torque limits are specified for three groups of bones: torso, arms and legs. The non-uniform knot sequence allows fine-grained control of fast movements such as jumps. The total number of optimized variables is 136 (i.e. x ? R 136 ), consisting of 30 target angles, 3 torque limits, and 1 time coordinate for each of the 4 control points. The spline defined by x gives continuous-time target joint angles q(t; x) and limits on maximum torque l(t; x). To evaluate the objective function, we feed these targets into the physics simulation and record what happens. The total duration of the simulation for each sample varies depending on the control points. However, we only run the simulation up to a predefined planning horizon. Section 5 presents results with different planning horizons. The default used in the supplementary video is 2 seconds. For each time step t j , we evaluate the target angles q(t j ; x) and torque limits l(t j ; x) and feed them to the ODE physics simulator. ODE motors are controlled by a target velocities that ODE tries to make the motors reach. We compute the target velocity for the ith motor from the target pose as (q i target ? q i current )/?t with q i denoting joint angles as seen by the motor. The simulator is then stepped forward by the time step; internally, it drives the motors to try to match the target velocities, while respecting the torque limits. The simulation produces a time series of realized 3D positions b and velocities b  ? for all the 15 rigid bodies in the skeleton, representing what happened when we tried controlling the character using the strategy x. We denote the series by S(x) = {b(t j ; x), b(t  ? j ; x)} N j=?1 s (x) , where N s (x) is the number of simulated time steps for the sample and j = 1 denotes the current time step. We also use the shorthand notation b (j) = b(t j ; x). The time index j of S(x) starts from -1, as we also include a history of past two frames in the evaluation, which allows the objective function evaluation to prefer continuity with previously selected control strategies. This reduces movement jitter, which could otherwise be a problem in a stochastic sampling system like ours. Note that as the LCP solver will adapt the torque based on, e.g., contact forces, our scheme provides a slightly higher level of control than using PD controllers. The human motor system comprises both motion-inducing and stabilizer muscles, and stabilizing the character in a given pose is easier with the motors than with PD controllers, especially with the large ?t we use. Appendix A describes important implementation details related to obtaining a causal, reproducible simulation. The objective function drives the character towards the desired goals. The corresponding objective function is formulated as where f d , f s , f b , f u denote damage avoidance, smoothness, balancing, and get up objectives, respectively, and w u adjusts the priority of the get up objective. We use w u = 0.0001. All components of the objective function are functions of S, but in the following, we omit the dependence for brevity. Damage avoidance The damage avoidance objective tries to avoid high-velocity impacts to important body parts. We include head and pelvis in the objective to allow versatile movement but prevent the character from falling on its head or bottom. if if\n          where n c is the number of all important body contacts during the realized plan and v i and n i are the relative velocity and contact  normal of the ith contact, respectively. We use t d = 2.2 and c = 2.5. Smoothness The smoothness objective consist of minimizing acceleration and jerk (the time-derivative of acceleration), which has been found to help in producing natural movement [Van Welbergen et al. 2010]. The objective is given by where ? a and ? J are the mean squared acceleration and jerk, respectively, computed as: b  ? (j) = b  ? (j) ? b  ? (j+1) , ... b (j) = b  ? (j?1) ? 2 b  ? (j) + b  ? (j+1) . ?t (?t) 2 We use values ? a = 5.0 and ? j = 13.7. The jerk term ? J is affected by the history of the last two frames (j = ?1, j = 0) to avoid acceleration jitter from frame to frame. Balancing The balancing objective is the most complex one, comprising a desired target pose, desired up-vector direction, velocity minimization, COM displacement minimization and penalization based on other body parts than feet touching the ground. We define it as where j denotes the jth frame. Here, f g is the penalizing term that gets the value 0 if any body part other than the feet is touching the ground, and 1 otherwise. The vector r b is defined as Velocity minimization is done by the following terms: c (j) is the velocity of the center of mass, projected to the ground plane. b  ? (j) is the concatenation of the velocities of all bodies. (j) The COM displacement d com is computed relative to the COM of the target balancing pose in a character-centric coordinate system defined by the global up vector, and the character facing direction vector projected to the ground plane, with the origin at midway be(j) tween the feet. Similarly, the up vector difference d up is computed in the character centric coordinates as d up = u root ? u balanced , where u root is the up-vector of the root bone, and u balanced is the corresponding vector of the target balancing pose. Finally, q d denotes the differences between the local joint angles of the simulated and target poses, using angles as seen by ODE motors. The values we use for the scaling multipliers are ? vel1 = 0.05m/s, ? vel2 = 0.75m/s, ? disp = 0.05m, ? up = 0.1m and ? pose = 15.0 degrees. The balancing objective is computed for each frame between a specified minimum time and the length of the planning horizon, and the best scoring frame is used for evaluating the whole sample. We use 0.5s as the minimum. In many MPC systems, the objective function is partitioned into a running cost and a terminal cost, and the terminal cost is only evaluated at a fixed planning horizon. In contrast, our system allows the optimizer some slack in terms of when to reach the goals, which should make the objective function modes larger and thus easier to find and track. Get-Up The get up objective is the same as the balancing objective, but omitting the pose term and having less strict velocity multipliers ? vel1 = 1.0m/s and ? vel2 = 15.0m/s. where j is the jth frame and where terms are computed similar to f b , but the COM displacement term also includes the y-component clamped to y = min(0, y ? (y target + h)), where h = 0.1m denotes an offset of the COM that is higher than in the target balancing pose. This is to not penalize motion where the COM is temporarily above the balancing pose, e.g., when taking steps or leaping. The main difference to previous work is that the objective function formulation is multimodal due to the max function. In practice, we have found that when the character has fallen down, the sampler has difficulties maximizing all the components of the balancing objective f b . However, maximizing f u is much easier, and very often leads to a situation where, as a consequence, f b is easier to maximize. In effect, this is similar to how Jain et al. [2009] define balancing as a sequence of states including balancing and taking a step. The f u component also allows the character to take steps to regain balance or dodge projectiles, as it does not penalize deviations from the target pose. Roll With the heavier model in the middle of Figure 9 , even a get up strategy is sometimes difficult to find when the character has fallen on its back. In these cases, we add a third alternative objective f r inside the max function in Equation 3 that makes the character roll away from its back Heuristics At each frame, we generate 20% of the samples uniformly within the parameter space. We also add a guess where each control point of the spline equals the target balancing pose and where joint torque limits are constant. Finally, we add the best sample x b of the previous frame after stepping its parameters one time step forward, i.e., shifting the spline backward in time by ?t. When evaluating the last heuristic, it is important to ensure that the interpolated results from the original x b and the shifted spline match to machine precision over the entire horizon. Machine Learning Our system supports the optional generation of guesses (lines 11-15 in Algorithm 2) from an arbitrary machine learning component, with the idea of drawing on previous experience to infer good strategies for the current situation. The feature vectors consist of current pose angles, the ?up? direction of the root node, the rotation and velocity of the root node, and optionally, the relative position and velocity of the closest projectile to dodge. The training set is normalized with respect to L 2 norms of the feature variables. We train the mapping during online optimization (the ball evading test explained in Section 5), storing the feature vector and best sample x for all frames where f (x) > 10 ?10 . While the simple ANN search is probably not the optimal machine learning method for our case, Section 5.2 shows that as few as 3 approximate nearest neighbors improve get-up performance considerably. We have tested our method in three ways: 1) throwing spheres at the character, 2) adding sudden impulses to body parts to disturb balance and throw the character around, and 3) triggering simulated explosions that add impulses to all body parts. Figures 1, 10, 11, and 14 illustrate these tests. In the tests, the character is able to avoid the spheres ? the avoidance behavior implicitly caused by the jerk minimization goal ? recover lost balance in creative ways, such as rolling over the shoulders to land back on its feet, and get up when thrown to the ground. We describe the results both qualitatively (Section 5.1) and quantitatively (Section 5.2). In the following, we refer to the supplemental video using the time in parenthesis (mm:ss). Performance The supplemental video was captured in real-time (using Fraps, www.fraps.com) on a Windows 7 PC with Intel Core i7-4930k 3.40GHz CPU (12 logical cores), and an NVIDIA GeForce GTX 480 GPU. On this computer, the optimizer runs at approximately 20 fps with a 1/30s physics time step, N = 25 samples per frame, and a planning horizon of 2 seconds. On a 2012 MacBook Pro laptop with a 2.4GHz processor, the same settings yield 6-10 fps, enough for interactive experimenting and parameter tuning, which we consider one of the best aspects of the system. As shown in the video, 25 samples is enough to synthesize a variety of movements, whereas using 100 samples (01:39) slows the simulation down considerably. On the other hand, using fewer samples per frame or a shorter planning horizon yields fully real-time but unreliable results (01:21). The system shows considerable creativity in adapting to surprising situations and utilizing the environment. For example, the character dodges the spheres using pirouette jumps (02:22) and slides to dodge a rolling sphere, using a hand to keep the sphere away (00:32). When the character?s head is punched to the ground, it continues the movement as a cartwheel of sorts and rises up (00:49). The character also often lands on its feet when thrown in the air (00:00, 00:38). The top left corner of the video shows which of the alternative objective function components gives the highest score for the best scoring sample. ?Balancing? corresponds to f b and ?Getting up? to w u f u . Using the 2s planning horizon, the sampler is often able to find a balancing strategy while still rolling on the ground after an impact (01:02, 01:12). The main drawbacks of the system are that movement is sometimes stiff and has unnecessary joint contortions (02:18). The stiffness is probably caused by our parameterization using target angles instead of joint torques. The character also often keeps the hands greedily close to the target pose even when not nearly balanced. We experimented with shoulder and elbow torque minimization goals, but this easily leads to the other extreme of the hands hanging limp, which does not look natural for our fighter character. Sometimes this appears almost unphysical, as the character uncannily knows that although it is swaying, it will ultimately end up balanced. Without the heuristic or machine learning guesses, however, the character keeps howering about the target pose, illustrating a typically slow final convergence of global sampling methods. We have also tested two other balancing poses an asymmetric Taido (a martial art) ready stance and a regular standing position. Both poses work, although the regular standing appears more difficult it is less stable as the support polygon is smaller and COM is higher. The system is stochastic, and hence may occasionally provide good results even with just a few samples. To ensure that our results are representative, we have run a quantitative balancing and avoidance test with varying parameters. In each test, 100 spheres are thrown at the character from random directions. The spheres are 3x heavier than the character, i.e., failure to avoid the ball almost certainly leads to the character falling down. We measured the percentage of times the character was balanced 5 seconds after the ball was thrown, determined by thresholding the objective function value. To succeed, the character could either dodge the ball, or get successfully up after a failed dodge. The test also saves a screenshot of each failure case. The most typical cases are wide splits and lying on the back. The supplementary video shows that these are difficult situations (01:33, 01:48). The left side of Figure 12 shows the success percentage as a function of optimizer samples per frame in four conditions. ST denotes the ?standard? setup used in capturing the supplemental video (2s planning horizon, lightweight character model). In ST+ML, 3 FLANN predictions were generated in each frame from a dataset of 100k training vectors, which yielded better results at low sample budgets. This indicates that our system can utilize machine learning as intended. The HV curve denotes the heavier character model with no changes compared to ST, which yields abysmal success rates at low sample budgets. Performance is better in the HV2 case, where we activated the ?roll away from back? goal, used a 3.5s planning horizon, and measured success after a longer period of 8 seconds after each ball throw. The right side of Figure 12 shows the successful attempts as a function of the greedy sampling parameter N g . There appears to be a sweet spot of 25-50% greedy samples. All our tests and the supplemental video capturing use N g = 25%. Figure 13 shows the successful attempts as a function of the number of samples and the length of the planning horizon. One can see that the 2s horizon used in the supplementary video is a reasonable default, and longer horizons do not produce considerable benefit. We have demonstrated that Sequential Monte Carlo (SMC) sampling is a viable approach for online synthesis of complex human movements without reliance on animation or motion capture data. The central features of the system are the use of kD-trees for sampling, non-uniform splines for pose interpolation, and a rigid body physics engine with custom modifications to ensure reproducible simulations. While the key component, an adaptive sequential sampling method, allows easy integration of machine learning to draw on previous experience, we are surprised by the performance of the sampler even without machine learning or using dimensionality reduction methods to constrain the search space. We have integrated our system with Unity3D, a state-of-the-art commercial game engine. The results will be released as open source. However, we believe our sampler is simple enough to also implement from scratch. We expect that both can be addressed by precomputing a suitable prior for the sampling, and/or developing an interactive training application where the user may instruct a machine learning system to learn the most interesting movements that have emerged. Our parameterization also allows for pose-space dimensionality reduction, and according to our initial experiments, it does make abnormal poses less frequent. However, heavy dimensionality reduction using a small training set easily overconstrains the movement while a larger training set allows the character to use poses in abnormal contexts, e.g., kicking while balancing. Contextual and temporal information could be incorporated, e.g., by using offline optimization to generate a training set of control splines that follow motion capture trajectories, similar to [Muico et al. 2009]. We thank all the reviewers for their valuable comments. The research has been supported by the Skene Games Refueled program of the Finnish Funding Agency for Innovation. We ended up using ODE and its direct LCP solver, as the iterative solvers in ODE, Bullet Physics or PhysX engines were not stable enough for active characters except at very small time steps that were not computationally efficient. The 3-DOF hip and shoulder joints were especially unstable, and although previous studies have successfully used 2-DOF joints [Tassa et al. 2012], 3-DOF joints are needed for a realistic character with a skinned mesh. It appears that the current mainstream physics engines are optimized for passive objects and ragdolls, although a new version of Bullet has just appeared with new solvers geared towards robotics. We have made two important changes to ODE. Firstly, the original implementation of ODE is not causal due to some internal implementation details such as reordering of arrays for optimization purposes and due to the way random numbers are generated. We have solved these issues by removing the non-deterministic optimizations and by storing the random number generator seed on a threading context level. This ensures that running two simulations in different threads with the same control parameters achieve exactly the same motion. If the simulation is not fully causal, the sampler sometimes forgets a chosen control strategy before it has been completely executed. Secondly, ODE implements joint motor limits in a way that might cause too much force to be applied when the motor is moving away from the limit. This causes instability, and ODE has solved this by introducing a hand-tuned fudge factor that scales the force. Getting  the maximum available force and the fudge factor correct for each body part is delicate and difficult, and to solve this we used a fudgefree patch from the official ODE issue tracker that instead adds the motor limits as constraint rows in the LCP formulation. This makes the simulation more robust. Our threading uses a pool of worker threads, which each obtain a sample from the sampler, simulate the physics forward, compute f (S) and store the computed value to the sampler. Access to the sampler is synchronized, which means that our implementation is not optimal for massively parallel computing. However, with our current computers with up to 12 logical cores, we have achieved a decent 75-80% core utilization.",
  "resources" : [ ]
}