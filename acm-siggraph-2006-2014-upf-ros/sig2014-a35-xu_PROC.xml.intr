{
  "uri" : "sig2014-a35-xu_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2014/a35-xu_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Organizing Heterogeneous Scene Collections through Contextual Focal Points",
    "published" : "2014",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Kai Xu-null",
      "name" : "Kai Xu",
      "surname" : null
    }, {
      "uri" : "http://drinventor/Rui-Ma",
      "name" : "Rui",
      "surname" : "Ma"
    }, {
      "uri" : "http://drinventor/Hao Zhang-null",
      "name" : "Hao Zhang",
      "surname" : null
    }, {
      "uri" : "http://drinventor/Chenyang-Zhu",
      "name" : "Chenyang",
      "surname" : "Zhu"
    }, {
      "uri" : "http://drinventor/Ariel-Shamir",
      "name" : "Ariel",
      "surname" : "Shamir"
    }, {
      "uri" : "http://drinventor/Daniel-Cohen-Or",
      "name" : "Daniel",
      "surname" : "Cohen-Or"
    }, {
      "uri" : "http://drinventor/Hui Huang-null",
      "name" : "Hui Huang",
      "surname" : null
    } ]
  },
  "bagOfWords" : [ "recent", "work", "organize", "explore", "3d", "visual", "datum", "have", "mostly", "be", "devote", "object", "collection", "-lsb-", "Ovsjanikov", "et", "al.", "2011", "Jain", "et", "al.", "2012", "Kim", "et", "al.", "2012", "van", "Kaick", "et", "al.", "2013", "Huang", "et", "al.", "2013b", "-rsb-", "paper", "we", "interested", "analyze", "organize", "visual", "datum", "larger", "scope", "namely", "3d", "indoor", "scene", "even", "moderately", "complex", "indoor", "scene", "would", "contain", "ten", "hundred", "object", "compare", "individual", "object", "therein", "scene", "more", "complex", "looser", "structural", "spatial", "relation", "among", "its", "component", "more", "diverse", "mixture", "functional", "substructure", "latter", "point", "attest", "hybrid", "scene", "which", "contain", "element", "reminiscent", "different", "semantic", "category", "example", "middle", "scene", "Figure", "partly", "bedroom", "partly", "living", "room", "greater", "intra-class", "variability", "richer", "characteristic", "scene", "datum", "motivate", "we", "work", "go", "beyond", "provide", "only", "holistic", "singular", "view", "scene", "scene", "collection", "we", "introduce", "use", "focal", "point", "characterize", "compare", "organize", "collection", "complex", "datum", "apply", "concept", "algorithm", "develop", "3d", "indoor", "scene", "particular", "we", "interested", "organize", "scene", "heterogeneous", "collection", "i.e.", "scene", "belong", "multiple", "semantic", "category", "analyze", "complex", "heterogeneous", "datum", "difficult", "without", "reference", "certain", "point", "attention", "focus", "i.e.", "focal", "point", "example", "compare", "New", "York", "City", "Paris", "whole", "unlikely", "yield", "useful", "answer", "comparison", "lot", "more", "meaningful", "focus", "particular", "aspect", "city", "e.g.", "architectural", "style", "fashion", "trend", "one", "natural", "consequence", "focal", "point", "drive", "datum", "view", "scene", "comparison", "may", "yield", "different", "similarity", "distance", "depend", "focal", "point", "see", "Figure", "illustration", "well", "accompany", "video", "we", "represent", "indoor", "scene", "graph", "its", "constituent", "object", "focal-driven", "scene", "clustering", "produce", "overlap", "cluster", "exploratory", "path", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "through", "overlap", "which", "often", "contain", "hybrid", "scene", "-lrb-", "-rrb-", "possess", "multiple", "focal", "can", "smoothly", "transition", "between", "scene", "cluster", "scene", "cluster", "often", "characterize", "meaningful", "scene", "category", "example", "transition", "from", "bedroom", "scene", "office", "focal", "point", "focal", "short", "substructure", "scene", "correspond", "subgraph", "however", "we", "interested", "all", "sub-scene", "key", "premise", "we", "work", "meaningful", "focal", "should", "determine", "contextually", "set", "-lrb-", "figure", "-rrb-", "through", "co-analysis", "illustrate", "probably", "too", "many", "notable", "aspect", "about", "Paris", "when", "put", "London", "Paris", "together", "one?s", "focus", "narrow", "down", "e.g.", "european", "capital", "we", "throw", "New", "York", "Milan", "mix", "most", "people", "first", "remind", "four", "city", "fashion", "capital", "world", "work", "we", "interested", "extract", "contextual", "focal", "point", "representative", "give", "scene", "collection", "focal", "representative", "must", "occur", "sufficiently", "frequently", "however", "frequency", "analysis", "alone", "insufficient", "example", "chair", "likely", "find", "almost", "all", "scene", "can", "hardly", "regard", "representative", "any", "meaningful", "scene", "group", "e.g.", "bedroom", "live", "room", "we", "stipulate", "representativity", "also", "tie", "notion", "coherence", "compactness", "group", "scene", "focal", "point", "represent", "characterize", "therefore", "frequency", "analysis", "focal", "extraction", "intermix", "clustering", "which", "compute", "compact", "group", "scene", "where", "scene", "each", "cluster", "closely", "connect", "when", "view", "from", "perspective", "representative", "focal", "cluster", "once", "again", "representative", "focal", "occur", "frequently", "cluster", "must", "also", "induce", "compact", "cluster", "solve", "two", "couple", "problem", "simultaneously", "we", "develop", "co-analysis", "algorithm", "which", "interleave", "frequent", "pattern", "mining", "-lsb-", "Han", "et", "al.", "2007", "-rsb-", "subspace", "clustering", "-lsb-", "Vidal", "2011", "-rsb-", "focal", "point", "play", "key", "role", "we", "organization", "heterogeneous", "scene", "collection", "first", "we", "define", "compactness", "cluster", "base", "focal-centric", "scene-to-scene", "similarity", "which", "build", "rooted", "walk", "graph", "kernel", "Fisher", "et", "al.", "-lsb-", "2011", "-rsb-", "assign", "higher", "weight", "walk", "which", "originate", "from", "representative", "focal", "cluster", "secondly", "scene", "organization", "give", "clustering", "scene", "base", "representative", "focal", "extract", "some", "scene", "may", "contain", "multiple", "focal", "thus", "belong", "multiple", "cluster", "scene", "typically", "hybrid", "nature", "provide", "linkage", "gateway", "between", "scene", "cluster", "allow", "exploration", "scene", "organization", "naturally", "transition", "between", "meaningful", "scene", "category", "illustrate", "Figure", "we", "main", "contribution", "focal-driven", "analysis", "organization", "heterogeneous", "datum", "collection", "while", "we", "only", "consider", "3d", "indoor", "scene", "paper", "we", "aware", "previous", "work", "coanalysis", "organization", "heterogeneous", "scene", "collection", "analysis", "general", "confine", "scene", "datum", "important", "characteristic", "we", "work", "which", "set", "apart", "from", "previous", "approach", "organize", "datum", "collection", "include", "datum", "compare", "holistically", "without", "discrimination", "we", "develop", "focal-centric", "scene", "descriptor", "scene", "com", "parison", "which", "support", "scene", "analysis", "perspective", "similarity", "distance", "between", "two", "scene", "may", "non-unique", "i.e.", "base", "focal", "designate", "comparison", "multiple", "view", "scene", "datum", "depend", "focal", "point", "lead", "overlap", "clustering", "scene", "collection", "rather", "than", "partition", "result", "organization", "particularly", "suit", "retrieve", "explore", "complex", "hybrid", "scene", "we", "show", "advantage", "focal-centric", "scene", "comparison", "organization", "over", "exist", "approach", "particularly", "deal", "hybrid", "scene", "we", "also", "demonstrate", "new", "capability", "offer", "new", "datum", "organization", "scene", "retrieval", "exploration", "background", "conceptual", "level", "we", "work", "can", "see", "realization", "notion", "family", "resemblance", "from", "seminal", "work", "Wittgenstein", "-lsb-", "1953", "-rsb-", "scene", "collection", "form", "family", "extract", "focal", "represent", "resemblance", "which", "overlap", "criss-cross", "among", "scene", "Works", "from", "cognitive", "psychology", "particular", "those", "Rosch", "-lsb-", "1975", "-rsb-", "provide", "evidence", "perceptual", "semantic", "category", "naturally", "form", "term", "focal", "point", "prototype", "-lrb-", "see", "account", "-lsb-", "Tversky", "1977", "-rsb-", "-rrb-", "though", "so-called", "cognitive", "reference", "point", "she", "work", "refer", "whole", "representative", "category", "instead", "featured", "substructure", "role", "context", "measure", "datum", "similarity", "have", "long", "be", "study", "various", "field", "e.g.", "-lsb-", "Biberman", "1994", "Jeh", "Widom", "2002", "-rsb-", "we", "work", "present", "algorithm", "identify", "conceptual", "focal", "which", "serve", "reference", "point", "compare", "scene", "heterogeneous", "collection", "scene", "analysis", "most", "familiar", "environment", "human", "indoor", "scene", "ubiquitous", "graphic", "application", "virtual", "reality", "gaming", "design", "much", "research", "vision", "graphic", "have", "be", "devote", "recognize", "classify", "retrieve", "indoor", "scene", "e.g.", "-lsb-", "Rasiwasia", "Vasconcelos", "2008", "Quattoni", "Torralba", "2009", "Fisher", "et", "al.", "2011", "Juneja", "et", "al.", "2013", "Xu", "et", "al.", "2013", "Zhao", "et", "al.", "2014", "-rsb-", "among", "other", "we", "work", "recognize", "difficulty", "compare", "complex", "scene", "globally", "e.g.", "via", "classic", "graph", "kernel", "-lsb-", "Fisher", "et", "al.", "2011", "-rsb-", "we", "propose", "extract", "utilize", "focal", "substructure", "scene", "analysis", "relevance", "work", "which", "extract", "distinctive", "region", "-lsb-", "shilane", "Funkhouser", "2007", "Juneja", "et", "al.", "2013", "-rsb-", "representative", "semantic", "category", "focal", "we", "extract", "mean", "scene", "recognition", "organization", "one", "focal", "may", "share", "scene", "from", "different", "category", "object", "collection", "co-analysis", "have", "be", "grow", "body", "work", "unsupervised", "co-analysis", "-lsb-", "xu", "et", "al.", "2012", "Huang", "et", "al.", "2012", "van", "Kaick", "et", "al.", "2013", "Huang", "et", "al.", "2013a", "Zheng", "et", "al.", "2013", "-rsb-", "organization", "3d", "object", "collection", "-lsb-", "Ovsjanikov", "et", "al.", "2011", "Jain", "et", "al.", "2012", "Kim", "et", "al.", "2012", "Huang", "et", "al.", "2013b", "-rsb-", "similar", "work", "exist", "image", "collection", "e.g.", "image", "co-salience", "detection", "-lsb-", "Cheng", "et", "al.", "2014", "-rsb-", "most", "case", "co-analysis", "operate", "object", "belong", "same", "semantic", "category", "exception", "recent", "work", "Huang", "et", "al.", "-lsb-", "2013b", "-rsb-", "which", "perform", "qualitative", "analysis", "heterogeneous", "object", "collection", "however", "object", "comparison", "employ", "global", "shape", "descriptor", "while", "still", "result", "unique", "qualitative", "distance", "term", "number", "hop", "tree", "representation", "between", "object", "another", "recent", "work", "co-hierarchical", "analysis", "van", "Kaick", "et", "al.", "-lsb-", "2013", "-rsb-", "also", "employ", "clustering", "approach", "clustering", "partition", "set", "shape", "different", "mode", "structural", "variation", "while", "hierarchical", "model", "offer", "flexibility", "account", "structural", "variation", "still", "provide", "only", "single", "view", "each", "shape", "we", "representation", "allow", "multiple", "view", "scene", "model", "each", "which", "may", "see", "from", "perspective", "particular", "focal", "point", "moreover", "we", "analysis", "produce", "overlap", "cluster", "which", "characterize", "underlie", "datum", "larger", "granularity", "contextual", "analysis", "part-in-whole", "object-in-scene", "type", "retrieval", "have", "be", "study", "semantic", "analysis", "3d", "object", "indoor", "scene", "Shapira", "et", "al.", "-lsb-", "2009", "-rsb-", "define", "context", "shape", "part", "within", "extract", "part", "hierarchy", "series", "work", "from", "Fisher", "et", "al.", "rely", "spatial", "semantic", "relation", "among", "scene", "object", "context-based", "object", "search", "-lsb-", "Fisher", "Hanrahan", "2010", "Fisher", "et", "al.", "2011", "-rsb-", "object", "replacement", "scene", "synthesis", "-lsb-", "Fisher", "et", "al.", "2012", "-rsb-", "all", "work", "substructure", "scene", "provide", "context", "characterize", "individual", "object", "therein", "we", "treat", "substructure", "explicit", "scene", "feature", "i.e.", "potential", "focal", "perform", "contextual", "analysis", "larger", "scope", "one", "possible", "way", "find", "salient", "substructure", "scene", "collection", "extract", "object", "group", "base", "co-occurrence", "object", "category", "like", "work", "Xu", "et", "al.", "-lsb-", "2013", "-rsb-", "contrast", "we", "group", "scene", "object", "rather", "than", "object", "category", "form", "focal", "furthermore", "group", "Xu", "et", "al.", "-lsb-", "2013", "-rsb-", "base", "frequency", "analysis", "only", "while", "we", "perform", "both", "frequent", "pattern", "mining", "subspace", "clustering", "focal", "point", "extraction", "Singh", "et", "al.", "-lsb-", "2012", "-rsb-", "detect", "mid-level", "discriminative", "patch", "from", "set", "unlabeled", "image", "alternate", "between", "clustering", "training", "discriminative", "classifier", "similar", "idea", "apply", "extract", "from", "large", "repository", "geo-tagged", "imagery", "visual", "feature", "which", "both", "frequently", "occur", "geographically", "distinctive", "under", "weak", "supervision", "-lsb-", "Doersch", "et", "al.", "2012", "-rsb-", "we", "co-analysis", "unsupervised", "drive", "novel", "cluster", "compactness", "objective", "both", "focal", "selection", "focal-induced", "clustering", "frequent", "pattern", "mining", "frequent", "pattern", "mining", "have", "be", "extensively", "study", "topic", "datum", "mining", "-lsb-", "Han", "et", "al.", "2007", "-rsb-", "most", "relevant", "work", "those", "design", "frequent", "subgraph", "mining", "e.g.", "-lsb-", "Yan", "Han", "2002", "-rsb-", "which", "primarily", "base", "subgraph", "isomorphism", "testing", "directly", "adapt", "method", "we", "problem", "set", "infeasible", "since", "relation", "among", "object", "we", "input", "graph", "loose", "possibly", "uncertain", "we", "adopt", "inexact", "subgraph", "matching", "formulate", "graph", "edit", "distance", "-lsb-", "Riesen", "et", "al.", "2010", "-rsb-", "where", "edit", "cost", "define", "base", "spatial", "arrangement", "between", "scene", "object", "also", "worth", "note", "frequency", "occurrence", "only", "criterion", "focal", "point", "selection", "subsequent", "cluster", "analysis", "further", "adjust", "extract", "focal", "subspace", "clustering", "subspace", "clustering", "cluster", "highdimensional", "datum", "multiple", "subspace", "each", "model", "subset", "feature", "-lsb-", "Vidal", "2011", "-rsb-", "high", "level", "clustering", "problem", "we", "face", "have", "similar", "setting", "subspace", "clustering", "where", "focal", "act", "feature", "subset", "characterize", "subspace", "contain", "cluster", "scene", "subspace", "analysis", "via", "spectral", "clustering", "have", "be", "one", "most", "effective", "approach", "subspace", "clustering", "-lsb-", "Wang", "et", "al.", "2011a", "-rsb-", "however", "spectral", "clustering", "always", "produce", "partition", "we", "work", "we", "perform", "cluster", "attachment", "reveal", "cluster", "overlap", "base", "representative", "focal", "make", "obtain", "cluster", "better", "reflect", "complexity", "heterogeneity", "datum", "collection" ],
  "content" : "Recent works on organizing and exploring 3D visual data have mostly been devoted to object collections [Ovsjanikov et al. 2011; Jain et al. 2012; Kim et al. 2012; van Kaick et al. 2013; Huang et al. 2013b]. In this paper, we are interested in analyzing and organizing visual data at a larger scope, namely, 3D indoor scenes. Even a moderately complex indoor scene would contain tens to hundreds of objects. Compared to the individual objects therein, a scene is  more complex with looser structural and spatial relations among its components and a more diverse mixture of functional substructures. The latter point is attested by hybrid scenes which contain elements reminiscent of different semantic categories. For example, the middle scene in Figure 1 is partly a bedroom and partly a living room. The greater intra-class variabilities and richer characteristics in scene data motivate our work to go beyond providing only a holistic and singular view of a scene or a scene collection. We introduce the use of focal points for characterizing, comparing, and organizing collections of complex data and apply the concepts and algorithms developed to 3D indoor scenes. In particular, we are interested in organizing scenes in a heterogeneous collection, i.e., scenes belonging to multiple semantic categories. Analyzing complex and heterogeneous data is difficult without references to certain points of attention or focus, i.e., the focal points. For example, comparing New York City to Paris as a whole will unlikely yield a useful answer. The comparison is a lot more meaningful if it is focused on particular aspects of the cities, e.g., architectural style or fashion trends. One of the natural consequences of the focal point driven data view is that scene comparison may yield different similarity distances depending on the focal points; see Figure 1 for an illustration, as well as the accompanying video. We represent an indoor scene by a graph of its constituent objects. Focal-driven scene clustering produces overlapping clusters. An exploratory path, (a) to (e), through an overlap, which often contains hybrid scenes (c) possessing multiple focals, can smoothly transition between the scene clusters. These scene clusters often characterize meaningful scene categories. In this example, the transition is from bedroom scenes to offices. A focal point, or focal, for short, is a substructure in a scene and corresponds to a subgraph. However, we are not interested in all sub-scenes. A key premise of our work is that meaningful focals should be determined contextually, in a set ( Figure 2 ), and through a co-analysis. To illustrate, there are probably too many notable aspects about Paris. When putting London and Paris together, one?s focuses narrow down to, e.g., European capitals. If we throw New York and Milan into the mix, then most people are first reminded that the four cities are the fashion capitals of the world. In this work, we are interested in extracting contextual focal points that are representative in a given scene collection. For a focal to be representative, it must occur sufficiently frequently. However, frequency analysis alone is insufficient. For example, chairs are likely to be found in almost all scenes, but they can hardly be regarded as representative of any meaningful scene groups, e.g., bedrooms or living rooms. We stipulate that representativity is also tied to a notion of coherence or compactness of the group of scenes the focal point is to represent or characterize. Therefore, frequency analysis for focal extraction is intermixed with clustering, which computes compact groups of scenes, where the scenes in each cluster are closely connected when viewed from the perspective of the representative focals of the cluster. Once again, the representative focals occur frequently in the cluster and they must also induce a compact cluster. To solve the two coupled problems simultaneously, we develop a co-analysis algorithm which interleaves frequent pattern mining [Han et al. 2007] and subspace clustering [Vidal 2011]. Focal points play a key role in our organization of a heterogeneous scene collection. First, we define compactness of a cluster based on a focal-centric scene-to-scene similarity, which builds on the rooted walk graph kernels of Fisher et al. [2011] and assigns higher weights to walks which originate from the representative focals of that cluster. Secondly, the scene organization is given by the clustering of scenes based on the representative focals extracted. Some scenes may contain multiple focals, thus belong to multiple clusters. Such scenes, typically of a hybrid nature, provide linkages or gateways between scene clusters, allowing an exploration of the scene organization to naturally transition between meaningful scene categories, as illustrated in Figure 3 . Our main contribution is a focal-driven analysis and organization of heterogeneous data collections. While we only consider 3D indoor scenes in this paper and we are not aware of previous works on coanalysis and organization of heterogeneous scene collections, the analysis is general and not confined to scene data. Important characteristics of our work which set it apart from previous approaches to organizing data collections include: ? Data are not compared holistically without discrimination. We develop a focal-centric scene descriptor for scene com- parison, which supports scene analysis in perspective. ? Similarity distance between two scenes may be non-unique, i.e., it is based on the focals designated for comparison. ? Multiple views on scene data depend on focal points, leading to overlapping clustering of a scene collection, rather than a partition. The resulting organization is particularly suited for retrieving and exploring complex and hybrid scenes. We show advantages of focal-centric scene comparison and organization over existing approaches, particularly in dealing with hybrid scenes. We also demonstrate new capabilities offered by the new data organization for scene retrieval and exploration. Background. At a conceptual level, our work can be seen as a realization of the notion of ?family resemblances? from the seminal work of Wittgenstein [1953]. A scene collection forms the ?family?, and the extracted focals represent the resemblances which ?overlap and criss-cross? among the scenes. Works from cognitive psychology, in particular those by Rosch [1975], provided evidences that perceptual and semantic categories are naturally formed in terms of focal points or prototypes (see account in [Tversky 1977]), though the so-called ?cognitive reference points? in her work referred to whole representatives of a category instead of featured substructures. The role of context in measuring data similarity has long been studied in various fields, e.g., [Biberman 1994; Jeh and Widom 2002]. Our work presents an algorithm for identifying conceptual focals which serve as reference points for comparing scenes in a heterogeneous collection. Scene analysis. As the most familiar environments to humans, indoor scenes are ubiquitous in graphics applications such as virtual reality, gaming, and design. Much research in vision and graphics has been devoted to recognizing, classifying, and retrieving indoor scenes, e.g., [Rasiwasia and Vasconcelos 2008; Quattoni and Torralba 2009; Fisher et al. 2011; Juneja et al. 2013; Xu et al. 2013; Zhao et al. 2014], among others. Our work recognizes the difficulty in comparing complex scenes globally, e.g., via the classic graph kernels [Fisher et al. 2011]. We propose extracting and utilizing focal substructures for scene analysis. Of relevance are works which extract distinctive regions [Shilane and Funkhouser 2007; Juneja et al. 2013] that are representative of a semantic category. The focals we extract are not meant for scene recognition but organization; one focal may be shared by scenes from different categories. Object collections and co-analysis. There have been a growing body of work on unsupervised co-analysis [Xu et al. 2012; Huang et al. 2012; van Kaick et al. 2013; Huang et al. 2013a; Zheng et al. 2013] and organization of 3D object collections [Ovsjanikov et al. 2011; Jain et al. 2012; Kim et al. 2012; Huang et al. 2013b]. Similar works exist on image collections, e.g., for image co-salience detection [Cheng et al. 2014]. In most cases, co-analysis operates on objects belonging to the same semantic category. An exception is the recent work of Huang et al. [2013b] which performs qualitative analysis on heterogeneous object collections. However, their object comparison employs global shape descriptors while still resulting in unique qualitative distances, in terms of number of ?hops? in a tree representation, between objects. Another recent work, the co-hierarchical analysis of van Kaick et al. [2013], also employs a clustering approach and the clustering partitions a set of shapes into different modes of structural variation. While hierarchical models offer the flexibility to account for structural variations, they still provide only a single view on each shape. Our representation allows multiple views of a scene model, each of which may be seen as from the perspective of a particular focal point. Moreover, our analysis produces overlapping clusters which characterize the underlying data with larger granularity. Contextual analysis. Part-in-whole or object-in-scene types of retrievals have been studied in semantic analysis of 3D objects or indoor scenes. Shapira et al. [2009] define the context for a shape part within an extracted part hierarchy. The series of work from Fisher et al. rely on spatial and semantic relations among the scene objects for context-based object search [Fisher and Hanrahan 2010; Fisher et al. 2011] or object replacement for scene synthesis [Fisher et al. 2012]. In all of these works, substructures in a scene provide the contexts for characterizing individual objects therein. We treat the substructures as explicit scene features, i.e., potential focals, and perform contextual analysis in a larger scope. One possible way to find salient substructures in a scene collection is to extract object groups based on co-occurrences of object categories, like in the work of Xu et al. [2013]. In contrast, we group scene objects, rather than object categories, to form focals. Furthermore, the grouping in Xu et al. [2013] is based on frequency analysis only, while we perform both frequent pattern mining and subspace clustering for focal point extraction. Singh et al. [2012] detect mid-level discriminative patches from a set of unlabeled images by alternating between clustering and training discriminative classifiers. A similar idea is then applied to extract, from a large repository of geo-tagged imagery, visual features which are both frequently occurring and geographically distinctive under weak supervision [Doersch et al. 2012]. Our co-analysis is unsupervised, driven by a novel cluster compactness objective for both focal selection and focal-induced clustering. Frequent pattern mining. Frequent pattern mining has been an extensively studied topic in data mining [Han et al. 2007]. The most relevant works are those designed for frequent subgraph mining, e.g., [Yan and Han 2002], which are primarily based on subgraph isomorphism testing. Directly adapting these methods to our problem setting is infeasible since the relations among objects in our input graphs are loose and possibly uncertain. We adopt inexact subgraph matching formulated by graph edit distances [Riesen et al. 2010] where the edit cost is defined based on spatial arrangements between scene objects. It is also worth noting that frequency of occurrence is not the only criterion for focal point selection. The subsequent cluster analysis further adjusts the extracted focals. Subspace clustering. Subspace clustering clusters highdimensional data into multiple subspaces, each modeled by a subset of features [Vidal 2011]. At a high level, the clustering problem we face has a similar setting as subspace clustering, where focals act as the feature subsets and characterize the subspaces that contain the clusters of scenes. Subspace analysis via spectral clustering has been one of the most effective approaches to subspace clustering [Wang et al. 2011a]. However, spectral clustering always produces a partition. In our work, we perform cluster attachment to reveal cluster overlap based on their representative focals, making the obtained clusters better reflect the complexity and heterogeneity of the data collection.",
  "resources" : [ ]
}