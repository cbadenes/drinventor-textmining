{
  "uri" : "sig2014-a129-huang_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2014/a129-huang_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Image Completion using Planar Structure Guidance",
    "published" : "2014",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Jia-Bin-Huang",
      "name" : "Jia-Bin",
      "surname" : "Huang"
    }, {
      "uri" : "http://drinventor/Sing Bing-Kang",
      "name" : "Sing Bing",
      "surname" : "Kang"
    }, {
      "uri" : "http://drinventor/Narendra-Ahuja",
      "name" : "Narendra",
      "surname" : "Ahuja"
    }, {
      "uri" : "http://drinventor/Johannes-Kopf",
      "name" : "Johannes",
      "surname" : "Kopf"
    } ]
  },
  "bagOfWords" : [ "information", "convert", "soft", "constraint", "low-level", "completion", "algorithm", "define", "prior", "probability", "patch", "offset", "transformation", "we", "validate", "we", "technique", "through", "extensive", "comparison", "state-of-the-art", "algorithm", "variety", "scene", "task", "know", "image", "completion", "use", "application", "range", "from", "removal", "unwanted", "object", "personal", "photo", "movie", "post-production", "because", "some", "amount", "higher", "level", "understanding", "scene", "often", "require", "state-of-the-art", "automatic", "algorithm", "typically", "rely", "low-level", "cue", "synthesize", "missing", "region", "field", "overlap", "patch", "copy", "from", "known", "region", "-lsb-", "Wexler", "et", "al.", "2007", "-rsb-", "second", "problem", "somewhat", "alleviate", "apply", "algorithm", "coarse-to-fine", "manner", "improve", "algorithm?s", "ability", "complete", "general", "scene", "result", "exponential", "increase", "search", "space", "from", "degree", "freedom", "per", "output", "pixel", "up", "-lrb-", "more", "-rrb-", "specifically", "we", "estimate", "planar", "projection", "parameter", "-lrb-", "i.e.", "local", "perspective", "slope", "scene", "-rrb-", "well", "translational", "regularity", "affine", "rectify", "domain", "-lrb-", "explain", "later", "section", "4.1", "-rrb-", "information", "use", "constrain", "search", "space", "missing", "region", "result", "we", "can", "use", "even", "richer", "patch", "transformation", "model", "than", "previous", "work", "-lrb-", "i.e.", "full", "homography", "-rrb-", "since", "we", "constraint", "effectively", "reduce", "high", "dimensional", "model", "lower", "degree", "subspace", "note", "while", "we", "model", "world", "piecewise", "planar", "we", "just", "restricted", "scene", "just", "original", "completion", "algorithm", "limit", "fronto-parallel", "scene", "ours", "allow", "significant", "deviation", "from", "piecewise", "planar", "model", "evidence", "we", "result", "we", "algorithm", "significantly", "improve", "performance", "challenging", "man-made", "scene", "those", "architecture", "indoors", "absence", "any", "detect", "structural", "cue", "e.g.", "most", "natural", "landscape", "image", "-lrb-", "figure", "-rrb-", "we", "algorithm", "fall", "back", "standard", "unconstrained", "completion", "i.e.", "we", "implementation", "Wexler", "et", "al.", "algorithm", "-lsb-", "2007", "-rsb-", "we", "validate", "we", "method", "compare", "against", "state-of-the-art", "algorithm", "we", "show", "numerous", "representative", "result", "paper", "supplementary", "material", "section", "we", "review", "representative", "technique", "image", "completion", "technique", "still", "fundamentally", "rely", "low-level", "cue", "which", "less", "effective", "image", "larger", "structure", "while", "additional", "motion", "parameter", "do", "help", "when", "need", "increase", "dimensionality", "complexity", "render", "nearest", "neighbor", "search", "algorithm", "even", "harder", "find", "good", "solution", "we", "handle", "issue", "constrain", "transformation", "base", "mid-level", "structural", "analysis", "image", "miss", "region", "image", "could", "also", "complete", "help", "external", "image", "dataset", "similar", "scene", "match", "strategy", "adopt", "Zhang", "et", "al.", "-lsb-", "2013", "-rsb-", "main", "difference", "transfer", "self-similarity", "field", "guide", "completion", "instead", "actual", "contents", "match", "image", "another", "example", "use", "external", "database", "through", "instance-level", "matching", "method", "fill", "miss", "region", "via", "appropriate", "geometric", "photometric", "transformation", "retrieve", "image", "-lsb-", "Whyte", "et", "al.", "2009", "-rsb-", "example", "Jia", "et", "al.", "-lsb-", "2003", "-rsb-", "infer", "line", "contour", "continuation", "miss", "region", "use", "they", "completion", "similar", "type", "salient", "line", "matching", "use", "problem", "tele-registration", "-lsb-", "Huang", "et", "al.", "2013a", "-rsb-", "while", "desirable", "have", "fully", "automatic", "approach", "image", "completion", "technique", "may", "still", "fail", "occasion", "because", "computer", "vision", "technique", "typically", "far", "from", "perfect", "interactive", "method", "allow", "user", "explicitly", "provide", "high-level", "expertise", "guide", "completion", "we", "implement", "baseline", "algorithm", "non-parametric", "optimization", "algorithm", "Wexler", "et", "al.", "-lsb-", "2007", "-rsb-", "use", "random", "search", "propagation", "PatchMatch", "-lsb-", "Barnes", "et", "al.", "2009", "-rsb-", "we", "use", "two", "type", "mid-level", "constraint", "scene", "guide", "lowlevel", "completion", "process", "planar", "perspective", "translational", "regularity", "give", "image", "user-specified", "mask", "specify", "region", "-lrb-", "hole", "-rrb-", "fill", "we", "first", "detect", "multiple", "plane", "estimate", "perspective", "parameter", "determine", "spatial", "support", "within", "scene", "-lrb-", "section", "-rrb-", "determine", "translational", "regularity", "within", "each", "plane", "we", "perform", "feature", "matching", "use", "sift", "feature", "-lsb-", "Lowe", "2004", "-rsb-", "position", "all", "match", "feature", "pair", "affine", "rectify", "use", "corresponding", "plane", "parameter", "allow", "dominant", "translational", "shift", "easily", "detect", "through", "cluster", "displacement", "vector", "rectify", "domain", "we", "use", "detect", "perspective", "plane", "translational", "regularity", "within", "each", "plane", "soft", "constraint", "guide", "low-level", "image", "completion", "-lrb-", "section", "-rrb-", "we", "achieve", "integrate", "derive", "constraint", "prior", "probability", "search", "space", "regularity", "detection", "step", "provide", "positional", "guidance", "i.e.", "where", "source", "patch", "should", "copy", "from", "contrast", "plane", "orientation", "constraint", "provide", "non-positional", "guidance", "source", "patch", "i.e.", "how", "source", "patch", "should", "deform", "incorporate", "both", "positional", "non-positional", "constraint", "search", "source", "patch", "from", "known", "region", "we", "show", "two", "type", "mid-level", "image", "analysis", "can", "significantly", "improve", "quality", "complete", "region", "semantically", "meaningful", "way", "section", "we", "describe", "we", "analysis", "known", "image", "region", "detect", "planar", "surface", "-lrb-", "section", "4.1", "-rrb-", "translational", "regularity", "within", "plane", "-lrb-", "section", "4.2", "-rrb-", "result", "analysis", "use", "constrain", "low-level", "completion", "algorithm", "describe", "section", "we", "use", "technique", "involve", "line", "segment", "extraction", "vanish", "point", "estimation", "-lsb-", "Hartley", "Zisserman", "2004", "-rsb-", "group", "base", "vanish", "point", "since", "part", "we", "algorithm", "relatively", "standard", "we", "provide", "only", "brief", "description", "here", "we", "detect", "up", "three", "vanish", "point", "-lrb-", "vp", "-rrb-", "use", "ransac-based", "voting", "approach", "mean", "we", "assume", "only", "up", "three", "different", "plane", "orientation", "scene", "reasonable", "typical", "man-made", "structure", "we", "show", "sample", "result", "Figure", "give", "three", "vp", "we", "can", "recover", "up", "three", "plane", "orientation", "one", "from", "each", "pair", "detect", "vp", "we", "compactly", "represent", "parameter", "plane", "use", "vanish", "line", "-lrb-", "image", "line", "infinity", "world", "plane", "connect", "two", "distinct", "vp", "-rrb-", "note", "homogeneous", "have", "two", "degree", "freedom", "perspective", "image", "plane", "can", "affine", "rectify", "-lrb-", "so", "parallel", "line", "3d", "appear", "parallel", "image", "-rrb-", "use", "pure", "perspective", "transformation", "matrix", "however", "plane", "parameter", "provide", "information", "spatial", "support", "plane", "image", "domain", "instead", "we", "address", "problem", "via", "rather", "simple", "straightforward", "approach", "we", "key", "insight", "plane", "typically", "consist", "two", "set", "parallel", "3d", "line", "other", "word", "usually", "two", "set", "line", "segment", "two", "distinct", "vp", "should", "reside", "within", "same", "image", "region", "we", "identify", "support", "each", "plane", "locate", "position", "where", "two", "set", "line", "segment", "correspond", "two", "vp", "overlap", "each", "other", "we", "estimate", "spatial", "support", "plane", "perform", "elementwise", "multiplication", "its", "vp?s", "support", "line", "density", "map", "product", "map", "have", "high", "response", "where", "two", "set", "line", "segment", "overlap", "each", "other", "note", "we", "always", "add", "fronto-parallel", "plane", "parameter", "-lsb-", "-rsb-", "assign", "fix", "density", "value", "10", "uniformly", "across", "image", "we", "perform", "per-pixel", "normalization", "density", "product", "map", "so", "sum", "over", "plane", "membership", "probability", "we", "call", "posterior", "probability", "pr", "-lsb-", "-rsb-", "assign", "plane", "membership", "pixel", "process", "illustrate", "Figure", "here", "posterior", "probability", "distribution", "show", "color-code", "density", "map", "right", "column", "-lrb-", "note", "density", "map", "fronto-parallel", "plane", "show", "-rrb-", "line", "can", "only", "detect", "known", "region", "image", "posterior", "probability", "within", "unknown", "region", "highly", "unreliable", "address", "problem", "we", "assign", "every", "miss", "pixel", "probability", "closest", "boundary", "pixel", "posterior", "probability", "map", "example", "image", "show", "Figure", "similar", "he", "Sun", "-lsb-", "2012", "-rsb-", "we", "also", "detect", "translational", "regularity", "use", "offset", "match", "image", "feature", "however", "we", "detect", "regularity", "localized", "manner", "affine", "rectify", "space", "order", "account", "possibly", "multiple", "foreshorten", "plane", "we", "gin", "detect", "standard", "difference", "gaussian", "feature", "point", "known", "image", "region", "compute", "sift", "descriptor", "each", "feature", "point", "-lsb-", "Lowe", "2004", "-rsb-", "we", "choose", "extract", "feature", "original", "image", "rather", "than", "rectify", "space", "because", "rectification", "would", "severely", "distort", "image", "slant", "plane", "-lrb-", "e.g.", "rectify", "ground", "plane", "middle", "image", "Figure", "would", "lead", "extreme", "distortion", "near", "horizon", "-rrb-", "we", "compute", "two", "nearest", "neighbor", "each", "feature", "use", "kd-tree", "we", "only", "retain", "match", "whose", "feature", "distance", "below", "threshold", "0.1", "next", "each", "plane", "we", "extract", "all", "feature", "match", "where", "both", "feature", "position", "have", "high", "posterior", "probability", "pr", "-lsb-", "-rsb-", "-lrb-", "define", "section", "4.1", "-rrb-", "specifically", "we", "check", "product", "two", "posterior", "probability", "-lrb-", "from", "two", "detect", "feature", "position", "-rrb-", "exceed", "0.5", "however", "equal", "spacing", "preserve", "image", "space", "-lrb-", "hence", "we", "feature", "match", "-rrb-", "due", "perspective", "distortion", "we", "undo", "distortion", "affinely", "rectify", "position", "match", "feature", "point", "we", "use", "mean-shift", "algorithm", "-lsb-", "comaniciu", "-lrb-", "-rrb-", "input", "image", "-lrb-", "-rrb-", "match", "feature", "-lrb-", "-rrb-", "rectify", "space", "mode", "-lrb-", "-rrb-", "fronto-parallel", "mode", "-lrb-", "-rrb-", "rectify", "displacement", "-lrb-", "-rrb-", "fronto-parallel", "displacement", "Meer", "2002", "-rsb-", "detect", "mode", "-lrb-", "set", "bandwidth", "parameter", "10", "pixel", "reject", "spurious", "mode", "fewer", "than", "10", "member", "-rrb-", "we", "denote", "set", "mode", "-lcb-", "-rcb-", "where", "displacement", "vector", "rectify", "space", "Figure", "-lrb-", "c-d", "-rrb-", "show", "detect", "mode", "both", "rectify", "-lrb-", "leave", "-rrb-", "axis-aligned", "space", "-lrb-", "right", "-rrb-", "-lrb-", "e-f", "-rrb-", "we", "also", "show", "position", "relative", "target", "patch", "image", "-lrb-", "white", "square", "-rrb-", "figure", "highlight", "importance", "have", "perspective", "correction", "compute", "displacement", "vector", "addition", "accurate", "position", "suggestion", "plane", "parameter", "explicitly", "provide", "how", "source", "patch", "should", "deform", "spatially", "recover", "candidate", "outline", "blue", "have", "significantly", "deform", "match", "image", "axis", "align", "target", "patch", "white", "difficult", "recover", "geometric", "transformation", "use", "low-level", "algorithm", "alone", "he", "Sun", "-lsb-", "2012", "-rsb-", "have", "show", "regularity", "use", "statistics", "match", "patch", "offset", "can", "helpful", "context", "image", "com", "pletion", "detection", "optimization", "both", "do", "image", "space", "we", "technique", "while", "detection", "rectify", "affine", "space", "objective", "function", "optimize", "image", "space", "use", "constrain", "homography", "-lrb-", "describe", "next", "section", "-rrb-", "we", "regularity", "detection", "handle", "more", "general", "scene", "because", "we", "deal", "each", "plane", "independently", "-lrb-", "soft", "membership", "-rrb-", "give", "major", "difference", "he", "sun?s", "technique", "have", "substantially", "modify", "work", "scene", "section", "we", "describe", "how", "detect", "plane", "extract", "regularity", "from", "previous", "section", "use", "guide", "low-level", "image", "completion", "algorithm", "we", "build", "Wexler", "et", "al.", "algorithm", "-lsb-", "2007", "-rsb-", "use", "random", "search", "propagation", "PatchMatch", "-lsb-", "Barnes", "et", "al.", "2009", "-rsb-", "please", "refer", "papers", "detail", "base", "algorithm", "we", "incorporate", "sampling", "from", "plane", "modify", "patch", "distance", "function", "-lrb-", "section", "5.1-5", ".3", "-rrb-", "regularity", "modify", "random", "sample", "generation", "-lrb-", "section", "5.4", "-rrb-", "we", "augment", "image", "completion", "objective", "function", "two", "way", "First", "we", "augment", "patch", "distance", "-lrb-", "call", "coherence", "measure", "original", "paper", "-lsb-", "2007", "-rsb-", "-rrb-", "include", "guidance", "term", "second", "we", "augment", "search", "space", "plane", "index", "which", "determine", "patch", "transformation", "objective", "function", "take", "form", "two", "term", "color", "guide", "appearance", "guidance", "term", "respectively", "which", "together", "make", "up", "patch", "distance", "note", "target", "patch", "image-aligned", "geometric", "transformation", "scaling", "rotation", "while", "source", "patch", "have", "geometric", "transform", "implicitly", "derive", "from", "geometry", "plane", "sample", "from", "geometric", "transform", "describe", "next", "section", "we", "appearance", "cost", "sum", "absolute", "value", "two", "sample", "patch", "RGB", "space", "where", "-lrb-", "-rrb-", "denote", "patch", "sample", "around", "center", "position", "-lrb-", "-rrb-", "denote", "sample", "patch", "center", "geometric", "transformation", "subject", "plane", "orientation", "define", "target", "patch", "position", "plane", "parameter", "plane", "most", "prior", "approach", "use", "pure", "translational", "patch", "-lsb-", "Wexler", "et", "al.", "2007", "Komodakis", "Tziritas", "2007", "-rsb-", "explicitly", "search", "geometric", "transformation", "e.g.", "rotation", "scale", "flip", "-lsb-", "Mansfield", "et", "al.", "2011", "Darabi", "et", "al.", "2012", "-rsb-", "instead", "we", "sample", "patch", "use", "homography", "rather", "than", "search", "all", "parameter", "homography", "we", "derive", "implicitly", "from", "combination", "coordinate", "corresponding", "plane", "index", "we", "first", "compute", "transformation", "map", "patch", "transform", "patch", "sample", "let", "-lsb-", "-rsb-", "-lsb-", "-rsb-", "homogenous", "representation", "respectively", "let", "row", "vector", "source", "target", "patch", "position", "affine", "rectify", "space", "compute", "we", "define", "-lrb-", "-rrb-", "displacement", "vector", "from", "target", "source", "patch", "position", "rectify", "space", "term", "represent", "apply", "inverse", "rectify", "matrix", "we", "have", "get", "motion", "parameter", "patch", "around", "-lrb-", "i.e.", "factor", "out", "dependency", "-rrb-", "we", "apply", "translation", "matrix", "offset", "where", "compactly", "represent", "domain", "transformation", "sample", "source", "patch", "note", "special", "case", "frontoparallel", "plane", "-lrb-", "-rrb-", "reduce", "translation", "matrix", "offset", "-lrb-", "-rrb-", "we", "guidance", "cost", "include", "three", "constraint", "derive", "from", "analysis", "stage", "guide", "-lrb-", "-rrb-", "plane", "-lrb-", "-rrb-", "direction", "-lrb-", "-rrb-", "proximity", "-lrb-", "-rrb-", "-lrb-", "10", "-rrb-", "where", "10", "10", "weighting", "parameter", "plane", "compatibility", "orthogonal", "direction", "proximity", "cost", "respectively", "next", "we", "describe", "each", "constraint", "detail", "plane", "compatibility", "analysis", "stage", "we", "compute", "posterior", "probability", "map", "pr", "-lsb-", "-rsb-", "assign", "plane", "membership", "position", "located", "we", "directly", "convert", "penalty", "term", "use", "negative", "log-likelihood", "specifically", "i.e.", "term", "encourage", "sampling", "from", "plane", "have", "high", "probability", "both", "source", "target", "location", "orthogonal", "direction", "cost", "Urban", "scene", "often", "consist", "repetitive", "structure", "along", "horizontal", "vertical", "direction", "e.g.", "window", "building", "facade", "term", "encourage", "use", "source", "patch", "locate", "either", "one", "orthogonal", "direction", "note", "affine", "rectification", "make", "support", "line", "each", "vp", "parallel", "however", "line", "from", "two", "vp", "necessarily", "orthogonal", "each", "other", "we", "estimate", "rotation", "angle", "map", "set", "line", "segment", "each", "vp", "align", "horizontal", "axis", "mapping", "denote", "two", "vp", "define", "plane", "we", "define", "orthogonal", "direction", "cost", "truncate", "l1-norm", "ensure", "cost", "invariant", "scale", "image", "we", "divide", "distance", "y-axis", "rectify", "space", "largest", "image", "dimension", "case", "target", "patch", "available", "source", "sample", "both", "direction", "constraint", "have", "effect", "search", "source", "patch", "because", "constant", "proximity", "cost", "have", "be", "show", "Kopf", "et", "al.", "-lsb-", "2012", "-rsb-", "constrain", "search", "space", "nearby", "region", "can", "improve", "synthesis", "result", "addition", "above", "mid-level", "constraint", "we", "also", "introduce", "low-level", "search", "space", "constraint", "which", "favor", "nearby", "source", "patch", "completion", "constraint", "implicitly", "avoid", "copying", "patch", "from", "extremely", "different", "scale", "we", "define", "proximity", "cost", "where", "-lrb-", "-rrb-", "square", "distance", "target", "position", "nearest", "border", "known", "region", "-lrb-", "-rrb-", "parameter", "adjust", "strength", "proximity", "constraint", "-lrb-", "largest", "image", "dimension", "-rrb-", "we", "extend", "random", "location", "sampling", "PatchMatch", "algorithm", "-lsb-", "Barnes", "et", "al.", "2009", "-rsb-", "incorporate", "we", "computed", "plane", "probability", "translational", "regularity", "addition", "regular", "random", "location", "sampling", "we", "also", "sample", "from", "cluster", "regularity", "mode", "compute", "section", "4.2", "we", "do", "include", "regularity", "prior", "term", "previous", "section", "because", "detection", "sometimes", "reliable", "use", "regularity", "instead", "random", "location", "sample", "generation", "provide", "more", "robust", "way", "incorporate", "constraint", "we", "implementation", "PatchMatch", "we", "use", "iteration", "plane", "probability", "guide", "sampling", "regularity", "guide", "sampling", "-lrb-", "describe", "below", "-rrb-", "search", "propagation", "stage", "plane", "probability", "guide", "sampling", "give", "target", "patch", "we", "first", "sample", "plane", "index", "accord", "posterior", "probability", "pr", "-lsb-", "-rsb-", "we", "sample", "draw", "random", "sample", "from", "pr", "-lsb-", "-rsb-", "use", "rejection", "sampling", "effectively", "bias", "search", "space", "toward", "find", "correct", "patch", "from", "same", "plane", "regularity", "guide", "sampling", "while", "plane", "probability", "guide", "random", "sampling", "scheme", "sample", "from", "right", "plane", "do", "impose", "constraint", "where", "plane", "should", "sample", "from", "usually", "lead", "visible", "artifact", "when", "regular", "structure", "present", "sample", "from", "we", "detect", "regularity", "mode", "alleviate", "problem", "each", "target", "patch", "we", "first", "draw", "plane", "index", "above", "we", "randomly", "draw", "one", "displacement", "rectify", "space", "from", "example", "candidate", "source", "patch", "show", "Figure", "regularity", "guide", "sampling", "scheme", "greatly", "improve", "completion", "quality", "when", "repetitive", "structure", "exist", "we", "compare", "we", "result", "against", "several", "state-of-the-art", "image", "completion", "algorithm", "specifically", "we", "choose", "Photoshop", "Content", "Aware", "fill", "-lsb-", "Barnes", "et", "al.", "2009", "Wexler", "et", "al.", "2007", "-rsb-", "he", "sun?s", "method", "-lsb-", "2012", "-rsb-", "image", "melding", "-lsb-", "Darabi", "et", "al.", "2012", "-rsb-", "supplementary", "material", "we", "also", "compare", "against", "Priority", "Belief", "propagation", "-lsb-", "Komodakis", "Tziritas", "2007", "-rsb-", "gimp", "resynthesizer", "Figure", "we", "show", "series", "comparison", "challenging", "scene", "first", "row", "building", "consist", "near", "regular", "structure", "we", "can", "see", "compete", "algorithm", "fail", "synthesize", "large", "structure", "because", "only", "minimize", "localized", "texture", "energy", "without", "consider", "global", "consistency", "we", "method", "other", "hand", "fill", "hole", "repetitive", "pattern", "similar", "known", "region", "addition", "recover", "plane", "orientation", "we", "synthesize", "result", "physically", "plausible", "second", "row", "we", "show", "single", "planar", "building", "facade", "regular", "pattern", "even", "only", "mild", "perspective", "distortion", "translational", "patch", "insufficient", "synthesize", "foreshortening", "effect", "thus", "result", "broken", "line", "structure", "image", "melding", "while", "theoretically", "equip", "ability", "apply", "appropriate", "scaling", "patch", "fail", "find", "solution", "high-dimensional", "space", "we", "algorithm", "effectively", "use", "plane", "constraint", "extend", "facade", "minimally", "visible", "artifact", "result", "3rd", "6th", "row", "show", "we", "algorithm", "limit", "ideal", "piecewise", "plane", "scene", "homogeneous", "texture", "plane", "support", "detection", "weighting", "scheme", "we", "leverage", "low-level", "algorithm", "find", "good", "transition", "boundary", "between", "one", "structure", "another", "example", "illustrate", "good", "transition", "boundary", "stair", "region", "pure", "texture", "region", "around", "tree", "fourth", "row", "multiple", "unknown", "surface", "discontinuity", "fifth", "row", "last", "row", "we", "demonstrate", "effectiveness", "combine", "plane", "constraint", "regularity-guided", "sampling", "from", "example", "realistic", "scene", "we", "can", "see", "we", "image", "completion", "algorithm", "robust", "deviation", "from", "perfectly", "textured", "planar", "surface", "other", "word", "we", "completion", "algorithm", "do", "require", "perfect", "plane", "orientation", "recovery", "support", "estimation", "segmentation", "symmetry", "detection", "fact", "analysis", "many", "region", "contain", "error", "because", "vision", "algorithm", "far", "from", "perfect", "however", "exemplify", "here", "combine", "powerful", "lowlevel", "algorithm", "mid-level", "constraint", "we", "able", "extend", "state-of-the-art", "image", "completion", "please", "refer", "supplementary", "material", "where", "we", "show", "extensive", "comparison", "result", "variety", "scene", "image", "natural", "scene", "we", "analysis", "usually", "do", "detect", "any", "plane", "because", "reliable", "feature", "detect", "plane", "translational", "regularity", "case", "we", "we", "algorithm", "automatically", "revert", "baseline", "image", "completion", "algorithm", "i.e.", "we", "implementation", "Wexler", "et", "al.", "algorithm", "-lsb-", "2007", "-rsb-", "four", "example", "show", "Figure", "we", "compare", "unguided", "version", "we", "completion", "algorithm", "-lrb-", "fourth", "column", "-rrb-", "validate", "we", "result", "look", "visually", "similar", "baseline", "supplementary", "material", "we", "present", "more", "extensive", "comparison", "25", "natural", "image", "we", "extract", "from", "project", "website", "Kopf", "et", "al.", "paper", "-lsb-", "2012", "-rsb-", "we", "use", "relatively", "simple", "algorithm", "we", "image", "analysis", "stage", "which", "can", "fail", "detect", "vanish", "point", "plane", "regularity", "more", "severely", "return", "false", "positive", "former", "case", "we", "algorithm", "just", "revert", "fronto-parallel", "completion", "while", "latter", "case", "might", "lead", "some", "artifact", "first", "two", "row", "Figure", "10", "demonstrate", "demonstrate", "difficulty", "find", "demarcation", "line", "between", "different", "perspective", "plane", "when", "unknown", "region", "large", "result", "third", "row", "show", "example", "falsely", "detect", "plane", "may", "overconstrain", "patch", "synthesis", "lead", "poor", "result", "near", "bush", "Notice", "though", "compete", "technique", "also", "fail", "generate", "satisfactory", "result", "we", "have", "present", "automatic", "image", "completion", "algorithm", "exploit", "extract", "mid-level", "scene", "structure", "guide", "lowlevel", "completion", "we", "algorithm", "detect", "multiple", "plane", "corresponding", "translational", "regularity", "constraint", "incorporate", "augmented", "patch", "distance", "sampling", "scheme", "absence", "reliable", "plane", "detection", "we", "algorithm", "automatically", "revert", "baseline", "completion", "algorithm", "we", "demonstrate", "we", "method", "consistently", "outperform", "state-ofthe-art", "image", "completion", "algorithm", "wide", "range", "challenging", "scene", "Historically", "conventional", "statistical", "texture", "synthesis", "method", "formulate", "texture", "synthesis", "analysis", "synthesis", "framework", "however", "type", "framework", "have", "be", "mostly", "set", "aside", "due", "simplicity", "effectiveness", "example-based", "method", "Input", "hole", "Photoshop", "image", "melding", "-lsb-", "2012", "-rsb-", "-lsb-", "he", "Sun", "2012", "-rsb-", "we", "result", "Input", "hole", "Photoshop", "image", "melding", "-lsb-", "2012", "-rsb-", "Input", "hole", "Photoshop", "image", "melding", "-lsb-", "2012", "-rsb-", "we", "result", "-lrb-", "unguided", "-rrb-", "we", "result", "-lrb-", "guide", "-rrb-", "-lsb-", "he", "Sun", "2012", "-rsb-", "we", "result", "we", "show", "quality", "image", "completion", "can", "significantly", "improve", "strike", "balance", "between", "analysis", "synthesis", "we", "thank", "flickr", "user", "who", "put", "image", "under", "Creative", "Commons", "license", "allow", "we", "use", "they", "detailed", "list", "contributor", "we", "image", "dataset", "please", "refer", "accompany", "project", "website", "support", "Office", "Naval", "Research", "under", "grant", "n00014-12-1-0259", "gratefully", "acknowledge" ],
  "content" : "This information is then converted into soft constraints for the low-level completion algorithm by defining prior probabilities for patch offsets and transformations. We validate our technique through extensive comparisons with state-of-the-art algorithms on a variety of scenes. This task, known as image completion, is used in applications ranging from the removal of unwanted objects in personal photos to movie post-production. This is because some amount of higher level understanding of the scene is often required. The state-of-the-art automatic algorithms typically rely on low-level cues; they synthesize the missing region as a field of overlapping patches copied from the known region [Wexler et al. 2007]. This second problem is somewhat alleviated by applying the algorithm in a coarse-to-fine manner. this improves the algorithm?s ability to complete general scenes, it results in an exponential increase of the search space from 2 degrees of freedom per output pixel up to 8 (or more). Specifically, we estimate planar projection parameters (i.e., the local perspective slope of the scene) as well as translational regularity in the affine rectified domain (explained later in Section 4.1); this information is used to constrain the search space in the missing region. As a result, we can use an even richer patch transformation model than previous work (i.e., full homographies) since our constraints effectively reduce this high dimensional model to a lower degree subspace. Note that while we model the world as piecewise planar, we are not just restricted to such scenes: just as the original completion algorithm was not limited to fronto-parallel scenes, ours allows significant deviation from the piecewise planar model, as evidenced by our results. Our algorithm significantly improves performance for challenging man-made scenes such as those of architecture and indoors. In the absence of any detected structural cues, e.g., for most natural landscape images ( Figure 9 ), our algorithm falls back to standard unconstrained completion, i.e., our implementation of Wexler et al.?s algorithm [2007]. We validate our method by comparing against state-of-the-art algorithms. We show numerous representative results in the paper and supplementary material. In this section, we review representative techniques for image completion. These techniques still fundamentally rely on low-level cues, which are less effective for images with larger structures. While the additional motion parameters do help when needed, the increased dimensionality and complexity render the nearest neighbor searching algorithm even harder to find a good solution. We handle this issue by constraining the transformation based on mid-level structural analysis of the image. Missing regions in images could also be completed with the help of external image datasets. A similar scene matching strategy was adopted by Zhang et al. [2013]; the main difference is that they transfer the self-similarity field to guide the completion instead of the actual contents of the matched image. Another example of using external database is through instance-level matching methods to fill in missing regions via appropriate geometric and photometric transformation of the retrieved image [Whyte et al. 2009]. For example, Jia et al. [2003] inferred the line and contour continuation in the missing regions and used them for completion. A similar type of salient line matching was used in problems of tele-registration [Huang et al. 2013a]. While it is desirable to have a fully automatic approach, the image completion technique may still fail on occasion because computer vision techniques are typically far from perfect. Interactive methods allows users to explicitly provide high-level expertise to guide the completion. We implemented as baseline algorithm the non-parametric optimization algorithm of Wexler et al. [2007], and use random search  and propagation as in PatchMatch [Barnes et al. 2009]. We use two types of mid-level constraints of the scene to guide the lowlevel completion process: planar perspective and translational regularity. Given an image and a user-specified mask that specifies the region (or hole) to fill, we first detect multiple planes, estimate their perspective parameters, and determine their spatial supports within the scene (Section 4). To determine translational regularity within each plane, we perform feature matching using SIFT features [Lowe 2004]. The positions of all matched feature pairs are then affine rectified 1 using the corresponding plane parameters. This allows the dominant translational shifts to be easily detected through clusters of displacement vectors in the rectified domain. We use the detected perspective planes and the translational regularity within each plane as soft constraints to guide the low-level image completion (Section 5). We achieve this by integrating these derived constraints as prior probabilities of the search space. The regularity detection step provides ?positional? guidance, i.e., where the source patch should be copied from. In contrast, the plane orientation constraints provide ?non-positional? guidance of source patches, i.e., how the source patch should be deformed. By incorporating both positional and non-positional constraints on searching source patches from the known region, we show that these two types of mid-level image analysis can significantly improve the quality of the completed region in a semantically meaningful way. In this section, we describe our analysis of the known image region to detect planar surfaces (Section 4.1) and translational regularity within these planes (Section 4.2). The results of this analysis will be used to constrain the low-level completion algorithm, as described in Section 5. We use a technique that involves line segment extraction, vanishing point estimation [Hartley and Zisserman 2004], and grouping based on vanishing points. Since this part of our algorithm is relatively standard, we provide only a brief description here. We then detect up to three vanishing points (VPs) using a RANSAC-based voting approach. This means we assume there are only up to three different plane orientations in the scene. This is reasonable for typical man-made structures. We show a sample result in Figure 3 . Given the three VPs, we can recover up to three plane orientations, one from each pair of the detected VPs. We compactly represent the parameters of plane m using the vanishing line l m (the image of ? the line at infinity on the world plane connecting the two distinct VPs): Note that l m is homogeneous and has two degrees of freedom. The ? perspective image of a plane can then be affine rectified (so that parallel lines in 3D appear parallel in the image) using a pure perspective transformation matrix ? 1 0 0 ? However, the plane parameters provide no information on the spatial support of the plane in the image domain. Instead, we address this problem via a rather simple and straightforward approach. Our key insight is that a plane typically consists of two sets of parallel 3D lines. In other words, there are usually two sets of the line segments with two distinct VPs that should reside within the same image region. We identify the support of each plane by locating positions where the two sets of line segments corresponding to the two VPs overlap with each other. Then, we estimate the spatial support for the planes by performing elementwise multiplication of its VP?s support line density maps. These product maps have a high response where the two sets of the line segments overlapped with each other. Note that we always add the fronto-parallel plane with parameters l 0 = [0, 0, 1] and assign ? a fixed density value 10 ?5 uniformly across the image. We then perform per-pixel normalization of this density product map so that the sum over the plane membership probability is 1; we call this the ?posterior probability? Pr[m|x] for assigning plane membership m at pixel x. This process is illustrated in Figure 4 . Here, the posterior probability distributions are shown as color-coded density maps on the right column (note that the density map for the fronto-parallel plane is not shown). As lines can only be detected in the known region of the image, the posterior probabilities within the unknown region are highly unreliable. To address this problem, we assign to every missing pixel the probabilities of the closest boundary pixel. The posterior probability map of an example image is shown in Figure 5 . Similar to He and Sun [2012], we also detect translational regularity using offsets of matched image features. However, we detect regularity in a localized manner and in affine rectified space in order to account for possibly multiple foreshortened planes. We be gin with detecting standard Difference of Gaussian feature points in the known image region and compute the SIFT descriptors for each feature point [Lowe 2004]. We choose to extract features in the original image rather than rectified space because the rectification would severely distort the image for slanted planes (e.g., rectifying the ground plane in the middle image in Figure 1 would lead to extreme distortions near the horizon). We compute the two nearest neighbors for each feature using a kd-tree. We only retain matches whose 2 feature distances are below a threshold of 0.1. Next, for each plane m, we extract all feature matches, where both feature positions have a high posterior probability Pr[m|x] (defined in Section 4.1). Specifically, we check if the product of two posterior probabilities (from two detected feature positions) exceeds 0.5. However, the equal spacing is not preserved in image space (and, hence, in our feature matches), due to perspective distortion. We undo this distortion by affinely rectifying the positions of the matched feature points. We use the mean-shift algorithm [Comaniciu and (a) Input image (b) Matched features (c) Rectified space modes (d) Fronto-parallel modes (e) Rectified displacements (f) Fronto-parallel displacements Meer 2002] to detect these modes (setting the bandwidth parameter to 10 pixels, and rejecting spurious modes with fewer than 10 members). We denote the set of the modes as D m = {d i }, where d i ? R 2 is the displacement vector in the rectified space. Figure 6 (c-d) shows detected modes in both rectified (left) and axis-aligned space (right). In (e-f) we also show their positions relative to a target patch in the image (white square). This figure highlights the importance of having perspective correction in computing the displacement vectors. In addition to the accurate position suggestion, the plane parameters explicitly provides how the source patches should deform spatially. The recovered candidates, outlined in blue, have to be significantly deformed to match with the image axis aligned target patch, in white. It is difficult to recover such geometric transformations using low-level algorithms alone. He and Sun [2012] have shown that regularity using statistics of matched patch offsets can be helpful in the context of image com- pletion. Detection and optimization are both done in image space. For our technique, while the detection is in rectified affine space, the objective function is optimized in image space using constrained homographies (as described in the next section). Our regularity detection handles more general scenes because we deal with each plane independently (but with soft membership). Given the major differences, He and Sun?s technique will have to be substantially modified to work on such scenes. In this section, we describe how the detected planes and extracted regularity from the previous section are used to guide the low-level image completion algorithm. We build on Wexler et al.?s algorithm [2007] using random search and propagation as in PatchMatch [Barnes et al. 2009]. Please refer to these papers for details on the base algorithm. We incorporate sampling from planes by modifying the patch distance function (Sections 5.1-5.3), and the regularity by modifying the random sample generation (Section 5.4). We augment the image completion objective function in two ways: First, we augment the patch distance (called ?coherence measure? in the original paper [2007]) by including a guidance term. Second, we augment the search space by the plane index, which determines the patch transformation. The objective function takes the form The two terms E color and E guide are the appearance and guidance terms, respectively, which together make up the patch distance. Note that the target patches are image-aligned with no geometric transformation such as scaling or rotation, while the source patches have a geometric transform that is implicitly derived from geometry of the plane they are sampled from. The geometric transform is described in the next section. Our appearance cost is the sum of the absolute values of two sampled patches in the RGB space: where p(t i ) denotes the 7 ? 7 patch sampled around the center position t i and q(s i , t i , m i ) denotes the sampled patch centered at s i with geometric transformation subject to the plane orientation defined by target patch position t i and the plane parameter of plane m i . Most prior approaches use pure translational patches [Wexler et al. 2007; Komodakis and Tziritas 2007] or explicitly search geometric transformations, e.g., rotation, scale, and flip [Mansfield et al. 2011;  Darabi et al. 2012]. Instead, we sample patches using homographies. Rather than searching for all parameters of the homography, we derive it implicitly from the combination of the coordinates s i , t i with their corresponding plane index m i . We first compute the transformation that maps a 7 ? 7 patch at t i to transformed patch sampled at s i . Let t  ? i = [t i x ,t i y , 1] and s  ? i = x y [s i , s i , 1] as homogenous representations of t i and s i , respectively. Let h 1 , h 2 , h 3 be the row vectors of H m i . The source and target patch positions in the affine rectified space are computed as: We define (d x , d y ) as the displacement vector from target to source patch positions in the rectified space. The term s  ? i is represented as By applying the inverse of the rectifying matrix H ?1 m i , we have To get the motion parameters of the patch around s i (i.e., factoring out the dependency of t i ), we apply a translation matrix with offset t i : where T s i compactly represents the domain transformation of the sampled source patch. Note that in the special case of frontoparallel plane (H 0 = I 3 ), T s i reduces to a translation matrix with x y offset (s i , s i ). Our guidance cost includes three constraints derived from the analysis stage:  E guide (s i , t i , m i ) = ? 1 E plane (s i , t i , m i ) + ? 2 E direction (s i , t i , m i )+ ? 3 E proximity (s i , t i ), (10) where ? 1 = 10, ? 2 = 10 3 , and ? 3 = 1 are the weighting parameters for plane compatibility, orthogonal direction, and proximity cost, respectively. Next, we describe each of these constraints in detail. Plane compatibility. In the analysis stage, we computed the posterior probability map Pr[m i |x] for assigning plane membership m i for position located at x. We directly convert this into a penalty term using the negative log-likelihood. Specifically, i.e., the term encourages sampling from a plane that has a high probability both in the source and target location. Orthogonal direction cost. Urban scenes often consist of repetitive structures along horizontal and vertical directions, e.g., windows on a building facade. This term encourages using source patches located on either one of the orthogonal directions. Note that affine rectification makes the support lines for each VP parallel, however, the lines from the two VPs are not necessarily orthogonal to each other. We estimate the rotation angle that maps the set of line segments for each VP to align with the horizontal axis. This mapping is denoted as H 1 m i and H 2 m i for the two VPs defining the plane m i : ? ? We define the orthogonal direction cost as a truncated L1-norm: To ensure that the cost is invariant to the scale of the image, we divide the distances in y-axis in the rectified space by the largest image dimension. For cases of target patches with no available source samples on the both directions, this constraint has no effect on searching of the source patch because it is constant. Proximity cost. It has been shown by Kopf et al. [2012] that constraining the search space to nearby regions can improve the synthesis result. In addition to the above mid-level constraints, we also introduce a low-level search space constraint which favors nearby source patches for completion. This constraint implicitly avoid copying patches from extremely different scales. We define the proximity cost as where ? d (t i ) 2 is the squared distance of target position to the nearest border to the known region and ? c 2 = (W /8) 2 is the parameter for adjusting the strength of the proximity constraint (W is the largest image dimension). We extend the random location sampling in the PatchMatch algorithm [Barnes et al. 2009] to incorporate our computed plane probabilities and translational regularity. In addition to the regular random location sampling, we also sample from the clustered regularity modes computed in Section 4.2. We did not include the regularity as a prior term in the previous sections because the detection is  sometimes not reliable. Using regularity instead for random location sample generation provides a more robust way of incorporating this constraint. In our implementation of PatchMatch, we use 5 iterations of plane probability guided sampling and regularity guided sampling (as described below) in the search and propagation stage. Plane probability guided sampling. For a given target patch t i , we first sample the plane index m i according to the posterior probability Pr[m i |t i ]. Then, we sample s i by drawing random samples from Pr[s i |m i ] using rejection sampling. This effectively biases the search space toward finding the correct patches from the same plane. Regularity guided sampling. While the plane probability guided random sampling scheme to sample from the right plane, it does not impose constraints on where on the plane it should sample from. This usually leads to visible artifacts when regular structures are present. Sampling from our detected regularity modes alleviates this problem. For each target patch t i , we first draw a plane index m i as above, then, we randomly draw one displacement in rectified space from D m . Examples of candidate source patches are shown in Figure 6 . This regularity guided sampling scheme greatly improves the completion quality when repetitive structures exist. We compare our results against several state-of-the-art image completion algorithms. Specifically, we choose Photoshop Content Aware Fill [Barnes et al. 2009; Wexler et al. 2007], He and Sun?s method [2012], and Image Melding [Darabi et al. 2012]. In the supplementary material we also compare against Priority Belief Propagation [Komodakis and Tziritas 2007] and GIMP Resynthesizer 2 . In Figure 8 , we show a series of comparisons on challenging scenes. In the first row, the building consist of near regular structures. We can see that the competing algorithms fail to synthesize such large structure because they only minimize localized texture energy without considering a global consistency. Our method, on the other hand, fills in the hole with repetitive pattern similar to the known region. In addition, with the recovered plane orientation, our synthesized result is physically plausible. In the second row, we show a single planar building facade with regular patterns. Even with only mild perspective distortion, translational patches are insufficient to synthesize the foreshortening effect and thus result in broken line structures. Image Melding, while theoretically equipped with the ability to apply appropriate scaling of the patches, fails to find such solution in high-dimensional space. Our algorithm effectively use the plane constraint to extend the facade with minimally visible artifacts. The results on the 3rd to 6th rows show that our algorithm is not limited to ideal piecewise plane scenes with homogeneous textures. With the plane support detection and the weighting scheme, we leverage the low-level algorithm to find a good transition boundary between one structure and another. Examples illustrating good transition boundaries are the stairs regions and the pure texture region around the tree in the fourth row, and multiple unknown surface discontinuity in the fifth row. In the last row, we demonstrate the effectiveness of combining plane constraints and regularity-guided sampling. From these examples of realistic scenes, we can see that our image completion algorithm is robust to deviations from perfectly textured planar surfaces. In other words, our completion algorithm does not require perfect plane orientation recovery, support estimation, segmentation, and symmetry detection. In fact, the analysis in many regions contains errors because vision algorithms are far from perfect. However, as exemplified here, by combining a powerful lowlevel algorithm with mid-level constraints, we are able to extend the state-of-the-art in image completion. Please refer to the supplementary materials where we show extensive comparison results on a variety of scenes. For images of natural scenes our analysis usually does not detect any planes because there are no reliable features to detect planes and translational regularity. In such cases our our algorithm automatically reverts to the baseline image completion algorithm, i.e., our implementation of Wexler et al.?s algorithm [2007]. Four such examples are shown in Figure 9 . We compare to the unguided version of our completion algorithm (fourth column) to validate that our result looks visually similar to the baseline. In the supplementary material we present a more extensive comparison on 25 natural images we extracted from the project website of Kopf et al.?s paper [2012]. We used relatively simple algorithms in our image analysis stages, which can fail to detect vanishing points or plane regularities, or more severely, return false positives. In the former case our algorithm just reverts to fronto-parallel completion, while the latter case might lead to some artifacts. The first two rows in Figure 10 demonstrate demonstrate the difficulty of finding demarcation lines between different perspective planes when the unknown region is large. The results in the third row shows an example that the falsely detected plane may overconstrain the patch synthesis and lead to poor results near the bushes. Notice, though, that the competing techniques also fail to generate satisfactory results. We have presented an automatic image completion algorithm that exploits extracted mid-level scene structures for guiding the lowlevel completion. Our algorithm detects multiple planes and their corresponding translational regularity. These constraints are incorporated into the augmented patch distance and the sampling scheme. In the absence of reliable plane detection, our algorithm automatically reverts to a baseline completion algorithm. We demonstrated that our method consistently outperforms state-ofthe-art image completion algorithms for a wide range of challenging scenes. Historically, conventional statistical texture synthesis methods formulate texture synthesis as an ?analysis then synthesis? framework. However, this type of framework has been mostly set aside due to the simplicity and the effectiveness of example-based methods. Input & hole Photoshop Image Melding [2012] [He and Sun 2012] Our result Input & hole Photoshop Image Melding [2012] Input & hole Photoshop Image Melding [2012] Our result (unguided) Our result (guided)\n        [He and Sun 2012] Our result We show that the quality of image completion can be significantly improved by striking a balance between analysis and synthesis. We thank the flickr users who put their images under Creative Commons license or allowed us to use them. For a detailed list of contributors to our image dataset, please refer to the accompanying project website. The support of the Office of Naval Research under grant N00014-12-1-0259 is gratefully acknowledged.",
  "resources" : [ ]
}