{
  "uri" : "sig2014a-a232-liu_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2014a/a232-liu_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Fast Burst Images Denoising",
    "published" : null,
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ ]
  },
  "bagOfWords" : [ "align", "image", "fuse", "create", "denoised", "output", "rapid", "per-pixel", "operation", "temporal", "spatial", "domain", "burst", "shooting", "mode", "most", "camera", "allow", "multiple", "shot", "capture", "quick", "succession", "either", "press", "hold", "shutter", "button", "recently", "burst", "capture", "have", "become", "ubiquitous", "many", "hand-held", "imaging", "device", "-lrb-", "e.g.", "smartphone", "compact", "dslr", "camera", "-rrb-", "example", "iPhone", "5", "support", "burst", "up", "10", "shot", "per", "second", "state-of-the-art", "method", "heavily", "rely", "optical", "flow", "patch", "matching", "establish", "temporal", "spatial", "correspondence", "which", "unacceptably", "slow", "fast", "method", "like", "average", "filter", "-lsb-", "Tomasi", "Manduchi", "1998", "-rsb-", "insufficient", "both", "noise", "reduction", "avoid", "ghost", "artifact", "cause", "either", "camera", "motion", "-lrb-", "hand", "shake", "-rrb-", "scene", "motion", "-lrb-", "dynamic", "object", "-rrb-", "representation", "inspire", "recent", "multiple", "homography", "model", "-lsb-", "Grundmann", "et", "al.", "2012", "Liu", "et", "al.", "2013", "-rsb-", "video", "stabilization", "idea", "successfully", "apply", "recent", "hdr", "deghosting", "-lsb-", "Granados", "et", "al.", "2013", "-rsb-", "single", "image", "denoising", "have", "great", "progress", "recent", "decade", "improve", "efficiency", "few", "fast", "variant", "have", "be", "propose", "fast", "bilateral", "filter", "-lsb-", "Paris", "Durand", "2009", "-rsb-", "gaussian", "kd-tree", "-lsb-", "Adams", "et", "al.", "2009", "-rsb-", "geodesic", "path", "-lsb-", "Chen", "et", "al.", "2013", "-rsb-", "estimate", "camera", "motion", "Optical", "flow", "-lsb-", "Brox", "et", "al.", "2004", "-rsb-", "most", "general", "representation", "establish", "correspondence", "between", "frame", "recent", "work", "-lsb-", "Liu", "Freeman", "2010", "-rsb-", "show", "its", "importance", "video", "denoising", "optical", "flow", "itself", "have", "difficulty", "occlusion/large", "displacement", "fragile", "noise", "however", "presence", "strong", "noise", "both", "nonparametric", "method", "degrade", "rapidly", "camera", "motion", "burst", "mode", "similar", "motion", "study", "video", "stabilization", "handle", "scene", "motion", "since", "optical", "flow", "patch", "matching", "intrinsically", "hard", "problem", "recent", "work", "-lsb-", "Gallo", "et", "al.", "2009", "Granados", "et", "al.", "2013", "-rsb-", "hdr", "reconstruction", "bypass", "motion", "estimation", "find", "consistent", "subset", "color", "every", "pixel", "reconstruct", "ghost-free", "image", "Granados", "et", "al.", "-lsb-", "2013", "-rsb-", "consistency", "test", "rely", "accurate", "estimation", "noise", "distribution", "which", "may", "require", "complex", "calibration", "super-pixels", "computation", "multiscale", "denoising", "effective", "way", "exploit", "cross-scale", "similarity", "noise", "reduction", "recently", "Zontak", "et", "al.", "-lsb-", "2013", "-rsb-", "propose", "directional", "pyramid", "technique", "find", "corresponding", "patch", "across", "scale", "which", "produce", "state-of-the-art", "result", "Zhang", "Gunturk", "-lsb-", "2008", "-rsb-", "extend", "bilateral", "filter", "multiscale", "framework", "coarse", "level", "node", "provide", "robustness", "while", "fine", "level", "node", "help", "produce", "detail", "graph", "-lrb-", "finest", "level", "only", "-rrb-", "obtain", "per-pixel", "translation", "vector", "homography", "flow", "total", "frame", "number", "number", "inlier", "-lrb-", "inlier", "when", "where", "standard", "deviation", "-lcb-", "-rcb-", "-rrb-", "identify", "temporal", "fusion", "furthermore", "multi-scale", "processing", "effective", "handle", "non-gaussian", "type", "noise", "-lrb-", "e.g.", "splotch", "-lsb-", "Chatterjee", "et", "al.", "2011", "-rsb-", "-rrb-", "real", "imaging", "pipeline", "textureness", "probability", "tex", "compute", "sigmoid", "function", "-lrb-", "exp", "-lrb-", "-lrb-", "-rrb-", "-rrb-", "-rrb-", "which", "maximum", "absolute", "difference", "between", "pixel", "its", "neighbor", "estimated", "standard", "deviation", "noise", "different", "from", "point-wise", "fusion", "LMMSE", "estimator", "patch", "apply", "frequency", "domain", "which", "similar", "Wiener", "filter", "use", "transform", "domain", "-lsb-", "Dabov", "et", "al.", "2007b", "-rsb-", "conclusion", "consistent", "previous", "work", "since", "patch", "can", "usually", "use", "more", "spatially", "correlate", "information", "than", "pixel" ],
  "content" : "The aligned images are then fused to create a denoised output with rapid per-pixel operations in temporal and spatial domains. Burst, a shooting mode in most cameras, allows multiple shots to be captured in a quick succession by either pressing or holding the shutter button. Recently, burst capturing has become ubiquitous in many hand-held imaging devices (e.g., smartphone, compact and DSLR cameras). For example, iPhone 5s supports a burst of up to 10 shots per second. The state-of-the-art methods heavily rely on optical flow or patch matching to establish temporal and spatial correspondence, which is unacceptably slow. Fast methods like averaging or filtering [Tomasi and Manduchi 1998] are insufficient on both noise reduction and avoiding ?ghost? artifacts caused by either camera motion (by hand shake) or scene motion (by dynamic objects). This representation is inspired by the recent multiple homographies model [Grundmann et al. 2012; Liu et al. 2013] for video stabilization. The idea was successfully applied in recent HDR deghosting [Granados et al. 2013]. Single image denoising has great progresses in recent decades. To improve the efficiency, a few fast variants have been proposed, such as fast bilateral filtering [Paris and Durand 2009], Gaussian kd-trees [Adams et al. 2009], and geodesic paths [Chen et al. 2013]. Estimating camera motion. Optical flow [Brox et al. 2004] is the most general representation for establishing correspondences between frames. Recent work [Liu and Freeman 2010] showed its importance in video denoising. But optical flow itself has difficulties with occlusion/large displacement, and is fragile to noise. However, in the presence of strong noise, both nonparametric methods degrade rapidly. Camera motion in burst mode is similar to the motion studied in video stabilization. Handling scene motion. Since optical flow or patch matching is an intrinsically hard problem, recent work [Gallo et al. 2009; Granados et al. 2013] in HDR reconstruction bypasses the motion estimation by finding a consistent subset of colors for every pixel to reconstruct a ghost-free image. Granados et al. [2013]?s consistency test relies on accurate estimation of the noise distribution, which may require complex calibration and super-pixels computation. Multiscale denoising is an effective way to exploit cross-scale similarity for noise reduction. Recently, Zontak et al. [2013] proposed a directional pyramid technique to find corresponding patches across scales, which produces state-of-the-art results. Zhang and Gunturk [2008] extended the bilateral filter in a multiscale framework. The coarse level node provides robustness while the fine level node helps produce details. graph (the finest level only) to obtain per-pixel translation vector homography flow. N is the total frame number and m is the number of inliers (x t is an inlier when |x t ? x| < 3? t , where ? t is the standard deviation of {x t }) identified by the temporal fusion. Furthermore, the multi-scale processing is effective for handling non-gaussian types of noise (e.g., splotches [Chatterjee et al. 2011]) in the real imaging pipeline. The textureness probability p tex is computed by a sigmoid function 1/(1 + exp (?5 ? (g/? ? 3))), in which g is the maximum absolute difference between the pixel and its 4 neighbors, and ? is the estimated standard deviation of noise. Different from point-wise fusion, the LMMSE estimator for patches is applied in the frequency domain, which is similar to the Wiener filter used in the transform domain [Dabov et al. 2007b]. The conclusion is consistent to previous work since patches can usually use more spatially correlated information than pixels.",
  "resources" : [ ]
}