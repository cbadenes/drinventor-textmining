{
  "uri" : "sig2010a-a138-lee_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2010a/a138-lee_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Motion Fields for Interactive Character Locomotion",
    "published" : "2014",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Yongjoon-Lee",
      "name" : "Yongjoon",
      "surname" : "Lee"
    }, {
      "uri" : "http://drinventor/Kevin-Wampler",
      "name" : "Kevin",
      "surname" : "Wampler"
    }, {
      "uri" : "http://drinventor/Gilbert-Bernstein",
      "name" : "Gilbert",
      "surname" : "Bernstein"
    }, {
      "uri" : "http://drinventor/Jovan-Popovic",
      "name" : "Jovan",
      "surname" : "Popovic"
    }, {
      "uri" : "http://drinventor/Zoran-Popovic",
      "name" : "Zoran",
      "surname" : "Popovic"
    } ]
  },
  "bagOfWords" : [ "representation", "organize", "motion", "datum", "sample", "high", "dimensional", "generalization", "vector", "field", "we", "call", "motion", "field", "furthermore", "since", "we", "approach", "require", "very", "little", "structure", "motion", "capture", "datum", "use", "minimal", "effort", "need", "generate", "new", "controller", "hence", "even", "when", "method", "anticipate", "some", "user", "input", "-lsb-", "McCann", "Pollard", "2007", "-rsb-", "character", "may", "react", "too", "slowly", "transition", "too", "abruptly", "because", "shorter", "path", "graph", "model", "use", "estimate", "single", "most", "likely", "motion", "character", "take", "each", "possible", "state", "allow", "we", "interactively", "control", "character", "while", "enjoy", "benefit", "fully", "continuous", "state", "space", "although", "we", "controller", "kinematic", "dynamic", "controller", "have", "be", "extensively", "explore", "alternative", "method", "character", "animation", "despite", "broad", "repertoire", "demonstrate", "skill", "-lsb-", "hodgin", "et", "al.", "1995", "Hodgins", "Pollard", "1997", "Wooten", "Hodgins", "2000", "Faloutsos", "et", "al.", "2001", "Yin", "et", "al.", "2007", "Coros", "et", "al.", "2008b", "-rsb-", "nonparametric", "modeling", "coarse-scale", "dynamics", "-lsb-", "coro", "et", "al.", "2009", "Coros", "et", "al.", "2008a", "-rsb-", "use", "motion", "capture", "-lsb-", "Laszlo", "et", "al.", "1996", "Sok", "et", "al.", "2007", "da", "Silva", "et", "al.", "2008", "Muico", "et", "al.", "2009", "-rsb-", "agile", "lifelike", "fully-dynamic", "character", "remain", "open", "challenge", "interactive", "application", "video", "game", "require", "character", "can", "react", "quickly", "user", "command", "unexpected", "disturbance", "all", "while", "maintain", "believability", "generate", "animation", "although", "infeasible", "completely", "model", "entire", "space", "natural", "character", "motion", "we", "can", "use", "motion", "capture", "datum", "local", "approximation", "we", "propose", "structure", "call", "motion", "field", "find", "use", "motion", "capture", "datum", "similar", "character?s", "current", "motion", "any", "point", "consult", "similar", "motion", "determine", "which", "future", "behavior", "plausible", "we", "ensure", "we", "synthesize", "animation", "remain", "natural", "similar", "rarely", "identical", "motion", "capture", "datum", "free", "character", "from", "simply", "replay", "motion", "datum", "allow", "move", "freely", "through", "general", "vicinity", "datum", "pose", "-lrb-", "root", "...", "-rrb-", "consist", "3d", "root", "position", "vector", "root", "root", "orientation", "quaternion", "joint", "orientation", "quaternion", "...", "root", "point", "located", "pelvis", "velocity", "-lrb-", "root", "...", "-rrb-", "consist", "3d", "root", "displacement", "vector", "root", "root", "displacement", "quaternion", "joint", "displacement", "quaternion", "...", "all", "find", "via", "finite", "difference", "give", "two", "pose", "we", "can", "compute", "finite", "difference", "root", "root", "...", "invert", "above", "difference", "we", "can", "add", "velocity", "pose", "get", "new", "displaced", "pose", "set", "all", "possible", "motion", "state", "form", "high", "dimensional", "continuous", "space", "where", "every", "point", "represent", "state", "we", "character", "single", "instant", "time", "path", "trajectory", "through", "space", "represent", "continuous", "motion", "we", "character", "when", "discuss", "dynamic", "system", "space", "usually", "call", "phase", "space", "however", "because", "we", "motion", "synthesis", "kinematic", "we", "use", "phrase", "motion", "space", "instead", "avoid", "confusion", "Motion", "Database", "we", "approach", "take", "input", "set", "motion", "capture", "datum", "construct", "set", "motion", "state", "-lcb-", "-rcb-", "term", "motion", "database", "each", "state", "database", "construct", "from", "pair", "successive", "frame", "+1", "aforementioned", "method", "-lrb-", "-rrb-", "-lrb-", "+1", "-rrb-", "we", "also", "compute", "store", "velocity", "next", "pair", "frame", "compute", "+2", "+1", "generally", "motion", "state", "pose", "velocity", "from", "database", "subscript", "-lrb-", "e.g.", "-rrb-", "while", "arbitrary", "state", "pose", "velocity", "appear", "without", "subscript", "similarity", "neighborhood", "Central", "we", "definition", "motion", "field", "notion", "similarity", "between", "motion", "state", "give", "motion", "state", "we", "compute", "neighborhood", "-lrb-", "-rrb-", "-lcb-", "-rcb-", "most", "similar", "motion", "state", "via", "k-nearest", "neighbor", "query", "over", "database", "-lsb-", "Mount", "Arya", "1997", "-rsb-", "we", "test", "we", "use", "15", "we", "calculate", "-lrb-", "dis", "-rrb-", "similarity", "we", "experiment", "we", "set", "bone", "length", "body", "joint", "meter", "root", "set", "0.5", "note", "we", "factor", "out", "root", "world", "position", "root", "yaw", "orientation", "-lrb-", "respective", "velocity", "-rrb-", "similarity", "weight", "since", "we", "allow", "character", "deviate", "from", "motion", "state", "database", "we", "frequently", "have", "interpolate", "datum", "from", "we", "neighborhood", "-lrb-", "-rrb-", "action", "value", "motion", "field", "motion", "state", "set", "control", "action", "-lrb-", "-rrb-", "determine", "which", "state", "character", "can", "transition", "single", "frame?s", "time", "each", "action", "-lrb-", "-rrb-", "specify", "convex", "combination", "neighbor", "-lsb-", "...", "-rsb-", "-lrb-", "-rrb-", "unfortunately", "function", "frequently", "cause", "we", "character?s", "state", "drift", "off", "region", "where", "we", "have", "little", "datum", "about", "how", "character", "should", "move", "lead", "unrealistic", "motion", "correct", "problem", "we", "use", "small", "drift", "correction", "term", "constantly", "tug", "we", "character", "towards", "closest", "known", "motion", "state", "-lrb-", "-rrb-", "database", "strength", "tug", "control", "parameter", "0.1", "question", "primarily", "subject", "section", "-rrb-", "we", "choice", "action", "choice", "result", "character", "meander", "through", "datum", "generate", "stream", "realistic", "-lrb-", "albeit", "undirected", "-rrb-", "human", "motion", "Foot-Skate", "Cleanup", "result", "motion", "synthesis", "might", "contain", "foot-skating", "artifact", "we", "remove", "artifact", "apply", "inverse", "kinematic", "contact", "foot", "do", "we", "first", "annotate", "foot", "contact", "motion", "datum", "every", "motion", "state", "database", "we", "store", "whether", "left", "foot", "contact", "contact", "-lrb-", "-rrb-", "contact", "-lrb-", "-rrb-", "likewise", "right", "foot", "contact", "-lrb-", "-rrb-", "when", "foot", "leave", "contact", "we", "blend", "out", "inverse", "kinematic", "solution", "hold", "foot", "place", "during", "contact", "within", "0.2", "seconds", "reweight", "neighbor", "-lrb-", "black", "dot", "-rrb-", "we", "current", "state", "-lrb-", "white", "dot", "-rrb-", "we", "can", "control", "motion", "synthesis", "direct", "we", "character", "towards", "different", "next", "state", "-lrb-", "dash", "dot", "-rrb-", "general", "which", "particular", "action", "from", "set", "best", "choose", "depend", "user?s", "current", "command", "decide", "which", "action", "choose", "each", "state", "response", "user?s", "command", "thus", "key", "enable", "real", "time", "interactive", "locomotion", "controller", "Markov", "decision", "process", "mathematical", "structure", "formalize", "concept", "make", "decision", "light", "both", "immediate", "long-term", "result", "express", "character", "animation", "task", "framework", "we", "make", "we", "character", "aware", "long", "term", "consequence", "action", "useful", "even", "graph-based", "controller", "vital", "motion", "field", "controller", "because", "we", "act", "every", "frame", "rather", "than", "every", "clip", "further", "background", "mdp-based", "control", "see", "-lsb-", "Sutton", "Barto", "1998", "-rsb-", "-lsb-", "treuille", "et", "al.", "2007", "-rsb-", "-lsb-", "Lo", "Zwicker", "2008", "-rsb-", "use", "graph-based", "locomotion", "controller", "States", "simply", "represent", "state", "character", "motion", "state", "insufficient", "interactive", "control", "because", "we", "must", "also", "represent", "how", "well", "character", "achieve", "its", "user-specified", "task", "we", "therefore", "add", "vector", "task", "parameter", "keep", "track", "how", "well", "task", "be", "perform", "form", "joint", "task", "state", "-lrb-", "-rrb-", "instance", "we", "direction", "follow", "task", "record", "single", "number", "angular", "deviation", "from", "desire", "head", "alter", "value", "user", "control", "character?s", "direction", "infinitely", "many", "different", "action", "-lrb-", "-rrb-", "many", "technique", "use", "solve", "mdp", "require", "finite", "set", "action", "each", "state", "order", "satisfy", "requirement", "we", "mdp", "controller", "we", "sample", "finite", "set", "action", "-lrb-", "-rrb-", "from", "-lrb-", "-rrb-", "each", "action", "design", "prefer", "one", "neighbor", "over", "other", "word", "derive", "action", "simply", "set", "renormalize", "scheme", "sample", "action", "which", "too", "different", "from", "passive", "action", "so", "avoid", "jerkiness", "motion", "while", "give", "character", "enough", "flexibility", "move", "towards", "nearby", "motion", "state", "how", "update", "task", "parameter", "normally", "obvious", "instance", "direction", "follow", "task", "where", "character", "deviation", "from", "desire", "direction", "we", "simply", "adjust", "angle", "character", "turn", "reward", "order", "make", "we", "character", "perform", "desire", "task", "we", "offer", "reward", "formally", "reward", "function", "specify", "real", "number", "-lrb-", "-rrb-", "quantify", "reward", "receive", "perform", "action", "state", "s.", "instance", "we", "direction", "follow", "task", "we", "give", "high", "high", "reward", "-lrb-", "-rrb-", "maintain", "small", "deviation", "from", "desire", "head", "lower", "reward", "large", "deviation", "see", "section", "section", "specific", "task", "parameter", "reward", "function", "we", "use", "we", "demo", "although", "simple", "policy", "myopic", "ignore", "future", "ramification", "each", "action", "choice", "we", "already", "know", "greedy", "graphbased", "controller", "perform", "poorly", "-lsb-", "treuille", "et", "al.", "2007", "-rsb-", "Motion", "field", "even", "worse", "even", "simple", "task", "change", "direction", "we", "need", "much", "longer", "horizon", "than", "th", "second", "30", "anticipate", "execute", "turn", "lookahead", "policy", "do", "just", "consider", "cumulative", "reward", "over", "future", "task", "state", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "call", "discount", "factor", "control", "how", "much", "character", "focus", "short", "term", "-lrb-", "-rrb-", "versus", "long", "term", "-lrb-", "-rrb-", "reward", "despite", "apparent", "impracticality", "standard", "trick", "allow", "we", "efficiently", "solve", "correct", "next", "action", "trick", "begin", "define", "value", "funciton", "-lrb-", "-rrb-", "scalar-valued", "function", "represent", "expect", "cumulative", "future", "reward", "receive", "act", "optimally", "start", "from", "task", "state", "now", "lookahead", "policy", "only", "marginally", "more", "expensive", "compute", "than", "greedy", "policy", "we", "choose", "task", "state", "sample", "take", "cartesian", "product", "database", "motion", "state", "uniform", "grid", "sampling", "across", "problem?s", "task", "parameter", "see", "Section", "detail", "sampling", "sampling", "give", "we", "high", "resolution", "near", "motion", "database", "state", "-lrb-", "-rrb-", "every", "state", "we", "have", "several", "possible", "action", "-lrb-", "dash", "line", "-rrb-", "next", "state", "-lrb-", "dash", "circle", "-rrb-", "-lrb-", "-rrb-", "we", "interpolate", "value", "function", "store", "database", "state", "-lrb-", "black", "point", "-rrb-", "determine", "value", "each", "next", "state", "-lrb-", "-rrb-", "we", "select", "highest", "value", "action", "perform", "which", "where", "character", "generally", "stay", "give", "mdp", "derive", "from", "motion", "field", "task", "specification", "we", "solve", "approximate", "value", "function", "form", "use", "fitted", "value", "iteration", "-lsb-", "Ernst", "et", "al.", "2005", "-rsb-", "we", "express", "value", "task", "state", "sample", "recursively", "term", "value", "other", "task", "state", "sample", "we", "can", "solve", "-lrb-", "-rrb-", "each", "sample", "state", "iteratively", "apply", "equation", "12", "13", "we", "begin", "allzero", "value", "function", "-lrb-", "-rrb-", "each", "sample", "each", "equation", "12", "use", "compute", "-lrb-", "-rrb-", "after", "which", "we", "use", "equation", "13", "determine", "update", "value", "after", "all", "sample", "have", "be", "process", "manner", "we", "have", "update", "approximation", "value", "function", "we", "repeat", "process", "until", "convergence", "use", "last", "iteration", "final", "value", "function", "unlike", "graph-based", "approach", "motion", "field", "let", "character", "constant", "transition", "between", "many", "source", "datum", "consequently", "we", "need", "access", "value", "function", "all", "motion", "state", "rather", "than", "only", "transition", "between", "clip", "fact", "lead", "large", "memory", "footprint", "relative", "graph", "we", "offset", "weakness", "compression", "purpose", "compression", "we", "want", "think", "we", "value", "function", "collection", "value", "function", "task", "parameter", "without", "compression", "we", "store", "one", "value", "sub-function", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "every", "database", "motion", "state", "-lrb-", "see", "Figure", "-rrb-", "30Hz", "temporally", "adjacent", "motion", "state", "value", "function", "frequently", "similar", "we", "expect", "change", "smoothly", "over", "consecutive", "motion", "state", "relative", "original", "clip", "time", "we", "call", "database", "state", "store", "value", "function", "anchor", "motion", "state", "we", "compute", "value", "function", "ith", "motion", "state", "between", "two", "anchor", "we", "can", "learn", "temporally", "compress", "value", "function", "trivially", "modified", "form", "algorithm", "give", "section", "4.2.1", "instead", "iterate", "over", "all", "task", "state", "we", "only", "iterate", "over", "those", "state", "associate", "anchor", "motion", "state", "technique", "allow", "tradeoff", "between", "agility", "motion", "field-based", "controller", "its", "memory", "requirement", "perform", "little", "temporal", "interpolation", "yield", "very", "agile", "controller", "cost", "additional", "memory", "while", "controller", "significant", "temporal", "compression", "tend", "less", "agile", "we", "experiment", "we", "find", "motion", "field", "controller", "temporal", "compression", "approximately", "agile", "graph-based", "controller", "when", "restricted", "use", "equivalent", "amount", "memory", "significantly", "more", "agile", "when", "use", "moderately", "more", "memory", "-lrb-", "see", "section", "-rrb-", "because", "each", "motion", "state", "consist", "pose", "velocity", "space", "motion", "state", "character", "can", "occupy", "identical", "phase", "space", "character", "treat", "dynamic", "system", "identification", "allow", "we", "easily", "apply", "arbitrary", "physical", "nonphysical", "perturbation", "adjustment", "example", "we", "can", "incorporate", "dynamics", "engine", "inverse", "kinematic", "recovery", "occur", "automatically", "simultaneously", "perturbation", "by-product", "we", "motion", "synthesis", "control", "algorithm", "illustrate", "integration", "perturbation", "we", "synthesis", "algorithm", "we", "describe", "simple", "technique", "which", "provide", "pseudophysical", "interaction", "ability", "apply", "force", "any", "part", "body", "approach", "blend", "result", "obtain", "physical", "simulator", "result", "we", "motion", "synthesis", "technique", "blend", "occur", "over", "window", "update", "step", "begin", "when", "set", "force", "first", "apply", "-lrb-", "we", "set", "20", "i.e.", "2/3", "second", "we", "implementation", "-rrb-", "during", "blend", "phase", "we", "use", "modify", "integration", "formulum", "-lrb-", "equation", "-lrb-", "-rrb-", "-rrb-", "where", "-lrb-", "-rrb-", "state", "after", "step", "dynamic", "simulation", "start", "pose", "initial", "velocity", "can", "use", "conjunction", "both", "passive", "controlled", "motion", "field", "we", "implementation", "we", "use", "Open", "Dynamics", "Engine", "-lrb-", "ODE", "-lsb-", "Smith", "2010", "-rsb-", "-rrb-", "calculate", "-lrb-", "-rrb-", "each", "next", "frame", "after", "force", "apply", "we", "set", "state", "character", "ODE", "zero", "initial", "velocity", "we", "apply", "any", "perturbation", "force", "simulate", "result", "dynamics", "frame", "gravity", "disabled", "setup", "-lrb-", "zero", "initial", "velocity", "gravity", "-rrb-", "have", "useful", "property", "absence", "any", "perturbation", "force", "character?s", "pose", "go", "unaltered", "order", "better", "mimic", "way", "which", "actual", "person", "would", "tip", "about", "foot", "when", "push", "we", "also", "pin", "any", "contact", "foot", "ground", "ball", "joint", "during", "simulation", "result", "velocity", "do", "transfer", "correctly", "between", "multiple", "quick", "push", "addition", "because", "-lrb-", "-rrb-", "do", "handle", "velocity", "same", "manner", "dynamical", "system", "we", "perturbation", "method", "physically", "accurate", "rather", "heuristic", "which", "give", "plausible-looking", "result", "section", "present", "analysis", "two", "important", "property", "motion", "field", "agility", "respond", "user", "directive", "change", "ability", "respond", "dynamic", "perturbation", "we", "create", "value", "function", "two", "example", "task", "follow", "arbitrary", "user-specified", "direction", "stay", "straight", "line", "while", "follow", "user", "direction", "-lrb-", "see", "Figure", "-rrb-", "reward", "direction", "direction", "task", "reward", "line", "line", "follow", "task", "respectively", "define", "Motion", "Data", "Setup", "we", "use", "142", "seconds", "motion", "datum", "contain", "leisurely-paced", "locomotion", "quick", "response", "direction", "face", "direction", "use", "line", "follow", "task", "-lrb-", "-rrb-", "distance", "desire", "line", "also", "consider", "objective", "graph", "Motion", "base", "field", "from", "Deviation", "Angular", "Time", "Elapsed", "Direction", "adjustment", "over", "time", "three", "consecutive", "direction", "change", "within", "4.23", "seconds", "motion", "field", "control", "adjust", "significantly", "shorter", "time", "than", "graph-based", "control", "line", "change", "we", "select", "source", "motion", "datum", "minimum", "care", "except", "roughly", "cover", "space", "possible", "motion", "only", "manual", "pre-processing", "foot", "contact", "annotation", "Value", "function", "Computation", "we", "use", "value", "iteration", "calculate", "value", "function", "direction", "task", "we", "store", "value", "18", "uniformly", "sample", "direction", "line", "follow", "task", "we", "take", "cartesian", "cross", "product", "sampling", "between", "18", "uniform", "sample", "13", "uniform", "sample", "span", "-2.0", "2.0", "we", "set", "discount", "factor", "0.99", "each", "task", "we", "also", "create", "temporally", "compress", "version", "value", "function", "where", "we", "set", "10", "20", "30", "equation", "14", "use", "value", "iteration", "solve", "value", "function", "take", "within", "minute", "sufficient", "memory", "cache", "action", "transition", "hour", "otherwise", "distribute", "value", "iteration", "update", "over", "compute", "cluster", "can", "easily", "address", "time", "memory", "burden", "-lrb-", "see", "Lee", "et", "al.", "-lsb-", "2009", "-rsb-", "detail", "-rrb-", "Figure", "show", "typical", "response", "change", "user", "direction", "both", "task", "motion", "field", "demonstrate", "much", "quicker", "convergence", "new", "goal", "show", "accompany", "video", "Table", "effect", "Value", "function", "compression", "we", "record", "response", "time", "use", "compress", "value", "function", "uniformly", "sample", "user", "direction", "change", "increase", "degree", "compression", "Representation", "Minimum", "Average", "Maximum", "graph-based", "0.31", "0.94", "2.36", "Motion", "Field", "0.21", "0.40", "1.01", "Motion", "Field", "10", "0.21", "0.49", "1.23", "Motion", "Field", "20", "0.25", "0.66", "1.19", "Motion", "Field", "30", "0.38", "0.78", "1.93", "system", "still", "reliably", "achieve", "user", "goal", "gradually", "lose", "agility", "initial", "response", "-lrb-", "see", "Table", "-rrb-", "we", "run", "similar", "experiment", "line", "follow", "task", "we", "uniformly", "sample", "user", "direction", "change", "well", "line", "displacement", "change", "we", "measure", "time", "until", "character", "converge", "within", "degree", "from", "desire", "direction", "0.1", "meter", "from", "desire", "tracking", "line", "we", "observe", "similar", "loss", "agility", "-lrb-", "see", "Table", "-rrb-", "uncompressed", "value", "function", "direction-following", "task", "store", "320kb", "compress", "value", "function", "require", "35kb", "19kb", "13kb", "10x", "20x", "30x", "case", "respectively", "compare", "storage", "require", "graph-based", "method", "14kb", "we", "believe", "reasonable", "allow", "flexible", "trade", "off", "between", "storage", "agility", "more", "complex", "task", "size", "increase", "value", "function", "line", "size", "increase", "graph-based", "value", "function", "runtime", "performance", "depend", "sample", "action", "size", "-lrb-", "equation", "-lrb-", "-rrb-", "-rrb-", "we", "make", "-lrb-", "-rrb-", "ANN", "call", "find", "optimal", "action", "one", "ANN", "call", "find", "neighbor", "current", "state", "more", "ANN", "call", "find", "neighbor", "next", "state", "evaluate", "value", "interpolation", "we", "believe", "localized", "neighborhood", "search", "PatchMatch", "-lsb-", "Barnes", "et", "al.", "2009", "-rsb-", "can", "reduce", "cost", "subsequent", "call", "because", "next", "state", "tend", "quite", "close", "each", "other", "30Hz", "same", "ANN", "overhead", "apply", "learn", "time", "naive", "learning", "implementation", "take", "hour", "learn", "value", "function", "large", "database", "high", "dimensional", "task", "cache", "result", "ANN", "call", "fixed", "motion", "sample", "we", "can", "dramatically", "speed", "up", "learn", "time", "just", "couple", "minute", "use", "algorithm", "describe", "section", "we", "integrate", "pseudophysical", "interaction", "motion", "field", "drive", "synthesis", "use", "both", "passive", "controlled", "motion", "field", "we", "test", "perturbation", "follow", "four", "dataset", "18", "walk", "include", "sideways", "backwards", "crouch", "dataset", "plus", "walk", "push", "standing", "push", "walk", "arm", "pull", "standing", "arm", "pull", "walk", "torso", "push", "standing", "torso", "push", "walk", "14", "walk", "turn", "character", "respond", "realistically", "small", "moderate", "disturbance", "even", "dataset", "which", "only", "contain", "non-pushed", "motion", "capture", "dataset", "push", "datum", "we", "observe", "wider", "variety", "realistic", "response", "better", "handling", "larger", "disturbance", "force", "apply", "different", "part", "character?s", "body", "generally", "result", "appropriate", "reaction", "from", "character", "even", "presence", "user", "control", "we", "have", "however", "observe", "some", "case", "where", "force", "produce", "unrealistic", "motion", "occur", "when", "character", "push", "state", "far", "from", "datum", "reasonable", "response", "can", "address", "include", "more", "datum", "push", "motion", "just", "any", "other", "data-driven", "method", "we", "method", "limit", "datum", "give", "so", "long", "character", "remain", "close", "datum", "synthesize", "motion", "appear", "very", "realistic", "when", "character", "far", "from", "datum", "realism", "physical", "plausibility", "motion", "decline", "although", "always", "limit", "presence", "datum", "we", "expect", "range", "plausible", "motion", "can", "extend", "incorporation", "concept", "from", "physical", "dynamics", "-lrb-", "inertia", "gravity", "etc.", "-rrb-", "integration", "process", "we", "have", "successfully", "generate", "controller", "two-dimensional", "near-optimal", "control", "problem", "use", "moderate-sized", "motion", "database", "order", "technique", "scale", "much", "larger", "set", "motion", "datum", "all", "possible", "task", "current", "time", "space", "performance", "algorithm", "need", "improve", "although", "we", "have", "present", "technique", "which", "allow", "storage", "requirement", "we", "method", "reduce", "-lrb-", "section", "4.2.2", "-rrb-", "high", "level", "compression", "controller?s", "agility", "degrade", "graph-based", "controller", "we", "find", "value", "function", "locomotion", "task", "generally", "smooth", "both", "space", "time", "we", "expect", "more", "advanced", "compression", "technique", "can", "effectively", "enable", "motion", "flow", "more", "complicated", "control", "task", "massive", "datum", "set", "one", "particularly", "interesting", "possibility", "would", "apply", "motion", "field-based", "analogue", "-lsb-", "Lee", "et", "al.", "2009", "-rsb-", "which", "would", "adaptively", "select", "compact", "representation", "while", "preserve", "controller?s", "behavior", "we", "have", "choose", "k-nn", "rather", "than", "radius", "search", "define", "-lrb-", "-rrb-", "because", "lead", "more", "predictable", "runtime", "performance", "even", "case", "significant", "redundant", "datum", "so", "long", "just", "one", "neighbor", "go", "desire", "direction", "optimal", "control-based", "action", "selection", "choose", "none", "less", "although", "we", "have", "observe", "possible", "highly", "redundant", "datum", "set", "-lrb-", "-rrb-", "won?t", "provide", "sufficient", "variety", "action", "intelligently", "select", "which", "motion", "state", "include", "motion", "database", "likely", "necessary", "use", "we", "technique", "large", "unprocessed", "motioncapture", "corpus", "because", "we", "make", "heavy", "use", "k-nearest", "neighbor", "lookup", "interpolation", "we", "method", "more", "expensive", "runtime", "than", "graphbased", "approach", "none", "less", "we", "have", "find", "even", "we", "unoptimized", "implementation", "run", "approximately", "200", "frame", "per", "sec", "ond", "further", "efficiency", "improvements?such", "incremental", "nearest", "neighbor", "searches?are", "interesting", "avenue", "research", "would", "allow", "large", "crowd", "character", "animated", "well", "enable", "motion", "field", "which", "have", "very", "large", "set", "action", "each", "state", "one", "final", "current", "limitation", "motion", "field", "lie", "lack", "wellunderstood", "tool", "analyze", "edit", "they", "contrast", "motion", "graph", "which", "can", "rely", "extremely", "well-understood", "set", "algorithm", "manipulate", "graph", "develop", "over", "many", "decade", "although", "we", "have", "find", "pruning", "necessary", "we", "controller", "sort", "task", "which", "we", "do", "yet", "have", "good", "tool", "context", "motion", "field", "paper", "introduce", "new", "representation", "character", "motion", "control", "allow", "realtime-controlled", "motion", "flow", "through", "continuous", "configuration", "space", "character", "pose", "flow", "can", "alter", "response", "realtime", "user-supplied", "task", "due", "its", "continuous", "nature", "address", "some", "key", "issue", "inherent", "discrete", "nature", "graph-like", "representation", "include", "agility", "responsiveness", "ability", "from", "arbitrary", "pose", "response", "perturbation", "furthermore", "representation", "require", "preprocessing", "datum", "determine", "where", "connect", "clip", "capture", "datum", "make", "we", "approach", "both", "flexible", "easy", "implement", "easy", "use", "we", "believe", "structureless", "technique", "one", "we", "propose", "provide", "valuable", "tool", "enable", "highly", "responsive", "interactive", "character", "require", "create", "believable", "virtual", "character", "although", "motion", "field", "representation", "can", "use", "itself", "we", "think", "can", "easily", "integrate", "graph-based", "approach", "since", "motion", "field", "make", "very", "few", "requirement", "underlie", "datum", "can", "directly", "augment", "graph-based", "representation", "way", "one", "could", "reap", "benefit", "graph", "-lrb-", "computational", "efficiency", "ease", "analysis", "etc.", "-rrb-", "when", "motion", "can", "safely", "restrict", "lie", "graph", "retain", "ability", "handle", "case", "where", "motion", "leave", "graph", "-lrb-", "instance", "due", "perturbation", "-rrb-", "when", "extreme", "responsiveness", "requry", "more", "generally", "we", "feel", "motion", "field", "provide", "valuable", "start", "point", "motion", "representation", "which", "wish", "move", "beyond", "rigidly", "structure", "notion", "state", "we", "believe", "structureless", "motion", "techniques?such", "ours?have", "potential", "significantly", "improve", "realism", "responsiveness", "virtual", "character", "applicability", "animation", "problem", "continue", "improve", "better", "distance", "metric", "integration", "technique", "more", "efficient", "search", "representation", "method", "develop", "work", "support", "UW", "Animation", "Research", "Labs", "Weil", "Family", "Endowed", "Graduate", "Fellowship", "UW", "Center", "Game", "Science", "Microsoft", "Intel", "Adobe", "Pixar" ],
  "content" : "The representation organizes motion data as samples in a high dimensional generalization of a vector field we call a ?motion field?. Furthermore, since our approach requires very little structure in the motion capture data that it uses, minimal effort is needed to generate a new controller. Hence, even when the method anticipates some user inputs [McCann and Pollard 2007], the character may react too slowly, or transition too abruptly because there is no shorter path in the graph. These models are used to estimate a single ?most likely? motion for the character to take at each possible state. This allows us to interactively control the character while enjoying the benefits of a fully continuous state space. Although our controllers are kinematic, dynamic controllers have been extensively explored as an alternative method of character animation. Despite a broad repertoire of demonstrated skills [Hodgins et al. 1995; Hodgins and Pollard 1997; Wooten and Hodgins 2000; Faloutsos et al. 2001; Yin et al. 2007; Coros et al. 2008b], nonparametric modeling of coarse-scale dynamics [Coros et al. 2009; Coros et al. 2008a], and use of motion capture [Laszlo et al. 1996; Sok et al. 2007; da Silva et al. 2008; Muico et al. 2009], agile, lifelike, fully-dynamic characters remain an open challenge. Interactive applications such as video games require characters that can react quickly to user commands and unexpected disturbances, all while maintaining believability in the generated animation. Although it is infeasible to completely model the entire space of natural character motion, we can use motion capture data as a local approximation. We propose a structure called a motion field that finds and uses motion capture data similar to the character?s current motion at any point. By consulting similar motions to determine which future behaviors are plausible, we ensure that our synthesized animation remains natural: similar, but rarely identical to the motion capture data. This frees the character from simply replaying the motion data, allowing it to move freely through the general vicinity of the data. A pose x = (x root , p 0 , p 1 , . . . , p n ) consists of a 3d root position vector x root , a root orientation quaternion p 0 and joint orientation quaternions p 1 , . . . p n . The root point is located at the pelvis. A velocity v = (v root , q 0 , q 1 , . . . , q n ) consists of a 3d root displacement vector v root , root displacement quaternion q 0 , and joint displacement quaternions q 1 , . . . , q n , all found via finite differences. Given two poses x and x , we can compute this finite  difference as: v = x x = ` x root ? x root , p 0 p ?1 , p 1 p ?1 1 , . . . , p n p ?1 n  ? By inverting the above difference, we can add a velocity v to a pose x to get a new displaced pose x = x ? v. The set of all possible motion states forms a high dimensional continuous space, where every point represents the state of our character at a single instant in time. A path or trajectory through this space represents a continuous motion of our character. When discussing dynamic systems, this space is usually called the phase space. However, because our motion synthesis is kinematic, we use the phrase motion space instead to avoid confusion. Motion Database Our approach takes as input a set of motion capture data and constructs a set of motion states {m i } n i=1 termed a motion database. Each state m i in this database is constructed from a pair of successive frames x i and x i+1 by the aforementioned method of m i = (x i , v i ) = (x i , x i+1 x i ). We also compute and store the velocity of the next pair of frames, computed by y i = x i+2 x i+1 . Generally, motions states, poses and velocities from the database will be subscripted (e.g. m i , x i , v i , and y i ), while arbitrary states, poses and velocities appear without subscripts. Similarity and neighborhoods Central to our definition of a motion field is the notion of the similarity between motion states. Given a motion state m, we compute a neighborhood N (m) = {m i } k i=1 of the k most similar motion states via a k-nearest neighbor query over the database [Mount and Arya 1997]. In our tests we use k = 15. We calculate the (dis-)similarity by: In our experiments, we set ? i as bone lengths of the body at the joint i in meters, ? root and ? 0 are set to 0.5. Note that we factor out root world position and root yaw orientation (but not their respective velocities). Similarity Weights Since we allow the character to deviate from motion states in the database, we frequently have to interpolate data from our neighborhood N (m). Actions The value of a motion field at a motion state m is a set of control actions A(m) determining which states the character can transition to in a single frame?s time. Each of these actions a ? A(m) specifies a convex combination of neighbors a = [a 1 , . . . , a k ] (with P a i = 1 and a i > 0). Unfortunately, this function frequently causes to our character?s state to drift off into regions where we have little data about how the character should move, leading to unrealistic motions. To correct for this problem, we use a small drift correction term that constantly tugs our character towards the closest known motion state m  ? = ( x, v) in the database. The strength of this tug is controlled by a parameter ? = 0.1 This question is primarily the subject of section 4. 2) as our choice of action. This choice results in the character meandering through the data, generating streams of realistic (albeit undirected) human motion. Foot-Skate Cleanup The result of motion synthesis might contain foot-skating artifacts. We remove these artifacts by applying inverse kinematics on the contact foot. To do this, we first annotate foot contacts in the motion data. For every motion state m i in the database, we store whether the left foot is in contact l contact (m i ) = 1 or not l contact (m i ) = 0, and likewise for the right foot r contact (m i ). When the foot leaves contact, we blend out of the inverse kinematics solution that holds the foot in place during contact, within 0.2 seconds. By reweighting the neighbors (black dots) of our current state (white dot), we can control motion synthesis to direct our character towards different next states (dashed dots). In general, which particular action from this set it is best to choose depends on the user?s current commands. Deciding on which action to choose in each state in response to a user?s commands is thus key in enabling real time interactive locomotion controllers. A Markov decision process is a mathematical structure formalizing the concept of making decisions in light of both their immediate and long-term results. By expressing character animation tasks in this framework, we make our characters aware of long term consequences of their actions. This is useful even in graph-based controllers, but vital for motion field controllers because we are acting every frame rather than every clip. For further background on MDP-based control see [Sutton and Barto 1998], or [Treuille et al. 2007] and [Lo and Zwicker 2008] for their use in graph-based locomotion controllers. States Simply representing the state of a character as a motion state m is insufficient for interactive control, because we must also represent how well the character is achieving its user-specified task. We therefore add a vector of task parameters ? T to keep track of how well the task is being performed, forming joint task states s = (m, ? T ). For instance in our direction following task ? T records a single number: the angular deviation from the desired heading. By altering this value, the user controls the character?s direction. There are infinitely many different actions in A(m), but many of the techniques used to solve MDPs require a finite set of actions at each state. In order to satisfy this requirement for our MDP controller, we sample a finite set of actions A(s) from A(m). Each action is designed to prefer one neighbor over the others. In words, to derive action a i simply set w i to 1 and renormalize. This scheme samples actions which are not too different from the passive action at m so as to as to avoid jerkiness in the motion, while giving the character enough flexibility to move towards nearby motion states. How to update task parameters is normally obvious. For instance in the direction following task, where ? T is the characters deviation from the desired direction, we simply adjust ? T by the angle the character turned. Rewards In order to make our character perform the desired task we offer rewards. Formally, a reward function specifies a real number R(s, a) quantifying the reward received for performing the action a at state s. For instance, in our direction following task we give high a high reward R(s, a) for maintaining a small deviation from the desired heading and a lower reward for large deviations. See section Section 6 for the specific task parameters and reward functions we use in our demos. Although simple, this policy is myopic, ignoring the future ramifications of each action choice. We already know that greedy graphbased controllers perform poorly [Treuille et al. 2007]. Motion fields are even worse. Even for the simple task of changing direction, we need a much longer horizon than 1 th of a second to 30 anticipate and execute a turn. A lookahead policy ? L does just this by considering the cumulative reward over future task states: with s 1 = I s (s, a) and s t = I s (s t?1 , a t?1 ). ? is called the discount factor and controls how much the character focuses on short term (? ? 0) versus long term (? ? 1) reward. Despite this apparent impracticality, a standard trick allows us to efficiently solve for the correct next action. The trick begins by defining a value funciton V (s), a scalar-valued function representing the expected cumulative future reward received for acting optimally starting from task state s. Now the lookahead policy is only marginally more expensive to compute than the greedy policy. We choose these task state samples by taking the Cartesian product of the database motion states m i and a uniform grid sampling across the problem?s task parameters. See Section 6 for details of the sampling. This sampling gives us high resolution near the motion database states, (A) At every state, we have several possible actions (dashed lines) and their next states (dashed circles). (B) We interpolate the value function stored at database states (black points) to determine the value of each next state. (C) We select the highest value action to perform. which is where the character generally stays. Given an MDP derived from a motion field and a task specification, we solve for an approximate value function in this form using fitted value iteration [Ernst et al. 2005]. We express the value at a task state sample s i recursively in terms of the value at other task state samples: We can solve for V (s i ) at each sample state by iteratively applying equations 12 and 13. We begin with an allzero value function V 0 (s i ) = 0 for each sample s i . Then at each s i equation 12 is used to compute ? L (s) after which we use equation 13 to determine an updated value at s i . After all the s i samples have been processed in this manner, we have an updated approximation of the value function. We repeat this process until convergence and use the last iteration as the final value function. Unlike graph-based approaches, motion fields let characters be in constant transition between many sources of data. Consequently, we need access to the value function at all motion states, rather than only at transitions between clips. This fact leads to a large memory footprint relative to graphs. We offset this weakness with compression. For the purpose of compression, we want to think of our value function as a collection of value functions of task parameters. Without compression, we store one of these value sub-functions V m i (? T ) = V (m i , ? T ) at every database motion state m i (see Figure 3 ). At 30Hz temporally adjacent motion states and their value functions are frequently similar; we expect that V m t changes smoothly over ?consecutive? motion states m t relative to the original clip time. We call these database states storing value functions ?anchor? motion states. We compute the value function at the ith motion state between two anchors m 0 and m N as We can learn a temporally compressed value function with a trivially modified form of the algorithm given in section 4.2.1. Instead of iterating over all task states, we only iterate over those states associated with anchor motion states. This technique allows the tradeoff between the agility of a motion field-based controller and its memory requirements. Performing little or no temporal interpolation yields very agile controllers at the cost of additional memory, while controllers with significant temporal compression tend to be less agile. In our experiments we found that motion field controllers with temporal compression are approximately as agile as graph-based controllers when restricted to use an equivalent amount of memory, and significantly more agile when using moderately more memory (see Section 6). Because each motion state consists of a pose and a velocity, the space of motion states the character can occupy is identical to the phase space of the character treated as a dynamic system. This identification allows us to easily apply arbitrary physical or nonphysical perturbations and adjustments. For example, we can incorporate a dynamics engine or inverse kinematics. Recovery occurs automatically and simultaneously with the perturbation as a by-product of our motion synthesis and control algorithm. To illustrate the integration of perturbations into our synthesis algorithm, we describe a simple technique which provides pseudophysical interaction with the ability to apply forces to any part of the body. This approach blends the results obtained by a physical simulator with the results of our motion synthesis technique. This blend occurs over a window of k update steps, beginning when a set of forces is first applied. (We set k = 20 i.e. 2/3 of a second in our implementation.) During this blending phase, we use a modified integration formula (Equation (4)): where D(x, 0, i) is the state after i steps of dynamic simulation starting at pose x with initial velocity 0. I D can be used in conjunction with both passive and controlled motion fields. In our implementation we use Open Dynamics Engine (ODE, [Smith 2010]) to calculate D(x, 0, i). At each of the next k frames after a force is applied we set the state of the character in ODE to x with zero initial velocity. We then apply any perturbation forces and simulate the resulting dynamics for i frames with gravity disabled. This setup (with zero initial velocity and no gravity) has the useful property that in the absence of any perturbation forces the character?s pose x goes unaltered. In order to better mimic the way in which an actual person would ?tip? about their feet when pushed we also pin any contacting feet to the ground with ball joints during this simulation. As a result, velocities do not transfer correctly between multiple quick pushes. In addition, because I(x, v, a) does not handle velocity in the same manner as a dynamical system, our perturbation method is not physically accurate, but rather a heuristic which gives plausible-looking results. This section presents analysis on two important properties of motion fields ? agility in responding to user directive changes and ability to respond to dynamic perturbation. We created value functions for two example tasks: following an arbitrary user-specified direction and staying on a straight line while following the user direction. (See Figure 6 ). The reward R direction for the direction task and the reward R line for the line following task are respectively defined as Motion Data Setup We used 142 seconds of motion data containing leisurely-paced locomotion and quick responses to direction facing direction is used. For the line following task (b), distance to the desired line d L is also considered with ? c . Objective Graph Motion Based Field from Deviation Angular Time Elapsed Direction adjustment over time with three consecutive direction changes within 4.23 seconds. The motion field control adjusts in a significantly shorter time period than the graph-based control. and line changes. We selected the source motion data with minimum care except to roughly cover the space of possible motion. The only manual pre-processing was foot contact annotation. Value Function Computation We use value iteration to calculate the value function. For the direction task, we store values for 18 uniformly sampled directions ? c . For the line following task, we take a Cartesian cross product sampling between 18 uniform ? c samples and 13 uniform d L samples spanning -2.0m to 2.0m. We set the discount factor to ? = 0.99. For each task, we also created ?temporally compressed? versions of the value functions, where we set N = 1, 10, 20, 30 in equation 14. Using value iteration to solve for the value function takes within 2 minutes if there is sufficient memory to cache the actions and transitions, and 3 hours otherwise. Distributing the value iteration updates over compute clusters can easily address these time and memory burdens. (See Lee et al. [2009] for details.) Figure 7 shows typical responses to changing user directions. For both tasks, the motion fields demonstrated much quicker convergence to new goals, as shown in the accompanying video and the Table 1 . Effect of Value Function Compression We recorded response times using the compressed value functions on uniformly sampled user direction changes. With increasing degree of compression the\n            Representation Minimum Average Maximum Graph-based 0.31 0.94 2.36 Motion Field 0.21 0.40 1.01 Motion Field ?10 0.21 0.49 1.23 Motion Field ?20 0.25 0.66 1.19 Motion Field ?30 0.38 0.78 1.93 system still reliably achieved user goals, but gradually lost agility in the initial response (See Table 1 ). We ran a similar experiment for the line following task. We uniformly sampled user direction changes as well as line displacement changes. Then we measured the time until the character converged to within 5 degrees from the desired direction and 0.1 meters from the desired tracking line. We observed similar losses of agility (See Table 2 ). The uncompressed value function for the direction-following task is stored in 320KB. The compressed value functions required 35KB, 19KB, and 13KB for 10x, 20x, and 30x cases respectively. This compares to the storage required for the graph-based method of 14KB. We believe this is reasonable and allows flexible trade off between storage and agility. For more complex tasks, the size increase of the value functions are in line with the size increased for graph-based value functions. The runtime performance depends on the sample action size k (Equation (8)), as we make (k + 1) ANN calls to find the optimal action: one ANN call to find the neighbors of the current state, and then k more ANN calls to find the neighbors of the next states to evaluate value by interpolation. We believe localized neighborhood search as in PatchMatch [Barnes et al. 2009] can reduce the cost of the n subsequent calls, because the next states tend to be quite close to each other at 30Hz. The same ANN overhead applies at learning time. A naive learning implementation takes hours to learn a value function for a large database or a high dimensional task. By caching the result of the ANN calls on the fixed motion samples, we can dramatically speed up learning time to just a couple minutes. Using the algorithm described in section 5 we integrated pseudophysical interaction with motion field driven synthesis, using both passive and controlled motion fields. We tested the perturbations on the following four datasets: 1. 18 walks, including sideways, backwards, and a crouch. dataset 1 plus 7 walking pushes and 7 standing pushes. 5 walks, 6 arm pulls on standing, 6 arm pulls on walking, 7 torso pushes on standing, and 7 torso pushes on walking. 14 walks and turns. The character responds realistically to small or moderate disturbances, even in datasets 1 and 4 which only contain non-pushed motion capture. In datasets 2 and 3 with pushed data, we observe a wider variety of realistic responses, and better handling of larger disturbances. Forces applied to different parts of the character?s body generally result in appropriate reactions from the character, even in the presence of user control. We have, however, observed some cases where forces produced unrealistic motion. This occurs when the character is pushed into a state far from data with a reasonable response. This can be addressed by including more data for pushed motion. Just as with any other data-driven method, our method is limited by the data it is given. So long as the character remains close to the data the synthesized motion appears very realistic. When the character is far from the data, realism and physical plausibility of the motion declines. Although always limited by the presence of data, we expect that the range of plausible motion can be extended by an incorporation of concepts from physical dynamics (inertia, gravity, etc.) into the integration process. We have successfully generated controllers for two-dimensional near-optimal control problems using a moderate-sized motion database. In order for this technique to scale to much larger sets of motion data and all possible tasks, the current time and space performance of the algorithm needs to be improved. Although we have presented a technique which allows the storage requirements of our method to be reduced (section 4.2.2) at high levels of compression the controller?s agility degrades to that of graph-based controllers. As we find the value functions for locomotion tasks are generally smooth both in space and time, we expect that more advanced compression techniques can effectively enable motion flows on more complicated control tasks on massive data sets. One particularly interesting possibility would be to apply a motion field-based analogue of [Lee et al. 2009] which would adaptively select a compact representation while preserving the controller?s behavior. We have chosen k-NN rather than a radius search to define N (m) because it leads to more predictable runtime performance. Even in cases with significant redundant data, so long as just one of the k neighbors goes in a desired direction, the optimal control-based action selection will choose it. None the less, although we have not observed it, it is possible that in highly redundant data sets N (m) won?t provide a sufficient variety of actions. Intelligently selecting which motion states to include in the motion database is will likely be necessary to use our technique with large unprocessed motioncapture corpuses. Because we make heavy use of k-nearest neighbors lookups and interpolation, our method is more expensive at runtime than graphbased approaches. None the less, we have found that even our unoptimized implementation runs at approximately 200 frames per sec ond. Further efficiency improvements?such as incremental nearest neighbor searches?are an interesting avenue of research. This would allow for large crowds of characters to be animated as well as enable motion fields which have very large sets of actions at each state. One final current limitation of motion fields lies in the lack of wellunderstood tools to analyze and edit them. This is in contrast to motion graphs, which can rely on an extremely well-understood set of algorithms for manipulating graphs developed over many decades. Although we have not found this pruning to be necessary in our controllers, this is the sort of task for which we do not yet have good tools in the context of motion fields. This paper introduces a new representation for character motion and control that allows realtime-controlled motion to flow through the continuous configuration space of character poses. This flow can altered in response to realtime user-supplied tasks. Due to its continuous nature, it addresses some of the key issues inherent to the discrete nature of graph-like representations, including agility and responsiveness, the ability to start from an arbitrary pose, and response to perturbations. Furthermore, the representation requires no preprocessing of data or determining where to connect clips of captured data. This makes our approach both flexible, easy to implement, and easy to use. We believe that structureless techniques such as the one we propose will provide a valuable tool in enabling the highly responsive and interactive characters required to create believable virtual characters. Although the motion field representation can be used by itself, we think it can easily integrate with graph-based approaches. Since motion fields make very few requirements of their underlying data, they can directly augment graph-based representations. In this way, one could reap the benefits of graphs (computational efficiency, ease of analysis, etc.) when the motion can safely be restricted to lie on the graph, but retain the ability to handle cases where the motion leaves the graph (for instance due to a perturbation), or when extreme responsiveness is requried. More generally, we feel that motion fields provide a valuable starting point for motion representations which wish to move beyond a rigidly structured notion of state. We believe that structureless motion techniques?such as ours?have the potential to significantly improve the realism and responsiveness of virtual characters, and that their applicability to animation problems will continue to improve as better distance metrics, integration techniques, and more efficient search and representation methods are developed. This work was supported by the UW Animation Research Labs, Weil Family Endowed Graduate Fellowship, UW Center for Game Science, Microsoft, Intel, Adobe, and Pixar.",
  "resources" : [ ]
}