{
  "uri" : "sig2011-a69-gastal_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2011/a69-gastal_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Domain Transform for Edge-Aware Image and Video Processing",
    "published" : "2011",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Eduardo S. L.-Gastal",
      "name" : "Eduardo S. L.",
      "surname" : "Gastal"
    }, {
      "uri" : "http://drinventor/Manuel M.-Oliveira",
      "name" : "Manuel M.",
      "surname" : "Oliveira"
    } ]
  },
  "bagOfWords" : [ "we", "present", "new", "approach", "perform", "high-quality", "edgepreserving", "filter", "image", "video", "real", "time", "transform", "preserve", "geodesic", "distance", "between", "point", "curve", "adaptively", "warp", "input", "signal", "so", "1d", "edge-preserving", "filter", "can", "efficiently", "perform", "linear", "time", "we", "demonstrate", "three", "realization", "1d", "edge-preserving", "filter", "show", "how", "produce", "high-quality", "2d", "edge-preserving", "filter", "iterate", "1d-filtering", "operation", "empirically", "analyze", "convergence", "process", "we", "demonstrate", "versatility", "we", "domain", "transform", "edge-preserving", "filter", "several", "real-time", "image", "video", "processing", "task", "include", "edgepreserve", "filter", "depth-of-field", "effect", "stylization", "recoloring", "colorization", "detail", "enhancement", "tone", "mapping", "we", "present", "new", "approach", "efficiently", "perform", "edgepreserve", "filter", "image", "video", "address", "main", "limitation", "previous", "technique", "preserve", "geodesic", "distance", "between", "point", "curve", "adaptively", "warp", "input", "signal", "so", "1d", "edge-preserving", "filter", "can", "efficiently", "perform", "linear", "time", "we", "demonstrate", "three", "realization", "we", "1d", "edge-preserving", "filter", "base", "normalize", "convolution", "interpolate", "convolution", "recursion", "finally", "although", "we", "1d", "filter", "can", "exactly", "generalize", "higher", "dimension", "we", "show", "how", "use", "they", "efficiently", "produce", "high-quality", "2d", "edge-preserving", "filter", "instance", "can", "filter", "one", "megapixel", "color", "image", "0.007", "seconds", "GPU", "Third", "first", "edge-preserving", "technique", "capable", "work", "color", "image", "arbitrary", "scale", "real", "time", "without", "resort", "subsampling", "quantization", "we", "demonstrate", "versatility", "we", "domain", "transform", "edgepreserve", "filter", "several", "real-time", "image", "video", "processing", "task", "include", "edge-preserving", "smoothing", "depth-of-field", "effect", "stylization", "recoloring", "colorization", "detail", "enhancement", "tone", "mapping", "-lrb-", "section", "-rrb-", "example", "some", "effect", "can", "see", "Figure", "apply", "photograph", "show", "far", "left", "we", "approach", "lead", "filter", "several", "desirable", "feature", "significant", "speed-up", "over", "exist", "technique", "technique", "perform", "anisotropic", "edge-preserving", "filter", "curve", "2d", "image", "manifold", "use", "1d", "linear", "filter", "consist", "anisotropically", "scale", "curve", "which", "map", "real", "line", "use", "isometry", "follow", "application", "1d", "linear", "filter", "-lrb-", "section", "-rrb-", "technique", "efficiently", "implement", "2d", "edge-preserving", "smoothing", "filter", "sequence", "1d", "filter", "operation", "-lrb-", "section", "-rrb-", "we", "show", "example", "approximate", "gaussian", "exponential", "response", "-lrb-", "section", "-rrb-", "demonstration", "we", "approach", "can", "use", "create", "variety", "effect", "image", "video", "real", "time", "-lrb-", "section", "-rrb-", "exist", "method", "able", "produce", "good", "result", "many", "practical", "scenario", "edge-aware", "filter", "available", "several", "image-processing", "application", "-lsb-", "Kimball", "et", "al.", "2011", "Adobe", "Systems", "Inc.", "-lrb-", "2d", "-rrb-", "rgb", "image", "can", "interpret", "operating", "5d", "space", "-lsb-", "Barash", "2002", "-rsb-", "porikli", "-lsb-", "2008", "-rsb-", "extend", "idea", "use", "sum", "area", "table", "filter", "each", "intensity", "level", "Yang", "et", "al.", "-lsb-", "2009", "-rsb-", "further", "extend", "arbitrary", "kernel", "simplify", "version", "method", "show", "perform", "real-time", "gpus", "three-dimensional", "-lrb-", "grayscale", "-rrb-", "bilateral", "filter", "-lsb-", "Chen", "et", "al.", "2007", "-rsb-", "Adams", "et", "al.", "-lsb-", "2010", "-rsb-", "propose", "use", "uniform", "simplice", "efficiently", "implement", "color", "bilateral", "filter", "5d", "all", "approach", "accelerate", "bilateral", "filter", "derive", "performance", "from", "use", "quantization", "downsampling", "lead", "runtime", "and/or", "memory", "cost", "inversely", "proportional", "kernel", "size", "define", "over", "space", "-lrb-", "-rrb-", "range", "-lrb-", "-rrb-", "result", "performance", "severely", "affect", "use", "small", "value", "-lrb-", "require", "enforce", "edge", "preservation", "-rrb-", "-lrb-", "need", "small", "amount", "blur", "-rrb-", "finally", "Pham", "Vliet", "-lsb-", "2005", "-rsb-", "implement", "bilateral", "filter", "separable", "operation", "multiscale", "representation", "can", "quickly", "compute", "constrain", "size", "smoothing", "kernel", "-lrb-", "pixel", "-rrb-", "power", "two", "Criminisi", "et", "al.", "-lsb-", "2010", "-rsb-", "present", "geodesic", "framework", "edge-aware", "filter", "define", "grayscale", "image", "employ", "quantization", "luma", "channel", "finally", "Farbman", "et", "al.", "-lsb-", "2010", "-rsb-", "propose", "use", "diffusion", "distance", "calculate", "affinity", "among", "pixel", "which", "can", "seamlessly", "integrate", "we", "approach", "can", "understand", "reduce", "dimensionality", "input", "signal", "prior", "filter", "Lee", "Verleysen", "-lsb-", "2010", "-rsb-", "present", "comprehensive", "survey", "dimensionality-reduction", "technique", "we", "approach", "inspire", "multi-dimensional", "interpretation", "edge-preserving", "filter", "-lsb-", "Barash", "2002", "-rsb-", "let", "2d", "rgb", "color", "image", "define", "2d", "manifold", "-lsb-", "Kimmel", "et", "al.", "1997", "-rsb-", "also", "let", "-lrb-", "-rrb-", "point", "manifold", "let", "-lrb-", "-rrb-", "edge-preserving", "filter", "kernel", "5d", "image", "obtain", "when", "filter", "can", "express", "where", "-lrb-", "-rrb-", "dq", "where", "norm", "typically", "gaussian", "spatial", "range", "filter", "support", "give", "respectively", "since", "bilateral", "filter", "work", "5d", "space", "its", "naive", "implementation", "too", "slow", "many", "practical", "use", "Problem", "Statement", "we", "work", "address", "fundamental", "question", "whether", "exist", "transformation", "filter", "kernel", "define", "over", "any", "input", "image", "produce", "equivalent", "result", "5d", "edge-preserving", "kernel", "construction", "become", "attractive", "when", "evaluate", "plus", "more", "efficient", "than", "evaluate", "original", "kernel", "we", "case", "we", "interested", "replace", "evaluation", "computationally", "expensive", "edge-preserving", "filter", "define", "5d", "domain", "transformation", "lower-dimensional", "linear", "filter", "evaluate", "euclidean", "space", "-lrb-", "-rrb-", "transformation", "preserve", "original", "distance", "from", "also", "maintain", "edge-preserving", "property", "filter", "define", "lowerdimensional", "space", "let", "we", "consider", "case", "map", "grayscale", "image", "plane", "which", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "center", "-rrb-", "Arc", "length", "from", "-lrb-", "right", "-rrb-", "involve", "find", "isometry", "we", "purpose", "edge-aware", "filter", "preserve", "distance", "among", "pixel", "essential", "furthermore", "exist", "approach", "from", "dimensionalityreduction", "-lsb-", "Belkin", "Niyogi", "2003", "-rsb-", "texture-mapping", "-lsb-", "l?vy", "et", "al.", "2002", "-rsb-", "literature", "use", "optimization", "method", "which", "too", "slow", "we", "use", "real-time", "edge-preserving", "filter", "while", "solution", "2d", "domain", "do", "exist", "general", "section", "show", "isometric", "transform", "exist", "1d", "domain", "section", "show", "how", "1d", "transform", "can", "effectively", "use", "filter", "2d", "color", "image", "derive", "isometric", "1d", "transform", "let", "-lsb-", "-rrb-", "1d", "signal", "which", "define", "curve", "graph", "-lrb-", "-lrb-", "-rrb-", "-rrb-", "-lrb-", "figure", "leave", "-rrb-", "thus", "let", "-lcb-", "...", "-rcb-", "sampling", "where", "+1", "some", "sampling", "interval", "we", "seek", "transform", "satisfy", "-lrb-", "-lrb-", "-rrb-", "-rrb-", "-lrb-", "-lrb-", "-rrb-", "-rrb-", "-lrb-", "-lrb-", "-rrb-", "-rrb-", "-lrb-", "-lrb-", "-rrb-", "-rrb-", "where", "absolute", "value", "operator", "some", "choose", "metric", "simplicity", "we", "use", "nearest-neighbor", "norm", "thus", "only", "need", "preserve", "distance", "between", "neighbor", "sample", "+1", "we", "soon", "show", "choice", "give", "rise", "geodesic", "metric", "finally", "let", "ct", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-lrb-", "-rrb-", "-rrb-", "avoid", "need", "absolute", "value", "operator", "left", "-lrb-", "-rrb-", "we", "constrain", "ct", "monotonically", "increase", "i.e.", "ct", "-lrb-", "-rrb-", "ct", "-lrb-", "-rrb-", "divide", "both", "side", "-lrb-", "-rrb-", "take", "limit", "we", "obtain", "where", "ct", "-lrb-", "-rrb-", "denote", "derivative", "ct", "-lrb-", "-rrb-", "respect", "x.", "integrate", "-lrb-", "-rrb-", "both", "side", "let", "ct", "-lrb-", "-rrb-", "we", "get", "intuitively", "ct", "unfold", "curve", "define", "-lrb-", "figure", "leave", "-rrb-", "while", "preserve", "distance", "among", "neighbor", "sample", "moreover", "any", "two", "point", "distance", "between", "they", "new", "domain", "give", "transformation", "give", "equation", "preserve", "geodesic", "distance", "between", "all", "point", "curve", "Multichannel", "signal", "edge-preserving", "filter", "important", "process", "all", "channel", "input", "signal", "once", "process", "they", "independently", "should", "introduce", "artifact", "around", "edge", "-lsb-", "tomasus", "Manduchi", "1998", "-rsb-", "1d", "signal", "channel", "define", "curve", "+1", "one", "can", "apply", "similar", "derivation", "obtain", "multichannel", "transformation", "where", "k-th", "channel", "signal", "case", "image", "can", "color", "channel", "some", "color", "space", "-lrb-", "e.g.", "RGB", "CIE", "Lab", "-rrb-", "more", "complex", "representation", "diffusion", "map", "-lsb-", "Farbman", "et", "al.", "2010", "-rsb-", "we", "call", "ct", "domain", "transform", "equation", "reduce", "evaluation", "domain", "filter", "from", "+1", "R.", "thus", "filter", "-lrb-", "see", "equation", "-rrb-", "one-dimensional", "since", "we", "transformation", "isometric", "any", "filter", "whose", "response", "decrease", "distance", "least", "fast", "edge-preserving", "section", "discuss", "some", "choice", "H.", "reduce", "dimensionality", "filter", "from", "may", "seem", "we", "lose", "ability", "control", "its", "support", "over", "signal?s", "space", "range", "-lrb-", "i.e.", "control", "value", "bilateral", "filter", "notation", "-rrb-", "we", "show", "one", "can", "encode", "value", "transformation", "itself", "give", "1d", "signal", "1d", "filter", "kernel", "-lrb-", "unit", "area", "-rrb-", "we", "can", "define", "-lrb-", "-rrb-", "-lrb-", "u/a", "-rrb-", "which", "stretches/shrinks", "1/a", "-lrb-", "??", "-rrb-", "-lrb-", "au", "??", "-rrb-", "which", "shrinks/stretches", "1/a", "renormalize", "unit", "area", "where", "translation", "??", "-lrb-", "-rrb-", "thus", "under", "convolution", "scale", "filter?s", "support", "1/a", "equivalent", "scale", "signal?s", "support", "-lrb-", "vice-versa", "-rrb-", "therefore", "encode", "filter?s", "support", "onto", "domain", "transform", "we", "-lrb-", "-rrb-", "derive", "each", "dimension", "signal", "from", "desire", "support", "filter", "over", "-lrb-", "ii", "-rrb-", "scale", "each", "its", "correspond", "-lrb-", "iii", "-rrb-", "apply", "domain", "transform", "scale", "signal", "-lrb-", "iv", "-rrb-", "filter", "signal", "1d", "use", "important", "observation", "since", "show", "support", "original", "multidimensional", "kernel", "can", "completely", "encode", "1d", "we", "refer", "desire", "variance", "filter", "over", "signal?s", "spatial", "domain", "over", "signal?s", "range", "-lcb-", "...", "-rcb-", "all", "channel", "k.", "obtain", "scaling", "factor", "scale", "property", "variance", "-lsb-", "Loeve", "1977", "-rsb-", "ar", "-lrb-", "1/a", "-rrb-", "ar", "-lrb-", "h/a", "-rrb-", "ar", "-lrb-", "-rrb-", "which", "solve", "where", "variance", "filter", "scaling", "factor", "spatial", "domain", "give", "note", "scaling", "factor", "may", "vary", "each", "dimension", "+1", "allow", "definition", "anisotropic", "filter", "1d", "result", "valid", "produce", "correct", "filter", "any", "value", "scale", "signal", "accord", "equation", "before", "can", "filter", "signal", "should", "scale", "prior", "evaluate", "domain", "transform", "since", "free", "parameter", "we", "let", "obtain", "we", "final", "domain", "transform", "where", "single", "value", "have", "be", "use", "all", "channel", "simplicity", "filter", "signal", "transform", "domain", "do", "through", "1d", "convolution", "H.", "further", "detail", "present", "section", "Figure", "illustrate", "use", "domain", "transform", "filter", "1d", "signal", "show", "-lrb-", "-rrb-", "its", "original", "domain", "-lrb-", "-rrb-", "show", "associated", "domain", "transform", "ct", "-lrb-", "-rrb-", "compute", "use", "equation", "11", "-lrb-", "-rrb-", "show", "signal", "transform", "domain", "more", "compactly", "-lrb-", "ct", "-lrb-", "-rrb-", "-rrb-", "-lrb-", "-rrb-", "result", "filter", "gaussian", "filter", "show", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "show", "desire", "filtered", "signal", "obtain", "reverse", "ct", "-lrb-", "-rrb-", "signal", "show", "-lrb-", "-rrb-", "smallscale", "variation", "be", "eliminate", "strong", "edge", "preserve", "section", "analyze", "filtering-related", "property", "we", "domain", "transform", "-lrb-", "equation", "11", "-rrb-", "ct", "-lrb-", "-rrb-", "apply", "1d", "signal", "its", "domain", "locally", "scale", "where", "summation", "over", "all", "channel", "have", "be", "omit", "simplicity", "accord", "equation", "scale", "input", "signal", "ct", "-lrb-", "-rrb-", "equivalent", "scale", "support", "filter", "1/ct", "-lrb-", "-rrb-", "thus", "amount", "local", "smoothing", "introduce", "signal", "-lrb-", "-rrb-", "can", "express", "smooth", "-lrb-", "-rrb-", "-lrb-", "ct", "-lrb-", "-rrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "13", "-rrb-", "use", "-lrb-", "13", "-rrb-", "we", "analyze", "relationship", "h?s", "response", "parameter", "well", "-lrb-", "-rrb-", "smooth", "smoothing", "-lrb-", "-rrb-", "smooth", "smoothing", "-lrb-", "-rrb-", "smooth", "smoothing", "-lrb-", "-rrb-", "when", "approach", "zero", "ct", "-lrb-", "-rrb-", "go", "infinity", "any", "filter", "compact", "support", "produce", "filtered", "signal", "identical", "input", "expect", "relationship", "interestingly", "approach", "infinity", "do", "produce", "unbounded", "smoothing", "image", "exactly", "what", "expect", "from", "edge-preserving", "filter", "when", "hold", "constant", "furthermore", "amount", "smoothing", "inversely", "proportional", "gradient", "magnitude", "signal", "which", "most", "commonly", "use", "estimator", "image", "edge", "finally", "when", "approach", "zero", "smoothing", "perform", "expect", "relationship", "when", "gradient", "magnitude", "input", "signal", "very", "large", "smoothing", "perform", "other", "hand", "region", "where", "gradient", "magnitude", "significant", "smoothing", "perform", "same", "response", "linear", "smoothing", "filter", "note", "both", "case", "we", "filter", "behave", "edge-preserving", "one", "equation", "11", "define", "domain", "transform", "1d", "signal", "ideally", "inherently", "2d", "transform", "ct", "-lrb-", "-rrb-", "should", "use", "2d", "signal", "directly", "map", "content", "position", "-lrb-", "-rrb-", "original", "domain", "position", "-lrb-", "-rrb-", "transform", "domain", "unfortunately", "discuss", "section", "ct", "-lrb-", "-rrb-", "-lrb-", "i.e.", "+2", "-rrb-", "do", "exist", "general", "-lsb-", "o?neill", "2006", "-rsb-", "since", "possible", "simultaneously", "satisfy", "all", "distance", "requirement", "use", "space", "higher-dimensionality", "would", "need", "imply", "additional", "computational", "memory", "cost", "avoid", "extra", "cost", "we", "use", "we", "1d", "transform", "perform", "2d", "filter", "image", "mean", "perform", "-lrb-", "horizontal", "-rrb-", "pass", "along", "each", "image", "row", "-lrb-", "vertical", "-rrb-", "pass", "along", "each", "image", "column", "-lsb-", "Smith", "1987", "Oliveira", "et", "al.", "2000", "-rsb-", "assume", "horizontal", "pass", "perform", "first", "vertical", "pass", "apply", "result", "produce", "vertical", "one", "-lrb-", "vice-versa", "-rrb-", "construction", "extensively", "use", "standard", "separable", "linear", "filter", "-lsb-", "Dougherty", "1994", "-rsb-", "anisotropic", "diffusion", "-lsb-", "Weickert", "et", "al.", "1998", "-rsb-", "also", "relate", "computation", "geodesic", "distance", "image", "manifold", "use", "raster-scan", "algorithm", "-lsb-", "Criminisi", "et", "al.", "2010", "-rsb-", "one", "caveat", "filter", "2d", "signal", "use", "1d", "domain", "transform", "separable", "operation", "otherwise", "would", "equivalent", "perform", "ct", "-lrb-", "-rrb-", "2d", "situation", "illustrate", "Figure", "where", "pixel", "belong", "same", "region", "-lrb-", "represent", "white", "-lrb-", "-rrb-", "-rrb-", "therefore", "should", "have", "information", "combine", "Figure", "-lrb-", "-rrb-", "show", "blue", "region", "reachable", "from", "after", "one", "horizontal", "pass", "-lrb-", "-rrb-", "after", "one", "complete", "iteration", "-lrb-", "assume", "horizontal", "pass", "perform", "first", "-rrb-", "region", "reachable", "from", "analogous", "reach", "entire", "white", "region", "after", "one", "iteration", "process", "may", "introduce", "visual", "artifact", "perceive", "stripe", "-lrb-", "indicate", "black", "arrow", "Figure", "-lrb-", "-rrb-", "-rrb-", "example", "one", "additional", "horizon", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "tal", "pass", "would", "need", "propagate", "p?s", "information", "entire", "white", "region", "thus", "eliminate", "stripe", "-lrb-", "figure", "-lrb-", "-rrb-", "-rrb-", "further", "pass", "do", "alter", "result", "-lrb-", "-rrb-", "require", "number", "horizontal", "vertical", "pass", "depend", "-lrb-", "geometry", "-rrb-", "image", "content", "therefore", "hard", "predict", "however", "we", "use", "two", "key", "observation", "make", "artifact", "unnoticeable", "filter", "image", "-lrb-", "-rrb-", "stripe", "only", "present", "along", "last", "filtered", "dimension", "horizontal", "-lrb-", "vertical", "-rrb-", "step", "remove", "stripe", "introduce", "previous", "vertical", "-lrb-", "horizontal", "-rrb-", "step", "-lrb-", "ii", "-rrb-", "length", "stripe", "proportional", "size", "filter", "support", "use", "last", "pass", "thus", "we", "interleave", "sequence", "vertical", "horizontal", "pass", "two", "1d", "filter", "use", "each", "iteration", "-lrb-", "consist", "vertical", "horizontal", "filter", "-rrb-", "have", "value", "half", "one", "use", "previous", "iteration", "progressively", "reduce", "extension", "artifact", "make", "they", "virtually", "unnoticeable", "practice", "three", "iteration", "usually", "suffice", "achieve", "good", "result", "-lrb-", "section", "5.1", "-rrb-", "during", "horizontal", "pass", "equation", "11", "partial", "derivative", "compute", "along", "row", "image", "while", "vertical", "pass", "represent", "partial", "derivative", "compute", "along", "image", "column", "since", "variance", "-lrb-", "standard", "deviation", "-rrb-", "add", "-lsb-", "Loeve", "1977", "-rsb-", "care", "must", "take", "when", "compute", "value", "each", "iteration", "we", "must", "use", "standard", "deviation", "halve", "each", "step", "whose", "square", "sum", "match", "original", "desire", "variance", "image", "result", "from", "i-th", "iteration", "use", "input", "-lrb-", "-rrb-", "th", "iteration", "domain", "transform", "ct", "-lrb-", "-rrb-", "compute", "only", "once", "-lrb-", "original", "image", "-rrb-", "use", "all", "different", "scale", "filter", "h.", "filtering", "diagonal", "edge", "-lrb-", "leave", "-rrb-", "Input", "image", "-lrb-", "1280", "960", "pixel", "-rrb-", "-lrb-", "center", "-rrb-", "filter", "image", "two", "iteration", "we", "two-pass", "1d", "filter", "-lrb-", "50", "0.5", "-rrb-", "-lrb-", "right", "-rrb-", "detail", "from", "filter", "image", "figure", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "illustrate", "result", "perform", "respectively", "one", "three", "1d", "edge-preserving", "filter", "iteration", "image", "show", "-lrb-", "-rrb-", "Figure", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "compare", "face", "statue", "before", "after", "filter", "operation", "show", "small", "scale", "detail", "have", "be", "smooth", "while", "important", "edge", "have", "be", "preserve", "although", "we", "filter", "perform", "series", "1d", "operation", "along", "row", "column", "correctly", "handle", "diagonal", "edge", "Figure", "illustrate", "property", "example", "contain", "several", "sharp", "edge", "various", "slope", "image", "center", "show", "filtered", "result", "obtain", "use", "only", "two", "iteration", "we", "two-pass", "1d", "filter", "original", "edge", "have", "be", "faithfully", "preserve", "while", "color", "have", "be", "properly", "filter", "decomposition", "2d", "edge-preserving", "filter", "sequence", "1d", "filter", "operation", "can", "generalize", "higher", "dimension", "unfortunately", "also", "cause", "filter", "rotationally", "invariant", "however", "also", "true", "other", "fast", "edge-preserving", "filter", "-lsb-", "Farbman", "et", "al.", "2008", "Fattal", "2009", "-rsb-", "artifact-free", "filter", "image", "can", "obtain", "increase", "number", "iteration", "here", "we", "describe", "experiment", "design", "empirically", "analyze", "convergence", "2d", "filter", "process", "color", "image", "channel", "-lsb-", "-rsb-", "range", "ten", "twelve", "iteration", "sufficient", "cause", "mean-square", "difference", "between", "result", "subsequent", "iteration", "fall", "below", "threshold", "10", "define", "experimentally", "quality", "filtered", "result", "obtain", "after", "iteration", "evaluate", "compare", "result", "obtain", "same", "image", "after", "15", "iteration", "which", "practical", "purpose", "can", "consider", "artifact", "free", "comparison", "perform", "use", "structural", "similarity", "-lrb-", "ssim", "-rrb-", "index", "-lsb-", "Wang", "et", "al.", "2004", "-rsb-", "SSIM", "image-quality", "metric", "consistent", "human", "perception", "its", "structural", "nature", "make", "appropriate", "detect", "stripe", "since", "SSIM", "index", "detect", "similarity", "we", "use", "its", "complement", "-lrb-", "SSIM", "-rrb-", "error", "measure", "graph", "Figure", "summarize", "error", "measure", "various", "number", "filter", "iteration", "result", "represent", "maximum", "error", "obtain", "while", "filter", "31", "natural", "image", "various", "contents", "each", "curve", "correspond", "fix", "value", "each", "point", "along", "curve", "we", "plot", "maximum", "error", "obtain", "among", "all", "value", "-lcb-", "10", "20", "40", "60", "80", "100", "200", "500", "1000", "3000", "-rcb-", "graph", "show", "dissimilarity", "metric", "decrease", "quickly", "first", "three", "iteration", "which", "define", "good", "tradeoff", "between", "filter", "quality", "computational", "time", "give", "domain", "transform", "ct", "transform", "signal", "-lrb-", "ct", "-lrb-", "-rrb-", "-rrb-", "-lrb-", "-rrb-", "filter", "use", "1d", "kernel", "section", "discuss", "alternative", "perform", "filter", "operation", "digital", "signal", "where", "likely", "non-uniformly", "sample", "between", "filtered", "image", "corresponding", "ideal", "result", "function", "number", "iteration", "different", "value", "6.1", "normalize", "convolution", "-lrb-", "nc", "-rrb-", "filter", "non-uniformly", "sample", "signal", "-lrb-", "ct", "-lrb-", "-rrb-", "-rrb-", "can", "see", "filter", "uniformly", "sample", "signal", "miss", "sample", "-lrb-", "figure", "leave", "-rrb-", "scenario", "have", "be", "study", "Knutsson", "Westin", "-lsb-", "1993", "-rsb-", "context", "datum", "uncertainty", "where", "show", "optimal", "filter", "result", "mean", "square", "sense", "obtain", "normalize", "convolution", "-lrb-", "nc", "-rrb-", "uniform", "discretization", "-lrb-", "-rrb-", "original", "domain", "nc", "describe", "filter", "value", "sample", "-lrb-", "-rrb-", "where", "q?d", "-lrb-", "-rrb-", "-lrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-rrb-", "normalization", "factor", "-lrb-", "-rrb-", "ct", "-lrb-", "-rrb-", "sample", "arbitrary", "kernel", "cost", "evaluate", "equation", "15", "all", "-lrb-", "-rrb-", "however", "ct", "-lrb-", "-rrb-", "monotonically", "increase", "-lrb-", "equation", "11", "-rrb-", "we", "use", "efficient", "moving-average", "approach", "-lsb-", "Dougherty", "1994", "-rsb-", "perform", "nc", "box", "filter", "-lrb-", "-rrb-", "time", "box", "kernel", "define", "where", "filter", "radius", "boolean", "function", "return", "when", "its", "argument", "true", "otherwise", "box", "kernel", "have", "constant", "radius", "space-varying", "non-symmetric", "radius", "where", "its", "size", "change", "accord", "similarity", "between", "its", "neighborhood", "image", "manifold", "-lrb-", "figure", "right", "blue", "-rrb-", "cost", "evaluate", "equation", "15", "use", "box", "kernel", "from", "equation", "16", "linear", "number", "sample", "we", "use", "1d", "filter", "iteration", "describe", "section", "define", "equation", "14", "three", "iteration", "result", "filter", "produce", "indistinguishable", "approximation", "gaussian", "filter", "-lrb-", "psnr", "40", "-rrb-", "when", "Figure", "11", "compare", "result", "one", "obtain", "several", "other", "filter", "thus", "perform", "box", "filter", "require", "update", "plus", "one", "additional", "memory", "read", "per", "sample", "check", "its", "domain", "coordinate", "one", "only", "need", "perform", "convolution", "position", "contain", "sample", "other", "position", "contribute", "filter", "image", "-lrb-", "discrete", "-rrb-", "original", "domain", "finally", "derivative", "estimate", "use", "backward", "difference", "GPU", "Implementation", "we", "domain", "transform", "highly", "parallel", "each", "thread", "calculate", "value", "ct", "-lrb-", "-rrb-", "-lrb-", "equation", "12", "-rrb-", "one", "sample", "scan", "operation", "perform", "integration", "filter", "each", "thread", "compute", "filter", "value", "one", "pixel", "find", "first", "last", "pixel", "inside", "current", "1d", "kernel", "window", "we", "perform", "two", "convolution", "-lrb-", "nc", "-rrb-", "-lrb-", "center", "-rrb-", "interpolated", "convolution", "-lrb-", "ic", "-rrb-", "-lrb-", "right", "-rrb-", "interpretation", "nc", "box", "kernel", "blue", "ic", "box", "kernel", "red", "binary", "search", "transform", "domain", "-lrb-", "-rrb-", "coordinate", "once", "first", "last", "pixel", "under", "1d", "kernel", "have", "be", "identify", "sum", "color", "all", "contribute", "pixel", "calculate", "use", "1d", "sum", "area", "table", "-lrb-", "per", "color", "channel", "-rrb-", "another", "option", "when", "deal", "irregularly", "sample", "datum", "use", "interpolation", "approximate", "original", "continuous", "function", "-lsb-", "piroddus", "Petrou", "2004", "-rsb-", "Figure", "-lrb-", "center", "-rrb-", "show", "reconstructed", "signal", "obtain", "linear", "interpolation", "-lrb-", "-rrb-", "sample", "show", "Figure", "-lrb-", "left", "-rrb-", "filter", "perform", "continuous", "convolution", "where", "normalize", "kernel", "interpolate", "convolution", "have", "interesting", "interpretation", "linear", "diffusion", "process", "work", "signal", "Figure", "-lrb-", "right", "-rrb-", "show", "interpretation", "box", "filter", "radius", "where", "kernel", "window", "show", "red", "same", "interpretation", "1D", "Beltrami", "flow", "pde", "-lsb-", "Sochen", "et", "al.", "2001", "-rsb-", "implementation", "box", "filter", "equation", "17", "can", "evaluate", "all", "pixel", "-lrb-", "-rrb-", "time", "achieve", "weighted", "movingaverage", "-lsb-", "Dougherty", "1994", "-rsb-", "normalize", "box", "kernel", "give", "where", "filter", "radius", "substitute", "-lrb-", "18", "-rrb-", "-lrb-", "17", "-rrb-", "linearly-interpolated", "signal", "do", "need", "uniformly", "resampled", "since", "area", "under", "its", "graph", "can", "explicitly", "compute", "use", "trapezoidal", "rule", "discrete", "signal", "-lsb-", "-rsb-", "-lrb-", "-rrb-", "non", "edge-preserving", "filter", "can", "perform", "use", "1st-order", "recursive", "filter", "where", "-lsb-", "-rsb-", "feedback", "coefficient", "-lsb-", "Smith", "2007", "-rsb-", "filter", "have", "infinite", "impulse", "response", "-lrb-", "iir", "-rrb-", "exponential", "decay", "impulse", "magnitude", "position", "generate", "response", "magnitude", "-lrb-", "-rrb-", "j?i", "i.", "note", "can", "interpret", "distance", "between", "sample", "assume", "unitary", "sampling", "interval", "base", "observation", "recursive", "edge-preserving", "filter", "can", "define", "transform", "domain", "where", "ct", "-lrb-", "-rrb-", "ct", "-lrb-", "-rrb-", "distance", "between", "neighbor", "sample", "transform", "domain", "-lrb-", "-rrb-", "increase", "go", "zero", "stop", "propagation", "chain", "thus", "preserve", "edge", "can", "interpret", "geodesic", "propagation", "image", "lattice", "impulse", "response", "-lrb-", "21", "-rrb-", "symmetric", "since", "only", "depend", "previous", "input", "output", "-lrb-", "causal", "filter", "-rrb-", "symmetric", "response", "achieve", "apply", "filter", "twice", "1d", "signal", "-lrb-", "21", "-rrb-", "perform", "left-to-right", "-lrb-", "top-tobottom", "-rrb-", "right-to-left", "-lrb-", "bottom-to-top", "-rrb-", "feedback", "coefficient", "filter", "compute", "from", "desire", "filter", "variance", "exp", "-lrb-", "-rrb-", "-lrb-", "see", "appendix", "derivation", "-rrb-", "since", "-lsb-", "-rsb-", "filter", "stable", "-lsb-", "Smith", "2007", "-rsb-", "its", "implementation", "-lrb-", "-rrb-", "time", "straightforward", "we", "compare", "we", "edge-preserving", "filter", "base", "normalize", "convolution", "-lrb-", "nc", "-rrb-", "interpolate", "convolution", "-lrb-", "ic", "-rrb-", "recursion", "-lrb-", "rf", "-rrb-", "against", "previous", "work", "brute-force", "bilateral", "filter", "-lrb-", "bf", "-rrb-", "-lsb-", "Tomasi", "Manduchi", "1998", "-rsb-", "anisotropic", "diffusion", "-lrb-", "ad", "-rrb-", "-lsb-", "Perona", "Malik", "1990", "-rsb-", "edge-avoiding", "wavelet", "-lrb-", "eaw", "-rrb-", "-lsb-", "fattal", "2009", "-rsb-", "weight", "least", "square", "filter", "-lrb-", "wl", "-rrb-", "-lsb-", "Farbman", "et", "al.", "2008", "-rsb-", "which", "have", "be", "show", "produce", "optimal", "result", "tone", "detail", "manipulation", "finally", "permutohedral", "lattice", "bf", "-lrb-", "plbf", "-rrb-", "-lsb-", "Adams", "et", "al.", "2009", "-rsb-", "constant", "time", "bf", "-lrb-", "ctbf", "-rrb-", "-lsb-", "Yang", "et", "al.", "2009", "-rsb-", "which", "respectively", "fastest", "color", "grayscale", "bilateral", "filter", "approximation", "Filter", "Response", "Figure", "show", "comparison", "impulse", "response", "we", "three", "filter", "NC", "ic", "rf", "-lrb-", "all", "perform", "use", "three", "iteration", "-rrb-", "against", "impulse", "response", "bf", "ad", "wl", "presence", "strong", "edge", "ic", "filter", "behave", "similarly", "ad", "nc", "filter", "have", "higher", "response", "near", "strong", "edge", "which", "direct", "implication", "its", "interpretation", "robust", "mean", "pixel", "near", "edge", "have", "less", "neighbor", "same", "population", "weight", "contribution", "strongly", "finally", "we", "recursive", "filter", "-lrb-", "rf", "-rrb-", "have", "exponential", "impulse", "response", "which", "completely", "attenuate", "strong", "edge", "like", "wls?s", "response", "nc", "filter", "ideal", "stylization", "abstraction", "since", "accurately", "smoothe", "similar", "image", "region", "while", "preserve", "sharpen", "relevant", "edge", "application", "where", "sharpen", "edge", "desirable", "-lrb-", "e.g.", "tone", "mapping", "detail", "manipulation", "-rrb-", "ic", "rf", "filter", "produce", "result", "equal", "quality", "state-of-the-art", "technique", "-lsb-", "Farbman", "et", "al.", "2008", "Fattal", "2009", "-rsb-", "finally", "edgeaware", "interpolation", "-lrb-", "e.g.", "colorization", "recoloring", "-rrb-", "rf", "filter", "produce", "best", "result", "due", "its", "infinite", "impulse", "response", "which", "propagate", "information", "across", "whole", "image", "lattice", "section", "illustrate", "use", "we", "filter", "all", "application", "smooth", "quality", "figure", "10", "show", "side-by-side", "comparison", "edge-aware", "smoothing", "apply", "portion", "photograph", "show", "Figure", "-lrb-", "-rrb-", "small", "amount", "smoothing", "bilateral", "filter", "-lrb-", "-rrb-", "we", "nc", "filter", "-lrb-", "-rrb-", "produce", "visually", "similar", "result", "further", "smoothing", "bilateral", "filter", "may", "incorrectly", "mix", "color", "observe", "window", "frame", "-lrb-", "figure", "10", "-lrb-", "-rrb-", "-rrb-", "contrast", "we", "filter", "manage", "continuously", "smooth", "image", "region", "while", "preserve", "strong", "edge", "effect", "illustrate", "Figure", "10", "-lrb-", "-rrb-", "sim", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "ilar", "result", "obtain", "WLS", "show", "-lrb-", "-rrb-", "anisotropic", "diffusion", "-lrb-", "use", "-lsb-", "D?Almeida", "2004", "-rsb-", "-rrb-", "show", "-lrb-", "-rrb-", "Figure", "10", "-lrb-", "-rrb-", "show", "result", "produce", "eaw", "maximum", "decomposition", "depth", "coefficient", "each", "detail", "level", "define", "0.6", "-lrb-", "level", "-rrb-", "which", "preserve", "some", "high-frequency", "detail", "set", "coefficient", "zero", "result", "distract", "artifact", "additional", "comparison", "among", "technique", "can", "find", "supplementary", "material", "we", "filter", "converge", "standard", "linear", "smoothing", "filter", "region", "weak", "edge", "when", "range", "support", "set", "large", "value", "-lrb-", "see", "Section", "4.2", "-rrb-", "feature", "desirable", "instance", "joint", "filter", "perform", "depth-of-field", "effect", "show", "Figure", "-lrb-", "-rrb-", "discuss", "section", "contrast", "we", "filter", "provide", "indistinguishable", "approximation", "gaussian", "-lrb-", "-rrb-", "show", "-lrb-", "-rrb-", "section", "report", "performance", "number", "obtain", "2.8", "GHz", "Quad", "Core", "PC", "gb", "memory", "GeForce", "GTX", "280", "filter", "CPU", "we", "implement", "we", "nc", "rf", "filter", "CPU", "use", "C++", "ic", "filter", "we", "have", "MATLAB", "implementation", "its", "performance", "expect", "similar", "nc?s", "single", "CPU", "core", "typical", "runtime", "we", "nc", "rf", "filter", "process", "megapixel", "color", "image", "use", "three", "iteration", "0.16", "0.06", "seconds", "respectively", "performance", "scale", "linearly", "image", "size", "filter", "10", "megapixel", "color", "image", "under", "1.6", "0.6", "seconds", "quad-core", "CPU", "we", "achieve", "3.3", "speedup", "we", "compare", "performance", "we", "edge-aware", "filter", "against", "fastest", "filter", "from", "previous", "work", "eaw", "plbf", "ctbf", "plbf", "we", "nc", "rf", "filter", "process", "all", "three", "color", "channel", "simultaneously", "while", "ctbf", "only", "process", "grayscale", "thus", "ctbf", "actually", "perform", "one", "third", "work", "do", "other", "three", "method", "we", "measure", "report", "result", "single", "CPU", "core", "plbf", "ctbf", "we", "use", "source", "code", "provide", "author", "runtime", "both", "plbf", "ctbf", "inversely", "proportional", "value", "approach", "zero", "runtime", "above", "10", "seconds", "runtime", "we", "filter", "independent", "parameter", "use", "simplification", "improve", "performance", "range", "we", "filter", "three", "iteration", "15", "faster", "than", "approach", "small", "amount", "smoothing", "one", "can", "obtain", "good", "result", "use", "two", "even", "one", "iteration", "we", "filter", "-lrb-", "figure", "-rrb-", "speed-up", "25", "40", "over", "plbf", "color", "filter", "accord", "fattal", "-lsb-", "2009", "-rsb-", "eaw", "can", "smooth", "megapixel", "grayscale", "image", "0.012", "seconds", "3.0", "GHz", "CPU", "since", "generate", "decomposition", "only", "few", "scale", "generally", "applicable", "edge-preserving", "smoothing", "WLS", "take", "3.5", "seconds", "solve", "its", "sparse", "linear", "system", "use", "fast", "CPU", "implementation", "graph", "compare", "performance", "technique", "can", "find", "supplementary", "material", "filter", "GPU", "we", "implement", "we", "nc", "filter", "GPU", "use", "CUDA", "total", "time", "require", "filter", "megapixel", "color", "image", "0.7", "msec", "compute", "domain", "transform", "plus", "msec", "each", "2d", "filter", "iteration", "give", "total", "runtime", "approximately", "0.007", "seconds", "three", "iteration", "we", "filter", "speedup", "23", "compare", "we", "one-core", "CPU", "implementation", "since", "we", "filter", "scale", "linearly", "image", "size", "we", "GPU", "implementation", "able", "filter", "10", "megapixel", "color", "image", "under", "0.07", "seconds", "we", "compare", "performance", "we", "GPU", "filter", "against", "GPU", "Bilateral", "Grid", "-lsb-", "Chen", "et", "al.", "2007", "-rsb-", "while", "implementation", "fast", "ours", "only", "process", "luminance", "value", "which", "may", "generate", "undesired", "color-ghosting", "artifact", "GPU", "implementation", "plbf", "can", "filter", "0.5", "megapixel", "image", "0.1", "sec", "GeForce", "gtx", "280", "-lsb-", "Adams", "et", "al.", "2010", "-rsb-", "GPU", "implementation", "WLS", "filter", "megapixel", "grayscale", "image", "about", "second", "-lsb-", "Farbman", "et", "al.", "2008", "-rsb-", "we", "show", "variety", "application", "demonstrate", "versatility", "we", "domain", "transform", "filter", "image", "processing", "give", "its", "speed", "we", "approach", "can", "perform", "fly", "high-resolution", "image", "video", "improved", "performance", "provide", "user", "instant", "feedback", "when", "tuning", "filter", "parameter", "example", "video", "application", "include", "supplementary", "material", "detail", "manipulation", "edge-preserving", "filter", "can", "use", "decompose", "image", "detail", "several", "scale", "which", "can", "manipulate", "independently", "recombine", "produce", "various", "effect", "-lsb-", "Farbman", "et", "al.", "2008", "Fattal", "2009", "-rsb-", "let", "...", "progressively", "smoother", "version", "image", "several", "detail", "layer", "capture", "progressively", "coarser", "detail", "construct", "+1", "Figure", "12", "show", "example", "fine-scale", "detail", "enhancement", "apply", "flower", "image", "-lrb-", "-rrb-", "result", "-lrb-", "-rrb-", "create", "filter", "image", "-lrb-", "-rrb-", "once", "use", "we", "ic", "filter", "-lrb-", "20", "0.08", "-rrb-", "manipulate", "detail", "layer", "use", "sigmoid", "function", "describe", "Farbman", "et", "al.", "-lsb-", "2008", "-rsb-", "Figure", "12", "-lrb-", "-rrb-", "show", "result", "produce", "eaw", "filter", "fattal", "-lsb-", "2009", "-rsb-", "image", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "present", "similar", "visual", "quality", "we", "filter", "however", "allow", "extra", "flexibility", "when", "decompose", "image", "detail", "since", "can", "produce", "continuum", "smooth", "image", "vary", "value", "parameter", "tone", "mapping", "edge-aware", "tone", "mapping", "avoid", "haloing", "other", "artifact", "introduce", "compression", "process", "Figure", "13", "compare", "result", "tone", "mapping", "operator", "implement", "use", "we", "rf", "filter", "-lrb-", "-rrb-", "WLS", "filter", "Farbman", "et", "al.", "-lsb-", "2008", "-rsb-", "-lrb-", "-rrb-", "quality", "result", "similar", "we", "filter", "significantly", "faster", "result", "fastest", "high-quality", "tone-mapping", "solution", "available", "result", "Figure", "13", "-lrb-", "-rrb-", "obtain", "manipulate", "three", "detail", "layer", "from", "HDR", "image?s", "log-luminance", "channel", "each", "layer", "obtain", "12", "msec", "use", "two", "iteration", "we", "rf", "filter", "20", "0.33", "50", "0.67", "100", "1.34", "compress", "luminance", "channel", "obtain", "0.12", "0.9", "-lrb-", "-rrb-", "0.3", "0.2", "0.2", "where", "linear", "compression", "range", "-lsb-", "-rsb-", "-lrb-", "i.e.", "-lrb-", "min", "-lrb-", "-rrb-", "-rrb-", "-lrb-", "max", "-lrb-", "-rrb-", "min", "-lrb-", "-rrb-", "-rrb-", "-rrb-", "mean", "value", "B.", "be", "define", "previous", "paragraph", "edge-aware", "filter", "ideal", "stylization", "can", "abstract", "region", "lowcontrast", "while", "preserve", "enhance", "high-contrast", "feature", "Figure", "14", "illustrate", "application", "we", "nc", "filter", "produce", "abstracted", "result", "give", "input", "image", "-lrb-", "top", "left", "-rrb-", "magnitude", "gradient", "filter", "image", "-lrb-", "top", "right", "-rrb-", "superimpose", "filter", "image", "itself", "produce", "high-contrast", "edge", "around", "most", "salient", "feature", "another", "interesting", "stylization", "effect", "can", "obtain", "assign", "each", "output", "pixel", "scale", "version", "value", "normalization", "factor", "from", "equation", "15", "produce", "pencil-like", "non-photorealistic", "drawing", "one", "show", "Figure", "-lrb-", "-rrb-", "obtain", "scale", "0.11", "Joint", "Filtering", "we", "approach", "can", "also", "use", "joint", "filter", "where", "content", "one", "image", "smooth", "base", "edge", "information", "from", "second", "image", "instance", "use", "value", "alpha", "matte", "-lsb-", "gastal", "Oliveira", "2010", "-rsb-", "image", "derivative", "equation", "11", "one", "can", "simulate", "depth-of-field", "effect", "-lrb-", "figure", "-lrb-", "-rrb-", "-rrb-", "example", "emphasize", "why", "converge", "gaussian-like", "response", "important", "property", "we", "filter", "example", "alpha", "matte", "structure", "resemble", "Voronoi", "diagram", "have", "be", "add", "define", "new", "edge", "preserve", "-lrb-", "Figure", "15", "bottom", "left", "-rrb-", "result", "filter", "produce", "unique", "stylized", "depth-of-field", "effect", "edge", "diagram", "be", "superimpose", "filter", "image", "create", "result", "show", "right", "similar", "result", "show", "Figure", "-lrb-", "-rrb-", "where", "edge", "preserve", "be", "identify", "canny", "edge", "detector", "Colorization", "similar", "previous", "approach", "-lsb-", "Levin", "et", "al.", "2004", "Fattal", "2009", "-rsb-", "we", "propagate", "color", "from", "user-supplied", "scribble", "blur", "they", "use", "edge", "information", "from", "grayscale", "image", "-lrb-", "figure", "16", "leave", "-rrb-", "keep", "track", "how", "much", "color", "propagate", "each", "pixel", "we", "also", "blur", "normalization", "function", "which", "define", "one", "pixel", "where", "scribble", "provide", "zero", "otherwise", "let", "blur", "version", "respectively", "final", "color", "each", "pixel", "obtain", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "value", "combine", "original", "luminance", "from", "grayscale", "image", "produce", "colorized", "result", "Figure", "16", "compare", "result", "obtain", "we", "rf", "filter", "-lrb-", "100", "0.03", "-rrb-", "one", "Levin", "et", "al.", "-lsb-", "2004", "-rsb-", "we", "experience", "good", "colorization", "result", "can", "obtain", "value", "from", "0.01", "0.1", "100", "recolor", "localized", "manipulation", "image", "color", "achieve", "use", "soft", "segmentation", "Color", "scribble", "define", "set", "region", "interest", "where", "each", "region", "define", "color", "each", "region", "influence", "map", "-lsb-", "Lischinski", "et", "al.", "2006", "-rsb-", "obtain", "blur", "its", "associate", "normalization", "function", "define", "all", "scribble", "color", "contribution", "recoloring", "pixel", "define", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "Figure", "-lrb-", "-rrb-", "show", "recoloring", "example", "obtain", "use", "technique", "we", "filter", "temporally", "stable", "can", "apply", "video", "real", "time", "please", "see", "accompany", "video", "example", "we", "have", "present", "new", "approach", "perform", "high-quality", "edge-preserving", "filter", "image", "video", "real", "time", "we", "solution", "base", "transform", "define", "isometry", "between", "curve", "2d", "image", "manifold", "5d", "real", "line", "transform", "preserve", "geodesic", "distance", "between", "point", "curve", "adaptively", "warp", "input", "signal", "so", "1d", "edge-preserving", "filter", "can", "efficiently", "perform", "linear", "time", "we", "demonstrate", "three", "realization", "we", "1d", "edge-preserving", "filter", "base", "normalize", "convolution", "interpolate", "convolution", "recursion", "filter", "have", "very", "distinct", "impulse", "response", "make", "each", "one", "more", "appropriate", "specific", "application", "we", "have", "show", "how", "produce", "high-quality", "2d", "edge-preserving", "filter", "iterate", "1d-filtering", "operation", "we", "analyze", "convergence", "process", "show", "three", "iteration", "provide", "good", "compromise", "between", "image", "quality", "computational", "time", "we", "approach", "have", "several", "desirable", "feature", "first", "apply", "signal?s", "original", "sample", "correctly", "handle", "color", "image", "second", "use", "1d", "operation", "lead", "considerable", "speedup", "over", "exist", "technique", "potential", "memory", "savings", "finally", "first", "edge-preserving", "filter", "capable", "work", "color", "image", "arbitrary", "scale", "real", "time", "without", "resort", "subsampling", "quantization", "can", "filter", "megapixel", "color", "image", "approximately", "150", "fp", "use", "three", "iteration", "which", "significantly", "faster", "than", "previous", "technique", "we", "have", "demonstrate", "versatility", "we", "domain", "transform", "edge-preserving", "filter", "several", "real-time", "image", "video", "processing", "task", "include", "edge-preserving", "filter", "depth-of-field", "effect", "stylization", "recoloring", "colorization", "detail", "enhancement", "-lrb-", "-rrb-", "result", "Levin", "et", "al.", "-lsb-", "2004", "-rsb-", "tone", "mapping", "one", "feature", "we", "filter", "response", "stop", "strong", "edge", "contrast", "bilateral", "filter", "whose", "kernel", "can", "cross", "edge", "-lrb-", "figure", "-rrb-", "we", "believe", "both", "behavior", "valid", "may", "provide", "optimal", "result", "different", "kind", "application", "speed", "flexibility", "high-quality", "result", "achieve", "we", "technique", "may", "enable", "many", "new", "application", "have", "be", "previously", "possible", "Limitations", "most", "other", "fast", "edge-preserving", "filter", "we", "2d", "filter", "rotationally", "invariant", "-lrb-", "i.e.", "filter", "rotate", "image", "rotate", "filter", "image", "may", "produce", "different", "result", "-rrb-", "behaviour", "may", "cause", "problem", "application", "rely", "content", "matching", "we", "1d", "edge-preserving", "filter", "can", "apply", "other", "kind", "signal", "higher-dimensional", "datum", "other", "possible", "direction", "exploration", "involve", "apply", "we", "filter", "mesh", "implementation", "frequency", "domain", "we", "would", "like", "thank", "anonymous", "reviewer", "insightful", "comment", "work", "sponsor", "cnpq-brazil", "-lrb-", "fellowship", "grant", "557814/2010", "-3", "200284/2009", "-6", "308936/2010", "-8", "480485/2010", "-0", "-rrb-", "input", "image", "from", "figure", "12", "15", "16", "courtesy", "Farbman", "et", "al", "-lsb-", "2008", "-rsb-", "www.alphamatting.com", "Levin", "et", "al.", "-lsb-", "2004", "-rsb-", "respectively", "Figure", "13", "generate", "from", "radiance", "map", "courtesy", "Paul", "Debevec", "input", "image", "from", "figure", "14", "from", "publicdomainpictures.net", "-lrb-", "image", "8363", "5298", "-rrb-", "continuous", "equivalent", "recursive", "kernel", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lsb-", "-rrb-", "-lrb-", "-rrb-", "where", "represent", "distance", "between", "sample", "feedback", "coefficient", "-lrb-", "-rrb-", "normalize", "since", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "dx", "log", "-lrb-", "-rrb-", "log", "-lrb-", "-rrb-", "normalize", "we", "obtain", "-lrb-", "-rrb-", "log", "-lrb-", "-rrb-", "first", "second", "moment", "respectively", "log", "-lrb-", "-rrb-", "dx", "log", "-lrb-", "-rrb-", "log", "-lrb-", "-rrb-", "dx", "log", "-lrb-", "-rrb-", "variance", "give", "ar", "-lrb-", "-rrb-", "log", "-lrb-", "-rrb-", "since", "signal", "filter", "twice", "-lrb-", "left-to-right", "right-toleft", "-rrb-", "total", "variance", "filter", "ar", "-lrb-", "-rrb-", "give", "desire", "variance", "ar", "-lrb-", "-rrb-", "log", "-lrb-", "-rrb-", "we", "solve", "find", "exp", "-lrb-", "-rrb-", "exp", "-lrb-", "-rrb-", "where", "former", "we", "solution", "since", "-lrb-", "-rrb-" ],
  "content" : "We present a new approach for performing high-quality edgepreserving filtering of images and videos in real time. This transform preserves the geodesic distance between points on these curves, adaptively warping the input signal so that 1D edge-preserving filtering can be efficiently performed in linear time. We demonstrate three realizations of 1D edge-preserving filters, show how to produce high-quality 2D edge-preserving filters by iterating 1D-filtering operations, and empirically analyze the convergence of this process. We demonstrate the versatility of our domain transform and edge-preserving filters on several real-time image and video processing tasks including edgepreserving filtering, depth-of-field effects, stylization, recoloring, colorization, detail enhancement, and tone mapping. We present a new approach for efficiently performing edgepreserving filtering of images and videos that addresses the main limitations of previous techniques. It preserves the geodesic distances between points on the curve, adaptively warping the input signal so that 1D edge-preserving filtering can be efficiently performed in linear time. We demonstrate three realizations for our 1D edge-preserving filters, based on normalized convolution, interpolated convolution, and recursion. Finally, although our 1D filters cannot be exactly generalized to higher dimensions, we show how to use them to efficiently produce high-quality 2D edge-preserving filters. For instance, it can filter one megapixel color images in 0.007 seconds on a GPU. Third, it is the first edge-preserving technique capable of working on color images at arbitrary scales in real time, without resorting to subsampling or quantization. We demonstrate the versatility of our domain transform and edgepreserving filters on several real-time image and video processing tasks including edge-preserving smoothing, depth-of-field effects, stylization, recoloring, colorization, detail enhancement, and tone mapping (Section 8). Examples of some of these effects can be seen in Figure 1 , applied to the photograph shown on the far left. Our approach leads to filters with several desirable features and significant speed-ups over existing techniques; ? A technique to perform anisotropic edge-preserving filtering on curves of the 2D image manifold using 1D linear filters. It consists of anisotropically scaling the curve, which is then mapped to the real line using an isometry, followed by the application of a 1D linear filter (Section 4); ? A technique to efficiently implement 2D edge-preserving smoothing filters as a sequence of 1D filtering operations (Section 5). For this, we show examples of approximate Gaussian and exponential responses (Section 6); ? A demonstration that our approach can be used to create a variety of effects for images and videos in real time (Section 8). Existing methods are able to produce good results in many practical scenarios, and edge-aware filters are available in several image-processing applications [Kimball et al. 2011; Adobe Systems Inc. For (2D) RGB images, it can be interpreted as operating in a 5D space [Barash 2002]. Porikli [2008] extended this idea by using summed area tables to filter each intensity level, and Yang et al. [2009] further extended it to arbitrary kernels. A simplified version of this method was shown to perform in real-time on GPUs for three-dimensional (grayscale) bilateral filtering [Chen et al. 2007]. Adams et al. [2010] proposed the use of uniform simplices to efficiently implement color bilateral filters in 5D. All these approaches for accelerating bilateral filters derive their performance from the use of quantization or downsampling. This leads to runtime and/or memory costs that are inversely proportional to the kernels sizes defined over space (? s ) and range (? r ). As a result, their performances are severely affected by the use of small values of ? r (required to enforce edge preservation) or of ? s (needed for small amounts of blurring). Finally, Pham and Vliet [2005] implement the bilateral filter as a separable operation. This multiscale representation can be quickly computed, but constrains the sizes of the smoothing kernels (in pixels) to powers of two. Criminisi et al. [2010] presented a geodesic framework for edge-aware filtering defined for grayscale images  that employs quantization of the luma channel. Finally, Farbman et al. [2010] proposed the use of diffusion distances for calculating the affinity among pixels, which can be seamlessly integrated with our approach. It can be understood as reducing the dimensionality of the input signal prior to filtering. Lee and Verleysen [2010] present a comprehensive survey on dimensionality-reduction techniques. Our approach is inspired by the multi-dimensional interpretation of edge-preserving filters [Barash 2002]. Let I : ? ? R 2 ? R 3 be a 2D RGB color image, defining a 2D manifold M I in R 5 [Kimmel et al. 1997]. Also, let p = (x p , y p , r p , g p , b p ) ? M I be a point on this manifold. Let F ( p, q) be an edge-preserving filter kernel in 5D. J, the image obtained when filtering I with F can be expressed as where F ( p, q) dq = 1. where ? is the 2 norm. G ? s and G ? r are typically Gaussian spatial and range filters, with supports given by ? s and ? r , respectively. Since the bilateral filter works in 5D space, its naive implementation is too slow for many practical uses. Problem Statement Our work addresses the fundamental question of whether there exists a transformation t : R 5 ? R l , l < 5, and a filter kernel H defined over R l that, for any input image I, produce an equivalent result as the 5D edge-preserving kernel F : This construction becomes attractive when evaluating t plus H is more efficient than evaluating the original kernel F . In our case, we are interested in replacing the evaluation of a computationally expensive edge-preserving filter defined in 5D with a domain transformation t and a lower-dimensional linear filter H, evaluated in Euclidean space (R l ). If the transformation t preserves the original distances from R 5 in R l , it will also maintain the edge-preserving property of a filter defined in the lowerdimensional space. Let us consider the case of mapping a grayscale image to a plane, which |I(x + h) ? I(x)| (center). Arc length of C, from u to w (right). involves finding an isometry t : R 3 ? R 2 . For our purpose of edge-aware filtering, preserving the distances among pixels is essential. Furthermore, existing approaches from the dimensionalityreduction [Belkin and Niyogi 2003] and texture-mapping [L?vy et al. 2002] literature use optimization methods, which are too slow for our use in real-time edge-preserving filtering. While a solution for a 2D domain does not exist in general, Section 4 shows that an isometric transform exists for a 1D domain. Section 5 then shows how this 1D transform can be effectively used to filter 2D color images. For deriving an isometric 1D transform, let I : ? ? R, ? = [0, +?) ? R, be a 1D signal, which defines a curve C in R 2 by the graph (x, I(x)), for x ? ? ( Figure 2 , left). Thus, let S = {x 0 , x 1 , . . . , x n } be a sampling of ?, where x i+1 = x i + h, for some sampling interval h. We seek a transform t that satisfies |t(x i , I(x i )) ? t(x j , I(x j ))| = (x i , I(x i )) ? (x j , I(x j )) , where x i , x j ? S, |. | is the absolute value operator, and . is some chosen metric. For simplicity, we use the nearest-neighbor 1 norm; thus, t only needs to preserve the distances between neighboring samples x i and x i+1 . As we will soon show, this choice gives rise to the geodesic metric. Finally, let ct(x) = t( x) = t(x, I(x)). To avoid the need for the absolute value operator on the left of (4), we constrain ct to be monotonically increasing ? i.e., ct(x + h) ? ct(x). Dividing both sides of (4) by h and taking the limit as h ? 0 we obtain where ct (x) denotes the derivative of ct(x) with respect to x. Integrating (5) on both sides and letting ct(0) = 0, we get u Intuitively, ct is ?unfolding? the curve C defined in R ( Figure 2 , left) into R, while preserving the distances among neighboring samples. Moreover, for any two points u and w in ?, w ? u, the distance between them in the new domain is given by w As such, the transformation given by Equation 6 preserves the geodesic distance between all points on the curve. Multichannel Signals For edge-preserving filtering, it is important to process all channels of the input signal at once, as processing them independently should introduce artifacts around the edges [Tomasi and Manduchi 1998]. For a 1D signal I : ? ? R c with c channels defining a curve C in R c+1 , one can apply a similar derivation to obtain the multichannel transformation: u c where I k is the k-th channel of signal I. In the case I is an image, I k can be a color channel in some color space (e.g., RGB or CIE Lab), or a more complex representation, such as a diffusion map [Farbman et al. 2010]. We call ct a domain transform. Equation 8 reduces the evaluation domain of the filter from R c+1 to R. Thus, the filter H (see Equation 3) is one-dimensional. Since our transformation is isometric, any filter H, whose response decreases with distance at least as fast as F ?s, will be edge-preserving. Section 6 discusses some choices of H. By reducing the dimensionality of the filter from c + 1 to 1, it may seem that we lost the ability to control its support over the signal?s space and range (i.e., control the values of ? s and ? r , in bilateral filter notation). But, as we show, one can encode the values of ? s and ? r in the transformation itself. Given a 1D signal I and a 1D filtering kernel H (with unit area), we can define I a (u) = I(u/a), which stretches/shrinks I by a, and H 1/a (u?? ) = H(au?? ) a, which shrinks/stretches H by 1/a and renormalizes it to unit area, where ? is a translation. ?? (9) Thus, under convolution, scaling the filter?s support by 1/a is equivalent to scaling the signal?s support by a (and vice-versa). Therefore, to encode the filter?s support onto the domain transform, we: (i) derive a i , for each dimension d i of the signal I, from the desired support of filter F over d i ; (ii) scale each d i by its corresponding a i ; (iii) apply the domain transform to the scaled signal; and (iv) filter the signal in 1D using H. This is an important observation, since it shows that the support of the original multidimensional kernel F can be completely encoded in 1D. We will refer to the desired variances of the filter F over the signal?s spatial domain ? as ? s 2 , and over the signal?s range as ? r 2 k , k ? {1, . . . , c}, for all channels k. Obtaining the scaling factors By the scaling property of variances [Loeve 1977]: 2 2 2 2 ? r k = V ar(H 1/a ) = V ar(H/a) = V ar(H)/a = ? H /a ; which solves to a = ? H /? r k , where ? H 2 is the variance of filter H. The scaling factor for the spatial domain ? is given by a = ? H /? s . Note that the scaling factor ?a? may vary for each dimension in R c+1 , allowing the definition of anisotropic filtering in 1D. These results are valid and produce correct filtering for any value ? H > 0. Scaling the Signal According to Equation 9, before it can be filtered by H, the signal I should be scaled by ?a? prior to evaluating the domain transform. Since ? H is a free parameter, we let ? H = ? s and obtain our final domain transform, where a single value of ? r has been used for all channels for simplicity: Filtering the signal in the transformed domain is done through 1D convolution with H. Further details are presented in Section 6. Figure 3 illustrates the use of a domain transform for filtering the 1D signal I, shown in (a) in its original domain ?. (b) shows the associated domain transform ct(u) computed using Equation 11. (c) shows signal I in the transformed domain ? w or, more compactly, I w (ct(u)) = I(u). The result of filtering I with a Gaussian filter H in ? w is shown in (d). (e) shows the desired filtered signal obtained by reversing ct(u) for the signal shown in (d). The smallscale variations were eliminated and the strong edges preserved. This section analyzes the filtering-related properties of our domain transform (Equation 11). As ct(x) is applied to a 1D signal I, its domain is locally scaled by where the summation over all channels has been omitted for simplicity. According to Equation 9, scaling the input signal I by ct (x) is equivalent to scaling the support of the filter H by 1/ct (x). Thus, the amount of local smoothing introduced by H in the signal at I(x), can be expressed as\n          ? s smoothing H (x) ? (? H ct (x)) = ? s 1+ ? r I (x) . (13) Using (13), we analyze the relationship of H?s response with the parameters ? s and ? r , as well as with I(x): smoothing smoothing H (x) = 0, smoothing smoothing H (x) = 0, smoothing smoothing H (x) = ? s When ? r approaches zero, ct (x) goes to infinity, and any filter H with compact support will produce a filtered signal identical to the input, as expected. Relationship to ? s Interestingly, as ? s approaches infinity, H does not produce unbounded smoothing in the image. This is exactly what is expected from an edge-preserving filter when ? r is held constant. Furthermore, the amount of smoothing is inversely proportional to the gradient magnitude of the signal, which is the most commonly used estimator of image edges. Finally, when ? s approaches zero, no smoothing is performed, as expected. Relationship to I When the gradient magnitude of the input signal is very large, no smoothing is performed. On the other hand, in regions where the gradient magnitude is not significant, smoothing is performed with the same response of a linear smoothing filter. Note that in both cases, our filter behaves as an edge-preserving one. Equation 11 defines a domain transform for 1D signals. Ideally, an inherently 2D transform ct(x, y) should be used for 2D signals, directly mapping the content at positions (x, y) in the original domain to positions (u, v) in the transformed domain. Unfortunately, as discussed in Section 3, ct(x, y) (i.e., t : R c+2 ? R 2 ) does not exist in general [O?Neill 2006]. Since it is not possible to simultaneously satisfy all the distance requirements in R 2 , the use of a space with higher-dimensionality would be needed, implying additional computational and memory costs. To avoid these extra costs, we use our 1D transform to perform 2D filtering. For an image, this means performing a (horizontal) pass along each image row, and a (vertical) pass along each image column [Smith 1987; Oliveira et al. 2000]. Assuming the horizontal pass is performed first, the vertical pass is applied to the result produced by the vertical one (and vice-versa). This construction is extensively used with standard separable linear filters [Dougherty 1994] and anisotropic diffusion [Weickert et al. 1998], and is also related to the computation of geodesic distances on the image manifold using raster-scan algorithms [Criminisi et al. 2010]. One caveat is that filtering a 2D signal using a 1D domain transform is not a separable operation; otherwise, this would be equivalent to performing ct(x, y) in 2D. This situation is illustrated in Figure 4 , where pixels p and q belong to a same region (represented in white in (a)) and, therefore, should have their information combined. Figure 4 (b) shows, in blue, the region reachable from p after one horizontal pass; and (c) after one complete iteration (assuming that the horizontal pass is performed first). The region reachable from q is analogous. By not reaching the entire white region after one iteration, this process may introduce visual artifacts perceived as ?stripes? (indicated by the black arrow in Figure 4 (c)). For this example, one additional horizon- (a) (b) (c) (d) (e)\n        tal pass would be needed to propagate p?s information to the entire white region, thus eliminating the stripe ( Figure 4 (d)). Further passes do not alter the result (e). The required number of horizontal and vertical passes depends on (the geometry of) the image content, and, therefore, is hard to predict. However, we use two key observations to make these artifacts unnoticeable in the filtered images: (i) stripes are only present along the last filtered dimension: a horizontal (vertical) step removes stripes introduced by the previous vertical (horizontal) step; and (ii) the length of the stripes is proportional to the size of the filter support used in the last pass. Thus, we interleave a sequence of vertical and horizontal passes, such that the two 1D filters used in each iteration (consisting of a vertical and a horizontal filter) have a ? value that is half of the one used in the previous iteration. This progressively reduces the extension of the artifacts, making them virtually unnoticeable. In practice, three iterations usually suffice to achieve good results (Section 5.1). During a horizontal pass, I in Equation 11 is the partial derivative computed along the rows of image I, while, in a vertical pass, I represents the partial derivative computed along the image columns. Since variances (and not standard deviations) add [Loeve 1977], care must be taken when computing the ? H value for each iteration: we must use standard deviations that halve at each step and whose squared sum matches the original desired variance ? H 2 . The image resulting from the i-th iteration is used as input for the (i + 1)-th iteration. The domain transform ct(x) is computed only once (for the original image) and used with all the different scales of the filter H. Filtering of diagonal edges. (Left) Input image (1280?960 pixels). (Center) Filtered image with two iterations of our two-pass 1D filter (? H = ? s = 50 and ? r = 0.5). (Right) Detail from the filtered image. Figures 5 (b) and (c) illustrate the results of performing, respectively, one and three 1D edge-preserving filtering iterations on the image shown in (a). Figure 5 (d) and (e) compare the face of the statue before and after the filtering operation, and shows that small scale details have been smoothed while the important edges have been preserved. Although our filter is performed as a series of 1D operations along rows and columns, it correctly handles diagonal edges. Figure 6 illustrates this property on an example containing several sharp edges at various slopes. The image on the center shows the filtered result obtained using only two iterations of our two-pass 1D filter. The original edges have been faithfully preserved, while the colors have been properly filtered. The decomposition of a 2D edge-preserving filter as a sequence of 1D filtering operations can be generalized to higher dimensions. Unfortunately, this also causes the filter not to be rotationally invariant. However, this is also true for other fast edge-preserving filters [Farbman et al. 2008; Fattal 2009]. Artifact-free filtered images can be obtained by increasing the number of iterations. Here, we describe an experiment designed to empirically analyze the convergence of the 2D filtering process. For color images with channels in the [0, 1] range, ten to twelve iterations are sufficient to cause the mean-square difference between the results of subsequent iterations to fall below the threshold of 10 ?4 , defined experimentally. The quality of a filtered result obtained after n iterations is evaluated by comparing it to the result obtained for the same image after 15 iterations, which, for practical purposes, can be considered artifact free. The comparison is performed using the Structural Similarity (SSIM) index [Wang et al. 2004]. SSIM is an image-quality metric consistent with human perception. Its structural nature makes it appropriate for detecting ?stripes?. Since the SSIM index detects similarity, we use its complement (1 ? SSIM ) as an error measure. The graph in Figure 7 summarizes the errors measured for various numbers of filtering iterations. These results represent the maximum errors obtained while filtering 31 natural images with various contents. Each curve corresponds to a fixed value of ? r . For each point along a ? r curve, we plot the maximum error obtained among all values of ? s ? {1, 10, 20, 40, 60, 80, 100, 200, 500, 1000, 3000}. The graph shows that the dissimilarity metric decreases quickly with the first three iterations, which defines a good tradeoff between filtering quality and computational time. Given a domain transform ct : ? ? ? w , the transformed signal I w (ct(x)) = I(x) is then filtered using the 1D kernel H. This section discusses alternatives for performing this filtering operation on digital signals, where I w will likely be non-uniformly sampled. between filtered images and their corresponding ?ideal? results as a function of number of iterations, for different values of ? r . 6.1 Normalized Convolution (NC)\n        Filtering the non-uniformly sampled signal I w (ct(x)) in ? w can be seen as filtering a uniformly sampled signal with missing samples ( Figure 8 , left). This scenario has been studied by Knutsson and Westin [1993] in the context of data uncertainty, where they showed that optimal filtering results, in the mean square sense, are obtained by normalized convolution (NC). For a uniform discretization D(?) of the original domain ?, NC describes the filtered value of a sample p ? D(?) as where K p = q?D(?) H( t( p), t( q) ) is a normalization factor for p, and t( p) = ct(p). For N samples and an arbitrary kernel H, the cost of evaluating Equation 15 for all p is O(N 2 ). However, as ct(x) is monotonically increasing (Equation 11), we use an efficient moving-average approach [Dougherty 1994] to perform NC with a box filter in O(N ) time. The box kernel is defined as where r = ? H 3 is the filter radius, and ? is a boolean function that returns 1 when its argument is true, and 0 otherwise. This box kernel has a constant radius in ? w , but a space-varying and non-symmetric radius in ?, where its size changes according to the similarity between p and its neighborhood in the image manifold M I ( Figure 8 , right, in blue). The cost of evaluating Equation 15 using the box kernel from Equation 16 is linear in the number of samples. We use it for the 1D filtering iterations described in Section 5, with ? H i defined by Equation 14. For three iterations, the resulting filter produces an indistinguishable approximation to a Gaussian filter (PSNR > 40) when ? r = ?. Figure 11 compares this result to the ones obtained with several other filters. Thus, performing box filtering in ? w requires updating K p , plus one additional memory read per sample to check its domain coordinate. One only needs to perform convolution at positions in ? w that contain samples, as other positions will not contribute to the filtered image in the (discrete) original domain. Finally, derivatives are estimated using backward differences. GPU Implementation Our domain transform is highly parallel: each thread calculates the value of ct (x) (Equation 12) for one sample, and a scan operation performs the integration. For filtering, each thread computes the filtered value of one pixel. To find the first and last pixels inside the current 1D kernel window, we perform two convolution (NC). (Center) Interpolated convolution (IC). (Right) Their interpretation: NC box kernel in blue, IC box kernel in red. binary searches on the transformed domain (? w ) coordinates. Once the first and last pixels under the 1D kernel have been identified, the sum of the colors of all contributing pixels is calculated using a 1D summed area table (per color channel). Another option when dealing with irregularly sampled data is to use interpolation for approximating the original continuous function [Piroddi and Petrou 2004]. Figure 8 (center) shows a reconstructed signal L w obtained by linear interpolation (in ? w ) of the samples shown in Figure 8 (left). Filtering L w is performed by continuous convolution: where H is a normalized kernel. Interpolated convolution has an interesting interpretation: a linear diffusion process working on the signal. Figure 8 (right) shows this interpretation for a box filter of radius r, where the kernel window is shown in red. This is the same interpretation as the 1D Beltrami flow PDE [Sochen et al. 2001]. Implementation For a box filter, Equation 17 can be evaluated for all pixels in O(N ) time. This is achieved by a weighted movingaverage [Dougherty 1994]. The normalized box kernel is given by ? where r = ? H 3 is the filter radius. Substituting (18) in (17): The linearly-interpolated signal L w does not need to be uniformly resampled, since the area under its graph can be explicitly computed using the trapezoidal rule. For a discrete signal I[n] = I(x n ), non edge-preserving filtering can be performed using a 1st-order recursive filter as where a ? [0, 1] is a feedback coefficient [Smith 2007]. This filter has an infinite impulse response (IIR) with exponential decay: an impulse of magnitude m at position i generates a response of magnitude m (1 ? a) a j?i at j ? i. Note that j ? i can be interpreted as the distance between samples x i and x j , assuming a unitary sampling interval. Based on this observation, a recursive edge-preserving filter can be defined in the transformed domain as where d = ct(x n ) ? ct(x n?1 ) is the distance between neighbor samples x n and x n?1 in the transformed domain (? w ). As d increases, a d goes to zero, stopping the propagation chain and, thus, preserving edges. This can be interpreted as a geodesic propagation on the image lattice. The impulse response of (21) is not symmetric, since it only depends on previous inputs and outputs (it is a causal filter). A symmetric response is achieved by applying the filter twice: for a 1D signal, (21) is performed left-to-right (top-tobottom) and then right-to-left (bottom-to-top). The feedback coefficient of this filter ? is computed from the desired filter variance as a = exp(? 2/? H ) (see the appendix for a derivation). Since a ? [0, 1], the filter is stable [Smith 2007], and its implementation in O(N ) time is straightforward. We compare our edge-preserving filters based on normalized convolution (NC), interpolated convolution (IC), and recursion (RF) against previous works: brute-force bilateral filter (BF) [Tomasi and Manduchi 1998]; anisotropic diffusion (AD) [Perona and Malik 1990]; edge-avoiding wavelets (EAW) [Fattal 2009]; weighted least squares filter (WLS) [Farbman et al. 2008], which has been shown to produce optimal results for tone and detail manipulation; and finally the permutohedral lattice BF (PLBF) [Adams et al. 2009] and constant time BF (CTBF) [Yang et al. 2009], which are, respectively, the fastest color and grayscale bilateral filter approximations. Filter Response Figure 9 shows a comparison of the impulse response of our three filters NC, IC and RF (all performed using three iterations) against the impulse response of BF, AD and WLS. In the presence of strong edges, the IC filter behaves similarly to AD. The NC filter has a higher response near strong edges, which is a direct implication of its interpretation as a robust mean: pixels near edges have less neighbors in the same population, and will weight their contribution strongly. Finally, our recursive filter (RF) has an exponential impulse response which is completely attenuated by strong edges, like the WLS?s response. The NC filter is ideal for stylization and abstraction, since it accurately smoothes similar image regions while preserving and sharpening relevant edges. For applications where sharpening of edges is not desirable (e.g., tone mapping and detail manipulation), the IC and RF filters produce results of equal quality as the state-of-the-art techniques [Farbman et al. 2008; Fattal 2009]. Finally, for edgeaware interpolation (e.g., colorization and recoloring), the RF filter produces the best results due to its infinite impulse response, which propagates information across the whole image lattice. Section 8 illustrates the use of our filters for all these applications. Smoothing Quality Figure 10 shows a side-by-side comparison of edge-aware smoothing applied to a portion of the photograph shown in Figure 1 (a). For small amounts of smoothing, the bilateral filter (b) and our NC filter (c) produce visually similar results. For further smoothing, the bilateral filter may incorrectly mix colors, as observed in the window frame ( Figure 10 (d)). In contrast, our filter manages to continuously smooth image regions while preserving strong edges. This effect, illustrated in Figure 10 (e), is sim- (f)\n        (g), ilar to the results obtained with WLS, shown in (f), and anisotropic diffusion (using [D?Almeida 2004]), shown in (g). Figure 10 (h) shows the result produced by EAW with a maximum decomposition depth of 5 and coefficients for each detail level defined by 0.6 (5?level) , which preserve some high-frequency details. Setting these coefficients to zero results in distracting artifacts. Additional comparisons among these techniques can be found in the supplementary materials. Our filters converge to standard linear smoothing filters on regions with weak edges, or when the range support ? r is set to a large value (see Section 4.2). This feature is desirable, for instance, in joint filtering for performing depth-of-field effects, as shown in Figure 1 (g) and discussed in Section 8. In contrast, our filters provide an indistinguishable approximation to a Gaussian (f) for ? r = ?, as shown in (e). This section reports performance numbers obtained on a 2.8 GHz Quad Core PC with 8 GB of memory and a GeForce GTX 280. Filtering on CPU We implemented our NC and RF filters on CPU using C++. For the IC filter we have a MATLAB implementation, but its performance is expected to be similar to NC?s. On a single CPU core, the typical runtimes of our NC and RF filters for processing a 1 megapixel color image using three iterations are 0.16 and 0.06 seconds, respectively. Their performances scale linearly with image size, filtering 10 megapixel color images in under 1.6 and 0.6 seconds. On a quad-core CPU, we achieve a 3.3? speedup. We compare the performance of our edge-aware filters against the  fastest filters from previous works: EAW, PLBF and CTBF. The PLBF and our NC and RF filters process all three color channels simultaneously, while CTBF only processes grayscale. Thus, CTBF is actually performing one third of the work done by the other three methods. We measured the reported results on a single CPU core. For PLBF and CTBF we used source code provided by the authors. The runtimes for both PLBF and CTBF are inversely proportional to the value of ? r . For ? r approaching zero, their runtimes are above 10 seconds. The runtimes of our filters are independent of the ? s and ? r parameters, and they use no simplifications to improve performance. In this range, our filters with three iterations are 5 to 15? faster than these approaches. For small amounts of smoothing, one can obtain good results using two or even one iteration of our filter ( Figure 7 ), with speed-ups of 25 to 40? over PLBF for color filtering. According to Fattal [2009], EAW can smooth a 1 megapixel grayscale image in 0.012 seconds on a 3.0 GHz CPU. Since it generates decompositions at only a few scales, it is not generally applicable for edge-preserving smoothing. WLS takes 3.5 seconds to solve its sparse linear system using a fast CPU implementation. A graph comparing the performances of these techniques can be found in the supplementary materials. Filtering on GPU We implemented our NC filter on GPU using CUDA. The total time required for filtering a 1 megapixel color image is 0.7 msec for computing the domain transform plus 2 msec for each 2D filtering iteration. This gives a total runtime of approximately 0.007 seconds for three iterations of our filter? a speedup of 23? compared to our one-core CPU implementation. Since our filter scales linearly with the image size, our GPU implementation is able to filter 10 megapixel color images in under 0.07 seconds. We compare the performance of our GPU filter against the GPU Bilateral Grid [Chen et al. 2007]. While their implementation is as fast as ours, it only processes luminance values, which may generate undesired color-ghosting artifacts. The GPU implementation of PLBF can filter a 0.5 megapixel image in 0.1 sec on a GeForce GTX 280 [Adams et al. 2010]. A GPU implementation of WLS filters a 1 megapixel grayscale image in about 1 second [Farbman et al. 2008]. We show a variety of applications that demonstrate the versatility of our domain transform and filters for image processing. Given its speed, our approach can be performed on the fly on high-resolution images and videos. This improved performance provides users with instant feedback when tuning filter parameters. Examples of video applications are included in the supplementary materials. Detail Manipulation Edge-preserving filters can be used to decompose image details into several scales, which can be manipulated independently and recombined to produce various effects [Farbman et al. 2008; Fattal 2009]. Let J 0 , . . . , J k be progressively smoother versions of an image I = J 0 . Several detail layers capturing progressively coarser details are constructed as D i = J i ? J i+1 . Figure 12 shows an example of fine-scale detail enhancement applied to the flower image in (a). The result in (b) was created by filtering the image in (a) once using our IC filter (? s = 20 and ? r = 0.08) and by manipulating the detail layer D 0 using a sigmoid function described by Farbman et al. [2008]. Figure 12 (c) shows the result produced by an EAW filter of Fattal [2009]. The images (b) and (c) present similar visual quality. Our filter, however, allows for extra flexibility when decomposing image details, since it can produce a continuum of smoothed images J i , by varying the values of the parameters ? s and ? r . Tone Mapping Edge-aware tone mapping avoids haloing and other artifacts introduced in the compression process. Figure 13 compares the result of a tone mapping operator implemented using our RF filter (a) and the WLS filter by Farbman et al. [2008] (b). The quality of these results are similar, but our filter is significantly faster, resulting in the fastest high-quality tone-mapping solution available. The result in Figure 13 (a) was obtained by manipulating three detail layers from the HDR image?s log-luminance channel. Each layer was obtained in 12 msec using two iterations of our RF filter with: ? s = 20 and ? r = 0.33 for J 1 ; ? s = 50 and ? r = 0.67 for J 2 ; and ? s = 100 and ? r = 1.34 for J 3 . The compressed luminance channel L C was obtained as: L C = 0.12 + ? + 0.9 (B ? ?) + 0.3 D 0 + 0.2 D 1 + 0.2 D 2 ;\n        where B is a linear compression of J 3 to the range [0, 1] (i.e., B = (J 3 ? min(J 3 ))/(max(J 3 ) ? min(J 3 ))), and ? is the mean value of B. J i and D i were defined in the previous paragraph. Edge-aware filters are ideal for stylization, as they can abstract regions of lowcontrast while preserving, or enhancing, high-contrast features. Figure 14 illustrates an application of our NC filter to produce abstracted results. Given an input image (top left), the magnitude of the gradient of the filtered image (top right) is superimposed to the filtered image itself to produce high-contrast edges around the most salient features. Another interesting stylization effect can be obtained by assigning to each output pixel a scaled version of the value of the normalization factor K p from Equation 15. This produces a pencil-like non-photorealistic drawing, such as the one shown in Figure 1 (f), obtained scaling K p by 0.11. Joint Filtering Our approach can also be used for joint filtering, where the content of one image is smoothed based on the edge information from a second image. For instance, by using the values of an alpha matte [Gastal and Oliveira 2010] as the the image derivatives in Equation 11, one can simulate a depth-of-field effect ( Figure 1 (g)). This example emphasizes why converging to a Gaussian-like response is an important property of our filter. In this example, an alpha matte and a structure resembling a Voronoi diagram have been added to define new edges to be preserved ( Figure 15 , bottom left). The resulting filter produces a unique stylized depth-of-field effect. The edges of the diagram were then superimposed to the filtered image to create the result shown on the right. A similar result is shown in Figure 1 (d), where the edges to be preserved were identified by a Canny edge detector. Colorization Similar to previous approaches [Levin et al. 2004; Fattal 2009], we propagate the colors S from user-supplied scribbles by blurring them using the edge information from a grayscale image I ( Figure 16 , left). To keep track of how much color propagates to each pixel, we also blur a normalization function N , which is defined to be one at pixels where scribbles are provided and zero otherwise. Let S  ? and N  ? be the blurred versions of S and N , respectively. The final color of each pixel p is obtained as S(p)/  ? N  ? (p). This value is combined with the original luminance from the grayscale image to produce the colorized result. Figure 16 compares the results obtained with our RF filter (? s = 100 and ? r = 0.03) with the ones of Levin et al. [2004]. In our experience, good colorization results can be obtained with values of ? r from 0.01 to 0.1 and ? s > 100. Recoloring Localized manipulations of image colors is achieved using soft segmentation. Color scribbles define a set of regions of interest, where each region R i is defined by a color c i . For each region R i , an influence map [Lischinski et al. 2006] is obtained by blurring its associated normalization function N R i defined by all scribbles with color c i . The contribution of R i for the recoloring of pixel p is defined as N  ? R i (p)/ j N  ? R j (p). Figure 1 (e) shows a recoloring example obtained using this technique. Our filters are temporally stable and can be applied to videos in real time. Please, see the accompanying video for examples. We have presented a new approach for performing high-quality edge-preserving filtering of images and videos in real time. Our solution is based on a transform that defines an isometry between curves on the 2D image manifold in 5D and the real line. This transform preserves the geodesic distance between points on the curve, adaptively warping the input signal so that 1D edge-preserving filtering can be efficiently performed in linear time. We demonstrated three realizations for our 1D edge-preserving filters, based on normalized convolution, interpolated convolution, and recursion. These filters have very distinct impulse responses, making each one more appropriate for specific applications. We have shown how to produce high-quality 2D edge-preserving filtering by iterating 1D-filtering operations. We analyzed the convergence of this process and showed that three iterations provide a good compromise between image quality and computational time. Our approach has several desirable features. First, it is applied to the signal?s original samples, correctly handling color images. Second, the use of 1D operations leads to considerable speedups over existing techniques and potential memory savings. Finally, it is the first edge-preserving filter capable of working on color images at arbitrary scales in real time, without resorting to subsampling or quantization. It can filter a 1 megapixel color image at approximately 150 fps using three iterations, which is significantly faster than previous techniques. We have demonstrated the versatility of our domain transform and edge-preserving filters on several real-time image and video processing tasks including edge-preserving filtering, depth-of-field effects, stylization, recoloring, colorization, detail enhancement, and (b) Result of Levin et al. [2004]. tone mapping. One feature of our filters is that their responses stop at strong edges. This is in contrast with the bilateral filter, whose kernel can cross edges ( Figure 9 ). We believe both behaviors are valid and may provide optimal results for different kinds of applications. The speed, flexibility, and high-quality of the results achieved with our technique may enable many new applications that have not been previously possible. Limitations As most other fast edge-preserving filters, our 2D filters are not rotationally invariant (i.e., filtering a rotated image and rotating a filtered image may produce different results). This behaviour may cause problems for applications that rely on content matching. Our 1D edge-preserving filters can be applied to other kinds of signals and to higher-dimensional data. Other possible directions for exploration involve applying our filters on meshes, and their implementation in the frequency domain. We would like to thank the anonymous reviewers for their insightful comments. This work was sponsored by CNPq-Brazil (fellowships and grants 557814/2010-3, 200284/2009-6, 308936/2010-8, and 480485/2010-0). Input images from Figures 12, 15 and 16 courtesy of Farbman et al [2008], www.alphamatting.com and Levin et al. [2004], respectively. Figure 13 generated from a radiance map courtesy of Paul Debevec. Input images from Figures 6 and 14 are from publicdomainpictures.net (images 8363 and 5298). The continuous equivalent of the recursive kernel is f (x) = (1 ? a) a x , x ? [0, +?), a ? (0, 1); where x represents the distance between samples and a is the feedback coefficient. f (x) is not normalized since ? (1 ? a)a x ? 1 ? a f (x) dx = = ? . 0 log(a) 0 log(a) Normalizing f we obtain f (x) = ?log(a) a x . The first and second moments of f are, respectively: f = ?log(a) ? x a x dx = ? 1 and 0 log(a) f 2 = ?log(a) ? x 2 a x dx = 2 . 0 log(a) 2 The variance of f is then given by V ar(f ) = f 2 ? f 2 = 1 . log(a) 2 Since the signal is filtered twice with f (left-to-right and right-toleft), the total variance of the filter is 2 V ar(f ). Given the desired variance ? H 2 : 2 2 ? H = 2 V ar(f ) = log(a) 2 ; we solve for a and find ? ? a = exp(? 2/? H ) and a = exp( 2/? H ); where the former is our solution since a ? (0, 1).",
  "resources" : [ ]
}