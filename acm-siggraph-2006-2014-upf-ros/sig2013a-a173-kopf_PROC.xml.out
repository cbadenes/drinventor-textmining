{
  "uri" : "sig2013a-a173-kopf_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2013a/a173-kopf_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Content-Adaptive Image Downscaling",
    "published" : "2013",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Johannes-Kopf",
      "name" : "Johannes",
      "surname" : "Kopf"
    }, {
      "uri" : "http://drinventor/Ariel-Shamir",
      "name" : "Ariel",
      "surname" : "Shamir"
    }, {
      "uri" : "http://drinventor/Pieter-Peers",
      "name" : "Pieter",
      "surname" : "Peers"
    } ]
  },
  "bagOfWords" : [ "filter", "push", "image", "below", "Nyquist", "frequency", "prevent", "aliasing", "side", "effect", "result", "might", "suffer", "from", "loss", "fine", "detail", "blur", "sharp", "edge", "-lrb-", "figure", "2c", "-rrb-", "work", "we", "present", "new", "content-adaptive", "downscaling", "algorithm", "follow", "previous", "technique", "bilateral", "filter", "-lsb-", "Tomasi", "Manduchi", "1998", "-rsb-", "mean", "shift", "-lsb-", "Comaniciu", "et", "al.", "2002", "-rsb-", "we", "use", "kernel", "combination", "spatial", "gaussian", "kernel", "ensure", "locality", "color", "space", "gaussian", "kernel", "alignment", "image", "content", "Input", "Lanczos", "Bicubic", "we", "result", "sharpen", "result", "Kernels", "Reconst", "-lrb-", "-rrb-", "input", "-lrb-", "-rrb-", "bicubic", "-lrb-", "-rrb-", "bilateral", "-lrb-", "-rrb-", "we", "result", "find", "local", "filter", "kernel", "we", "formulate", "we", "task", "reconstruction", "problem", "input", "image", "from", "smaller", "set", "local", "kernel", "function", "-lrb-", "probability", "density", "function", "-rrb-", "fix", "color", "define", "joint", "5d", "space", "location", "color", "we", "interpret", "each", "input", "image", "pixel", "sample", "draw", "randomly", "from", "one", "local", "kernel", "uniform", "probability", "sampling", "local", "kernel", "theoretically", "kernel", "can", "have", "any", "shape", "location", "first", "number", "kernel", "must", "equal", "number", "output", "pixel", "hence", "kernel", "can", "vanish", "during", "optimization", "Third", "prevent", "aliasing", "artifact", "we", "add", "orientation", "constraint", "describe", "section", "where", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "unknown", "-rrb-", "weight", "kernel", "pixel", "relative", "all", "kernel", "overlap", "pixel", "-lrb-", "also", "unknown", "-rrb-", "kernel", "domain", "-lrb-", "-rrb-", "-lsb-", "-rsb-", "bilateral", "gaussian", "kernel", "we", "case", "i.e.", "we", "denote", "value", "kernel", "pixel", "give", "we", "input", "image", "we", "search", "most", "probable", "set", "parameter", "-lcb-", "-rcb-", "kernel", "set", "unknown", "variable", "-lrb-", "-rrb-", "can", "produce", "-lrb-", "reconstruct", "-rrb-", "image", "use", "baye", "rule", "convert", "maximize", "-lrb-", "log", "-rrb-", "likelihood", "input", "image", "give", "model", "set", "kernel", "problem", "well", "know", "statistics", "solve", "use", "expectation-maximization", "-lrb-", "em", "-rrb-", "algorithm", "-lsb-", "Hastie", "et", "al.", "2005", "-rsb-", "where", "unknown", "variable", "-lrb-", "-rrb-", "can", "see", "probability", "pixel", "draw", "from", "kernel", "k.", "ACM", "transaction", "Graphics", "Vol", "Article", "173", "publication", "date", "November", "2013", "we", "initialize", "kernel", "correspond", "output", "pixel", "-lrb-", "-rrb-", "where", "-lrb-", "-rrb-", "center", "output", "pixel", "scale", "input", "image", "dimension", "ratio", "input", "output", "image", "width", "height", "respectively", "expectation", "step", "we", "compute", "soft", "assignment", "probability", "each", "pixel", "each", "kernel", "assume", "current", "estimate", "parameter", "correct", "other", "word", "-lrb-", "-rrb-", "quantify", "how", "much", "input", "pixel", "contribute", "relatively", "final", "color", "output", "pixel", "maximization", "step", "we", "use", "soft", "assignment", "weighted", "maximum-likelihood", "fit", "update", "estimate", "parameter", "note", "we", "control", "color", "space", "Gaussians", "directly", "constrain", "locality", "edge", "orientation", "describe", "next", "section", "we", "add", "third", "correction", "step", "after", "every", "maximization", "step", "step", "we", "enforce", "different", "constraint", "specific", "we", "downsample", "problem", "-lrb-", "section", "-rrb-", "algorithm", "proceed", "iteratively", "alternate", "between", "perform", "expectation", "maximization", "correction", "step", "terminate", "when", "convergence", "model", "parameter", "reach", "please", "refer", "supplemental", "document", "detailed", "pseudo-code", "description", "downscale", "more", "restricted", "problem", "than", "general", "signal", "reconstruction", "thus", "find", "optimal", "kernel", "shape", "weight", "minimize", "reconstruction", "error", "sufficient", "condition", "obtain", "good", "downscaled", "result", "we", "perform", "additional", "correction", "step", "after", "every", "maximization", "step", "enforce", "downscaling-specific", "constraint", "spatial", "constraint", "since", "output", "pixel", "position", "arrange", "perfect", "lattice", "important", "constrain", "location", "corresponding", "kernel", "otherwise", "potentially", "move", "too", "far", "from", "initial", "position", "which", "can", "lead", "scramble", "result", "appearance", "-lrb-", "figure", "-rrb-", "influence", "should", "remain", "local", "-lrb-", "figure", "-rrb-", "Edge", "orientation", "boundary", "between", "two", "neighbor", "kernel", "should", "have", "similar", "orientation", "boundary", "between", "two", "pixel", "output", "image", "-lrb-", "figure", "-rrb-", "-lrb-", "-rrb-", "unconstrained", "-lrb-", "-rrb-", "kernel", "-lrb-", "-rrb-", "constrain", "-lrb-", "-rrb-", "input", "-lrb-", "-rrb-", "unconstrained", "-lrb-", "-rrb-", "constrain", "normalize", "retain", "characteristic", "grid", "topology", "output", "pixel", "we", "bias", "spatial", "mean", "towards", "smooth", "grid-like", "topology", "first", "we", "limit", "extent", "spatial", "mean", "can", "move", "constrain", "lie", "within", "box", "center", "around", "center", "output", "pixel", "formally", "we", "update", "where", "n?n", "-lrb-", "4-connected", "-rrb-", "neighbor", "show", "Figure", "we", "constrain", "shape", "spatial", "variance", "avoid", "vanishingly", "small", "exceedingly", "large", "kernel", "we", "first", "obtain", "singular", "value", "decomposition", "-lrb-", "-rrb-", "svd", "-lrb-", "-rrb-", "modify", "diagonal", "eigenvalue", "matrix", "clamp", "its", "element", "interval", "-lsb-", "0.05", "0.1", "-rsb-", "finally", "set", "where", "contain", "clamp", "eigenvalue", "while", "equation", "12", "impose", "hard", "constraint", "spatial", "component", "we", "kernel", "relatively", "smooth", "color", "component", "cause", "they", "align", "feature", "image", "general", "desire", "however", "certain", "situation", "too", "much", "adaptation", "can", "cause", "visual", "artifact", "we", "use", "color", "variance", "parameter", "which", "estimate", "directly", "control", "amount", "adaptation", "hence", "sharpness", "we", "result", "small", "cause", "kernel", "more", "sensitive", "color", "variation", "have", "sharper", "transition", "while", "larger", "lead", "smoother", "kernel", "reason", "freely", "estimate", "maximum", "likelihood", "estimation", "often", "yield", "too", "smooth", "configuration", "rather", "ACM", "transaction", "Graphics", "Vol", "Article", "173", "publication", "date", "November", "2013", "-lrb-", "-rrb-", "input", "-lrb-", "-rrb-", "unconstrained", "-lrb-", "-rrb-", "constrained", "than", "estimate", "from", "datum", "we", "control", "explicitly", "locally", "adjust", "sharpness", "result", "most", "kernel", "we", "let", "remain", "its", "initial", "crisp", "set", "we", "only", "increase", "local", "smoothing", "under", "two", "specific", "condition", "-lrb-", "-rrb-", "when", "kernel", "become", "too", "dominant", "compare", "neighbor", "-lrb-", "-rrb-", "prevent", "staircase", "artifact", "follow", "each", "maximization", "step", "we", "search", "kernel", "match", "one", "condition", "correct", "they", "increase", "10", "-lrb-", "i.e.", "increase", "smoothness", "color", "kernel", "-rrb-", "locality", "while", "clamp", "eigenvalue", "avoid", "large", "spatial", "Gaussians", "result", "bilateral", "kernel", "can", "still", "have", "large", "spatial", "extent", "due", "normalization", "equation", "Figure", "6b", "illustrate", "instance", "problem", "small", "figure", "show", "normalize", "kernel", "weight", "-lrb-", "-rrb-", "two", "pixel", "subfigure", "-lrb-", "-rrb-", "kernel", "keep", "small", "color", "variance", "lead", "solution", "where", "one", "kernel", "grab", "all", "dark", "pixel", "line", "while", "other", "kernel", "grab", "light", "pixel", "surrounding", "even", "though", "spatial", "weight", "kernel", "line", "fall", "off", "quickly", "normalization", "cause", "they", "become", "large", "again", "because", "surround", "kernel", "have", "even", "lower", "weight", "due", "strong", "color", "adaption", "cause", "line", "feature", "become", "disconnect", "we", "correct", "behavior", "detect", "kernel", "grow", "too", "strong", "any", "direction", "selectively", "increase", "color", "variance", "first", "we", "compute", "directional", "variance", "each", "eight", "neighbor", "where", "-lrb-", "-rrb-", "-lsb-", "-rsb-", "-lrb-", "-rrb-", "offset", "one", "eight", "neighbor", "any", "directional", "variance", "exceed", "threshk", "old", "0.2", "-lrb-", "where", "ratio", "input", "image?s", "width", "over", "output", "image?s", "width", "-rrb-", "we", "increase", "smoothness", "both", "current", "kernel", "respective", "neighbor", "effect", "heuristic", "illustrate", "Figure", "6c", "ability", "we", "algorithm", "keep", "linear", "feature", "connect", "while", "maintain", "sharpness", "can", "also", "nicely", "observe", "pixel", "art", "result", "figure", "15", "Edge", "Orientations", "form", "staircase", "artifact", "occur", "when", "orientation", "edge", "between", "two", "dissimilar", "pixel", "output", "pixel", "grid", "significantly", "different", "than", "orientation", "edge", "between", "corresponding", "kernel", "artifact", "most", "visible", "long", "line", "almost", "cardinal", "direction", "corresponding", "image", "edge", "input", "image", "almost", "vertical", "we", "selectively", "remove", "false", "edge", "increase", "corresponding", "kernel", "first", "we", "detect", "strong", "edge", "between", "adjacent", "pixel", "testing", "neighbor", "kernel", "have", "abrupt", "transition", "horizontal", "vertical", "neighbor", "we", "measure", "strength", "edge", "between", "normalize", "kernel", "kn", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "transition", "between", "two", "kernel", "abrupt", "few", "pixel", "where", "both", "kernel", "take", "large", "value", "thus", "kn", "small", "we", "consider", "edge", "where", "kn", "0.08", "strong", "256", "color", "12", "color", "Input", "quantize", "12", "color", "Input", "Gerstner", "et", "al.", "we", "result", "Input", "16", "color", "16", "color", "kn", "deviate", "more", "than", "25", "degree", "from", "orientation", "pixel", "edge", "we", "consider", "false", "edge", "increase", "smoothness", "both", "kernel", "involve", "effect", "correction", "illustrate", "Figure", "7c", "we", "test", "we", "algorithm", "wide", "range", "input", "image", "range", "from", "natural", "image", "line", "vector", "art", "all", "result", "be", "create", "same", "algorithm", "setting", "Figure", "13", "other", "figure", "throughout", "paper", "show", "representative", "result", "we", "algorithm", "we", "compare", "we", "method", "na?ve", "subsampling", "bicubic", "filter", "-lrb-", "arguably", "most", "commonly", "use", "rescaling", "algorithm", "-rrb-", "we", "result", "show", "we", "method", "yield", "sharper", "result", "-lrb-", "instance", "text", "-rrb-", "maintain", "detail", "better", "-lrb-", "e.g.", "lunar", "surface", "flower", "Figure", "13", "-rrb-", "preserve", "appearance", "high", "frequency", "texture", "-lrb-", "e.g.", "Figure", "leave", "-rrb-", "supplementary", "material", "we", "provide", "extensive", "comparison", "large", "set", "image", "compare", "we", "method", "wider", "range", "downscale", "method", "-lrb-", "include", "range", "linear", "filter", "unoptimized", "bilateral", "kernel", "Generalized", "sample", "-lsb-", "Nehab", "Hoppe", "2011", "-rsb-", "pixelated", "image", "abstraction", "-lsb-", "Gerstner", "et", "al.", "2012", "-rsb-", "-rrb-", "downscale", "we", "algorithm", "particularly", "well", "suit", "downscale", "cartoon", "vector", "art", "image", "create", "pixel", "art", "figure", "15", "show", "representative", "result", "when", "generate", "result", "we", "disable", "edge", "orientation", "constraint", "-lrb-", "section", "4.2", "-rrb-", "since", "we", "aim", "blocky", "old", "school", "look", "-lrb-", "i.e.", "big", "pixel", "-rrb-", "particular", "note", "we", "algorithm?s", "ability", "keep", "line", "feature", "connect", "comparison", "many", "line", "subsampled", "result", "interrupted", "while", "bicubic", "result", "exhibit", "wash", "out", "color", "due", "excessive", "smoothing", "we", "algorithm", "strike", "balance", "between", "both", "extreme", "keep", "outline", "sharp", "connected", "where", "ACM", "transaction", "Graphics", "Vol", "Article", "173", "publication", "date", "November", "2013", "color", "color", "color", "color", "Gerstner", "et", "al.", "result", "color", "color", "color", "color", "we", "result", "Gerstner", "et", "al.", "we", "result", "16", "color", "16", "color", "possible", "while", "too", "detailed", "area", "naturally", "resolve", "average", "out", "feature", "Extension", "Palette", "Reduction", "one", "particular", "form", "pixel", "art", "also", "include", "reduce", "color", "palette", "-lsb-", "Gerstner", "et", "al.", "2012", "-rsb-", "while", "focus", "we", "method", "we", "be", "interested", "investigate", "effectiveness", "apply", "color", "palette", "reduction", "postprocess", "we", "use", "mean", "shift", "segmentation", "follow", "description", "Comaniciu", "Meer?s", "paper", "-lsb-", "2002", "-rsb-", "-lrb-", "use", "Epanechnikov", "kernel", "fix", "spatial", "bandwidth", "-rrb-", "use", "color", "bandwidth", "parameter", "adjust", "number", "color", "output", "image", "we", "find", "work", "particularly", "well", "cartoon", "vector", "art", "input", "show", "Figure", "type", "image", "we", "method", "produce", "higher", "quality", "result", "than", "Gerstner", "et", "al.", "-lsb-", "2012", "-rsb-", "however", "mainly", "due", "we", "algorithm?s", "ability", "keep", "line", "feature", "connect", "when", "apply", "natural", "image", "however", "we", "find", "mean", "shift", "segmentation", "work", "well", "instead", "we", "use", "simple", "k-means", "clustering", "natural", "image", "where", "produce", "image", "similar", "quality", "Gerstner", "et", "al.", "-lsb-", "2012", "-rsb-", "-lrb-", "Figure", "-rrb-", "verify", "we", "algorithm", "we", "conduct", "formal", "user", "study", "51", "subject", "use", "Amazon", "mechanical", "Turk", "which", "we", "compare", "we", "algorithm", "against", "five", "alternative", "-lrb-", "-rrb-", "Generalized", "sample", "-lsb-", "Nehab", "Hoppe", "2011", "-rsb-", "which", "we", "consider", "state-of-the-art", "algorithm", "image", "scaling", "-lrb-", "-rrb-", "bicubic", "since", "one", "most", "commonly", "use", "scale", "algorithm", "-lrb-", "-rrb-", "subsampling", "its", "simplicity", "-lrb-", "-rrb-", "box", "filter", "because", "yield", "sharper", "result", "than", "bicubic", "-lrb-", "-rrb-", "unoptimized", "bilateral", "kernel", "verify", "effectiveness", "we", "optimization", "each", "test", "we", "show", "participant", "high", "resolution", "-lrb-", "400", "pixel", "long", "side", "-rrb-", "input", "image", "well", "two", "downscale", "re", "result", "user", "study", "compare", "we", "algorithm", "against", "several", "exist", "algorithm", "sult", "-lrb-", "128", "pixel", "-rrb-", "one", "produce", "we", "algorithm", "other", "produce", "one", "compete", "algorithm", "participant", "be", "ask", "which", "result", "represent", "better", "downscale", "version", "input", "image", "have", "choose", "either", "one", "result", "express", "preference", "time", "limit", "impose", "all", "image", "be", "show", "native", "display", "resolution", "participant", "be", "provide", "any", "means", "zoom", "image", "each", "participant", "present", "13", "test", "total", "each", "testing", "we", "algorithm", "against", "random", "compete", "algorithm", "different", "input", "image", "i.e.", "participant", "see", "same", "input", "image", "more", "than", "once", "we", "repeat", "every", "question", "throughout", "test", "filter", "unreliable", "participant", "remove", "all", "answer", "from", "participant", "who", "be", "consistent", "less", "than", "80", "test", "study", "we", "select", "variety", "natural", "image", "from", "MSRA", "Salient", "Object", "database", "-lsb-", "Liu", "et", "al.", "2007", "-rsb-", "span", "different", "category", "include", "people", "stochastic", "regular", "texture", "text", "smooth", "area", "result", "show", "Figure", "10", "analysis", "between", "each", "condition", "indicate", "we", "algorithm", "significantly", "prefer", "over", "each", "compete", "technique", "we", "method", "employ", "iterative", "optimization", "strategy", "downscale", "image", "consequently", "computationally", "more", "demand", "than", "classical", "linear", "rescaling", "filter", "follow", "we", "analyze", "performance", "we", "C++", "implementation", "run", "Intel", "Xeon", "E5640", "CPU", "2.66", "GHz", "we", "partially", "use", "multiple", "core", "we", "implementation", "we", "have", "fully", "parallelize", "optimize", "implementation", "convergence", "proof", "original", "em-algorithm", "do", "carry", "through", "onto", "we", "algorithm", "due", "we", "modification", "however", "we", "do", "encounter", "convergence", "issue", "several", "thousand", "image", "tested?if", "would", "happen", "one", "could", "simply", "terminate", "algorithm", "after", "fixed", "number", "iteration", "single", "iteration", "we", "algorithm", "linear", "both", "input", "output", "image", "size", "due", "content", "dependent", "nature", "we", "algorithm", "number", "iteration", "vary", "different", "output", "image", "same", "size", "Figure", "11", "report", "runtime", "-lrb-", "blue", "-rrb-", "number", "iteration", "-lrb-", "red", "-rrb-", "average", "over", "processing", "100", "randomly", "select", "natural", "image", "shaded", "region", "indicate", "standard", "deviation", "dash", "line", "indicate", "min?max", "range", "Figure", "11", "left", "output", "size", "keep", "fix", "80", "60", "pixel", "while", "input", "size", "vary", "from", "160", "120", "640", "480", "Figure", "11", "right", "output", "size", "vary", "from", "40", "30", "160", "120", "while", "input", "size", "remain", "fix", "640", "480", "pixel", "ACM", "transaction", "Graphics", "Vol", "Article", "173", "publication", "date", "November", "2013", "varying", "input", "dimension", "fixed", "output", "dimension", "varying", "output", "dimension", "fix", "input", "dimension", "we", "algorithm", "rely", "number", "heuristic", "constraint", "prevent", "certain", "downscale", "artifact", "-lrb-", "section", "-rrb-", "EM", "step", "process", "each", "kernel", "independently", "constraint", "other", "hand", "rely", "relation", "between", "neighbor", "kernel", "hence", "can", "directly", "solve", "step", "therefore", "constraint", "handle", "additional", "third", "step", "due", "content-adaptive", "nature", "we", "algorithm", "behave", "temporally", "less", "coherent", "than", "linear", "filter", "when", "apply", "smooth", "animation", "e.g.", "slow", "zoom", "picture", "we", "result", "flicker", "slightly", "while", "each", "individual", "image", "appear", "crisper", "exhibit", "more", "detail", "please", "refer", "supplementary", "material", "video", "illustrate", "issue", "similar", "problem", "can", "occur", "symmetric", "feature", "input", "image", "example", "we", "algorithm", "fail", "preserve", "symmetry", "yellow", "button", "Figure", "12", "we", "algorithm", "do", "prevent", "aliase", "under", "all", "circumstance", "consequently", "we", "method", "do", "perform", "well", "most", "standard", "aliasing", "test", "e.g.", "zone", "plate", "pattern", "Figure", "12", "furthermore", "we", "result", "can", "reach", "quality", "well-trained", "expert", "achieve", "when", "manually", "hint", "font", "manually", "create", "pixel", "art", "-lrb-", "figure", "12", "bottom", "-rrb-", "while", "we", "method", "significantly", "improve", "quality", "downscale", "image", "exhibit", "small", "detail", "eye", "stochastic", "texture", "do", "always", "produce", "better", "result", "image", "blur", "feature", "image", "contain", "structured", "texture", "latter", "case", "despite", "we", "effort", "-lrb-", "section", "-rrb-", "staircase", "can", "still", "occur", "artifact", "show", "up", "particular", "long", "almost", "cardinal", "line", "e.g.", "right", "edge", "sign", "top", "row", "Figure", "13", "systematic", "investigation", "artifact", "can", "find", "supplementary", "material", "accompany", "web", "site", "lastly", "since", "equation", "-lrb-", "-rrb-", "may", "have", "multiple", "local", "minimum", "we", "may", "reach", "slightly", "different", "solution", "depend", "we", "initialization", "supplementary", "material", "accompany", "web", "site", "we", "show", "various", "sensible", "initialization", "choice", "yield", "similar", "solution", "we", "settle", "use", "middle", "gray", "initialization", "which", "work", "well", "we", "test", "we", "result", "Input", "Bicubic", "we", "result", "we", "have", "present", "novel", "content-adaptive", "image", "downscaling", "method", "adapt", "shape", "its", "downsample", "kernel", "yield", "sharper", "more", "detailed", "downscale", "result", "contrary", "common", "wisdom", "dictate", "frequency", "above", "Nyquist", "frequency", "introduce", "artifact", "downsampled", "image", "-lrb-", "form", "aliasing", "-rrb-", "we", "show", "careful", "sampling", "certain", "high", "frequency", "feature", "can", "still", "preserve", "downscale", "image", "without", "artifact", "give", "grow", "resolution", "gap", "between", "camera", "display", "device", "advent", "gigapixel", "panoramic", "imaging", "we", "believe", "work", "open", "up", "exciting", "area", "research", "plentiful", "avenue", "future", "research", "we", "work", "have", "show", "possible", "sometimes", "drastically", "improve", "quality", "over", "exist", "downscale", "method", "would", "also", "interesting", "look", "other", "signal", "than", "image", "input", "natural", "immediate", "step", "would", "analyze", "constrain", "temporal", "behavior", "we", "algorithm", "e.g.", "when", "apply", "video", "work", "part", "support", "nsf", "iis-1217765", "Israeli", "Science", "Foundation", "-lrb-", "grant", "of-the-art", "superpixel", "method", "IEEE", "Trans", "pattern", "Anal", "34", "11", "2274", "2282", "VIDAN", "S.", "HAMIR", "A.", "Seam", "carve", "content-aware", "image", "resize", "ACM", "transaction", "graphic", "-lrb-", "Proc", "SIGGRAPH", "2007", "-rrb-", "26", "article", "omaniciu", "D.", "eer", "P.", "ember", "S.", "2002", "mean", "shift", "robust", "approach", "toward", "feature", "space", "analysis", "IEEE", "transaction", "Pattern", "analysis", "machine", "Intelligence", "24", "603", "619", "erstner", "T.", "ARLO", "D.", "LEXA", "M.", "inkelstein", "a.", "ingold", "Y.", "ealen", "a.", "2012", "pixelated", "image", "abstraction", "Proceedings", "International", "Symposium", "NonPhotorealistic", "Animation", "Rendering", "-lrb-", "npar", "-rrb-", "29", "36", "astie", "T.", "ibshiranus", "R.", "RIEDMAN", "J.", "ranklin", "J.", "2005", "element", "statistical", "learning", "datum", "mining", "inference", "prediction", "mathematical", "intelligencer", "27", "83", "85", "ngli", "T.", "C.", "APLAN", "C.", "S.", "2012", "pixelate", "vector", "line", "art", "Proceedings", "Symposium", "Non-Photorealistic", "Animation", "Rendering", "21", "28", "ARNI", "Z.", "reedman", "D.", "OTSMAN", "C.", "2009", "energybased", "image", "deformation", "Proceedings", "Symposium", "Geometry", "Processing", "-lrb-", "SGP", "2009", "-rrb-", "1257", "1268", "iu", "T.", "UN", "J.", "HENG", "N.-N.", "ang", "X.", "hum", "h.-y", "2007", "learn", "detect", "salient", "object", "Proceedings", "IEEE", "Conference", "Computer", "Vision", "Pattern", "recognition", "-lrb-", "cvpr", "2007", "-rrb-", "anson", "J.", "CHAEFER", "S.", "2012", "parameterization-aware", "mip-mapping", "Computer", "Graphics", "Forum", "-lrb-", "Proc", "Eurographics", "Symposium", "rendering", "-rrb-", "31", "1455", "1463", "ehab", "D.", "OPPE", "H.", "2011", "Generalized", "sampling", "computer", "graphic", "ubinstein", "m.", "hamir", "a.", "vidan", "S.", "2009", "multioperator", "media", "retargeting", "ACM", "transaction", "graphic", "-lrb-", "Proceedings", "SIGGRAPH", "2009", "-rrb-", "28", "11", "amadanus", "R.", "IM", "S.", "H.", "retter", "D.", "2007", "Representative", "image", "thumbnail", "good", "browsing", "Proceedings", "International", "conference", "image", "processing", "-lrb-", "icip", "2007", "-rrb-", "193", "196", "HANNON", "C.", "E.", "1949", "communication", "presence", "noise", "Proceedings", "Institute", "Radio", "Engineers", "37", "10", "21", "UH", "B.", "ING", "H.", "EDERSON", "B.", "B.", "ACOBS", "D.", "W.", "2003", "Automatic", "thumbnail", "crop", "its", "effectiveness", "Proceedings", "16th", "annual", "acm", "symposium", "user", "interface", "software", "technology", "95", "104", "omasus", "C.", "anduchus", "R.", "1998", "bilateral", "filter", "gray", "color", "image", "Proceedings", "IEEE", "International", "Conference", "Computer", "Vision", "-lrb-", "ICCV", "98", "-rrb-", "836", "846", "rentacoste", "m.", "antiuk", "R.", "eidrich", "W.", "2011", "blur-aware", "image", "downsizing", "Computer", "Graphics", "Forum", "-lrb-", "Proc", "eurographic", "2011", "-rrb-", "30", "573", "582", "rigg", "B.", "2001", "empirical", "filter", "estimation", "subpixel", "interpolation", "matching", "Proceedings", "IEEE", "International", "Conference", "Computer", "Vision", "-lrb-", "ICCV", "2001", "-rrb-", "550", "557", "OLBERG", "G.", "1990", "Digital", "image", "warping", "IEEE", "Computer", "Society", "Press", "Los", "Alamitos", "CA", "USA", "OLF", "L.", "UTTMANN", "M.", "ohen", "D.", "2007", "nonhomogeneous", "content-driven", "video-retargeting", "Proceedings", "IEEE", "International", "Conference", "Computer", "Vision", "-lrb-", "ICCV", "2007", "-rrb-", "Input", "Subsampling", "Bicubic", "Input", "Subsampling", "Bicubic", "Input", "Downscaled", "Input", "Subsampling", "we", "result", "Input", "we", "result", "Input", "Input", "Bicubic", "we", "result", "input" ],
  "content" : "The filtering pushes the image below the Nyquist frequency and prevents aliasing, but as a side effect the result might suffer from loss of fine details and blurring of sharp edges ( Figure 2c ). In this work we present a new content-adaptive downscaling algorithm. Following previous techniques such as bilateral filtering [Tomasi and Manduchi 1998] and mean shift [Comaniciu et al. 2002], we use kernels that are a combination of a spatial Gaussian kernel ensuring locality, and a color space Gaussian kernel for alignment with the image content. Input Lanczos Bicubic Our result sharpened Result Kernels\n      Reconst. (a) Input\n      (b) Bicubic (c) Bilateral (d) Our result To find the local filtering kernels, we formulate our task as a reconstruction problem of the input image from a smaller set of local kernel functions w k (probability density functions) with fixed colors ? k , and defined in the joint 5D space of location and color. We interpret each input image pixel as a sample drawn randomly from one of the local kernels with uniform probability and then sampling this local kernel. Theoretically, these kernels can have any shape and location. First, the number of kernels must be equal to the number of output pixels, hence, no kernel can vanish during optimization. Third, to prevent aliasing artifacts, we add orientation constraints as described in Section 4. where ? k (i) = ? w n w k (i) n (i) is the (unknown) weight of kernel k at pixel i relative to all kernels overlapping pixel i. The (also unknown) kernels w k : domain(X) ? [0, 1] are bilateral Gaussian kernels in our case, i.e., we denote the value of kernel k at pixel i as: Given our input image X, we search for the most probable set of parameters ? = {? k , ? k , ? k , ? k } of the kernels, and set of unknown variables ? k (i) that can produce (reconstruct) this image. Using Bayes rule, this converts to maximizing the (log) likelihood of the input image given the model of the set of kernels: This problem is well known in statistics and solved using the Expectation-Maximization (EM) algorithm [Hastie et al. 2005] where the unknown variables ? k (i) can be seen as the probability of pixel i to be drawn from kernel k. ACM Transactions on Graphics, Vol. 6, Article 173, Publication Date: November 2013\n        We initialize kernel k corresponding to output pixel (x, y) as: r where (x k , y k ) is the center of output pixel k scaled to input image dimensions, and r x , r y are the ratios of input and output image width and height, respectively. In the expectation step we compute soft assignment probabilities of each pixel to each kernel, assuming the current estimate of the parameters is correct: In other words, ? k (i) quantifies how much an input pixel i contributes relatively to the final color of the output pixel k. In the maximization step we use these soft assignments in a weighted maximum-likelihood fit to update the estimate of the parameters ? : Note, that we control the color space Gaussians? ? k directly to constrain the locality and edge orientations as described in the next section. We add a third correction step after every maximization step. In this step we enforce the different constraints specific to our downsampling problem (Section 4). The algorithm proceeds iteratively, alternating between performing expectation, maximization, and correction steps, and terminates when convergence of the model parameters is reached. Please refer to the supplemental document for a detailed pseudo-code description. Downscaling is a more restricted problem than general signal reconstruction, and thus finding the optimal kernel shape and weight that minimizes the reconstruction error is not a sufficient condition for obtaining a good downscaled result. We perform an additional correction step after every maximization step to enforce downscaling-specific constraints. Spatial constraints: Since the output pixel positions are arranged in a perfect lattice, it is important to constrain the locations of the corresponding kernels. Otherwise, they potentially move too far from their initial positions, which can lead to a scrambled result appearance ( Figure 5 ). Their influence should remain local ( Figure 6 ). Edge orientations: The boundary between two neighboring kernels should have a similar orientation as the boundary between the two pixels in the output image ( Figure 7 ). (a) Unconstrained\n        (b) Kernels\n        (c) Constrained (a) Input (b) Unconstrained (c) Constrained normalized To retain the characteristics of the grid topology of the output pixels, we bias the spatial mean ? k towards a smooth grid-like topology. First, we limit the extent the spatial mean can move by constraining ? k to lie within a box, centered around the center of the output pixel. Formally, we update where ? k = ? n?N 4 ? n / k (4-connected) neighbors of is shown in Figure 5 . We constrain the shape of the spatial variance ? k to avoid vanishingly small or exceedingly large kernels. We first obtain the singular value decomposition (U, S,V ) = SVD(? k ), and modify the diagonal eigenvalue matrix S by clamping its elements to the interval [0.05, 0.1], and finally set where S contains the clamped eigenvalues. While Equation 12 imposes a hard constraint on the spatial component of our kernels to be relatively smooth, the color component causes them to align with features in the image. In general this is desired, however, in certain situations too much adaptation can cause visual artifacts. We use the color variance parameter ? k , which is not estimated, to directly control the amount of adaptation, and, hence, the sharpness of our results. Small ? k cause kernels to be more sensitive to color variations and have sharper transitions, while larger ? k lead to smoother kernels. The reason for not freely estimating ? k is that the maximum likelihood estimation often yields too smooth configurations. Rather ACM Transactions on Graphics, Vol. 6, Article 173, Publication Date: November 2013 (a) Input (b) Unconstrained (c) Constrained than estimating ? k from the data, we control it explicitly to locally adjust the sharpness of the result. For most kernels we let ? k remain at its initial ?crisp? setting, and we only increase local smoothing under two specific conditions: (1) when kernels become too dominant compared to their neighbors, and (2) to prevent staircasing artifacts. Following each maximization step we search for kernels that match one of these conditions, and correct them by increasing ? k by 10% (i.e., increase the smoothness of the color kernel). Locality: While clamping the eigenvalues of ? k avoids large spatial Gaussians, the resulting bilateral kernels can still have a large spatial extent due to the normalization in Equation 7. Figure 6b illustrates an instance of this problem. The small figures show the normalized kernel weights ? k (i) for two pixels. In subfigure (b) the kernels keep a small color variance, leading to a solution where one kernel grabs all dark pixels on the line, while the other kernels grab the light pixels in the surrounding. Even though the spatial weights of the kernel on the line fall off quickly, the normalization causes them to become large again, because the surrounding kernels have even lower weights due to the strong color adaption. This causes the line feature to become disconnected. We correct this behavior by detecting kernels that are growing too strong in any direction, and then selectively increase their color variance. First, we compute the directional variance for each of the eight neighbors: where d ? (a, b) | a, b ? [?1, 1] \\ (0, 0) is the offset to one of the eight neighbors. If any directional variance s d exceed a threshk old of 0.2r x (where r x is the ratio of the input image?s width over the output image?s width), we increase the smoothness of both the current kernel and the respective neighbor. The effect of this heuristic is illustrated in Figure 6c . The ability of our algorithm to keep linear features connected while maintaining sharpness can also be nicely observed in the pixel art results in Figures 1, 8, and 15. Edge Orientations: A form of staircasing artifacts occur when the orientation of an edge between two dissimilar pixels in the output pixel grid is significantly different than the orientation of the edge between the corresponding kernels. This artifact is most visible on long lines with almost cardinal direction. The corresponding image edge in the input image is almost vertical. We selectively remove such false edges by increasing ? k of the corresponding kernels. First, we detect strong edges between adjacent pixels by testing for neighboring kernels that have an abrupt transition. If k and n are horizontal or vertical neighbors, we measure the strength of the edge between the normalized kernels f kn = ? i ? k (i)? n (i). If the transition between the two kernels is abrupt, there will be few pixels where both kernels take on large values, and, thus, f kn will be small. We consider edges where f kn < 0.08r x r y as strong. If\n        256 colors\n        12 colors Input Not quantized 12 colors Input Gerstner et al., Our result, Input 16 colors 16 colors d kn deviates by more than 25 degrees from the orientation of the pixel edge, we consider this a false edge and increase the smoothness of both kernels involved. The effect of this correction is illustrated in Figure 7c . We tested our algorithm on a wide range of input images ranging from natural images to line and vector art. All results were created with the same algorithm settings. Figure 13 and other figures throughout the paper show representative results of our algorithm. We compare our method to na?ve subsampling and the bicubic filter (arguably the most commonly used rescaling algorithms). Our results show that our method yields sharper results (for instance on text), maintains details better (e.g., on the lunar surface or the flower in Figure 13), and preserves the appearance of high frequency textures (e.g., Figure 1 -left). In the supplementary material we provide an extensive comparison on a large set of images, and compare our method to a wider range of downscaling methods (including a range of linear filters, unoptimized bilateral kernels, Generalized Sampling [Nehab and Hoppe 2011], and Pixelated Image Abstraction [Gerstner et al. 2012]). Downscaling: Our algorithm is particularly well suited for downscaling cartoon and vector art images to create pixel art. Figures 1, 8, and 15 show representative results. When generating these results we disabled the edge orientation constraint (Section 4.2), since we are aiming for a blocky ?old school? look (i.e., big pixels). Of particular note is our algorithm?s ability to keep line features connected. In comparison, many lines in the subsampled results are interrupted, while the bicubic results exhibits washed out colors due to excessive smoothing. Our algorithm strikes a balance between both extremes: it keeps outlines sharp and connected where ACM Transactions on Graphics, Vol. 6, Article 173, Publication Date: November 2013\n          5 colors\n          4 colors\n          8 colors 6 colors Gerstner et al.?s results\n          8 colors 6 colors 5 colors 4 colors Our results\n          Gerstner et al., Our result, 16 colors 16 colors\n          possible, while in too detailed areas it naturally resolves to averaging out features. Extension for Palette Reduction: One particular form of pixel art also includes a reduced color palette [Gerstner et al. 2012]. While not the focus of our method, we were interested in investigating the effectiveness of applying color palette reduction in a postprocess. We use mean shift segmentation, following the description of Comaniciu and Meer?s paper [2002] (using the Epanechnikov kernel, and fixed spatial bandwidth h s = 4), and use the color bandwidth parameter h r to adjust the number of colors in the output image. We found that this works particularly well on cartoon and vector art inputs as shown in Figure 8 . On these type of images, our method produces higher quality results than Gerstner et al. [2012]. However, this is mainly due to our algorithm?s ability to keep line features connected. When applied to natural images, however, we found mean shift segmentation to not work well. Instead, we use simple k-means clustering for natural images, where it produces images of similar quality as Gerstner et al. [2012] ( Figure 9 ). To verify our algorithm we conducted a formal user study with 51 subjects using Amazon Mechanical Turk, in which we compare our algorithm against five alternatives: (1) Generalized Sampling [Nehab and Hoppe 2011], which we consider the state-of-the-art algorithm for image scaling, (2) bicubic, since it is one of the most commonly used scaling algorithms, (3) subsampling, for its simplicity, (4) box filtering, because it yields sharper results than bicubic, and (5) unoptimized bilateral kernels, to verify the effectiveness of our optimization. In each test we showed the participant the ?high resolution? (400 pixels on the long side) input image as well as two downscaled re- Results of the user study comparing our algorithm against several existing algorithms. sults (128 pixels), one produced by our algorithm, and the other produced by one of the competing algorithms. Participants were asked which result ?represents a better downscaled version of the input image?, and had to choose either one of the results or express ?no preference?. No time limit was imposed. All images were shown at native display resolution and participants were not provided with any means to zoom into the images. Each participant was presented 13 tests in total, each testing our algorithm against a random competing algorithm on a different input image, i.e., no participant saw the same input image more than once. We repeated every question throughout the test to filter unreliable participants by removing all answers from participants who were consistent on less than 80% of the tests. For the study we selected a variety of natural images from the MSRA Salient Object Database [Liu et al. 2007] that span different categories, including people, stochastic and regular textures, text, and smooth areas. Results are shown in Figure 10 . A ? 2 -analysis between each condition indicates that our algorithm was significantly preferred over each of the competing techniques. Our method employs an iterative optimization strategy to downscale images, consequently, it is computationally more demanding than classical linear rescaling filters. In the following we analyze the performance of our C++ implementation, running on a Intel Xeon E5640 CPU at 2.66 GHz. We partially use multiple cores in our implementation, but we have not fully parallelized or optimized the implementation. The convergence proofs of the original EM-Algorithm do not carry through onto our algorithm due to our modifications. However, we did not encounter convergence issues on several thousand images tested?if this would happen one could simply terminate the algorithm after a fixed number of iterations. A single iteration of our algorithm is linear both in the input and output image sizes. Due to the content dependent nature of our algorithm, the number of iterations varies for different in-/output images of the same size. Figure 11 reports the runtime (blue) and number of iterations (red) averaged over processing 100 randomly selected natural images. The shaded region indicates the standard deviation and the dashed lines indicate the min?max ranges. In Figure 11 -left, the output size is kept fixed at 80?60 pixels, while the input size varies from 160?120 to 640?480. In Figure 11 -right, the output size varies from 40?30 to 160?120 while the input size remains fixed at 640?480 pixels. ACM Transactions on Graphics, Vol. 6, Article 173, Publication Date: November 2013\n          Varying input dimensions, fixed output dimensions Varying output dimensions, fixed input dimensions Our algorithm relies on a number of heuristic constraints to prevent certain downscaling artifacts (Section 4). The EM steps process each kernel independently. The constraints, on the other hand, rely on the relation between neighboring kernels, and hence, cannot be directly solved in the E or M step. Therefore, these constraints are handled in an additional third step. Due to the content-adaptive nature our algorithm behaves temporally less coherent than linear filters when applied to smooth animations, e.g., a slow zoom into a picture. Our results are flickering slightly, while each individual image appears crisper and exhibits more detail. Please refer to the supplementary material for videos illustrating this issue. A similar problem can occur for symmetric features in input images. For example, our algorithm fails to preserve the symmetry of the yellow buttons in Figure 12. Our algorithm does not prevent aliasing under all circumstances. Consequently, our method does not perform well on most standard aliasing tests, e.g., the zone plate pattern in Figure 12. Furthermore, our results cannot reach the quality that well-trained experts achieve when manually hinting fonts and manually creating pixel art (Figure 12, bottom). While our method significantly improves the quality of downscaled images exhibiting small details such as eyes or stochastic textures, it does not always produce better results on images with blurred features, or images that contain structured textures. In the latter case, despite our efforts (Section 4), staircasing can still occur. This artifact shows up in particular on long, almost cardinal lines, e.g., the right edge of the sign in the top row of Figure 13. A systematic investigation of this artifact can be found in the supplementary material and accompanying web site. Lastly, since Equation (5) may have multiple local minima, we may reach slightly different solutions depending on our initialization. In the supplementary material and accompanying web site we show that various sensible initialization choices yield similar solutions. We settled on using a ?middle gray? initialization, which worked well in our tests. Our result Input\n        Bicubic\n        Our result We have presented a novel content-adaptive image downscaling method that adapts the shape of its downsampling kernel, yielding sharper and more detailed downscaled results. Contrary to common wisdom that dictates that frequencies above the Nyquist frequency introduce artifacts in the downsampled image (in the form of aliasing), we show that by careful sampling, certain high frequencies features can still be preserved in the downscaled image without artifacts. Given the growing ?resolution gap? between cameras and display devices and the advent of gigapixel panoramic imaging, we believe that this work opens up an exciting area of research. There are plentiful avenues for future research. Our work has shown that it is possible to sometimes drastically improve quality over existing downscaling methods. It would also be interesting to look at other signals than images as inputs. A natural immediate step would be to analyze and constrain the temporal behavior of our algorithm, e.g., when applying it to videos. This work was in part supported by NSF IIS-1217765 and by the Israeli Science Foundation (grant no. of-the-art superpixel methods. IEEE Trans. Pattern Anal. 34, 11, 2274?2282. A VIDAN , S., AND S HAMIR , A. Seam carving for content-aware image resizing. ACM Transactions on Graphics, (Proc. SIGGRAPH 2007) 26, 3, article no. C OMANICIU , D., M EER , P., AND M EMBER , S. 2002. Mean shift: A robust approach toward feature space analysis. IEEE Transactions on Pattern Analysis and Machine Intelligence 24, 603?619. G ERSTNER , T., D E C ARLO , D., A LEXA , M., F INKELSTEIN , A., G INGOLD , Y., AND N EALEN , A. 2012. Pixelated image abstraction. Proceedings of the International Symposium on NonPhotorealistic Animation and Rendering (NPAR), 29?36. H ASTIE , T., T IBSHIRANI , R., F RIEDMAN , J., AND F RANKLIN , J. 2005. The elements of statistical learning: data mining, inference and prediction. The Mathematical Intelligencer 27, 2, 83?85. I NGLIS , T. C., AND K APLAN , C. S. 2012. Pixelating vector line art. Proceedings of the Symposium on Non-Photorealistic Animation and Rendering, 21?28. K ARNI , Z., F REEDMAN , D., AND G OTSMAN , C. 2009. Energybased image deformation. Proceedings of the Symposium on Geometry Processing (SGP 2009), 1257?1268. L IU , T., S UN , J., Z HENG , N.-N., T ANG , X., AND S HUM , H.-Y. 2007. Learning to detect a salient object. Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2007), 1?8. M ANSON , J., AND S CHAEFER , S. 2012. Parameterization-aware mip-mapping. Computer Graphics Forum (Proc. Eurographics Symposium on Rendering) 31, 4, 1455?1463. N EHAB , D., AND H OPPE , H. 2011. Generalized sampling for computer graphics. R UBINSTEIN , M., S HAMIR , A., AND A VIDAN , S. 2009. Multioperator media retargeting. ACM Transactions on Graphics (Proceedings SIGGRAPH 2009) 28, 3, 1?11. S AMADANI , R., L IM , S. H., AND T RETTER , D. 2007. Representative image thumbnails for good browsing. Proceedings of the International Conference on Image Processing (ICIP 2007), 193?196. S HANNON , C. E. 1949. Communication in the presence of noise. Proceedings of the Institute of Radio Engineers 37, 1, 10?21. S UH , B., L ING , H., B EDERSON , B. B., AND J ACOBS , D. W. 2003. Automatic thumbnail cropping and its effectiveness. Proceedings of the 16th annual ACM symposium on User interface software and technology, 95?104. T OMASI , C., AND M ANDUCHI , R. 1998. Bilateral filtering for gray and color images. Proceedings of IEEE International Conference on Computer Vision (ICCV ?98), 836?846. T RENTACOSTE , M., M ANTIUK , R., AND H EIDRICH , W. 2011. Blur-aware image downsizing. Computer Graphics Forum (Proc. Eurographics 2011) 30, 2, 573?582. T RIGGS , B. 2001. Empirical filter estimation for subpixel interpolation and matching. Proceedings of IEEE International Conference on Computer Vision (ICCV 2001) 2, 550?557. W OLBERG , G. 1990. Digital Image Warping. IEEE Computer Society Press, Los Alamitos, CA, USA. W OLF , L., G UTTMANN , M., AND C OHEN -O R , D. 2007. Nonhomogeneous content-driven video-retargeting. Proceedings of IEEE International Conference on Computer Vision (ICCV 2007), 1?6. Input Subsampling Bicubic Input Subsampling Bicubic Input\n        Downscaled Input Subsampling Our result Input\n        Our result Input\n        Input\n        Bicubic Our result Input",
  "resources" : [ ]
}