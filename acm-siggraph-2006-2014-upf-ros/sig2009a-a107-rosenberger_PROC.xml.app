{
  "uri" : "sig2009a-a107-rosenberger_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2009a/a107-rosenberger_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Layered Shape Synthesis: Automatic Generation of Control Maps for Non-Stationary Textures",
    "published" : "2009",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Amir-Rosenberger",
      "name" : "Amir",
      "surname" : "Rosenberger"
    }, {
      "uri" : "http://drinventor/Daniel-Cohen-Or",
      "name" : "Daniel",
      "surname" : "Cohen-Or"
    }, {
      "uri" : "http://drinventor/Dani-Lischinski",
      "name" : "Dani",
      "surname" : "Lischinski"
    } ]
  },
  "bagOfWords" : [ "many", "inhomogeneous", "real-world", "texture", "non-stationary", "exhibit", "various", "large", "scale", "pattern", "easily", "perceive", "human", "observer", "consequently", "can", "properly", "reproduce", "method", "unless", "suitable", "control", "map", "provide", "guide", "synthesis", "process", "control", "map", "typically", "either", "user", "specify", "generate", "simulation", "paper", "we", "present", "alternative", "method", "automatic", "example-based", "generation", "control", "map", "gear", "synthesis", "natural", "highly", "inhomogeneous", "texture", "those", "result", "from", "natural", "aging", "weather", "process", "we", "method", "base", "observation", "appropriate", "control", "map", "many", "texture", "may", "model", "superposition", "several", "layer", "where", "visible", "part", "each", "layer", "occupy", "more", "homogeneous", "texture", "thus", "give", "decomposition", "texture", "exemplar", "small", "number", "layer", "we", "employ", "novel", "example-based", "shape", "synthesis", "algorithm", "automatically", "generate", "new", "set", "layer", "we", "shape", "synthesis", "algorithm", "design", "preserve", "both", "local", "global", "characteristic", "exemplar?s", "layer", "map", "process", "result", "new", "control", "map", "which", "may", "use", "guide", "subsequent", "texture", "synthesis", "process", "computer", "generate", "imagery", "rely", "heavily", "texture", "achieve", "realism", "one", "easy", "way", "acquire", "realistic", "texture", "scanning", "Rosenberger", "a.", "cohen-or", "D.", "Lischinski", "D.", "2009", "ACM", "Trans", "28", "Article", "107", "-lrb-", "December", "2009", "-rrb-", "page", "dous", "10.1145", "1618452.1618453", "http://doi.acm.org/10.1145/1618452.1618453", "take", "photograph", "surface", "material", "surround", "we", "real", "world", "many", "method", "able", "produce", "impressive", "result", "when", "apply", "homogeneous", "texture", "may", "describe", "stationary", "Markov", "random", "field", "-lrb-", "mrf", "-rrb-", "model", "yet", "many", "real", "world", "texture", "highly", "inhomogeneous", "model", "well", "stationary", "stochastic", "process", "consider", "example", "rusty", "metal", "surface", "show", "leave", "Figure", "texture", "surface", "clearly", "non-stationary", "may", "see", "highly", "non-uniform", "mixture", "superposition", "several", "different", "texture", "peel", "paint", "bare", "metal", "rust", "typical", "situation", "many", "real", "world", "surface", "whose", "texture", "often", "result", "from", "natural", "process", "weather", "corrosion", "color", "crack", "peel", "growth", "moss", "etc.", "-lsb-", "Dorsey", "Hanrahan", "1996", "Dorsey", "et", "al.", "1999", "Bosch", "et", "al.", "2004", "Desbenoit", "et", "al.", "2004", "Dorsey", "et", "al.", "2008", "-rsb-", "common", "remedy", "cope", "texture", "guide", "synthesis", "process", "control", "map", "encode", "large", "scale", "variation", "non-local", "feature", "desire", "output", "texture", "-lrb-", "e.g.", "-lsb-", "Ashikhmin", "2001", "Hertzmann", "et", "al.", "2001", "Zhang", "et", "al.", "2003", "Wang", "et", "al.", "2006", "Wei", "et", "al.", "2008", "-rsb-", "-rrb-", "however", "control", "map", "typically", "either", "user-specified", "produce", "custom", "tailor", "simulation", "-lrb-", "e.g.", "biological", "physically-based", "-rrb-", "work", "we", "propose", "new", "method", "automatically", "generate", "control", "map", "from", "example", "gear", "natural", "texture", "one", "Figure", "observe", "above", "texture", "often", "look", "like", "superposition", "several", "layer", "where", "each", "visible", "region", "each", "layer", "occupy", "more", "homogeneous", "texture", "rather", "consequence", "specific", "natural", "process", "produce", "texture", "well", "shape", "layer", "underneath", "appearance", "may", "generate", "specialize", "shader", "physically-based", "simulation", "however", "we", "aware", "any", "general", "fully", "automatic", "way", "generate", "shader", "from", "specific", "example", "start", "from", "some", "initial", "output", "shape", "we", "iteratively", "optimize", "shape", "respect", "similarity", "measure", "summary", "main", "novelty", "we", "approach", "lie", "example-based", "synthesis", "suitable", "control", "map", "rather", "than", "work", "directly", "texture", "some", "associated", "appearance", "space", "-lsb-", "Lefebvre", "Hoppe", "2006", "-rsb-", "we", "knowledge", "approach", "have", "be", "explore", "before", "Parametric", "method", "attempt", "construct", "parametric", "model", "texture", "base", "input", "sample", "which", "have", "prove", "challenging", "task", "mostly", "successful", "structureless", "stationary", "texture", "we", "refer", "reader", "-lsb-", "Wei", "et", "al.", "2009", "-rsb-", "more", "comprehensive", "overview", "example-based", "texture", "synthesis", "order", "handle", "texture", "control", "large", "scale", "structure", "ashikhmin", "-lsb-", "2001", "-rsb-", "propose", "guide", "synthesis", "process", "user-provided", "target", "image", "which", "specify", "local", "average", "color", "across", "target", "texture", "however", "work", "address", "neither", "issue", "automatically", "generate", "label", "map", "natural", "inhomogeneous", "texture", "nor", "automatic", "synthesis", "target", "label", "map", "we", "do", "we", "work", "however", "formulation", "do", "account", "possibility", "may", "many", "other", "patch", "exemplar", "represent", "all", "synthesize", "result", "while", "possible", "inject", "some", "global", "statistics", "optimization", "-lsb-", "Kopf", "et", "al.", "2007", "-rsb-", "result", "process", "still", "fail", "capture", "large", "scale", "appearance", "highly", "inhomogeneous", "natural", "texture", "target", "work", "also", "control", "result", "synthesis", "typically", "involve", "specify", "large", "number", "parameter", "which", "always", "intuitive", "also", "related", "work", "Baht", "et", "al.", "-lsb-", "2004", "-rsb-", "which", "use", "binary", "voxel", "grid", "order", "synthesize", "geometric", "detail", "volume", "surface", "one", "can", "think", "layer", "stack", "top", "each", "other", "layer", "higher", "stack", "partially", "conceal", "lower", "layer", "figure", "paper", "we", "display", "value", "correspond", "different", "layer", "use", "unique", "color", "representation", "can", "predict", "spatial", "relationship", "between", "disconnect", "component", "shape", "do", "prevent", "self-intersection", "let", "denote", "set", "boundary", "patch", "respectively", "assume", "now", "two", "set", "have", "same", "size", "result", "some", "patch", "may", "have", "more", "than", "one", "exemplar", "patch", "assign", "they", "while", "other", "may", "have", "none", "-lrb-", "see", "Figure", "-rrb-", "after", "find", "assignment", "describe", "above", "we", "goal", "modify", "boundary", "so", "increase", "similarity", "-lrb-", "reduce", "-lrb-", "-rrb-", "-rrb-", "group", "highest", "score", "determine", "whether", "should", "include", "exclude", "from", "shape", "randomly", "generate", "shape", "number", "foreground", "pixel", "match", "corresponding", "exemplar", "layer", "may", "use", "initialization", "order", "generate", "follow", "layer", "however", "we", "must", "introduce", "number", "modification", "synthesis", "process", "texture", "consist", "three", "successive", "phase", "depict", "Figure", "layer", "decomposition", "shape", "synthesis", "texture", "synthesis", "we", "method", "limit", "texture", "however", "kopf?s", "result", "match", "global", "color", "statistics", "exemplar", "produce", "better", "result", "some", "repetition", "still", "apparent", "some", "region", "synthesize", "texture", "do", "have", "similar", "counterpart", "exemplar", "-lrb-", "large", "region", "lighter", "rust", "near", "center", "-rrb-", "we", "would", "like", "gain", "better", "understanding", "relation", "between", "property", "experiment", "various", "extension", "we", "similarity", "measure" ],
  "content" : "Many inhomogeneous real-world textures are non-stationary and exhibit various large scale patterns that are easily perceived by a human observer. Consequently, they cannot be properly reproduced by these methods, unless a suitable control map is provided to guide the synthesis process. Such control maps are typically either user specified or generated by a simulation. In this paper, we present an alternative: a method for automatic example-based generation of control maps, geared at synthesis of natural, highly inhomogeneous textures, such as those resulting from natural aging or weathering processes. Our method is based on the observation that an appropriate control map for many of these textures may be modeled as a superposition of several layers, where the visible parts of each layer are occupied by a more homogeneous texture. Thus, given a decomposition of a texture exemplar into a small number of such layers, we employ a novel example-based shape synthesis algorithm to automatically generate a new set of layers. Our shape synthesis algorithm is designed to preserve both local and global characteristics of the exemplar?s layer map. This process results in a new control map, which then may be used to guide the subsequent texture synthesis process. Computer generated imagery relies heavily on textures to achieve realism. One easy way to acquire realistic textures is by scanning or Rosenberger, A., Cohen-Or, D., Lischinski, D. 2009. ACM Trans. 28, 5, Article 107 (December 2009), 9 pages. DOI = 10.1145/1618452.1618453 http://doi.acm.org/10.1145/1618452.1618453. taking photographs of surfaces and materials that surround us in the real world. Many of these methods are able to produce impressive results when applied to homogeneous textures that may be described by stationary Markov random field (MRF) models. Yet many real world textures are highly inhomogeneous, and are not modeled well by a stationary stochastic process. Consider, for example, the rusty metal surface shown on the left in Figure 1 . The texture on this surface is clearly non-stationary, and it may be seen as a highly non-uniform mixture, or superposition, of several different textures: peeling paint, bare metal, and rust. This is a typical situation for many real world surfaces, whose texture often results from natural processes, such as weathering, corrosion, color cracking and peeling, growth of moss, etc. [Dorsey and Hanrahan 1996; Dorsey et al. 1999; Bosch et al. 2004; Desbenoit et al. 2004; Dorsey et al. 2008]. A common remedy to cope with such textures is to guide the synthesis process by a control map that encodes the large scale variations and the non-local features of the desired output texture (e.g., [Ashikhmin 2001; Hertzmann et al. 2001; Zhang et al. 2003; Wang et al. 2006; Wei et al. 2008]). However, such control maps are typically either user-specified or produced by a custom tailored simulation (e.g., biological or physically-based). In this work we propose a new method for automatically generating control maps from examples, geared at natural textures such as the one in Figure 1 . As observed above, such textures often look like a superposition of several layers, where each visible regions of each layer are occupied by a more homogeneous texture. Rather, it is the consequence of the specific natural process that produced this texture, as well as the shape of the layer underneath. Such appearances may be generated by specialized shaders or by physically-based simulations. However, we are not aware of any general fully automatic way for generating such a shader from a specific example. Starting from some initial output shape, we iteratively optimize the shape with respect to this similarity measure. In summary, the main novelty in our approach lies in example-based synthesis of a suitable control map, rather than working directly on the texture, or on some associated appearance space [Lefebvre and Hoppe 2006]. To our knowledge, such an approach has not been explored before. Parametric methods attempt to construct a parametric model of the texture based on the input sample, which has proven to be a challenging task, and are mostly successful with structureless stationary textures. We refer the reader to [Wei et al. 2009] for a more comprehensive overview of example-based texture synthesis. In order to handle such textures and control large scale structure, Ashikhmin [2001] proposed to guide the synthesis process by a user-provided target image, which specifies the local average colors across the target texture. However, that work addressed neither the issue of automatically generating a label map for natural inhomogeneous textures, nor the automatic synthesis of the target label map, as we do in our work. However, this formulation does not account for the possibility that there may be many other patches in the exemplar that are not represented at all in the synthesized result. While it is possible to inject some global statistics into the optimization [Kopf et al. 2007], the resulting process still fails to capture the large scale appearance of highly inhomogeneous natural textures that are the target of this work. Also, controlling the results of the synthesis typically involves specifying a large number of parameters, which are not always intuitive. Also related is the work of Baht et al. [2004], which uses binary voxel grids in order to synthesize geometric details on volume surfaces. One can think of the layers as stacked on top of each other, with layers higher in the stack partially ?concealing? lower layers. In the figures in this paper, we display values corresponding to different layers using unique colors. Such a representation cannot predict the spatial relationship between disconnected components of the shape, and does not prevent self-intersections. Let B E and B S denote the sets of boundary patches of E and S, respectively, and assume for now that the two sets have the same size. As a result, some patches in B S may have more than one exemplar patch assigned to them, while others may have none (see Figure 3 ). After finding the assignment as described above, our goal is to modify the boundary of S so as to increase the similarity to E (by reducing D(S, E)). The group with the highest score at x determines whether x should be included or excluded from the shape. A randomly generated shape, with the number of foreground pixels matching that of the corresponding exemplar layer may be used for initialization. In order to generate the following layers, however, we must introduce a number of modifications. The synthesis process for such textures consists of three successive phases depicted in Figure 6 : layer decomposition, shape synthesis, and texture synthesis. Our method is not limited to such textures, however. Kopf?s result matches the global color statistics of the exemplar, and produces a better result, but some repetitions are still apparent, and some regions of the synthesized texture do not have a similar counterpart in the exemplar (such as the large region of lighter rust near the center). We would like to gain a better understanding of the relations between such properties, and experiment with various extensions of our similarity measure.",
  "resources" : [ ]
}