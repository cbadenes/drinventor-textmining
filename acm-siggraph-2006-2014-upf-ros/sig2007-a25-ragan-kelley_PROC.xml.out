{
  "uri" : "sig2007-a25-ragan-kelley_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2007/a25-ragan-kelley_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "The Lightspeed Automatic Interactive Lighting Preview System",
    "published" : "2007",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Jonathan-Ragan-Kelley",
      "name" : "Jonathan",
      "surname" : "Ragan-Kelley"
    }, {
      "uri" : "http://drinventor/Charlie-Kilpatrick",
      "name" : "Charlie",
      "surname" : "Kilpatrick"
    }, {
      "uri" : "http://drinventor/Brian W.-Smith",
      "name" : "Brian W.",
      "surname" : "Smith"
    }, {
      "uri" : "http://drinventor/Doug-Epps",
      "name" : "Doug",
      "surname" : "Epps"
    }, {
      "uri" : "http://drinventor/Paul-Green",
      "name" : "Paul",
      "surname" : "Green"
    }, {
      "uri" : "http://drinventor/Christophe-Hery",
      "name" : "Christophe",
      "surname" : "Hery"
    }, {
      "uri" : "http://drinventor/Fr?do-Durand",
      "name" : "Fr?do",
      "surname" : "Durand"
    } ]
  },
  "bagOfWords" : [ "furthermore", "we", "extend", "prior", "deep-framebuffer", "system", "enable", "efficient", "rendering", "transparent", "surface", "multisampling", "effect", "motion", "blur", "we", "apply", "similar", "principle", "multisampling", "transparency", "subsurface", "scattering", "contrast", "we", "need", "handle", "effect", "local", "point", "light", "source", "arbitrary", "reflectance", "furthermore", "compute", "illumination", "itself", "large", "part", "we", "run-time", "calculation", "production", "light", "shader", "quite", "complex", "compiler", "specialization", "graphic", "computation", "first", "use", "ray", "trace", "-lsb-", "Hanrahan", "1983", "Mogensen", "1986", "Andersen", "1996", "-rsb-", "we", "solve", "specialization", "use", "graph", "formulation", "mention", "implement", "Knoblock", "Ruf", "-lsb-", "1996", "-rsb-", "Peercy", "et", "al.", "-lsb-", "2000", "-rsb-", "bleiweiss", "preetham", "-lsb-", "2003", "-rsb-", "address", "compilation", "RenderMan", "shader", "onto", "graphic", "hardware", "translation", "part", "larger", "process", "automatically", "generate", "deep-framebuffer", "datum", "from", "unmodified", "exist", "scene", "theory", "some", "RenderMan", "code", "can", "translate", "GPU", "shader", "we", "have", "find", "practice", "dynamic", "part", "we", "production", "shader", "translate", "well", "contrast", "pure", "static", "compiler", "analysis", "we", "use", "postexecution", "cache", "compression", "supplement", "simple", "compiler", "analysis", "give", "complexity", "shot", "we", "handle", "we", "also", "use", "progressive", "refinement", "offer", "both", "interactive", "feedback", "-lrb-", "multiple", "frame", "per", "second", "-rrb-", "faithful", "final", "quality", "-lrb-", "potentially", "after", "few", "seconds", "-rrb-", "finally", "important", "facilitate", "implementation", "new", "pass", "preview", "system", "we", "describe", "full", "production", "relighting", "system", "be", "deploy", "two", "studio", "different", "render", "workflow", "we", "primary", "objective", "give", "fixed", "scene", "geometry", "material", "viewpoint", "enable", "interactive", "manipulation", "all", "light", "source", "parameter", "include", "intensity", "position", "falloff", "well", "create", "remove", "light", "source", "high-performance", "preview", "minimize", "feedback", "time", "we", "primary", "goal", "final", "quality", "might", "take", "few", "seconds", "through", "progressive", "refinement", "low-latency", "feedback", "critical", "seamless", "user", "interaction", "fast", "initial", "precomputation", "accept", "artist", "tool", "should", "make", "take", "longer", "begin", "work", "shot", "seamless", "integration", "exist", "pipeline", "preview", "system", "should", "transparent", "user", "require", "additional", "work", "use", "within", "existing", "pipeline", "mean", "should", "stand", "exist", "offline", "render", "pipeline", "take", "same", "input", "unmodified", "RenderMan", "scene", "shader", "Producing", "same", "output", "use", "shade", "visibility", "computation", "extremely", "high", "fidelity", "final", "rendering", "include", "antialiasing", "motion", "blur", "transparency", "use", "same", "workflow", "particular", "same", "light", "editing", "GUI", "which", "vary", "from", "studio", "studio", "require", "we", "system", "communicate", "different", "GUI", "software", "ease", "implementation", "maintenance", "production", "render", "pipeline", "complex", "continually", "evolve", "preview", "system", "can", "afford", "same", "implementation", "investment", "should", "require", "major", "re-implementation", "whenever", "finalframe", "renderer", "update", "shader", "change", "pipeline", "alter", "extensibility", "should", "easy", "possible", "support", "new", "functionality?from", "use", "new", "shader", "implement", "new", "multipass", "effects?in", "simple", "modular", "fashion", "we", "approach", "-lrb-", "fig.", "-rrb-", "can", "decompose", "automatic", "preprocess", "run-time", "phase", "communicate", "through", "dynamically-generated", "computation", "graph", "we", "take", "input", "same", "RenderMan", "scene", "shader", "use", "final", "rendering", "surface", "shader", "we", "generate", "two", "new", "shader", "static", "precomputation", "shader", "which", "execute", "once", "final-frame", "renderer", "generate", "deep-framebuffer", "cache", "dynamic", "re-rendering", "shader", "-lrb-", "cg", "-rrb-", "which", "execute", "repeatedly", "over", "deep-framebuffer", "generate", "interactive", "preview", "automatic", "specialization", "shader", "can", "expect", "yield", "performance", "penalty", "interactive", "preview", "compare", "manually", "optimize", "simplify", "code", "-lsb-", "gershbein", "Hanrahan", "2000", "Pellacini", "et", "al.", "2005", "-rsb-", "we", "context", "seamless", "integration", "take", "precedence", "over", "final", "performance", "another", "potential", "limitation", "automatic", "translation", "all", "RenderMan", "code", "can", "map", "GPU", "however", "we", "production", "shader", "have", "be", "issue", "indirect", "framebuffer", "we", "core", "real-time", "rendering", "similar", "traditional", "deep-framebuffer", "approach", "use", "cg", "shader", "perform", "computation", "all", "deep-framebuffer", "sample", "GPU", "however", "we", "introduce", "new", "level", "indirection", "through", "indirect", "framebuffer", "decouple", "shade", "sample", "from", "final", "pixel", "value", "thereby", "efficiently", "handle", "antialiasing", "motion", "blur", "transparency", "also", "enable", "progressive", "refinement", "-lrb-", "sec", "cache", "compression", "we", "rely", "static", "preprocessing", "cache", "datum", "compensate", "overestimate", "compiler", "analysis", "well", "cull", "deep-framebuffer", "indirect", "framebuffer", "base", "visibility", "provide", "over", "order", "magnitude", "reduction", "total", "cached", "datum", "size", "while", "allow", "compiler", "remain", "relatively", "simple", "multipass", "render", "we", "enable", "multipass", "effect", "shadow", "mapping", "subsurface", "scattering", "require", "preprocessor", "also", "output", "auxiliary", "datum", "geometry", "need", "shadow", "mapping", "lighting", "sample", "translucency", "although", "translucency", "currently", "incur", "substantial", "cost", "we", "preview", "demonstrate", "generality", "we", "architecture", "computation", "graph", "overall", "re-rendering", "algorithm", "encode", "computation", "graph", "generate", "during", "preprocess", "from", "original", "scene", "shader", "computation", "graph", "provide", "two", "critical", "abstraction", "second", "graph", "abstract", "preprocessing", "from", "editing", "GUI", "so", "long", "generate", "graph", "conform", "certain", "basic", "convention", "preprocessing", "stage", "can", "update", "extend", "without", "affect", "GUI", "tool", "we", "first", "need", "determine", "which", "part", "computation", "static", "vs.", "dynamic", "respect", "light", "parameter", "we", "create", "new", "RenderMan", "Shading", "language", "-lrb-", "rsl", "-rrb-", "shader", "compute", "output", "static", "value", "use", "RenderMan", "create", "deep-framebuffer", "cache", "we", "preprocess", "cache", "output", "RenderMan", "compress", "redundant", "irrelevant", "value", "finally", "we", "translate", "dynamic", "part", "computation", "real-time", "GPU", "shader", "access", "deep", "framebuffer", "texture", "previous", "work", "have", "achieve", "step", "manually", "we", "contribution", "make", "process", "fully", "automatic", "shader", "operation", "can", "execute", "GPU", "we", "can", "force", "certain", "operations?namely", "call", "external", "routine", "unimplemented", "shadeop", "-lrb-", "e.g.", "trace", "-rrb-", "label", "cache", "even", "dependence", "analysis", "label", "they", "dynamic", "static/dynamic", "analysis", "eliminate", "most", "operation", "we", "shader", "we", "can", "recognize", "light-dependent", "cache-required", "node", "error", "we", "find", "simply", "warn", "user", "compute", "value", "statically", "cache", "time", "often", "provide", "usable", "preview", "result", "3.2", "Code", "Generation", "translation", "once", "we", "have", "decide", "which", "computation", "cache", "which", "execute", "dynamically", "during", "preview", "we", "generate", "two", "new", "surface", "shader", "one", "each", "phase", "RenderMan", "precomputation", "Caching", "computation", "emit", "new", "RSL", "shader", "when", "branch", "condition", "dynamic", "control", "flow", "dynamic", "preview", "shader", "may", "differ", "from", "caching", "execution", "value", "cache", "inside", "dynamic", "conditional", "caching", "shader", "must", "execute", "both", "potential", "branch", "finally", "we", "generate", "new", "RenderMan", "scene", "replace", "each", "shader", "its", "caching", "equivalent", "we", "run", "through", "RenderMan", "generate", "deep", "framebuffer", "-lrb-", "fig.", "-rrb-", "cg", "code", "generation", "Dynamic", "surface", "shader", "emit", "new", "cg", "shader", "which", "read", "deep-framebuffer", "cache", "texture", "key", "issue", "translate", "RSL", "Cg", "mimic", "renderman?s", "richer", "data-flow", "execution", "semantics", "communication", "light", "color", "direction", "accomplish", "through", "share", "global", "variable", "RSL", "however", "RSL", "also", "allow", "surface", "light", "access", "each", "other?s", "parameter", "name", "through", "messagepassing", "we", "implement", "communicate", "parameter", "through", "global", "variable", "3.3", "specialization", "result", "Figure", "summarize", "result", "we", "shader", "specialization", "approach", "note", "dynamic", "shader", "complexity", "depend", "both", "light", "surface", "shader", "generic", "surface", "multipurpose", "??", "bershader", "form", "basis", "most", "we", "custom", "shader", "however", "do", "result", "dramatically", "larger", "dynamic", "shader", "than", "simpler", "surface", "because", "most", "code", "static", "dynamic", "code", "dominate", "light", "computation", "size", "we", "caching", "shader", "28k", "22k", "rsl", "instruction", "Generic", "surface", "metallic", "paint", "respectively", "Pellacini", "et", "al.", "-lsb-", "2005", "-rsb-", "describe", "challenge", "binding", "overhead", "number", "unique", "surface", "generate", "specialization", "we", "technique", "have", "more", "shader", "than", "original", "shot", "we", "shot", "usually", "use", "most", "dozen", "unique", "shader", "which", "contrast", "thousand", "unique", "shader", "per", "shot", "use", "other", "studio", "-lsb-", "Pellacini", "et", "al.", "2005", "-rsb-", "further", "emphasize", "we", "context", "automatic", "specialization", "primarily", "motivate", "rate", "which", "shader", "change", "-lrb-", "well", "ability", "edit", "surface", "parameter", "-rrb-", "total", "number", "can", "easily", "reach", "hundred", "scalar", "per", "deep-framebuffer", "element", "potentially", "exceed", "gpu?s", "memory", "make", "cache", "compression", "well", "tiling", "describe", "section", "critical", "give", "increase", "program", "size", "limit", "latest", "gpus", "cg", "codegen", "could", "generate", "single", "compound", "shader", "perform", "dynamic", "dispatch", "subroutine", "implement", "each", "surface", "light", "technique", "already", "use", "effectively", "game", "contrast", "we", "find", "apply", "simple", "post-process", "we", "final", "cached", "datum", "provide", "tremendous", "reduction", "cache", "complexity", "sufficient", "enable", "effective", "automatic", "deep-framebuffer", "generation", "simple", "compiler", "optimization", "can", "reduce", "number", "cached", "component", "more", "than", "factor", "-lrb-", "fig.", "-rrb-", "because", "optimization", "inline", "significant", "new", "static", "datum", "dynamic", "cg", "shader", "also", "help", "cg", "compiler", "reduce", "runtime", "shader", "complexity", "through", "constant", "folding", "Shader", "dynamic", "vary", "unique", "-lrb-", "caching", "analysis", "-rrb-", "-lrb-", "compress", "-rrb-", "generic", "surface", "402", "145", "97", "metallic", "paint", "450", "150", "97", "number", "-lrb-", "scalar", "-rrb-", "value", "per", "deep-framebuffer", "sample", "scene", "fig.", "under", "compression", "Dynamic", "term", "determine", "initial", "caching", "analysis", "varying", "term", "remain", "after", "elimination", "value", "constant", "over", "frame", "unique", "term", "remain", "after", "further", "elimination", "duplicated", "value", "3.5", "specialize", "surface", "parameter", "key", "advantage", "automatic", "specialization", "allow", "user", "selectively", "tweak", "some", "surface", "well", "light", "parameter", "when", "user", "select", "surface", "parameter", "dynamic", "compiler", "can", "just", "easily", "generate", "code", "configurable", "surface", "parameter", "-lrb-", "fig.", "-rrb-", "significantly", "extend", "initially-planned", "range", "from", "light", "look-design", "practice", "main", "overhead", "editing", "surface", "parameter", "require", "reevaluation", "all", "light", "source", "editable", "surf", "parameter", "GPU", "instr", "relative", "perf", "-lrb-", "baseline", "-rrb-", "3518", "21", "100", "18", "-lrb-", "gain", "-rrb-", "3856", "27", "90", "41", "-lrb-", "gain", "specularity", "-rrb-", "3973", "29", "86", "preview", "performance", "function", "number", "editable", "surface", "parameter", "variant", "Generic", "surface", "editing", "41", "scalar", "vector", "surface", "parameter", "do", "significantly", "slow", "render", "compare", "light", "parameter", "alone", "traditional", "deep-framebuffer", "pure", "image-space", "structure", "which", "allow", "they", "scale", "image", "size", "scene", "complexity", "inspire", "decoupling", "between", "shading", "visibility", "computation", "central", "renderman?s", "REYES", "pipeline", "we", "introduce", "layer", "indirection", "between", "deep-framebuffer", "shading", "visibility/display", "sample", "through", "second", "datum", "structure", "we", "call", "indirect", "framebuffer", "we", "first", "review", "multisampling", "approach", "use", "RenderMan", "before", "introduce", "we", "new", "datum", "structure", "background", "renderman?s", "REYES", "architecture", "achieve", "high", "quality", "generality", "antialiasing", "motion", "blur", "depthof-field", "supersample", "visibility", "computation", "while", "reduce", "shade", "cost", "reuse", "shade", "value", "rather", "than", "supersample", "they", "-lsb-", "cook", "et", "al.", "1987", "Apodaca", "Gritz", "2000", "-rsb-", "while", "smooth", "reconstruction", "motion", "blur", "depth-of-field", "fine", "geometry", "may", "require", "100", "more", "visibility", "sample", "shade", "rate", "commonly", "just", "roughly", "one", "shade", "sample", "per", "output", "pixel", "pixel", "contain", "uniform", "density", "subpixel", "sample", "distribute", "screen-space", "-lrb-", "spatial", "antialiasing", "-rrb-", "time", "-lrb-", "motion", "blur", "-rrb-", "aperture", "location", "-lrb-", "depth-of-field", "-rrb-", "RenderMan", "first", "tessellate", "all", "primitive", "micropolygon", "-lrb-", "iii", "-rrb-", "deep-framebuffer", "-lrb-", "iv", "-rrb-", "indirect", "framebuffer", "indirect", "framebuffer", "densely", "encode", "variablerate", "visibility", "information", "enable", "efficient", "antialiasing", "transparency", "under", "static", "view", "resample", "denselypacked", "deep-framebuffer", "screen-space", "precisely", "reproduce", "renderman?s", "high-quality", "antialiasing", "linearize", "consolidate", "give", "static", "visibility", "configuration", "require", "far", "fewer", "unique", "sample", "same", "result", "duce", "color", "per", "vertex", "-lrb-", "fig.", "-rrb-", "RenderMan", "compute", "visibility", "-lrb-", "hiding", "-rrb-", "test", "each", "micropolygon", "against", "each", "subpixel", "sample", "potentially", "cover", "-lrb-", "rasterization", "-rrb-", "take", "account", "aperture", "time", "value", "sample", "depth", "test", "perform", "transparency", "handle", "maintain", "z-ordered", "list", "micropolygon", "pointer", "each", "subpixel", "sample", "-lrb-", "fig.", "ii", "-rrb-", "color", "subpixel", "sample", "compute", "look", "up", "color", "opacity", "each", "micropolygon", "composit", "they", "depth-order", "final", "pixel", "value", "weighted", "average", "color", "subpixel", "since", "subpixel", "jitter", "space", "time", "aperture", "location", "achieve", "high", "quality", "multisampling", "effect", "while", "keep", "shade", "cost", "tractable", "we", "note", "each", "final", "filtered", "pixel", "color", "ultimately", "correspond", "simple", "linear", "combination", "shaded", "color", "all", "micropolygon", "visible", "under", "pixel", "consider", "example", "Fig.", "ii", "first", "subpixel?s", "color", "linear", "combination", "shade", "sample", "weight", "give", "transparency", "final", "pixel", "value", "combination", "color", "shade", "sample", "weight", "0.175", "0.225", "0.435", "when", "visibility", "static", "cumulative", "linear", "weight", "similarly", "become", "static", "similar", "principle", "direct-to-indirect", "transfer", "-lsb-", "ha", "san", "et", "al.", "2006", "-rsb-", "context", "multisampling", "transparency", "we", "first", "use", "standard", "deep", "framebuffer", "instead", "organize", "per", "pixel", "we", "preprocess", "cache", "datum", "each", "shade", "sample", "-lrb-", "fig.", "iii", "-rrb-", "we", "real-time", "dynamic", "shader", "execute", "over", "cache", "output", "per-shading-sample", "color", "we", "indirect", "framebuffer", "encapsulate", "linear", "nature", "RenderMan", "we", "approach", "figure", "resolution", "sample", "shade", "subpix", "shade", "indir", "914x389", "13x13", "2.1", "32m", "633k", "1.6", "720x306", "13x13", "1.5", "21m", "467k", "3.8", "12", "640x376", "4x4", "2.5", "2.3", "327k", "716k", "15", "-lrb-", "0.1", "-rrb-", "720x389", "8x8", "54m", "121m", "21m", "35m", "15", "-lrb-", "0.6", "-rrb-", "720x389", "8x8", "43m", "58m", "11m", "17m", "15", "-lrb-", "1.0", "-rrb-", "720x389", "8x8", "25m", "17m", "3.9", "5.7", "figure", "10", "original", "RenderMan", "micropolygon", "pixelsample", "output", "complexity", "compare", "we", "compress", "indirect", "framebuffer", "number", "sample", "fig.", "15", "12", "static", "visibility", "compression", "losslessly", "reduce", "deep-framebuffer", "shading", "sample", "3-8x", "relative", "renderman?s", "shaded", "micropolygon", "reduce", "number", "unique", "indirect", "framebuffer", "sample", "3-20x", "relative", "renderman?s", "subpixel", "sample", "final", "color", "store", "each", "pixel", "list", "weight", "pointer", "deep-framebuffer", "output", "-lrb-", "fig.", "iv", "-rrb-", "example", "pixel", "Figure", "iii", "correspond", "three", "entry", "indirect", "framebuffer", "we", "need", "efficiently", "represent", "variable-length", "list", "shade", "value", "influence", "each", "pixel", "enable", "progressive", "rendering", "we", "use", "scatter", "strategy", "where", "point", "render", "each", "pixel", "location", "accumulate", "color", "contribution", "each", "indirect", "framebuffer", "entry", "encode", "vertex", "array", "point", "contain", "pointer", "shade", "sample", "-lrb-", "texture", "coordinate", "-rrb-", "weight", "output", "pixel", "coordinate", "-lrb-", "-rrb-", "render", "vertex", "array", "blend", "enable", "scatter", "weighted", "color", "final", "pixel", "note", "one", "entry", "deep", "framebuffer", "result", "shaded", "color", "often", "contribute", "multiple", "neighbor", "pixel", "especially", "presence", "motion", "blur", "highlight", "effectiveness", "we", "decoupling", "-lrb-", "RenderMan", "-rrb-", "where", "complex", "multisampling", "effect", "achieve", "without", "scale", "cost", "shade", "we", "implementation", "currently", "limit", "static", "opacity", "Dynamic", "transparency", "could", "support", "recompute", "weight", "fly", "light-dependent", "transparency", "do", "occur", "we", "shader", "we", "also", "do", "currently", "handle", "color", "transparency", "though", "simply", "require", "store", "rgb", "weight", "independently", "blend", "each", "color", "channel", "use", "static", "visibility", "information", "indirect", "framebuffer", "we", "apply", "two", "key", "transformation", "cache", "datum", "losslessly", "compress", "its", "size", "static", "linearization", "indirect", "framebuffer", "coalesce", "all", "visibility", "sample", "which", "reference", "same", "shade", "sample", "same", "pixel", "single", "combined", "indirect", "framebuffer", "weight", "provide", "3-20x", "reduction", "size", "indirect", "framebuffer", "while", "produce", "same", "output", "-lrb-", "fig.", "10", "-rrb-", "we", "cull", "all", "deep-framebuffer", "shading", "sample", "reference", "least", "one", "indirect", "framebuffer", "sample", "we", "maintain", "local", "neighborhood", "where", "necessary", "derivative", "computation", "optimization", "reduce", "number", "indirect", "framebuffer", "sample", "3-20x", "number", "deep-framebuffer", "sample", "3-8x", "-lrb-", "fig.", "10", "-rrb-", "loss", "generality", "even", "complex", "scene", "involve", "motion", "blur", "-lrb-", "fig.", "-rrb-", "transparent", "hair", "-lrb-", "fig.", "15", "-rrb-", "reduce", "only", "storage", "size", "also", "computation", "because", "shade", "apply", "once", "per-deep-framebuffer", "sample", "resampling", "once", "per-indirect", "framebuffer", "sample", "combine", "dense", "packing", "shade", "value", "optimization", "generally", "allow", "even", "heavily", "multisampled", "shot", "transparency", "require", "little", "more", "storage", "than", "simple", "single-sampled", "image-space", "deepframebuffer", "render", "interactively", "we", "system", "must", "scale", "final-resolution", "preview", "massive", "scene", "complex", "shader", "while", "maintain", "interactivity", "high", "resolution", "preview", "more", "complex", "shader", "may", "increase", "cache", "size", "beyond", "GPU", "memory", "we", "divide", "oversized", "cache", "screen-space", "tile", "small", "enough", "all", "hardware", "constraint", "each", "tile", "contain", "indirect", "framebuffer", "couple", "deepframebuffer", "all", "shade", "sample", "visible", "those", "indirect", "framebuffer", "sample", "we", "also", "use", "texture", "atlas", "because", "we", "deepframebuffer", "may", "contain", "more", "channel", "than", "number", "bindable", "texture", "we", "rely", "progressive", "refinement", "offer", "both", "interactive", "feedback", "slower", "yet", "faithful", "final", "image", "quality", "we", "progressively", "refine", "resolution", "typically", "step", "first", "step", "we", "begin", "4x4", "2x2", "pixel", "block", "next", "we", "increase", "full", "resolution", "only", "one", "indirect", "framebuffer", "value", "per", "pixel", "final", "step", "we", "use", "full", "multisample", "highest", "quality", "each", "stage", "represent", "group", "sample", "we", "indirect", "framebuffer", "we", "order", "indirect", "framebuffer", "sample", "give", "pixel", "weight", "accumulate", "they", "progressively", "pass", "shade", "only", "update", "point", "reference", "indirect", "framebuffer", "sample", "give", "refinement", "batch", "also", "help", "guarantee", "performance", "massive", "scene", "because", "first", "few", "refinement", "level", "can", "constrain", "fit", "entirely", "GPU", "finally", "we", "often", "disable", "shadow", "lowest", "refinement", "tile", "we", "deep-framebuffer", "store", "set", "shade", "sample", "group", "surface", "type", "batch", "multiple", "progressive", "refinement", "pass", "Passes", "store", "2d", "texture", "arbitrary", "layout", "-lrb-", "2x2", "quad", "maintain", "derivative", "-rrb-", "practice", "shade", "sample", "store", "accord", "order", "which", "RenderMan", "output", "they", "like", "prior", "lighting", "design", "system", "we", "exploit", "linearity", "-lrb-", "most", "-rrb-", "lighting", "cache", "contribution", "from", "all", "light", "currently", "be", "edit", "user", "we", "store", "light", "cache", "get", "update", "when", "subset", "light", "temporarily", "freeze", "practice", "when", "light", "unfrozen", "its", "contribution", "subtract", "from", "cache", "new", "frozen", "light?s", "contribution", "add", "we", "retain", "old", "parameter", "state", "which", "cache", "generate", "maintain", "correctness", "when", "subtract", "speed", "up", "freezing", "when", "work", "multiple", "ten", "light", "source", "have", "prove", "numerically", "stable", "over", "long", "edit", "session", "when", "use", "32-bit", "floating-point", "cache", "change", "surface", "parameter", "require", "reshade", "surface", "all", "light", "scene", "few", "light", "still", "comfortably", "interactive", "near-final", "shot", "dozen", "light", "may", "subinteractive", "still", "take", "only", "few", "seconds", "useful", "feedback", "light", "caching", "significantly", "complicate", "introduction", "progressive", "refinement", "order", "update", "cache", "we", "maintain", "table", "cached", "light", "parameter", "each", "light", "every", "refinement", "level", "give", "cache", "level", "valid", "light", "cached", "parameter", "match", "light?s", "current", "parameter", "cache", "update", "reshading", "subtract", "contribution", "old", "configuration", "shade", "add", "new", "contribution", "so", "far", "we", "have", "focus", "purely", "local", "illumination", "computation", "however", "global", "effect", "shadow", "translucency", "must", "also", "reproduce", "we", "first", "show", "how", "can", "include", "we", "approach", "use", "multipass", "rendering", "discuss", "both", "necessary", "preprocessing", "real-time", "component", "we", "address", "critical", "software", "architecture", "issue", "make", "development", "we", "system", "tractable", "complex", "dependence", "between", "multipass", "effect", "indirect", "framebuffer", "progressive", "refinement", "make", "important", "develop", "abstraction", "facilitate", "inclusion", "new", "effect", "manage", "dependence", "well", "abstract", "key", "low-level", "aspect", "data-flow", "binding", "GPU", "fig.", "11", "summarize", "data-flow", "we", "final", "real-time", "computation", "include", "shadow", "mapping", "translucency", "indirect", "framebuffer", "effect", "Shadow", "mapping", "illustrate", "how", "multipass", "effect", "from", "final", "render", "pipeline", "can", "include", "we", "architecture", "Shadow", "map", "necessitate", "one", "extra", "pass", "per", "light", "require", "auxiliary", "datum", "from", "preprocessor", "-lrb-", "scene", "geometry", "-rrb-", "real-time", "preview", "shadow", "map", "pass", "communicate", "main", "pass", "through", "texture", "we", "graph", "interface", "-lrb-", "present", "below", "-rrb-", "manage", "communication", "dependence", "when", "parameter", "edit", "during", "caching", "we", "run", "RenderMan", "second", "time", "over", "scene", "extract", "micropolygon", "after", "all", "transform", "displacement", "apply", "we", "store", "object", "id", "support", "selective", "shadow", "casting", "receive", "per-object", "specialization", "RenderMan", "shadow", "map", "call", "flag", "mark", "dynamic", "replace", "dynamic", "code", "cg", "shadow", "map", "lookup", "when", "render", "shadow", "map", "we", "also", "render", "object", "id", "allow", "shadow", "assignment", "modify", "real-time", "per-object", "basis", "subsurface", "scattering", "require", "integral", "incident", "light", "flux", "time", "bssrdf", "diffusion", "kernel", "over", "neighborhood", "each", "visible", "point", "we", "have", "adapt", "Jensen", "Buhler?s", "hierarchical", "two-pass", "approach", "-lsb-", "2002", "-rsb-", "exactly", "use", "we", "exist", "offline", "shader", "real-time", "preview", "method", "first", "create", "hierarchy", "irradiance", "sample", "which", "enable", "fast", "hierarchical", "evaluation", "integral", "we", "scheme", "build", "work", "Ha", "san", "et", "al.", "-lsb-", "2006", "-rsb-", "indirect", "lighting", "instead", "wavelet", "approach", "we", "directly", "use", "Jensen", "Buhler?s", "octree", "hierarchy", "-lsb-", "2002", "-rsb-", "translucency", "we", "must", "distinguish", "shading", "visible", "shade", "sample", "describe", "section", "irradiance", "computation", "gather", "sample", "use", "estimate", "subsurface", "scattering", "-lsb-", "jensen", "Buhler", "2002", "-rsb-", "particular", "latter", "can", "have", "view-dependent", "term", "usually", "only", "require", "albedo", "normal", "information", "we", "bake", "information", "during", "preprocess", "separate", "translucency", "deep-framebuffer", "generate", "simple", "dynamic", "cg", "shader", "base", "we", "offline", "irradiance", "shader", "evaluate", "irradiance", "-lrb-", "diffuse", "shade", "-rrb-", "during", "runtime", "each", "visible", "shade", "sample", "we", "cache", "index", "set", "node", "irradiance", "hierarchy", "contribute", "translucency", "we", "also", "store", "corresponding", "bssrdf", "coefficient", "weight", "-lrb-", "dipole", "kernel", "-rrb-", "-lsb-", "Jensen", "Buhler", "2002", "-rsb-", "distance", "allow", "dynamic", "editing", "scattering", "depth", "interactive", "preview", "we", "first", "evaluate", "irradiance", "each", "gather", "sample", "use", "dynamic", "diffuse", "shader", "translucency", "deep", "framebuffer", "provide", "we", "leaf", "value", "we", "hierarchy", "store", "texture", "we", "use", "iterative", "blend", "pass", "level", "octree", "accumulate", "value", "higher-level", "node", "sum", "child", "all", "octree", "value", "store", "same", "texture", "map", "leaf", "we", "can", "compute", "color", "visible", "shade", "sample", "because", "only", "accumulation", "weight", "actual", "octree", "traversal", "depend", "bssrdf", "coefficient", "lookup", "octree", "record", "statically", "during", "preprocessing", "encode", "vertex", "array", "much", "like", "indirect", "framebuffer", "we", "instead", "store", "static", "bssrdf", "attenuation", "distance", "term", "per-lookup", "albedo", "modulation", "per-visible-point", "we", "dynamically", "compute", "bssrdf", "contribution", "base", "dynamic", "scatter", "depth", "-lrb-", "sigma", "-rrb-", "value", "use", "fragment", "shader", "while", "accumulate", "each", "lookup", "hierarchy?s", "irradiance", "value", "use", "static", "index", "record", "during", "preprocessing", "note", "translucency", "computation", "perform", "granularity", "shade", "sample", "benefit", "from", "decoupling", "we", "indirect", "framebuffer", "both", "progressive", "refinement", "overall", "efficiency", "result", "we", "initial", "result", "-lrb-", "fig.", "12", "-rrb-", "while", "promise", "fidelity", "demonstrate", "need", "progressive", "shading", "technique", "while", "final", "scattering", "contribution", "evaluate", "progressively", "per", "visible", "shade", "point", "static", "octree", "lookup", "require", "translucency", "deep-framebuffer", "completely", "shaded", "prior", "any", "accumulation", "practice", "deep-framebuffer", "can", "even", "larger", "than", "primary", "deep-framebuffer", "1.3", "point", "example", "mean", "while", "change", "scattering", "coefficient", "render", "interactively", "-lrb-", "hz", "-rrb-", "scene", "base", "shader", "render", "2-10", "hz", "initial", "refinement", "exclude", "scattering", "computation", "reevaluate", "subsurface", "scattering", "result", "take", "several", "seconds", "reach", "initial", "refinement", "-lrb-", "though", "subsequent", "refinement", "very", "fast", "because", "octree", "already", "evaluate", "-rrb-", "multipass", "algorithm", "shadow", "mapping", "translucency", "together", "indirect", "framebuffer", "progressive", "refinement", "introduce", "complex", "data-dependency", "between", "computation", "subsurface", "scattering", "coefficient", "can", "edit", "interactively", "top", "less", "translucency", "bottom", "more", "translucency", "preview", "render", "initial", "refinement", "hz", "under", "change", "coefficient", "reshade", "1.3", "million-point", "translucency", "buffer", "take", "several", "seconds", "eye", "contain", "multiple", "transparent", "layer", "appear", "black", "without", "indirect", "framebuffer", "furthermore", "make", "we", "system", "extensible", "enforce", "abstraction", "between", "various", "component", "require", "more", "care", "than", "we", "initially", "anticipate", "we", "original", "monolithic", "engine", "quickly", "become", "challenging", "maintain", "node", "communicate", "through", "port", "which", "abstract", "computation", "from", "dependency", "data-flow", "global", "data-flow", "encode", "edge", "between", "port", "we", "core", "computation", "graph", "library", "also", "abstract", "low-level", "aspect", "shader", "datum", "management", "GPU", "include", "library", "basic", "building", "block", "node", "graph", "instance", "scene", "generate", "automatically", "compiler", "preprocessing", "stage", "we", "pipeline", "use", "internally", "user", "interface", "application", "Figure", "13", "summarize", "we", "system?s", "fully-automatic", "performance", "two", "we", "shot", "-lrb-", "fig.", "12", "-rrb-", "cache", "size", "fit", "within", "current", "GPU", "resource", "though", "we", "system", "scale", "support", "out-of-core", "shot", "much", "higher", "resolution", "even", "more", "complex", "shader", "we", "report", "all", "result", "we", "current", "deploy", "artist", "workstation", "dual", "2.6", "GHz", "AMD", "Opteron", "2218", "processor", "8gb", "RAM", "NVIDIA", "Quadro", "FX", "5500", "-lrb-", "g71", "-rrb-", "graphic", "we", "generally", "limit", "capability/performance", "curve", "we", "current", "hardware", "preliminary", "result", "suggest", "major", "performance", "improvement", "next-generation", "hardware", "Pirate", "-lrb-", "12", "-rrb-", "robot", "-lrb-", "-rrb-", "resolution", "640x376", "914x389", "supersampling", "4x4", "13x13", "light", "42", "RenderMan", "-lrb-", "total", "-rrb-", "409", "sec", "3406", "sec", "irradiance", "shade", "111", "sec", "material", "shader", "material", "instance", "44", "light", "shader", "light", "instance", "42", "caching", "-lrb-", "total", "-rrb-", "1425", "sec", "931", "sec", "initialization", "sec", "18", "sec", "shader", "specialization", "24", "sec", "63", "sec", "deep-framebuffer", "caching", "627", "sec", "499", "sec", "shadow", "geometry", "caching", "105", "sec", "164", "sec", "cache", "compression", "60", "sec", "187", "sec", "octree", "compression", "600", "sec", "preview", "irradiance", "shading", "-lrb-", "light", "-rrb-", "sec", "interaction", "-lrb-", "irradiance", "cache", "-rrb-", "0.5", "sec", "coarse", "refinement", "4x4", "block", "0.1", "sec", "full", "refinement", "-lrb-", "light", "change", "-rrb-", "10", "sec", "2.7", "sec", "full", "refinement", "-lrb-", "light", "-rrb-", "29", "sec", "-lrb-", "light", "-rrb-", "31.7", "-lrb-", "42", "light", "-rrb-", "deep-framebuffer", "104", "mb", "256", "mb", "indirect", "framebuffer", "33", "mb", "29", "mb", "irradiance", "deep-framebuffer", "83", "mb", "scattering", "index", "buffer", "436", "MB", "System", "performance", "compare", "we", "rendermanbased", "offline", "pipeline", "two", "production", "shot", "-lrb-", "fig.", "12", "-rrb-", "both", "initial", "feedback", "accelerate", "several", "order", "magnitude", "interactive", "rate", "cache", "time", "Pirate", "example", "dominate", "unoptimized", "octree", "caching", "compression", "process", "which", "-lrb-", "unnecessarily", "-rrb-", "read", "write", "multiple", "gb", "octree", "datum", "disk", "several", "time", "during", "caching", "we", "system", "have", "be", "integrate", "pipeline", "two", "special", "effect", "studio", "currently", "initial", "release", "number", "artist", "production", "both", "lighting", "look-design", "we", "have", "focus", "we", "effort", "iron", "out", "major", "previously-unsolved", "technical", "challenge", "system", "subsurface", "scattering", "only", "proof-of-concept", "require", "further", "optimization", "nevertheless", "initial", "feedback", "have", "be", "extremely", "positive", "example", "artist", "love", "freedom", "experiment", "complex", "feature", "noise", "-lsb-", "we", "-rsb-", "usually", "shy", "away", "from", "noise", "because", "take", "so", "long", "edit", "...", "interactivity", "make", "much", "more", "useful", "general", "strong", "feeling", "interactive", "feedback", "only", "accelerate", "adjustment", "key", "parameter", "-lrb-", "get", "level", "right", "-lsb-", "previously", "-rsb-", "take", "I", "hour", "-lsb-", "after", "just", "tuning", "light", "match", "background", "under", "10", "seconds", "-rsb-", "-rrb-", "leave", "user", "more", "willing", "experiment", "aggressively", "GPU", "vs.", "specialization", "speedup", "we", "have", "estimate", "gain", "due", "specialization", "vs.", "GPU", "execution", "since", "we", "do", "have", "software", "preview", "runtime", "we", "can", "only", "perform", "back", "envelope", "calculation", "compare", "GPU", "shader", "RenderMan", "shader", "prman", "timing", "real", "vs.", "trivial", "shader", "include", "scene", "we", "estimate", "specialization", "caching", "provide", "100x", "speedup", "while", "execution", "GPU", "bring", "another", "20x", "coarsest", "level", "refinement", "provide", "extra", "10-100x", "upper-right", "half", "image", "render", "we", "approach", "while", "lower", "left", "final", "RenderMan", "frame", "initial", "refinement", "render", "over", "20", "hz", "we", "full", "4k", "instruction", "specialize", "surface", "shader", "spot", "light", "include", "shadow", "error", "percentage", "max", "pixel", "value", "Figure", "15", "430k", "transparent", "hair", "-lrb-", "0.6", "opacity", "threshold", "0.96", "-rrb-", "render", "720x389", "8x8", "sampling", "generate", "43m", "micropolygon", "58m", "pixel", "sample", "RenderMan", "condense", "11m", "visible", "shade", "sample", "17m", "unique", "visibility", "sample", "through", "lossless", "visibility", "compression", "render", "12", "hz", "fully", "refining", "33", "sec", "compression", "performance", "even", "better", "1.0", "0.1", "-lrb-", "threshold", "0.996", "-rrb-", "generate", "21m", "visible", "shade", "sample", "overflow", "16m", "sample", "texture", "we", "currently", "use", "-lrb-", "cf.", "Fig.", "10", "-rrb-", "Shadow", "geometry", "scale", "scene", "complexity", "main", "scalability", "limitation", "practice", "use", "micropolygon", "instead", "source", "primitive", "design", "decision", "avoid", "re-implementing", "every", "primitive", "support", "prman", "we", "control", "shadow-geometry", "level", "detail", "alter", "shade", "rate", "shadow", "bake", "pass", "additional", "mesh", "decimation", "pass", "could", "useful", "aside", "from", "shadow", "we", "system", "effectively", "scale", "image", "complexity", "indirect", "framebuffer", "cache", "compression", "dramatically", "reduce", "memory", "cost", "transparency", "main", "difference", "from", "previous", "technique", "because", "add", "unbounded", "number", "sample", "we", "create", "complex", "scene", "test", "scalability", "-lrb-", "fig.", "15", "-rrb-", "430k", "transparent", "hair", "fiber", "-lrb-", "0.1", "opacity", "threshold", "0.996", "-rrb-", "result", "55m", "prman", "micropolygon", "20m", "visible", "Lightspeed", "shade", "sample", "render", "720x389", "64x", "supersampling", "overflow", "we", "shade", "sample", "texture", "because", "GPU?s", "4kx4k", "-lrb-", "16m", "-rrb-", "texture", "limit", "however", "reduce", "0.6", "same", "scene", "only", "require", "11m", "shade", "sample", "-lrb-", "vs.", "43m", "prman", "-rrb-", "work", "12", "hz", "-lrb-", "33", "sec", "full", "refinement", "because", "full", "cache", "2gb", "need", "page", "-rrb-", "transparency", "Lightspeed", "shade", "just", "4m", "sample", "-lrb-", "vs.", "25m", "prman", "-rrb-", "22", "hz", "-lrb-", "5.5", "sec", "full", "refinement", "-rrb-", "16m", "limit", "can", "trivially", "increase", "use", "multiple", "texture", "8k", "texture", "DirectX", "10", "we", "production", "scene", "however", "we", "have", "encounter", "extreme", "case", "we", "artist", "avoid", "transparent", "hair", "favor", "smaller", "sub-pixel", "hair", "because", "same", "scalability", "problem", "apply", "prman", "fact", "though", "unbounded", "transparency", "consistently", "contribute", "much", "less", "total", "frame", "complexity", "than", "-lrb-", "bound", "-rrb-", "multisample", "we", "scene", "while", "worst", "case", "scale", "supersampled", "image", "complexity", "-lrb-", "time", "depth", "complexity", "transparency", "-rrb-", "key", "goal", "we", "design?visibility", "compression", "linearization", "visibility", "indirect", "framebuffer?is", "provide", "real-world", "scaling", "much", "closer", "pixel-complexity", "even", "motion", "blur", "-lrb-", "fig.", "-rrb-", "subpixel", "microgeometry", "like", "hair", "-lrb-", "fig.", "15", "-rrb-", "modest", "average", "transparency", "depth", "overall", "conclusion", "we", "test", "ignore", "shadow", "we", "can", "handle", "lot", "fine", "geometry", "handle", "lot", "very", "transparent", "coarse", "geometry", "we", "current", "implementation", "handle", "lot", "very", "transparent", "fine", "geometry", "completely", "fill", "image", "antialiasing", "we", "can", "handle", "lot", "fine", "geometry", "semi-transparent", "even", "fill", "image", "high", "antialiasing", "where", "scene", "complexity", "can", "become", "issue", "indirect", "framebuffer", "during", "caching", "because", "simple", "method", "caching", "-lrb-", "bake3d", "-rrb-", "extract", "all", "shaded", "grid", "from", "prman", "initial", "cache", "size", "can", "very", "large", "compression", "become", "disk", "i/o", "bind", "we", "address", "push", "compression", "in-memory", "renderer", "-lrb-", "dso", "-rrb-", "which", "greatly", "accelerate", "caching", "culling", "number", "unique", "shader", "can", "also", "issue", "however", "give", "surface", "shader", "use", "multiple", "surface", "different", "parameter", "we", "only", "need", "specialize", "once", "total", "number", "dynamic", "shader", "product", "number", "different", "light", "shader", "number", "surface", "shader", "-lrb-", "number", "instance", "-rrb-", "because", "we", "mostly", "use", "bershader", "problem", "we", "workload", "-lrb-", "10-100", "combination", "practice", "Fig.", "13", "-rrb-", "though", "would", "studio", "thousand", "unique", "shader", "shot", "might", "address", "established", "technique", "discuss", "Footnote", "practice", "we", "find", "we", "approach", "quite", "robust", "major", "challenge", "we", "have", "address", "include", "Dynamic", "call", "external", "routine", "largely", "eliminate", "during", "specialization", "where", "aren?t", "have", "be", "effectively", "emulate", "GPU", "make", "cache-required", "generate", "deep-framebuffer", "compress", "modest", "size", "even", "we", "more", "complicated", "scene", "shader", "GPU", "texture", "limit", "abstract", "through", "tiling", "complex", "visibility", "effectively", "compress", "even", "high", "multisampling", "rate", "interactivity", "maintain", "face", "complexity", "progressive", "refinement", "automatically", "specialize", "shader", "fit", "within", "current", "GPU", "limit", "we", "key", "limitation", "same", "face", "any", "GPU", "shade", "system?namely", "operation", "easily", "express", "native", "GPU", "instruction", "require", "special", "handling", "most", "importantly", "nonlocal", "shade", "must", "handle", "explicitly", "use", "multipass", "algorithm", "we", "have", "achieve", "shadow", "translucency", "additional", "implementation", "require", "other", "effect", "still", "number", "feature", "can", "translate", "would", "result", "error", "message", "deem", "dynamic", "fortunately", "feature", "usually", "use", "dynamic", "part", "shader", "we", "studio", "may", "true", "all", "studio", "Ray", "Tracing", "we", "do", "perform", "ray", "casting", "note", "specular", "ray", "trace", "could", "preview", "deep-framebuffer", "use", "indirect", "buffer", "-lrb-", "ray", "intersection", "do", "change", "unless", "index", "refraction", "edit", "transmitted", "ray", "-rrb-", "main", "limitation", "concern", "ray-cast", "shadow", "inter-reflection", "ambient", "occlusion", "Lightspeed", "would", "require", "re-caching", "occlusion", "object-object", "shadow", "assignment", "change", "we", "artist", "only", "edit", "occlusion", "gain", "during", "lighting", "design", "interobject", "occlusion", "itself", "can", "cache", "shadow", "we", "system", "currently", "do", "implement", "deep", "shadow", "serious", "limitation", "scene", "hair", "brickmap", "pointcloud", "memory", "management", "would", "present", "challenge", "implement", "brickmap", "we", "do", "support", "they", "dynamic", "code", "particular", "problem", "brickmap", "use", "light", "shader", "we", "subsurface", "scattering", "implementation", "example", "where", "point", "cloud", "statically", "sample", "cache", "time", "return", "value", "dynamic", "non-linear", "light", "non-linear", "contribution", "easily", "cache", "Dynamic", "loop", "Dynamic", "loop", "contain", "cache", "expression", "limitation", "we", "support", "they", "special", "case", "where", "bound", "since", "we", "statically", "allocate", "space", "deep", "framebuffer", "Figure", "12", "use", "bound", "dynamic", "loop", "layered", "material", "we", "have", "introduce", "system", "real-time", "preview", "RenderMan", "scene", "during", "lighting", "design", "we", "method", "automatically", "specialize", "shader", "static", "RenderMan", "pass", "generate", "deepframebuffer", "dynamic", "cg", "pass", "use", "deep-framebuffer", "enable", "real-time", "preview", "GPU", "cache", "compression", "enable", "automatically", "generate", "deep-framebuffer", "fit", "modest", "GPU", "memory", "complex", "production", "shot", "we", "have", "introduce", "indirect", "framebuffer", "which", "efficiently", "encode", "multisample", "high-quality", "render", "transparency", "motion", "blur", "we", "computation", "graph-based", "system", "architecture", "flexible", "amenable", "multipass", "render", "algorithm", "which", "we", "demonstrate", "shadow", "mapping", "subsurface", "scattering", "we", "be", "surprise", "effectiveness", "cache", "compression", "initially", "we", "assume", "we", "would", "build", "complex", "compiler", "analysis", "control", "cache", "size", "however", "due", "data-parallel", "nature", "shade", "redundancy", "abound", "simple", "post-process", "easily", "uncover", "savings", "which", "static", "analysis", "could", "recognize", "whole", "we", "system", "bring", "level", "automation", "greatly", "simplify", "interactive", "lighting", "preview", "alleviate", "need", "write", "maintain", "different", "shader", "final", "rendering", "preprocessing", "preview", "however", "do", "close", "debate", "between", "manual", "instrumentation", "automatic", "specialization", "manual", "programming", "preview", "shader", "can", "bring", "extra", "level", "flexibility", "particular", "adapt", "level", "detail", "further", "accelerate", "preview", "illustrate", "lpic", "-lsb-", "Pellacini", "et", "al.", "2005", "-rsb-", "though", "Pellacini", "separately", "show", "automatic", "level-of-detail", "can", "help", "-lsb-", "2005", "-rsb-", "long", "run", "we", "believe", "lighting", "preview", "should", "address", "way", "similar", "traditional", "programming", "automatic", "tool", "provide", "compilation", "optimization", "programmer", "can", "provide", "hint", "manually", "optimize", "simplify", "critical", "portion", "code", "base", "profiling", "tool", "still", "greatest", "limitation", "deep-framebuffer", "rendering", "its", "basis", "local", "shading", "fortunately", "we", "technique", "specific", "gpus", "rather", "generally", "useful", "reduce", "complex", "shade", "efficient", "data-parallel", "execution", "include", "future", "manycore", "cpus", "may", "ultimately", "avenue", "through", "which", "global", "effect", "most", "efficiently", "achieve", "Acknowledgments", "numerous", "people", "have", "contribute", "project", "its", "many", "year", "exploration", "implementation", "work", "start", "under", "advise", "Pat", "Hanrahan", "initially", "collaboration", "ujval", "kapasus", "Alex", "Aiken", "John", "Kodumal", "propose", "dependence", "analysis", "graph", "reachability", "provide", "first", "analysis", "library", "we", "use", "Matt", "Pharr", "John", "Owens", "Aaron", "Lefohn", "Eric", "Chan", "many", "member", "Stanford", "MIT", "Graphics", "Labs", "provide", "year", "essential", "advice", "feedback", "Tippett", "Studio", "take", "great", "risk", "actively", "support", "early", "research", "Dan", "Goldman", "introduce", "work", "ILM", "where", "Alan", "Trombla", "Ed", "Hanway", "Steve", "Sullivan", "have", "oversee", "many", "developer", "have", "contribute", "code", "include", "Sebastian", "Fernandez", "Peter", "Murphy", "Simon", "Premo", "ze", "Aaron", "Luk", "Hilmar", "Koch", "Paul", "Churchill", "Tom", "Martinek", "Charles", "Rose", "provide", "critical", "artist?s", "perspective", "early", "design", "Dan", "Wexler", "Larry", "Gritz", "Reid", "Gershbein", "provide", "useful", "explanation", "commercial", "lighting", "technology", "we", "thank", "Michael", "Bay", "graciously", "share", "unreleased", "image", "from", "he", "movie", "Dan", "Piponi", "generate", "we", "hair", "datum", "anonymous", "reviewer", "insightful", "discussion", "criticism", "Sylvain", "Paris", "Ravi", "Ramamoorthi", "Kevin", "Egan", "Aner", "Ben-Artzi", "Kayvon", "Fatahalian", "provide", "critical", "write", "feedback", "work", "support", "NSF", "CAREER", "award", "0447561", "NSF", "Graduate", "Research", "Fellowship", "NVIDIA", "Graduate", "Fellowship", "Ford", "Foundation", "Graduate", "Fellowship", "Microsoft", "Research", "New", "Faculty", "Fellowship", "Sloan", "fellowship" ],
  "content" : "Furthermore, we extend prior deep-framebuffer systems by enabling the efficient rendering of transparent surfaces and multisampling effects, such as motion blur. We apply similar principles to multisampling, transparency and subsurface scattering. In contrast, we need to handle the effect of local point light sources and arbitrary reflectance. Furthermore, computing illumination itself is a large part of our run-time calculation as production light shaders are quite complex. Compiler specialization of graphics computation was first used for ray tracing [Hanrahan 1983; Mogensen 1986; Andersen 1996]. We solve specialization using a graph formulation, mentioned but not implemented by Knoblock and Ruf [1996]. Peercy et al. [2000] and Bleiweiss and Preetham [2003] addressed the compilation of RenderMan shaders onto graphics hardware. This translation is part of a larger process that automatically generates deep-framebuffer data from unmodified existing scenes. In theory, some RenderMan code cannot be translated into GPU shaders, but we have found that, in practice, the dynamic parts of our production shaders translate well. In contrast to pure static compiler analysis, we use postexecution cache compression to supplement a simple compiler analysis. Given the complexity of shots that we handle, we also use progressive refinement to offer both interactive feedback (multiple frames per second) and faithful final quality (potentially after a few seconds). Finally, it is important to facilitate the implementation of new passes in a preview system. We describe a full production relighting system that is being deployed in two studios with different rendering workflows. Our primary objective is, given a fixed scene geometry, material and viewpoint, to enable the interactive manipulation of all light source parameters, including intensity, position, and falloff, as well as to create and remove light sources. High-performance preview Minimizing feedback time is our primary goal. Final quality might take a few seconds through progressive refinement, but low-latency feedback is critical to seamless user interaction. ? Fast initial precomputation ? To be accepted by artists, this tool should not make it take longer to begin work on a shot. Seamless integration with existing pipelines A preview system should be transparent to the user and require no additional work to use within an existing pipeline. This means that it should stand in for the existing offline rendering pipeline by: ? Taking the same input ? unmodified RenderMan scenes and shaders. ? Producing the same output ? using shading and visibility computation with extremely high fidelity to final rendering, including antialiasing, motion blur, and transparency. ? Using the same workflow ? in particular the same light editing GUI, which varies from studio to studio. This requires our system to communicate with different GUI software. Ease of implementation and maintenance Production rendering pipelines are complex and continually evolving. A preview system cannot afford the same implementation investment and should not require major re-implementation whenever the finalframe renderer is updated, the shaders changed, or the pipeline altered. ? Extensibility ? It should be as easy as possible to support new functionality?from using new shaders to implementing new multipass effects?in a simple, modular fashion. Our approach ( Fig. 2 ) can be decomposed into an automatic preprocess and a run-time phase that communicate through a dynamically-generated computation graph. We take as input the same RenderMan scene and shaders used for final rendering. For surface shaders, we then generate two new shaders: a static precomputation shader, which is executed once in the final-frame renderer to generate a deep-framebuffer cache, and a dynamic re-rendering shader (in Cg), which is executed repeatedly over the deep-framebuffer to generate interactive previews. The automatic specialization of shaders can be expected to yield a performance penalty for the interactive preview compared to manually optimized and simplified code [Gershbein and Hanrahan 2000; Pellacini et al. 2005], but in our context, seamless integration took precedence over final performance. Another potential limitation of automatic translation is that not all RenderMan code can be mapped to the GPU. However, for our production shaders this has not been an issue. Indirect framebuffer Our core real-time rendering is similar to traditional deep-framebuffer approaches and uses Cg shaders to perform computation on all deep-framebuffer samples on the GPU. However, we introduce a new level of indirection through an indirect framebuffer to decouple shading samples from final pixel values, thereby efficiently handling antialiasing, motion blur, and transparency. It also enables progressive refinement (Sec. Cache compression We rely on static preprocessing of the cached data to compensate for overestimates of the compiler analysis, as well as to cull the deep-framebuffer and indirect framebuffer based on visibility. This provides over an order of magnitude reduction in total cached data sizes while allowing the compiler to remain relatively simple. Multipass rendering We enable multipass effects such as shadow mapping and subsurface scattering. This requires the preprocessor to also output auxiliary data such as geometry needed for shadow mapping or lighting samples for translucency. Although translucency currently incurs substantial cost for our preview, it demonstrates the generality of our architecture. Computation graph The overall re-rendering algorithm is encoded as a computation graph, generated during preprocessing from the original scene and shaders. The computation graph provides two critical abstractions. Second, the graph abstracts the preprocessing from the editing GUI. So long as the generated graph conforms to certain basic conventions, the preprocessing stage can be updated and extended without affecting the GUI tool. We first need to determine which parts of the computation are static vs. dynamic with respect to the light parameters. We then create new RenderMan Shading Language (RSL) shaders that compute and output the static values, and use RenderMan to create a deep-framebuffer cache. We preprocess the cache output by RenderMan to compress redundant and irrelevant values. Finally, we translate the dynamic part of the computation into real-time GPU shaders that access the deep framebuffer as textures. Previous work has achieved these steps manually. Our contribution is to make this process fully automatic. shaders to operations that can be executed on the GPU. We can force certain operations?namely calls to external C routines, and unimplemented shadeops (e.g., trace)?to be labeled cached even if the dependence analysis labeled them dynamic. Static/dynamic analysis eliminates most such operations in our shaders. We can recognize light-dependent cache-required nodes as errors, but we find simply warning the user and computing the values statically at cache time often provides usable preview results. 3.2 Code Generation and Translation Once we have decided which computations to cache, and which to execute dynamically during preview, we generate two new surface shaders, one for each phase. RenderMan precomputation Caching computations are emitted as a new RSL shader. When branch conditions are dynamic, control flow in the dynamic preview shader may differ from the caching execution. If values are cached inside a dynamic conditional, the caching shader must execute both potential branches. Finally, we generate a new RenderMan scene that replaces each shader by its caching equivalent. We run it through RenderMan to generate the deep framebuffer ( Fig. 3 ). Cg code generation Dynamic surface shaders are emitted as new Cg shaders which read the deep-framebuffer cache as textures. The key issue in translating RSL to Cg is to mimic RenderMan?s richer data-flow and execution semantics. Communication of light color and direction is accomplished through shared global variables, as in RSL. However, RSL also allows surfaces and lights to access each other?s parameters by name through messagepassing. We implement this by communicating parameters through global variables. 3.3 Specialization Results Figure 4 summarizes the results of our shader specialization approach. Note that the dynamic shader complexity depends on both the light and surface shaders. Generic Surface is a multipurpose ??bershader? that forms the basis of most of our custom shaders. However, it does not result in dramatically larger dynamic shaders than a simpler surface because most of the code is static and dynamic code is dominated by lighting computation. The sizes of our caching shaders are 28k and 22k RSL instructions for Generic Surface and Metallic Paint, respectively. Pellacini et al. [2005] describe challenges with binding overhead for the number of unique surfaces generated by specialization. Our technique has no more shaders than the original shot and our shots usually use at most a dozen unique shaders, which contrasts with the thousands of unique shaders per shot used in other studios [Pellacini et al. 2005] 1 . This further emphasizes that, in our context, automatic specialization is primarily motivated by the rate at which shaders change (as well as the ability to edit surface parameters), not their total number. It can easily reach hundreds of scalars per deep-framebuffer element, potentially exceeding the GPU?s memory. This makes cache compression, as well as the tiling described in Section 5, critical. 1 Given increased program size limits in latest GPUs, Cg codegen could generate a single compound shader performing dynamic dispatch to subroutines implementing each surface or light. This technique is already used effectively in games. In contrast, we find that applying simple post-processes to our final cached data provides tremendous reductions in cache complexity, sufficient to enable effective automatic deep-framebuffer generation with a simple compiler. These optimizations can reduce the number of cached components by more than a factor of 4 ( Fig. 5 ). Because these optimizations inline significant new static data in the dynamic Cg shaders, this also helps the Cg compiler reduce runtime shader complexity through constant folding. Shader dynamic varying unique (caching analysis) (compressed) generic surface 402 145 97 metallic paint 450 150 97 The number of (scalar) values per deep-framebuffer sample for the scene in Fig. 1 under compression. Dynamic terms are determined by the initial caching analysis. Varying terms remain after elimination of values that are constant over the frame. Unique terms remain after further elimination of duplicated values. 3.5 Specializing for Surface Parameters A key advantage of automatic specialization is to allow users to selectively tweak some surface, as well as light parameters. When users select surface parameters as dynamic, the compiler can just as easily generate code with configurable surface parameters ( Fig. 6 ). This significantly extended the initially-planned range from lighting to look-design. In practice, the main overhead in editing surface parameters is that it requires the reevaluation of all light sources. Editable surf. parameters GPU instr. relative perf. 0 (baseline) 3518 21 100% 18 (gain) 3856 27 90% 41 (gain & specularity) 3973 29 86% Preview performance as a function of the number of editable surface parameters for a variant of Generic Surface. Editing 41 scalar and vector surface parameters does not significantly slow rendering compared to light parameters alone. Traditional deep-framebuffers are pure image-space structures, which allows them to scale with image size, not scene complexity. Inspired by the decoupling between shading and visibility computation central to RenderMan?s REYES pipeline, we introduce a layer of indirection between deep-framebuffer shading and visibility/display samples through a second data structure we call the indirect framebuffer. We first review the multisampling approach used in RenderMan before introducing our new data structure. Background RenderMan?s REYES architecture achieves high quality and generality of antialiasing, motion blur, and depthof-field by supersampling visibility computation, while reducing shading cost by reusing shading values rather than supersampling them [Cook et al. 1987; Apodaca and Gritz 2000]. While smooth reconstruction of motion blur, depth-of-field, or fine geometry may require 100 or more visibility samples, the shading rate is commonly just roughly one shading sample per output pixel. ? Pixels contain a uniform density of subpixel samples, distributed in screen-space (spatial antialiasing), time (motion blur), and aperture location (depth-of-field). RenderMan first tessellates all primitives into micropolygons. (iii) Deep-framebuffer (iv) Indirect framebuffer The indirect framebuffer densely encodes variablerate visibility information to enable efficient antialiasing and transparency under a static view. It resamples a denselypacked deep-framebuffer into screen-space to precisely reproduce RenderMan?s high-quality antialiasing, but is linearized and consolidated for the given static visibility configuration, requiring far fewer unique samples for the same result. ducing a color per vertex ( Fig. 9.i ). RenderMan then computes visibility (hiding) by testing each micropolygon against each subpixel sample it potentially covers (rasterization), taking into account the aperture and time value of the sample. A depth test is performed and transparency is handled by maintaining a z-ordered list of micropolygon pointers at each subpixel sample ( Fig. 9.ii ). The color of a subpixel sample is then computed by looking up the color and opacity of each micropolygon and compositing them in depth-order. The final pixel value is the weighted average color of the subpixels, and since the subpixels are jittered in space, time, and aperture location, this achieves high quality multisampling effects while keeping shading cost tractable. We note that each final, filtered pixel color ultimately corresponds to a simple linear combination of the shaded colors of all micropolygons visible under that pixel. Consider the example in Fig. 9.ii : the first subpixel?s color is a linear combination of shading samples a 1 and b 1 with weights given by a 1 ?s transparency. The final pixel value is a combination of the colors of shading samples a 1 , b 1 , and b 2 with weights 0.175, 0.225 and 0.435. When visibility is static, these cumulative linear weights similarly become static. This is similar to the principle of the direct-to-indirect transfer [Ha san et al. 2006] but in the context of multisampling and transparency. We first use a standard deep framebuffer, but instead of organizing it per pixel, our preprocess caches data for each shading sample ( Fig. 9.iii ). Our real-time dynamic shaders execute over this cache and output per-shading-sample colors. Our indirect framebuffer encapsulates the linear nature of the\n          RenderMan our approach Figure resolution samples shade subpix shade indir. 1 914x389 13x13 2.1M 32M 633k 1.6M 8 720x306 13x13 1.5M 21M 467k 3.8M 12 640x376 4x4 2.5M 2.3M 327k 716k 15 (?: 0.1) 720x389 8x8 54M 121M 21M 35M 15 (?: 0.6) 720x389 8x8 43M 58M 11M 17M 15 (?: 1.0) 720x389 8x8 25M 17M 3.9M 5.7M Figure 10 : Original RenderMan micropolygon and pixelsample output complexity compared to our compressed indirect framebuffer, in numbers of samples, for Figs. 1, 8, 15, and 12. Static visibility compression losslessly reduces deep-framebuffer shading samples by 3-8x relative to RenderMan?s shaded micropolygons, and reduces the number of unique indirect framebuffer samples by 3-20x relative to RenderMan?s subpixel samples. final color and stores, for each pixel, a list of weights and pointers to the deep-framebuffer output ( Fig. 9.iv ). For example, the pixel in Figure 9.iii corresponds to three entries in the indirect framebuffer. We need to efficiently represent the variable-length list of shading values influencing each pixel and enable progressive rendering. We use a ?scatter? strategy where points are rendered at each pixel location to accumulate color contribution. Each indirect framebuffer entry is encoded into a vertex array as a point, containing a pointer to a shading sample (a texture coordinate), a weight, and an output pixel coordinate (x, y). Rendering the vertex array with blending enabled scatters the weighted colors into final pixels. Note that one entry in the deep framebuffer and the resulting shaded color often contributes to multiple neighboring pixels, especially in the presence of motion blur. This highlights the effectiveness of our decoupling (and that of RenderMan) where complex multisampling effects are achieved without scaling the cost of shading. Our implementation is currently limited to static opacity. Dynamic transparency could be supported by recomputing the weights on the fly, but light-dependent transparency does not occur in our shaders. We also do not currently handle colored transparency, though it simply requires storing an RGB weight and independently blending each color channel. Using the static visibility information of the indirect framebuffer, we apply two key transformations on the cached data to losslessly compress its size: ? The static linearization of the indirect framebuffer coalesces all visibility samples which reference the same shading sample at the same pixel into a single combined indirect framebuffer weight. This provides a 3-20x reduction in the size of the indirect framebuffer while producing the same output ( Fig. 10 ). ? We cull all deep-framebuffer shading samples not referenced by at least one indirect framebuffer sample. We maintain a local neighborhood where necessary for derivative computation. These optimizations reduce the number of indirect framebuffer samples by 3-20x, and the number of deep-framebuffer samples by 3-8x ( Fig. 10 ), with no loss of generality, even for complex scenes involving motion blur ( Fig. 8 ) and transparent hair (Fig. 15). This reduces not only storage size, but also computation, because shading is applied once per-deep-framebuffer sample, and resampling once per-indirect framebuffer sample. Combined with dense packing of shading values, these optimizations generally allow even heavily multisampled shots, with transparency, to require little more storage than a simple, single-sampled image-space deepframebuffer, and to be rendered interactively. Our system must scale to final-resolution previews of massive scenes with complex shaders, while maintaining interactivity. High resolution previews and more complex shaders may increase cache size beyond GPU memory. We divide oversized caches into screen-space tiles small enough for all hardware constraints. Each tile contains an indirect framebuffer coupled with a deepframebuffer of all shading samples visible at those indirect framebuffer samples. We also use texture atlases because our deepframebuffer may contain more channels than the number of bindable textures. We rely on progressive refinement to offer both interactive feedback and slower yet faithful final image quality. We progressively refine the resolution, typically in 3 steps. In the first step, we begin with 4x4 then 2x2 pixel blocks. Next, we increase to full resolution but with only one indirect framebuffer value per pixel. In the final step, we use full multisampling for the highest quality. Each stage is represented by a group of samples in our indirect framebuffer. We order the indirect framebuffer samples for a given pixel by weight and accumulate them progressively in passes. Shading is only updated for the points referenced by the indirect framebuffer samples in a given refinement batch. This also helps guarantee performance on massive scenes, because the first few refinement levels can be constrained to fit entirely on the GPU. Finally, we often disable shadows at the lowest refinement. Tiles of our deep-framebuffer are stored as sets of shading samples grouped by surface type, and into batches for multiple progressive refinement passes. Passes are stored in 2D textures with arbitrary layout (2x2 quads are maintained for derivatives). In practice, shading samples are stored according to the order in which RenderMan outputs them. Like prior lighting design systems, we exploit the linearity of (most) lighting by caching the contribution from all lights not currently being edited by the user. We store a light cache that gets updated when a subset of lights is temporarily ?frozen. ? In practice, when a light is ?unfrozen?, its contribution is subtracted from the cache, and a new frozen light?s contribution is added. We retain the old parameter state with which the cache was generated to maintain correctness when subtracting. This speeds up freezing when working with multiple tens of light sources, and has proven numerically stable over long edit sessions when using a 32-bit floating-point cache. Changing surface parameters requires reshading the surface with all lights. In scenes with few lights, this is still comfortably interactive. In near-final shots with dozens of lights, it may be subinteractive, but still takes only a few seconds for useful feedback. Light caching is significantly complicated by the introduction of progressive refinement. In order to update the cache, we maintain a table of the cached light parameters for each light at every refinement level. A given cache level is valid for a light if the cached parameters match the light?s current parameters. If not, the cache is updated by reshading and subtracting the contribution of the old configuration, then shading and adding the new contribution. So far, we have focused on purely local illumination computation. However, global effects such as shadowing and translucency must also be reproduced. We first show how they can be included in our approach using multipass rendering and discuss both the necessary preprocessing and real-time components. We then address critical software architecture issues in making the development of our system tractable. The complex dependences between multipass effects, the indirect framebuffer, and progressive refinement made it important to develop an abstraction to facilitate the inclusion of new effects and manage dependences, as well as abstract key low-level aspects such as data-flow and bindings on the GPU. Fig. 11 summarizes the data-flow for our final real-time computation including shadow mapping, translucency, and indirect framebuffer effects. Shadow mapping illustrates how multipass effects from the final rendering pipeline can be included in our architecture. Shadow maps necessitate one extra pass per light and require auxiliary data from the preprocessor (scene geometry). For real-time preview, the shadow map pass communicates with the main pass through a texture and our graph interface (presented below) manages communication and dependences when parameters are edited. During caching, we run RenderMan a second time over the scene to extract micropolygons after all transforms and displacements are applied. We store object IDs to support selective shadow casting and receiving per-object. For specialization, RenderMan shadow mapping calls are flagged and marked dynamic. They are replaced in the dynamic code by a Cg shadow map lookup. When rendering the shadow map, we also render the object IDs to allow shadow assignments to be modified in real-time on a per-object basis. Subsurface scattering requires the integral of incident light flux times a BSSRDF diffusion kernel over a neighborhood at each visible point. We have adapted Jensen and Buhler?s hierarchical two-pass approach [2002], exactly as used in our existing offline shaders, for real-time preview. This method first creates a hierarchy of irradiance samples which enables fast hierarchical evaluation of the integral. Our scheme builds on the work by Ha san et al. [2006] for indirect lighting, but instead of a wavelet approach, we directly use Jensen and Buhler?s octree hierarchy [2002]. For translucency, we must distinguish the shading of visible shading samples as described in Section 4 and the irradiance computation at gather samples used to estimate subsurface scattering [Jensen and Buhler 2002]. In particular, the latter cannot have view-dependent terms and usually only requires albedo and normal information. We ?bake? this information during preprocessing into a separate translucency deep-framebuffer and generate a simple dynamic Cg shader, based on our offline irradiance shader, to evaluate irradiance (diffuse shading) during runtime. For each visible shading sample, we cache the indices of the set of nodes of the irradiance hierarchy that contribute to the translucency. We also store the corresponding BSSRDF coefficient weight (the dipole kernel) [Jensen and Buhler 2002] and distance to allow dynamic editing of the scattering depth. For interactive preview, we first evaluate the irradiance at each gather sample using the dynamic diffuse shader and the translucency deep framebuffer. This provides us with the leaf values of our hierarchy, stored in a texture. We then use d iterative blending passes for the d levels of the octree to accumulate the values of higher-level nodes as a sum of their children. All octree values are stored in the same texture map as the leaves. We can then compute the color of the visible shading samples. Because only the accumulation weights, not the actual octree traversal, depend on the BSSRDF coefficients, lookups into the octree are recorded statically during preprocessing and encoded as vertex arrays, much like the indirect framebuffer. We instead store static BSSRDF attenuation and distance terms per-lookup, and albedo modulation per-visible-point. We then dynamically compute the BSSRDF contribution based on dynamic scattering depth (sigma) values using a fragment shader while accumulating each lookup into the hierarchy?s irradiance values using the static indices recorded during preprocessing. Note that translucency computation is performed at the granularity of shading samples and benefits from the decoupling of our indirect framebuffer, both for progressive refinement and overall efficiency. Results Our initial results ( Fig. 12 ), while promising in their fidelity, demonstrate the need for a progressive shading technique. While final scattering contributions are evaluated progressively, per visible shading point, the static octree lookups require the translucency deep-framebuffer to be completely shaded prior to any accumulation. In practice, these deep-framebuffers can be even larger than the primary deep-framebuffer?1.3M points, in this example. This means that, while changing scattering coefficients render interactively (2 Hz) for this scene, and the base shader renders at 2-10 Hz for initial refinement, excluding scattering computations, reevaluating the subsurface scattering result takes several seconds to reach initial refinement (though subsequent refinement is very fast because the octree is already evaluated). Multipass algorithms such as shadow mapping and translucency, together with the indirect framebuffer and progressive refinement, introduce complex data-dependencies between and computations. Subsurface scattering coefficients can be edited interactively. Top: less translucency. Bottom: more translucency. The preview renders initial refinement at 2 Hz under changing coefficients, but reshading the 1.3 million-point translucency buffer takes several seconds. The eyes contain multiple transparent layers, and appear black without the indirect framebuffer. Furthermore, making our system extensible, and enforcing abstraction between the various components, required more care than we initially anticipated, and our original, monolithic engine quickly became challenging to maintain. Nodes communicate through ports, which abstract computation from dependency and data-flow, and global data-flow is encoded as edges between ports. Our core computation graph library also abstracts low-level aspects of shader and data management on the GPU, and includes a library of basic building block nodes. The graph instance for a scene is generated automatically by the compiler and preprocessing stages of our pipeline, and is used internally by the user interface application. Figure 13 summarizes our system?s fully-automatic performance on two of our shots (Figs. 1, 12). Cache sizes fit within current GPU resources, though our system scales to support out-of-core shots at much higher resolutions or with even more complex shaders. We report all results for our current, deployed artist workstations, with dual 2.6GHz AMD Opteron 2218 processors, 8GB RAM, and NVIDIA Quadro FX 5500 (G71) graphics. We are generally at the limit of the capability/performance curve for our current hardware, but preliminary results suggest major performance improvements on next-generation hardware. Pirate (12) Robot (1) resolution 640x376 914x389 supersampling 4x4 13x13 lights 3 42 RenderMan (total) 409 sec 3406 sec irradiance shading 111 sec material shaders 1 2 material instances 4 44 light shaders 1 5 light instances 3 42 Caching (total) 1425 sec 931 sec initialization 8 sec 18 sec shader specialization 24 sec 63 sec deep-framebuffer caching 627 sec 499 sec shadow geometry caching 105 sec 164 sec cache compression 60 sec 187 sec octree compression 600 sec Preview irradiance shading (1 light) 7 sec interaction (irradiance cached) 0.5 sec coarse refinement, 4x4 blocks 0.1 sec full refinement (1 light changed) 10 sec 2.7 sec full refinement (n lights) 29 sec (3 lights) 31.7 (42 lights) deep-framebuffer 104 MB 256 MB indirect framebuffer 33 MB 29 MB irradiance deep-framebuffer 83 MB scattering index buffer 436 MB System performance compared to our RenderManbased offline pipeline for two production shots (Figs. 1 & 12). In both, initial feedback is accelerated several orders of magnitude, to interactive rates. Caching time for the Pirate example is dominated by unoptimized octree caching and compression processes which (unnecessarily) read and write multiple GB of octree data on disk several times during caching. Our system has been integrated into the pipelines of two special effects studios. It is currently in initial release with a number of artists in production for both lighting and look-design. We have focused our efforts on ironing out the major, previously-unsolved technical challenges with such a system. Subsurface scattering is only proof-of-concept and requires further optimization. Nevertheless, initial feedback has been extremely positive. For example, artists love the freedom to experiment with complex features such as noise: ?[we] usually shy away from noise because it takes so long to edit... this interactivity makes it much more useful. ? In general, there was a strong feeling that interactive feedback not only accelerated the adjustment of key parameters (?getting that level right [previously] took me an hour! ? [after just tuning a light to match the background in under 10 seconds]), but left users more willing to experiment aggressively. GPU vs. specialization speedup We have estimated the gain due to specialization vs. GPU execution. Since we do not have a software preview runtime, we can only perform back of the envelope calculations comparing the GPU shaders to RenderMan shaders, and prman timing with real vs. trivial shaders. For the included scenes, we estimate that specialization and caching provide a 100x speedup while execution on the GPU brings another 20x. The coarsest level of refinement provides an extra 10-100x. The upper-right half of the image is rendered with our approach while the lower left is the final RenderMan frame. Initial refinement renders at over 20 Hz with our full 4k instruction specialized surface shader and spot light, including shadows. Error is in percentage of max pixel value. Figure 15: 430k transparent hairs (? = 0.6, opacity threshold: 0.96) rendered at 720x389 with 8x8 sampling. This generates 43M micropolygons and 58M pixel samples in RenderMan, and condenses to 11M visible shading samples and 17M unique visibility samples through lossless visibility compression, rendering at 12 Hz and fully refining in 33 secs. Compression and performance are even better at ? = 1.0, but ? = 0.1 (threshold: 0.996) generates 21M visible shading samples, overflowing the 16M sample textures we currently use (cf. Fig. 10 ). Shadow geometry scales with scene complexity and is the main scalability limitation, in practice. Using micropolygons instead of source primitives was a design decision to avoid re-implementing every primitive supported by prman. We control shadow-geometry level of detail by altering the shading rate of the shadow bake pass. Additional mesh decimation passes could be useful. Aside from shadowing, our system effectively scales with image complexity. The indirect framebuffer and cache compression dramatically reduce memory costs. Transparency is the main difference from previous techniques because it adds an unbounded number of samples. We created a complex scene to test scalability (Fig. 15): 430k transparent hair fibers (? = 0.1, opacity threshold= 0.996), resulting in 55M prman micropolygons and 20M visible Lightspeed shading samples rendered at 720x389 with 64x supersampling. This overflows our shade sample texture because of the GPU?s 4kx4k (16M) texture limit. However, with ? reduced to 0.6, the same scene only requires 11M shade samples (vs. 43M in prman) and works at 12 Hz (33 secs for full refinement because the full cache is 2GB and needs to be paged). With no transparency, Lightspeed shades just 4M samples (vs. 25M for prman) at 22 Hz (5.5 secs for full refinement). The 16M limit can trivially be increased by using multiple textures or 8k textures in DirectX 10. For our production scenes, however, we have not encountered such extreme cases. Our artists avoid transparent hair in favor of smaller sub-pixel hair because these same scalability problems apply in prman. In fact, though unbounded, transparency consistently contributes much less to total frame complexity than (bounded) multisampling in our scenes. While the worst case scales with supersampled image complexity (times depth complexity for transparency), the key goal of our design?visibility compression and the linearization of visibility into the indirect framebuffer?is to provide real-world scaling much closer to pixel-complexity, even with motion blur ( Fig. 8 ), subpixel microgeometry like hair (Fig. 15), and a modest average transparency depth. The overall conclusion of our tests, ignoring shadowing, is: ? We can handle a lot of fine geometry, or handle a lot of very transparent coarse geometry, but our current implementation will not handle a lot of very transparent and fine geometry that completely fills the image, with antialiasing. ? We can handle a lot of fine geometry that is semi-transparent even if it fills the image, with high antialiasing. Where scene complexity can become an issue for the indirect framebuffer is during caching. Because simple methods of caching (bake3d) extract all shaded grids from prman, initial cache sizes can be very large, and compression becomes disk i/o bound. We addressed this by pushing compression in-memory with the renderer (as a DSO), which greatly accelerates caching and culling. The number of unique shaders can also be an issue. However, if a given surface shader is used for multiple surfaces with different parameters, we only need to specialize it once. The total number of dynamic shaders is the product of the number of different light shaders and the number of surface shaders (not the number of instances). Because we mostly use ?bershaders, this is not a problem for our workloads (?10-100 combinations in practice, Fig. 13 ), though it would be for studios with thousands of unique shaders in a shot. This might be addressed with established techniques, as discussed in Footnote 1. In practice we find our approach quite robust. Major challenges we have addressed include: ? Dynamic calls to external C routines are largely eliminated during specialization, and, where they aren?t, they have been effectively emulated on the GPU or made cache-required. ? Generated deep-framebuffers are compressed to modest sizes, even for our more complicated scenes and shaders. ? GPU texture limits are abstracted through tiling. ? Complex visibility is effectively compressed, even at high multisampling rates. ? Interactivity is maintained in the face of complexity by progressive refinement. ? Automatically specialized shaders fit within current GPU limits. Our key limitations are the same faced by any GPU shading system?namely, that operations not easily expressed as native GPU instructions require special handling. Most importantly, nonlocal shading must be handled explicitly using multipass algorithms. We have achieved this for shadows and translucency, but additional implementation is required for other effects. Still, a number of features cannot be translated and would result in an error message if deemed dynamic. Fortunately, such features are usually not used in the dynamic parts of shaders in our studio. This may not be true in all studios. Ray Tracing We do not perform ray casting. Note that specular ray tracing could be previewed in a deep-framebuffer using indirect buffers (ray intersections do not change unless the index of refraction is edited for transmitted rays). The main limitation concerns ray-casting for shadows and inter-reflections. Ambient occlusion Lightspeed would require re-caching of occlusion if object-object shadowing assignments changed. Our artists only edit occlusion gain during lighting design, and interobject occlusion, itself, can be cached. Shadows Our system currently does not implement deep shadows and this is a serious limitation for scenes with hair. Brickmaps and pointclouds Memory management would present challenges for implementing brickmaps. We do not support them in dynamic code. This is a particular problem if brickmaps are used in a light shader. Our subsurface scattering implementation is an example where a point cloud is statically sampled at cache time, but the returned values are dynamic. Non-linear lights Non-linear contributions are not easily cached. Dynamic loops Dynamic loops containing cached expressions are a limitation. We support them in the special case where they are bounded, since we statically allocate space in the deep framebuffer. Figure 12 uses bounded dynamic loops for layered materials. We have introduced a system for the real-time preview of RenderMan scenes during lighting design. Our method automatically specializes shaders into a static RenderMan pass that generates a deepframebuffer, and a dynamic Cg pass that uses the deep-framebuffer to enable real-time preview on a GPU. Cache compression enables automatically generated deep-framebuffers to fit in modest GPU memory for complex production shots. We have introduced the indirect framebuffer which efficiently encodes multisampling for high-quality rendering with transparency and motion blur. Our computation graph-based system architecture is flexible and is amenable to multipass rendering algorithms, which we demonstrate with shadow mapping and subsurface scattering. We were surprised by the effectiveness of cache compression. Initially, we assumed we would build complex compiler analyses to control cache size. However, due to the data-parallel nature of shading, redundancy abounds, and simple post-processes easily uncover savings which static analysis could not recognize. As a whole, our system brings a level of automation that greatly simplifies interactive lighting preview and alleviates the need to write and maintain different shaders for final rendering, preprocessing, and preview. However, it does not close the debate between manual instrumentation and automatic specialization. The manual programming of preview shaders can bring an extra level of flexibility, in particular to adapt the level of detail to further accelerate preview, as illustrated in lpics [Pellacini et al. 2005], though Pellacini separately showed that automatic level-of-detail can help [2005]. In the long run, we believe that lighting preview should be addressed in a way similar to traditional programming: automatic tools are provided for compilation and optimization, and the programmer can provide hints or manually optimize and simplify critical portions of the code based on profiling tools. Still, the greatest limitation to deep-framebuffer rendering is its basis in local shading. Fortunately, our techniques are not specific to GPUs. Rather, they are generally useful for reducing complex shading to efficient data-parallel execution, including on future manycore CPUs, and this may ultimately be the avenue through which global effects are most efficiently achieved. Acknowledgments Numerous people have contributed to this project in its many years of exploration and implementation. This work started under the advising of Pat Hanrahan, initially in collaboration with Ujval Kapasi. Alex Aiken and John Kodumal proposed dependence analysis by graph reachability and provided the first analysis library we used. Matt Pharr, John Owens, Aaron Lefohn, Eric Chan, and many members of the Stanford and MIT Graphics Labs provided years of essential advice and feedback. Tippett Studio took great risk in actively supporting early research. Dan Goldman introduced the work to ILM, where Alan Trombla, Ed Hanway, and Steve Sullivan have overseen it. Many developers have contributed code, including Sebastian Fernandez, Peter Murphy, Simon Premo ze, and Aaron Luk. Hilmar Koch, Paul Churchill, Tom Martinek, and Charles Rose provided a critical artist?s perspective early in design. Dan Wexler, Larry Gritz, and Reid Gershbein provided useful explanations of commercial lighting technologies. We thank Michael Bay for graciously sharing unreleased images from his movie, Dan Piponi for generating our hair data, and the anonymous reviewers for their insightful discussion and criticism. Sylvain Paris, Ravi Ramamoorthi, Kevin Egan, Aner Ben-Artzi, and Kayvon Fatahalian provided critical writing feedback. This work was supported by NSF CAREER award 0447561, an NSF Graduate Research Fellowship, NVIDIA Graduate Fellowship, Ford Foundation Graduate Fellowship, Microsoft Research New Faculty Fellowship and a Sloan fellowship.",
  "resources" : [ ]
}