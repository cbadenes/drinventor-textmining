{
  "uri" : "sig2007-a17-todo_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2007/a17-todo_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Locally Controllable Stylized Shading",
    "published" : "2007",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Hideki-Todo",
      "name" : "Hideki",
      "surname" : "Todo"
    }, {
      "uri" : "http://drinventor/Ken-ichi Anjyo",
      "name" : "Ken",
      "surname" : "ichi Anjyo"
    }, {
      "uri" : "http://drinventor/William V. Baxter-III",
      "name" : "William V. Baxter",
      "surname" : "III"
    }, {
      "uri" : "http://drinventor/Takeo-Igarashi",
      "name" : "Takeo",
      "surname" : "Igarashi"
    } ]
  },
  "bagOfWords" : [ "most", "technique", "design", "elucidate", "particular", "attribute", "inherent", "object", "left", "image", "Figure", "show", "example", "where", "dark", "area", "partly", "cover", "right", "eye", "character", "change", "geometry", "model", "animate", "texture", "light", "map", "might", "helpful", "achieve", "time-consuming", "impractical", "production", "schedule", "keyframebased", "technique", "appropriate", "since", "allow", "fine-tuning", "stylistic", "animation", "traditional", "convenient", "familiar", "way", "animator", "additionally", "real-time", "preview", "animation", "also", "indispensable", "basic", "requirement", "make", "stylized", "animation", "have", "lead", "we", "consider", "na?ve", "key-framing", "first", "approach", "towards", "new", "methodology", "we", "thus", "obtain", "real-time", "preview", "stylistic", "animation", "right", "image", "Figure", "from", "animation", "create", "use", "we", "technique", "while", "leftmost", "show", "scene", "before", "modification", "rest", "paper", "organize", "follow", "section", "demonstrate", "animation", "example", "discuss", "we", "result", "stylized", "rendering", "3d", "object", "Lake", "et", "al.", "-lsb-", "2000", "-rsb-", "propose", "several", "fundamental", "real-time", "rendering", "technique", "include", "traditional", "cartoon", "shader", "wysiwyg", "system", "Kalnins", "et", "al.", "-lsb-", "2002", "-rsb-", "allow", "direct", "drawing", "stroke", "onto", "3d", "object", "while", "learn", "stroke", "example", "cartoon", "highlight", "shader", "-lsb-", "Anjyo", "et", "al.", "2006", "-rsb-", "allow", "user", "directly", "click-and-drag", "highlight", "surface", "design", "animate", "they", "previous", "work", "user-specified", "indirect", "lighting", "design", "photo", "terface", "result", "new", "area", "can", "represent", "functionally", "introduce", "offset", "function", "modify", "standard", "lighting", "term", "bottom", "graph", "show", "1-d", "intensity", "distribution", "along", "green", "line", "realistic", "scene", "render", "some", "extent", "related", "we", "approach", "well", "exist", "several", "good", "approach", "-lrb-", "-lsb-", "Schoeneman", "et", "al.", "1993", "Kawai", "et", "al.", "1993", "Pellacini", "et", "al.", "2002", "-rsb-", "instance", "-rrb-", "geometry-dependent", "lighting", "method", "-lsb-", "Lee", "et", "al.", "2006", "-rsb-", "may", "also", "useful", "indirect", "light", "design", "tool", "visualize", "scientific", "datum", "we", "approach", "inspire", "all", "above", "method", "addition", "we", "demonstrate", "continuous", "tone", "detail", "can", "also", "paint", "animated", "extension", "we", "approach", "start", "from", "3d", "scene", "create", "use", "conventional", "lighting", "key-framing", "technique", "we", "consider", "how", "locally", "add", "light", "shade", "onto", "surface", "we", "implementation", "capable", "deal", "deform", "geometry", "multiple", "directional", "and/or", "point", "light", "source", "however", "without", "loss", "generality", "we", "explain", "we", "idea", "below", "context", "single", "light", "source", "extension", "deformation", "multiple", "light", "source", "straightforward", "more", "precisely", "use", "set", "notation", "we", "define", "light", "area", "surface", "give", "threshold", "where", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "unit", "vector", "represent", "light", "direction", "surface", "normal", "point", "respectively", "boundary", "between", "light", "dark", "area", "obtain", "replace", "inequality", "-lrb-", "-rrb-", "equality", "-lrb-", "-rrb-", "above", "we", "refer", "dot", "product", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "intensity", "distribution", "give", "definition", "let", "we", "consider", "how", "enlarge", "portion", "light", "area", "example", "character?s", "face", "figure", "where", "light", "area", "flesh", "color", "let", "area", "boundary", "-lrb-", "draw", "red", "figure", "-rrb-", "area", "paint", "we", "brush-type", "interface", "-lrb-", "see", "next", "section", "specifics", "-rrb-", "area", "area", "user", "wish", "add", "original", "area", "overall", "strategy", "follow", "we", "first", "construct", "offset", "function", "-lrb-", "-rrb-", "define", "globally", "prescribe", "new", "light", "area", "replace", "original", "intensity", "distribution", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "see", "Figure", "-rrb-", "after", "make", "modification", "one", "keyframe", "we", "can", "create", "different", "offset", "function", "define", "light", "area", "second", "keyframe", "smoothly", "interpolate", "offset", "function", "between", "keyframe", "we", "can", "achieve", "smooth", "animation", "light", "area", "between", "frame", "well", "procedure", "can", "repeat", "every", "pair", "adjacent", "keyframe", "result", "animated", "light", "area", "use", "just", "local", "edit", "paint-brush", "give", "original", "light", "area", "from", "-lrb-", "-rrb-", "paint", "area", "show", "figure", "offset", "function", "-lrb-", "-rrb-", "should", "satisfy", "where", "-lrb-", "-rrb-", "generate", "when", "user", "finish", "draw", "fulfill", "condition", "-lrb-", "-rrb-", "clear", "offset", "function", "should", "take", "value", "equal", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "new", "boundary", "we", "current", "implementation", "distance", "between", "control", "slider", "user", "interface", "size", "region", "give", "user", "way", "limit", "scope", "modification", "-lrb-", "also", "see", "detail", "section", "-rrb-", "therefore", "-lrb-", "-rrb-", "should", "minimally", "satisfy", "following", "condition", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-lrb-", "-rrb-", "-rrb-", "-lrb-", "-rrb-", "we", "choose", "continuous", "function", "satisfy", "above", "condition", "resultant", "area", "have", "continuous", "boundary", "user?s", "kth", "stroke", "provide", "from", "new", "input", "result", "light", "area", "can", "define", "recursively", "where", "we", "assume", "+1", "-lrb-", "-rrb-", "continuous", "function", "satisfy", "constraint", "+1", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-lrb-", "-rrb-", "-rrb-", "-lrb-", "-rrb-", "include", "serve", "same", "role", "do", "again", "we", "note", "outside", "modification", "make", "lighting", "-lrb-", "i.e.", "+1", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-rrb-", "region", "modification", "visible", "under", "current", "lighting", "condition", "some", "modification", "may", "visible", "when", "either", "light", "model", "move", "have", "band", "allow", "smooth", "transition", "from", "modify", "-lrb-", "-rrb-", "value", "original", "value", "thus", "practice", "we", "use", "rbf", "approximation", "make", "from", "shaded", "area", "obtain", "paint", "operation", "rigorously", "boundary", "may", "exactly", "match", "original", "painted", "area", "allow", "fine", "adjustment", "we", "provide", "two", "additional", "type", "brush", "intensity", "brush", "smoothing", "brush", "which", "describe", "section", "3.4", "Lighting", "animation", "whole", "can", "accomplish", "interpolate", "offset", "function", "we", "prototype", "we", "have", "use", "simple", "linear", "blending", "purpose", "though", "more", "complicated", "blend", "function", "possible", "worth", "explore", "suppose", "consist", "polygon", "mesh", "show", "Figure", "we", "assume", "simplicity", "we", "find", "set", "point", "-lcb-", "-rcb-", "follow", "procedure", "each", "vertex", "inside", "we", "check", "adjacent", "edge", "intersection", "boundary", "note", "we", "record", "stroke", "datum", "per-vertex", "only", "reconstruct", "stroke", "linearly", "thus", "edge", "can", "cross", "boundary", "more", "than", "once", "now", "let", "+1", "we", "find", "continuous", "satisfy", "-lrb-", "-rrb-", "-lcb-", "-rcb-", "following", "form", "-lsb-", "Duchon", "1977", "Wahba", "1990", "Turk", "O?Brien", "1999", "-rsb-", "we", "employ", "-lrb-", "-rrb-", "basis", "function", "after", "experiment", "various", "option", "correspond", "solution", "generalize", "thin-plate", "spline", "problem", "-lsb-", "Duchon", "1977", "Wahba", "1990", "-rsb-", "curvature", "minimize", "property", "basis", "function", "seem", "well", "suit", "task", "previous", "section", "describe", "how", "we", "enable", "user", "add", "edit", "light", "area", "use", "paint-brush", "metaphor", "similar", "way", "we", "can", "add", "edit", "dark", "area", "case", "only", "difference", "selection", "boundary", "point", "use", "-lrb-", "-rrb-", "instead", "use", "we", "use", "opposite", "half", "user", "simply", "switch", "editing", "mode", "from", "light", "dark", "both", "case", "paint", "brush", "use", "roughly", "specify", "shade", "boundary", "we", "call", "type", "brush", "boundary", "brush", "boundary", "brush", "work", "well", "get", "desire", "shape", "intensity", "distribution", "may", "change", "smoothly", "desire", "can", "due", "radial", "basis", "function", "we", "select", "due", "too", "many", "conflict", "constraint", "example", "we", "have", "see", "we", "experiment", "even", "smooth", "radial", "basis", "function", "may", "result", "rapidly", "change", "intensity", "distribution", "area", "where", "distribution", "contour", "very", "close", "one", "another", "may", "cause", "result", "keyframe", "animation", "look", "unnatural", "case", "we", "have", "create", "smoothing", "brush", "painting", "surface", "smoothing", "brush", "offset", "value", "filter", "while", "preserve", "original", "value", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "we", "implementation", "offset", "value", "store", "per", "vertex", "update", "use", "simple", "weighted", "average", "value", "connected", "vertex", "each", "stroke", "operation", "way", "we", "achieve", "shading", "effect", "fade", "out", "more", "gradually", "have", "smoother", "boundary", "-lrb-", "see", "Figure", "-rrb-", "some", "case", "useful", "able", "simply", "add", "remove", "isolate", "light", "dark", "area", "situation", "we", "provide", "simpler", "alternative", "boundary", "brush", "which", "we", "call", "intensity", "brush", "brush", "simply", "add", "subtract", "from", "offset", "function", "magnitude", "amount", "add", "along", "centerline", "stroke", "we", "fade", "add", "intensity", "smoothly", "zero", "edge", "stroke", "use", "smooth-step", "cubic", "polynomial", "falloff", "Figure", "show", "simple", "example", "how", "use", "brush", "Figure", "-lrb-", "-rrb-", "initial", "intensity", "distribution", "character", "display", "use", "green", "contour", "line", "boundary", "brush", "apply", "-lrb-", "-rrb-", "after", "get", "offset", "function", "-lrb-", "-rrb-", "we", "have", "new", "intensity", "distribution", "show", "-lrb-", "-rrb-", "order", "get", "more", "variation", "stylized", "light", "shade", "we", "add", "few", "simple", "useful", "extension", "main", "algorithm", "above", "Specular", "Highlight", "we", "can", "deal", "stylized", "highlight", "same", "framework", "shaded", "area", "we", "system", "we", "simply", "need", "replace", "lambertian", "term", "-lrb-", "dot", "product", "-rrb-", "-lrb-", "-rrb-", "from", "blinn?s", "specular", "highlight", "model", "-lsb-", "Blinn", "1977", "-rsb-", "where", "normalize", "half-way", "vector", "between", "light", "eye", "user", "can", "easily", "edit", "highlight", "brush", "same", "manner", "shaded", "area", "we", "prototype", "system", "currently", "implement", "maya", "plug", "use", "Maya?s", "hardware", "shader", "functionality", "allow", "shader", "code", "write", "use", "standard", "opengl", "glsl", "we", "prototype", "system", "user", "can", "freely", "add", "localized", "light", "shade", "object", "see", "result", "together", "conventional", "lighting", "real-time", "we", "paint-brush", "metaphor", "we", "need", "find", "all", "vertex", "inside", "brush", "stroke", "region", "calculate", "distance", "from", "stroke", "centerline", "information", "use", "determine", "location", "point", "boundary", "Figure", "well", "implement", "smooth", "falloff", "intensity", "brush", "we", "accomplish", "use", "depth", "first", "search", "from", "seed", "point", "along", "brush", "centerline", "from", "each", "seed", "point", "we", "find", "all", "vertex", "distance", "less", "than", "brush", "radius", "set", "distance", "value", "use", "minimum", "current", "value", "distance", "from", "current", "seed", "point", "datum", "need", "only", "duration", "single", "stroke", "operation", "can", "discard", "immediately", "afterward", "we", "have", "apply", "we", "prototype", "system", "make", "various", "stylistic", "animation", "we", "system", "currently", "run", "interactive", "rate", "2.16", "GHz", "Intel", "p4", "Core", "Duo", "CPU", "NVIDIA", "GeForce", "QuadroFX", "350M", "GPU", "editing", "preview", "animation", "frame", "rate", "range", "from", "20", "fp", "all", "example", "paper", "accompany", "video", "make", "facial", "animation", "control", "light", "shade", "face", "crucial", "Figure", "first", "half", "accompany", "video", "illustrate", "how", "effectively", "efficiently", "we", "algorithm", "work", "important", "case", "show", "video", "even", "make", "simple", "facial", "animation", "3d", "head", "model", "often", "create", "many", "unnecessary", "dark", "area", "very", "hard", "remove", "they", "selectively", "use", "conventional", "lighting", "control", "other", "hand", "we", "approach", "can", "eliminate", "they", "easily", "interactively", "moreover", "allow", "user", "successfully", "add", "variety", "effect", "each", "which", "dramatically", "change", "character?s", "impression", "Figure", "latter", "half", "video", "demonstrate", "typical", "case", "where", "animator", "use", "we", "system", "make", "animation", "less", "realistic", "more", "expressive", "compare", "animation", "under", "conventional", "lighting", "-lrb-", "left", "Figure", "-rrb-", "we", "note", "several", "effect", "have", "be", "add", "animation", "most", "obvious", "smoothing", "simplification", "move", "highlight", "protrude", "forehead", "also", "example", "animator", "have", "add", "light", "area", "accentuate", "jawline", "bright", "firm", "line", "above", "left", "eye", "delay", "emergence", "face", "light", "show", "right", "Figure", "some", "effect", "might", "achieve", "conventional", "lighting", "technique", "however", "almost", "impossible", "add", "all", "they", "same", "shot", "without", "resort", "frame-by-frame", "modification", "Figure", "first", "animation", "example", "video", "show", "use", "we", "technique", "animated", "character", "highly", "deforming", "cape", "use", "move", "point", "light", "fix", "directional", "light", "type", "situation", "can", "result", "light", "shade", "area", "distract", "because", "change", "too", "rapidly", "animation", "video", "demonstrate", "we", "technique", "effective", "eliminate", "unnecessary", "shading", "simplify", "light", "shade", "make", "suitable", "cartoon", "animation", "second", "animation", "video", "demonstrate", "local", "controllability", "continuous", "tone", "we", "intensity", "brush", "describe", "section", "3.5", "show", "movie", "even", "when", "adjust", "continuous", "tone", "object", "we", "approach", "allow", "local", "tone", "control", "add", "backlight", "effect", "around", "character?s", "shoulder", "-lrb-", "see", "Figure", "-rrb-", "we", "be", "able", "create", "animation", "without", "modify", "initial", "lighting", "setup", "however", "case", "where", "viewpoint", "and/or", "light", "move", "more", "dynamically", "may", "more", "difficult", "achieve", "same", "effect", "use", "we", "technique", "make", "animation", "we", "use", "either", "boundary", "brush", "intensity", "brush", "depend", "type", "modification", "desire", "boundary", "brush", "appropriate", "when", "user", "want", "specify", "exactly", "where", "new", "boundary", "should", "lie", "example", "we", "determine", "size", "paint", "brush", "experimentation", "example", "we", "choose", "width", "boundary", "brush", "so", "one", "stroke", "tem", "be", "solve", "while", "rbf", "-lrb-", "solve", "-rrb-", "time", "take", "solve", "linear", "system", "rbf", "-lrb-", "dist", "-rrb-", "time", "take", "compute", "rbf", "distance", "function", "calculate", "-lrb-", "-rrb-", "transfer", "time", "take", "transfer", "vertex", "datum", "from", "maya", "we", "plug", "brush", "include", "least", "two", "adjacent", "vertex", "surface", "mesh", "similarly", "distance", "between", "figure", "also", "set", "include", "least", "two", "adjacent", "vertex", "mesh", "which", "can", "accomplish", "use", "slider", "small", "value", "offset", "function", "specify", "intensity", "brush", "section", "3.4", "also", "set", "empirically", "give", "interactivity", "we", "system", "result", "particular", "parameter", "setting", "can", "see", "immediately", "so", "we", "have", "find", "burdensome", "search", "value", "via", "trial", "error", "Table", "show", "performance", "we", "current", "implementation", "computation", "cost", "however", "depend", "number", "vertex", "contain", "since", "we", "do", "paint", "very", "large", "region", "practice", "cost", "seem", "serious", "bottleneck", "we", "system", "most", "significant", "part", "basic", "cost", "transfer", "vertex", "datum", "between", "maya", "we", "plug", "performance", "datum", "Table", "also", "make", "clear", "algorithm", "itself", "sufficiently", "fast", "interactive", "editing", "we", "prototype", "system", "have", "be", "make", "test", "close", "collaboration", "professional", "animator", "we", "workplace", "since", "very", "early", "stage", "development", "initially", "we", "give", "20-minute", "tutorial", "animator", "since", "we", "system", "implement", "maya", "plugin", "be", "able", "try", "out", "own", "model", "immediately", "reaction", "have", "be", "positive", "do", "seem", "find", "system", "capable", "produce", "desire", "result", "easily", "quickly", "most", "animation", "video", "be", "design", "animator", "so", "clearly", "display", "capability", "propose", "technique", "typically", "animation", "those", "show", "video", "take", "few", "hour", "complete", "which", "drastic", "improvement", "over", "prevus", "ous", "technique", "available", "animator", "also", "claim", "conventional", "trick", "texture", "animation", "modification", "character?s", "geometry", "would", "make", "difficult", "maintain", "consistency", "between", "different", "shot", "same", "character", "therefore", "conventional", "technique", "kind", "edit", "would", "simply", "infeasible", "production", "schedule", "currently", "we", "add", "system", "actual", "production", "pipeline", "so", "soon", "ready", "use", "forthcoming", "project", "even", "limit", "discussion", "cartoon", "shading", "show", "paper", "we", "still", "feel", "considerable", "application", "we", "algorithm", "only", "feature", "film", "also", "television", "animation", "even", "illustrative", "visualization", "contrast", "direct", "application", "we", "method", "interactive", "video", "game", "may", "difficult", "however", "even", "context", "could", "useful", "non-interactive", "cut-scene", "since", "playback", "use", "we", "technique", "lightweight", "real-time", "any", "modern", "GPU", "we", "have", "present", "few", "simple", "algorithm", "step", "toward", "new", "methodology", "truly", "directable", "stylistic", "depiction", "light", "shade", "3d", "animation", "we", "prototype", "system", "allow", "user", "locally", "interactively", "edit", "light", "shade", "painting", "directly", "3d", "object", "moreover", "local", "edit", "integrate", "seamlessly", "conventional", "global", "lighting", "animate", "smoothly", "regardless", "conventional", "lighting", "setup", "use", "animation", "example", "video", "illustrate", "advantage", "over", "previous", "method", "algorithm", "however", "exploratory", "several", "thing", "leave", "accomplish", "we", "approach", "rbf-based", "algorithm", "use", "obtain", "rough", "boundary", "paint", "shaded", "area", "addition", "we", "make", "assumption", "vertex", "define", "object", "add", "remove", "during", "animation", "we", "do", "handle", "object", "change", "topology", "during", "animation", "when", "apply", "method", "cartoon", "animation", "highlight", "very", "sharp", "edge", "sometimes", "desire", "provide", "boolean", "operation", "-lsb-", "Anjyo", "et", "al.", "2006", "-rsb-", "may", "use", "here", "we", "method", "allow", "we", "add", "locally", "controllable", "light", "shade", "same", "time", "conventional", "lighting", "control", "can", "replace", "we", "approach", "example", "very", "simple", "case", "suppose", "we", "want", "move", "small", "round", "highlight", "ball", "from", "one", "location", "another", "could", "easily", "accomplish", "move", "light", "source", "however", "approach", "present", "paper", "highlight", "would", "move", "fade", "off", "original", "point", "fade", "destination", "clearly", "demonstrate", "difference", "between", "we", "approach", "conventional", "one", "we", "believe", "approach", "complementary", "we", "approach", "local", "which", "mean", "only", "enable", "local", "editing", "also", "movement", "light", "shade", "local", "we", "currently", "investigate", "how", "make", "cast", "shadow", "also", "locally", "controllable", "we", "believe", "modify", "version", "approach", "describe", "here", "have", "promise", "achieve", "paper", "we", "have", "focus", "area", "3d", "stylized", "animation", "however", "important", "practical", "area", "where", "clear", "need", "new", "technique", "help", "bridge", "gap", "between", "artistic", "direction", "animator?s", "heavy", "load", "we", "hope", "we", "approach", "indicate", "promising", "direction", "serve", "practical", "need", "many", "thanks", "also", "Shinji", "Morohashi", "Yosuke", "Katsura", "Ayumi", "Kimura", "dedicated", "help", "make", "animation", "example", "work", "support", "part", "Japan", "Science", "Technology", "Agency", "CREST", "project", "first", "author", "fund", "part", "grant", "from", "japanese", "Information-Technology", "Promotion", "Agency" ],
  "content" : "Most of these techniques are designed to elucidate particular attributes inherent to the object. The left image in Figure 1 shows such an example, where the dark area partly covers the right eye of the character. Changing the geometry of the model or animating textures or light maps might be helpful for achieving this, but these are time-consuming and impractical on a production schedule. A keyframebased technique is appropriate, since it allows fine-tuning of stylistic animation in a traditional, but convenient and familiar way for animators. Additionally, real-time preview of the animation is also indispensable. These basic requirements for making stylized animation have led us to consider na?ve key-framing as a first approach towards a new methodology. We thus obtain real-time preview of the stylistic animation. The right images in Figure 1 are from an animation created using our techniques, while the leftmost shows the scene before modifications. The rest of the paper is organized as follows. Section 5 demonstrates animation examples and discusses our results. For stylized rendering of 3D objects, Lake et al.[2000] proposed several fundamental real-time rendering techniques, including a traditional cartoon shader. The WYSIWYG system by Kalnins et al.[2002] allows direct drawing of strokes onto 3D objects, while learning strokes by example. The cartoon highlight shader in [Anjyo et al. 2006] allows a user to directly click-and-drag the highlights on a surface to design and animate them. Previous work on user-specified indirect lighting design for photo- terface: The resulting new area B 0 ? C 0 can be represented functionally by introducing an offset function that modifies the standard L ? N lighting term. The bottom graph shows a 1-d intensity distribution along the green line. realistic scene rendering is to some extent related to our approach as well. There exist several good approaches ([Schoeneman et al. 1993; Kawai et al. 1993; Pellacini et al. 2002], for instance). The geometry-dependent lighting method by [Lee et al. 2006] may also be a useful indirect light design tool for visualizing scientific data. Our approach is inspired by all of the above methods. In addition, we demonstrate that continuous tone detail can also be painted and animated as an extension of our approach. Starting from a 3D scene created using conventional lighting and key-framing techniques, we consider how to locally add light and shade onto surfaces. Our implementation is capable of dealing with deforming geometry and multiple directional and/or point light sources; however, without loss of generality, we explain our idea below in the context of  a single light source. The extension to deformations and multiple light sources is straightforward. More precisely, using set notation we define the light area B 0 on a surface S, for a given threshold d 0 to be: where L(p) and N(p) are the unit vectors representing the light direction and surface normal at a point p on S, respectively. The boundary between light and dark areas is obtained by replacing inequality (? d 0 ) with equality (= d 0 ) above. We will refer to the dot product L(p) ? N(p) in (1) as the intensity distribution. Given these definitions, let us consider how to enlarge a portion of the light area, for example on the character?s face in Figure 2 , where the light area B 0 is flesh colored. Let the area C 0 with boundary ? C 0 (drawn in red in Figure 2 ) be an area painted with our brush-type interface (see the next section for specifics). The area C 0 ? B 0 is the area that the user wishes to add to the original area B 0 . The overall strategy is as follows. We first construct an offset function o 1 (p) defined globally on S. This prescribes the new light area by replacing the original intensity distribution in (1) with L(p) ? N(p) + o 1 (p)(see Figure 2 ). After making a modification at one keyframe, we can create a different offset function to define the light area at a second keyframe. By smoothly interpolating the offset functions between keyframes, we can achieve smooth animation of the light areas between frames as well. The procedure can be repeated for every pair of adjacent keyframes, resulting in an animated light area on S using just local edits with a paint-brush. Given the original light area B 0 from (1) and the painted area C 0 , as shown in Figure 2 . The offset function o 1 (p) for B 0 ? C 0 should satisfy where o 1 (p) is generated when the user finishes drawing C 0 . To fulfill condition (2), it is clear that the offset function should take values that are equal to d 0 ? L(p) ? N(p)(? 0) on the new boundary ? C 0 ? B 0 . In our current implementation, the distance between ? D 0 and ? C 0 is controlled by a slider in the user interface. The size of this region gives the user a way to limit the scope of modification (also see the detail in section 5). Therefore o 1 (p) should minimally satisfy the following conditions: o 1 (p) = 0 d 0 ? L(p) ? N(p) p p ? ? (S ? C ? 0 ? D 0 B ) 0 ? (? B 0 ? (D 0 ? C 0 )) (3) If we choose for o 1 a continuous function satisfying the above conditions, then the resultant area B 1 will have a continuous boundary. The user?s kth stroke provides C k and D k . From this new input, the resulting light area can be defined recursively as: where we assume that o k+1 (p) is a continuous function satisfying the constraints: o k+1 (p) = d o 0 k (p) ? L(p) ? N(p) p p ? ? ? (S C ? k ? D k B ) k ? (? B k ? (D k ? C k )) (5) D k includes C k and serves the same role for C k as D 0 does for C 0 . Again we note that, outside of D k , no modifications will be made to the lighting (i.e., o k+1 (p) = o k (p)). In the D k ? C k region, no modification will be visible under the current lighting conditions, but some modification may be visible when either the lights or the model are moved. Having a D k ? C k band allows for smooth transition from modified o k (p) values to the original values. Thus in practice we use: The RBF approximation B ? k is made from the shaded area obtained by the paint operation. Rigorously, the boundary of B ? k may not exactly match that of the original painted area. To allow fine adjustment, we provide two additional types of brushes: an intensity brush and a smoothing brush, which will be described in section 3.4. Lighting of the animation as a whole can then be accomplished by interpolating the offset functions o k, f . In our prototype we have used simple linear blending for this purpose, though more complicated blending functions are possible and worth exploring. Suppose that S consists of polygon meshes, as shown in Figure 3 . We will assume for simplicity that B ? k = B k . We find a set of such points {x i } ? ? C k ? B k by the following procedure. For each vertex p m inside C k , we check adjacent edges for intersection with the boundary ? C k ? B k . Note that we record stroke data per-vertex only and reconstruct the stroke linearly, thus no edge can cross the boundary more than once. Now let f ? o ? k+1 . We find a continuous f satisfying (5) for {x i } in the following form [Duchon 1977; Wahba 1990; Turk and O?Brien 1999]: We employ ? (x) = x as the basis function after experimenting with various options. This corresponds to the solution of a generalized thin-plate spline problem on R 3 [Duchon 1977; Wahba 1990], and the curvature minimizing properties of this basis function seem to be well suited to this task. The previous sections described how we enable users to add and edit light areas using a paint-brush metaphor. In a similar way we can add and edit dark areas. In that case the only difference is the selection of boundary points used in (5). Instead of using ? C k ? B k , we use the opposite half of ? C k , that is, ? C k ? B k . The user simply switches the editing mode from light to dark. In both cases, the paint brush is used for roughly specifying the shading boundary. We call this type of brush a boundary brush. The boundary brush works well to get a desired shape, but the intensity distribution may not change as smoothly as desired. This can be due to the radial basis function we select or due to too many conflicting constraints. For example, we have seen in our experiments that even a smooth radial basis function may result in a rapidly changing intensity distribution in the area where the distribution contours are very close to one another. This may cause the resulting keyframe animation to look unnatural. For this case, we have created a smoothing brush. By painting on the surface with the smoothing brush, the offset values are filtered, while preserving the original value of L(p) ? N(p). In our implementation, the offset values stored per vertex are updated using a simple weighted average of values at connected vertices for each stroke operation. In this way we achieve shading effects that fade in and out more gradually and have smoother boundaries (see Figure 4 ). In some cases it is useful to be able simply to add or remove an isolated light or dark area. For these situations we provide a simpler alternative to the boundary brush, which we call the intensity brush. This brush simply adds to or subtracts from the offset function o k . The magnitude is the amount to add to o k along the centerline of the stroke. We fade the added intensity smoothly to zero at the edges of the stroke using a ?smooth-step? cubic polynomial falloff. Figure 4 shows a simple example of how to use these brushes. In Figure 4(a) , an initial intensity distribution on the character is displayed using green contour lines. The boundary brush is then applied in (b). After getting the offset function in (6), we have the new intensity distribution as shown in (c). In order to get more variations of stylized light and shade, we add a few simple, but useful, extensions of the main algorithms above. Specular Highlight: We can deal with stylized highlights in the same framework as the shaded area. In our system we simply need to replace the Lambertian term (the dot product, L ? N) in (6) with H ? N from Blinn?s specular highlight model [Blinn 1977], where H is the normalized half-way vector between the light and the eye. The user can easily edit the highlights by the brushes in the same manner as the shaded area. Our prototype system is currently implemented as a Maya plug in, using Maya?s hardware shader functionality that allows shader code to be written using standard OpenGL and GLSL. With our prototype system, the user can freely add localized light and shade to objects, and see the results, together with the conventional lighting, in real-time. As for our paint-brush metaphor, we need to find all of the vertices inside the brush stroke region and calculate their distances from the stroke centerline. This information is used to determine the locations of the points on the boundary in Figure 3 , as well as to implement the smooth falloff of the intensity brush. We accomplish this using a depth first search from seed points along the brush centerline. From each seed point, we find all the vertices with distance less than the brush radius, and set their distance values using the minimum of their current value and their distance from the current seed point. This data is needed only for the duration of a single stroke operation and can be discarded immediately afterward. We have applied our prototype system to making various stylistic animations. Our system currently runs at interactive rates on a 2.16GHz Intel P4 Core Duo CPU with an NVIDIA GeForce QuadroFX 350M GPU. In editing and previewing the animations, the frame rate ranges from 6 to 20 fps for all the examples in this paper and in the accompanying videos. In making facial animation, controlling light and shade on the face is crucial. Figure 1 and the first half of the accompanying video 1 illustrate how effectively and efficiently our algorithms work for this important case. As shown in the video, even for making a simple facial animation, a 3D head model often creates many unnecessary dark areas, and it is very hard to remove them selectively using conventional lighting control. On the other hand, our approach can eliminate them easily and interactively. Moreover it allows the user to successfully add a variety of effects, each of which dramatically changes the character?s impression. Figure 5 and the latter half of the video 1 demonstrate a typical case where an animator uses our system to make the animation less realistic, but more expressive. Comparing with the animation under conventional lighting (left of Figure 5 ), we note several effects that have been added to the animation. Most obvious is the smoothing and simplification of the moving highlight on the protruding forehead. But also for example, the animator has added a light area to accentuate the jawline; a bright, firm line above the left eye; and delayed emergence of the face into the light, as shown in the right of Figure 5 . Some of these effects might be achieved by conventional lighting techniques. However, it is almost impossible to add all of them into the same shot without resorting to frame-by-frame modifications. Figure 6 and the first animation example in video 2 show the use of our techniques on an animated character with a highly deforming cape using a moving point light and a fixed directional light. This type of situation can result in light and shade areas that are distracting because they change too rapidly. The animation in the video demonstrates that our techniques are effective in eliminating such unnecessary shading and in simplifying light and shade to make it suitable for cartoon animation. The second animation in video 2 demonstrates local controllability of continuous tone with our intensity brush described in section 3.5. As shown in the movie, even when adjusting the continuous tone on this object, our approach allows local tone control, adding a backlight effect around the character?s shoulder (see Figure 7 ). We were able to create this animation without modifying the initial lighting setup. However, in cases where the viewpoint and/or lights are moving more dynamically, it may be more difficult to achieve the same effect using our technique. In making these animations, we used either of boundary brush or the intensity brush, depending on the type of modification desired. The boundary brush is appropriate when the user wants to specify exactly where the new boundary should lie. In the examples we determined the size of the paint brushes by experimentation. For example, we chose the width of the boundary brush so that one stroke of the tem being solved for, while RBF(solve) is the time taken to solve the linear system. RBF(dist) is the time taken to compute the RBF distance function for calculating o k (p). Transfer is the time taken to transfer vertex data to and from Maya in our plug in. brush includes at least two adjacent vertices of the surface mesh. Similarly, the distance between ? C 0 and ? D 0 in Figure 2 , it is also set to include at least two adjacent vertices of the mesh, which can be accomplished using a slider. The small value of the offset function specified by the intensity brush in section 3.4 is also set empirically. Given the interactivity of our system, results of a particular parameter setting can be seen immediately, so we have not found it burdensome to search for these values via trial and error. Table 1 shows the performance of our current implementation. The computation cost, however, depends on the number of vertices contained in D k . Since we do not paint very large regions D k in practice, this cost seems not to be a serious bottleneck in our system. The most significant part was the basic cost of transferring vertex data between Maya and our plug in. The performance data in Table 1 also makes it clear that the algorithm itself is sufficiently fast for interactive editing. Our prototype system has been made and tested in close collaboration with professional animators in our workplace since the very early stages of development. Initially, we gave a 20-minute tutorial to the animators. Since our system is implemented as a Maya plugin, they were able to try it out on their own models immediately. The reaction has been positive they do seem to find the system capable of producing the desired results easily and quickly. Most of the animations in the videos were designed with the animators so as to clearly display the capabilities of the proposed technique. Typically animations such as those shown in the videos take a few hours to complete, which is a drastic improvement over the previ- ous techniques available to the animators. They also claimed that the conventional tricks such as texture animation or modifications to the character?s geometry would make it difficult to maintain consistency between different shots with the same character. Therefore, with such conventional techniques, these kind of edits would simply be infeasible on a production schedule. Currently we are adding this system to an actual production pipeline, so it will soon be ready for use in forthcoming projects. Even limiting the discussion to cartoon shading as shown in this paper, we still feel there are considerable applications of our algorithms not only in feature films, but also for television animation and even illustrative visualization. In contrast, the direct application of our method to interactive video games may be difficult; however, even in that context, it could be useful for non-interactive cut-scenes, since playback using our technique is lightweight and real-time on any modern GPU. We have presented a few simple algorithms as steps toward a new methodology for truly directable stylistic depiction of light and shade in 3D animation. Our prototype system allows the user to locally and interactively edit light and shade by painting directly on 3D objects. Moreover the local edits integrate seamlessly with the conventional global lighting and animate smoothly regardless of the conventional lighting setup used. The animation examples and the videos illustrate these advantages over previous methods. These algorithms, however, are exploratory. There are several things left to accomplish. In our approach, the RBF-based algorithm is used to obtain the rough boundary of the painted shaded area. In addition, we make the assumption that the vertices defining the object will not be added or removed during animation. We do not handle objects that change topology during an animation. When applying this method to cartoon animation, highlights with very sharp edges are sometimes desired. Providing boolean operations as in [Anjyo et al. 2006] may be of use here. Our method allows us to add locally controllable light and shade, but at the same time conventional lighting control cannot be replaced by our approach. For example, as a very simple case, suppose that we want to move a small rounded highlight on a ball from one location to another. This could be easily accomplished by moving the light source. However, with the approach presented in this paper, the highlight would not move, but fade off at the original point, and fade in at the destination. This clearly demonstrates a difference between our approach and the conventional one. We believe that these approaches are complementary. Our approach is local, which means not only that it enables local editing, but also that the movement of light and shade is local. We are currently investigating how to make cast shadows also locally controllable. We believe that a modified version of the approach described here has promise for achieving this. In this paper we have focused on the area of 3D stylized animation. However, this is an important practical area where there is a clear need for new techniques to help bridge the gap between artistic direction and the animator?s heavy load. We hope our approach indicates a promising direction to serving such a practical need. Many thanks also to Shinji Morohashi, Yosuke Katsura, and Ayumi Kimura for their dedicated help in making the animation examples. This work was supported in part by the Japan Science and Technology Agency, CREST project, and the first author was funded in part by grants from the Japanese Information-Technology Promotion Agency.",
  "resources" : [ ]
}