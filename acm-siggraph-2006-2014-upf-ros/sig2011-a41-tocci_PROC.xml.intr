{
  "uri" : "sig2011-a41-tocci_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2011/a41-tocci_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "A Versatile HDR Video Production System",
    "published" : "2011",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Michael D.-Tocci",
      "name" : "Michael D.",
      "surname" : "Tocci"
    }, {
      "uri" : "http://drinventor/Chris-Kiser",
      "name" : "Chris",
      "surname" : "Kiser"
    }, {
      "uri" : "http://drinventor/Nora-Tocci",
      "name" : "Nora",
      "surname" : "Tocci"
    }, {
      "uri" : "http://drinventor/Pradeep-Sen",
      "name" : "Pradeep",
      "surname" : "Sen"
    } ]
  },
  "bagOfWords" : [ "extension", "dynamic", "range", "digital", "image", "have", "be", "subject", "significant", "research", "both", "academia", "industry", "despite", "all", "previous", "work", "however", "currently", "readilyimplemented", "solution", "capture", "high-quality", "hdr", "video", "fast-moving", "scene", "paper", "we", "describe", "end-to-end", "system", "capture", "HDR", "video", "high", "pixel", "fidelity", "use", "lightefficient", "optical", "architecture", "fit", "single", "hand-held", "unit", "common", "method", "merge", "multiple", "ldr", "image", "single", "composite", "HDR", "image", "one", "Debevec", "Malik", "-lsb-", "1997", "-rsb-", "which", "first", "solve", "camera", "response", "curve", "translate", "pixel", "value", "log", "scene", "irradiance", "blend", "irradiance", "from", "image", "together", "during", "merging", "process", "algorithm", "combine", "value", "from", "every", "exposure", "weighting", "each", "contribution", "triangle", "filter", "fall", "off", "pixel", "value", "approach", "cutoff", "saturation", "peak", "middle", "idea", "give", "more", "weight", "pixel", "work", "range", "camera", "less", "one", "near", "extrema", "camera?s", "operate", "range", "we", "describe", "Sec", "however", "approach", "can", "suffer", "from", "undesirable", "artifact", "when", "apply", "widely-separated", "ldr", "image", "due", "blending", "between", "exposure", "follow", "work", "Debevec", "Malik", "other", "researcher", "have", "propose", "different", "weighting", "function", "merge", "differentlyexpose", "ldr", "image", "reduce", "noise", "improve", "result", "-lrb-", "e.g.", "-lsb-", "Mitsunaga", "Nayar", "1999", "Robertson", "et", "al.", "2003", "Kao", "2008", "Granados", "et", "al.", "2010", "-rsb-", "-rrb-", "approach", "typically", "work", "each", "pixel", "final", "HDR", "image", "independently", "use", "only", "information", "contain", "within", "respective", "pixel", "each", "ldr", "image", "unlike", "approach", "we", "propose", "use", "additional", "information", "available", "neighborhood", "pixel", "reduce", "noise", "we", "final", "irradiance", "estimate", "finally", "other", "have", "present", "algorithm", "fuse", "ldr", "image", "together", "without", "explicitly", "create", "hdr", "image", "first", "-lrb-", "e.g.", "-lsb-", "Agarwala", "et", "al.", "2004", "Mertens", "et", "al.", "2008", "-rsb-", "-rrb-", "method", "do", "produce", "true", "radiometrically-correct", "hdr", "image", "so", "result", "can", "incorporate", "hdr", "production", "workflow", "2.1", "HDR", "Acquisition", "system", "process", "capture", "hdr", "image", "have", "be", "focus", "work", "dozen", "researcher", "hundred", "artist", "photographer", "result", "many", "publish", "papers", "patent", "describe", "method", "system", "capture", "hdr", "image", "because", "space", "limit", "we", "focus", "only", "principal", "technology", "currently", "available", "HDR", "video", "refer", "interested", "reader", "text", "subject", "-lrb-", "e.g.", "-lsb-", "Myszkowski", "et", "al.", "2008", "-rsb-", "-rrb-", "more", "information", "simplest", "approach", "HDR", "imaging", "involve", "take", "series", "image", "different", "exposure", "time", "-lrb-", "e.g.", "-lsb-", "Mann", "Picard", "1995", "Debevec", "Malik", "1997", "-rsb-", "-rrb-", "although", "method", "work", "well", "static", "scene", "well-suited", "video", "because", "different", "moment", "time", "exposure", "length", "each", "photograph", "which", "result", "vary", "amount", "motion", "blur", "other", "timerelated", "effect", "nevertheless", "researcher", "have", "extend", "approach", "video", "capture", "frame", "alternate", "bright", "dark", "exposure", "-lsb-", "Ginosar", "et", "al.", "1992", "Kang", "et", "al.", "2003", "-rsb-", "use", "roll", "shutter", "vary", "exposure", "-lsb-", "Unger", "Gustavson", "2007", "Krymski", "2008", "-rsb-", "approach", "require", "image", "manipulation", "register", "image", "which", "also", "introduce", "artifact", "0.33", "0.33", "ME", "prism", "sensor", "0.33", "0.0272", "0.0016", "LE", "sensor", "traditional", "beamsplitting", "hdr", "optical", "system", "here", "beamsplitt", "prism", "break", "up", "light", "three", "part", "one", "each", "sensor", "fit", "different", "filter", "design", "use", "absorptive", "filter", "like", "one", "make", "inefficient", "use", "light", "other", "researcher", "have", "propose", "new", "camera", "sensor", "HDR", "imaging", "some", "approach", "place", "array", "neutral-density", "filter", "over", "individual", "pixel", "sensor", "vary", "amount", "absorption", "-lrb-", "e.g.", "-lsb-", "Nayar", "Mitsunaga", "2000", "-rsb-", "-rrb-", "which", "can", "require", "complex", "demosaicing", "algorithm", "approach", "also", "wasteful", "light", "enter", "camera", "sensor", "have", "filter", "pattern", "four", "differently-exposed", "pixel", "-lrb-", "one", "four", "fully", "expose", "-rrb-", "only", "pixel", "would", "receive", "full", "exposure", "level", "from", "scene", "other", "propose", "HDR", "sensor", "have", "unique", "response", "light", "either", "adapt", "sensitivity", "-lrb-", "e.g.", "-lsb-", "Nayar", "Branzoi", "2003", "-rsb-", "-rrb-", "measure", "pixel", "saturation", "time", "-lrb-", "e.g.", "-lsb-", "Brajovic", "Kanade", "1996", "-rsb-", "-rrb-", "have", "logarithmic", "response", "mimic", "human", "eye", "-lrb-", "e.g.", "-lsb-", "Seger", "et", "al.", "1999", "-rsb-", "-rrb-", "primary", "problem", "all", "approach", "require", "production", "new", "type", "camera", "sensor", "although", "commercial-scale", "production", "sensor", "may", "someday", "realize", "currently", "expensive", "manufacture", "render", "method", "unusable", "most", "researcher", "today", "we", "propose", "architecture", "other", "hand", "perform", "HDR", "imaging", "independent", "sensor", "use", "which", "make", "realizable", "use", "today?s", "technology", "allow", "we", "adopt", "better", "sensor", "technology", "-lrb-", "low-light", "level", "response", "faster", "framerate", "wider", "spectral", "response", "etc.", "-rrb-", "develop", "future", "approach", "similar", "we", "own", "light", "camera", "split", "pyramid-shaped", "mirror", "refract", "prism", "redirect", "toward", "set", "sensor", "fit", "absorptive", "filter", "produce", "image", "different", "exposure", "-lrb-", "e.g.", "Harvey", "-lsb-", "1998", "-rsb-", "Aggarwal", "Ahuja", "-lsb-", "2001", "2004", "-rsb-", "Wang", "et", "al.", "-lsb-", "2005", "-rsb-", "-rrb-", "design", "previous", "system", "all", "suffer", "from", "parallax", "error", "due", "fact", "image-forming", "beam", "split", "spatially-distinct", "subsection", "each", "individual", "sensor", "look", "through", "camera", "lens", "from", "slightly", "different", "angle", "show", "recent", "work", "handheld", "plenoptic", "camera", "-lrb-", "e.g.", "-lsb-", "Ng", "et", "al.", "2005", "-rsb-", "-rrb-", "provide", "each", "sensor", "slightly", "different", "information", "which", "significantly", "affect", "imaging", "scene", "close", "camera", "previous", "spatial-beamsplitting", "method", "also", "wasteful", "light", "absorptive", "filter", "use", "achieve", "dynamic", "range", "allow", "only", "fraction", "incoming", "light", "sensor", "Watts", "radiative", "power", "enter", "aperture", "camera", "three-way", "system", "show", "fig.", "-lrb-", "configure", "same", "dynamic", "range", "ours", "-rrb-", "allow", "only", "0.3622", "Watts", "sensor", "waste", "almost", "available", "light", "Aggarwal", "Ahuja", "-lsb-", "2004", "-rsb-", "point", "out", "possible", "vary", "amount", "light", "each", "sensor", "move", "beamsplitt", "prism", "away", "from", "optical", "axis", "instead", "use", "filter", "effectively", "change", "size", "shape", "aperture", "stop", "each", "sensor", "exacerbate", "problem", "each", "sensor", "get", "different", "view", "scene", "furthermore", "shiftedoptical-axis", "spatial-beamsplitting", "method", "easily", "integrate", "standard", "camera", "lens", "require", "either", "custom", "lens", "manufacture", "lens", "modification", "work", "correctly", "another", "option", "split", "incoming", "light", "beamsplitter", "prior", "lens", "example", "McGuire", "et", "al.", "-lsb-", "2007", "-rsb-", "present", "design", "tool", "create", "efficient", "beamsplitt", "tree", "separate", "lens", "each", "sensor", "show", "example", "HDR", "imaging", "same", "concept", "demonstrate", "soviet", "Montage", "Productions", "-lsb-", "Cole", "Safai", "2010", "-rsb-", "which", "can", "implement", "3d", "film", "rig", "intraocular", "distance", "zero", "use", "beamsplitter", "provide", "different", "light", "transmission", "two", "identical", "lens", "one", "each", "sensor", "two", "lens", "must", "perfectly", "match", "however", "zoom", "focus", "iris-tracking", "can", "difficult", "maintain", "between", "they", "addition", "put", "beamsplitter", "front", "camera", "lens", "place", "limit", "field", "view", "finally", "unclear", "how", "system", "could", "develop", "single", "hand-held", "unit", "we", "system", "place", "beamsplitter", "behind", "single", "camera", "lens", "so", "do", "suffer", "from", "limitation", "finally", "early", "prototype", "hdr", "system", "industry", "eventually", "intend", "commercial", "use", "spheronvr", "hdrv", "camera", "-lsb-", "spheron", "vr", "2011", "-rsb-", "however", "method", "achieve", "HDR", "capture", "have", "be", "publish", "while", "all", "system", "we", "mention", "section", "capable", "produce", "hdr", "video", "date", "method", "produce", "high-quality", "hdr", "video", "have", "be", "demonstrate", "robust", "yet", "simple", "enough", "readily", "introduce", "wide", "commercial", "audience", "implement", "modern", "optics", "laboratory", "goal", "work", "present", "system", "common", "method", "merge", "multiple", "ldr", "image", "single", "composite", "HDR", "image", "one", "Debevec", "Malik", "-lsb-", "1997", "-rsb-", "which", "first", "solve", "camera", "response", "curve", "translate", "pixel", "value", "log", "scene", "irradiance", "blend", "irradiance", "from", "image", "together", "during", "merging", "process", "algorithm", "combine", "value", "from", "every", "exposure", "weighting", "each", "contribution", "triangle", "filter", "fall", "off", "pixel", "value", "approach", "cutoff", "saturation", "peak", "middle", "idea", "give", "more", "weight", "pixel", "work", "range", "camera", "less", "one", "near", "extrema", "camera?s", "operate", "range", "we", "describe", "Sec", "however", "approach", "can", "suffer", "from", "undesirable", "artifact", "when", "apply", "widely-separated", "ldr", "image", "due", "blending", "between", "exposure", "follow", "work", "Debevec", "Malik", "other", "researcher", "have", "propose", "different", "weighting", "function", "merge", "differentlyexpose", "ldr", "image", "reduce", "noise", "improve", "result", "-lrb-", "e.g.", "-lsb-", "Mitsunaga", "Nayar", "1999", "Robertson", "et", "al.", "2003", "Kao", "2008", "Granados", "et", "al.", "2010", "-rsb-", "-rrb-", "approach", "typically", "work", "each", "pixel", "final", "HDR", "image", "independently", "use", "only", "information", "contain", "within", "respective", "pixel", "each", "ldr", "image", "unlike", "approach", "we", "propose", "use", "additional", "information", "available", "neighborhood", "pixel", "reduce", "noise", "we", "final", "irradiance", "estimate", "finally", "other", "have", "present", "algorithm", "fuse", "ldr", "image", "together", "without", "explicitly", "create", "hdr", "image", "first", "-lrb-", "e.g.", "-lsb-", "Agarwala", "et", "al.", "2004", "Mertens", "et", "al.", "2008", "-rsb-", "-rrb-", "method", "do", "produce", "true", "radiometrically-correct", "hdr", "image", "so", "result", "can", "incorporate", "hdr", "production", "workflow", "2.1", "HDR", "Acquisition", "system", "process", "capture", "hdr", "image", "have", "be", "focus", "work", "dozen", "researcher", "hundred", "artist", "photographer", "result", "many", "publish", "papers", "patent", "describe", "method", "system", "capture", "hdr", "image", "because", "space", "limit", "we", "focus", "only", "principal", "technology", "currently", "available", "HDR", "video", "refer", "interested", "reader", "text", "subject", "-lrb-", "e.g.", "-lsb-", "Myszkowski", "et", "al.", "2008", "-rsb-", "-rrb-", "more", "information", "simplest", "approach", "HDR", "imaging", "involve", "take", "series", "image", "different", "exposure", "time", "-lrb-", "e.g.", "-lsb-", "Mann", "Picard", "1995", "Debevec", "Malik", "1997", "-rsb-", "-rrb-", "although", "method", "work", "well", "static", "scene", "well-suited", "video", "because", "different", "moment", "time", "exposure", "length", "each", "photograph", "which", "result", "vary", "amount", "motion", "blur", "other", "timerelated", "effect", "nevertheless", "researcher", "have", "extend", "approach", "video", "capture", "frame", "alternate", "bright", "dark", "exposure", "-lsb-", "Ginosar", "et", "al.", "1992", "Kang", "et", "al.", "2003", "-rsb-", "use", "roll", "shutter", "vary", "exposure", "-lsb-", "Unger", "Gustavson", "2007", "Krymski", "2008", "-rsb-", "approach", "require", "image", "manipulation", "register", "image", "which", "also", "introduce", "artifact", "0.33", "0.33", "ME", "prism", "sensor", "0.33", "0.0272", "0.0016", "LE", "sensor", "traditional", "beamsplitting", "hdr", "optical", "system", "here", "beamsplitt", "prism", "break", "up", "light", "three", "part", "one", "each", "sensor", "fit", "different", "filter", "design", "use", "absorptive", "filter", "like", "one", "make", "inefficient", "use", "light", "other", "researcher", "have", "propose", "new", "camera", "sensor", "HDR", "imaging", "some", "approach", "place", "array", "neutral-density", "filter", "over", "individual", "pixel", "sensor", "vary", "amount", "absorption", "-lrb-", "e.g.", "-lsb-", "Nayar", "Mitsunaga", "2000", "-rsb-", "-rrb-", "which", "can", "require", "complex", "demosaicing", "algorithm", "approach", "also", "wasteful", "light", "enter", "camera", "sensor", "have", "filter", "pattern", "four", "differently-exposed", "pixel", "-lrb-", "one", "four", "fully", "expose", "-rrb-", "only", "pixel", "would", "receive", "full", "exposure", "level", "from", "scene", "other", "propose", "HDR", "sensor", "have", "unique", "response", "light", "either", "adapt", "sensitivity", "-lrb-", "e.g.", "-lsb-", "Nayar", "Branzoi", "2003", "-rsb-", "-rrb-", "measure", "pixel", "saturation", "time", "-lrb-", "e.g.", "-lsb-", "Brajovic", "Kanade", "1996", "-rsb-", "-rrb-", "have", "logarithmic", "response", "mimic", "human", "eye", "-lrb-", "e.g.", "-lsb-", "Seger", "et", "al.", "1999", "-rsb-", "-rrb-", "primary", "problem", "all", "approach", "require", "production", "new", "type", "camera", "sensor", "although", "commercial-scale", "production", "sensor", "may", "someday", "realize", "currently", "expensive", "manufacture", "render", "method", "unusable", "most", "researcher", "today", "we", "propose", "architecture", "other", "hand", "perform", "HDR", "imaging", "independent", "sensor", "use", "which", "make", "realizable", "use", "today?s", "technology", "allow", "we", "adopt", "better", "sensor", "technology", "-lrb-", "low-light", "level", "response", "faster", "framerate", "wider", "spectral", "response", "etc.", "-rrb-", "develop", "future", "approach", "similar", "we", "own", "light", "camera", "split", "pyramid-shaped", "mirror", "refract", "prism", "redirect", "toward", "set", "sensor", "fit", "absorptive", "filter", "produce", "image", "different", "exposure", "-lrb-", "e.g.", "Harvey", "-lsb-", "1998", "-rsb-", "Aggarwal", "Ahuja", "-lsb-", "2001", "2004", "-rsb-", "Wang", "et", "al.", "-lsb-", "2005", "-rsb-", "-rrb-", "design", "previous", "system", "all", "suffer", "from", "parallax", "error", "due", "fact", "image-forming", "beam", "split", "spatially-distinct", "subsection", "each", "individual", "sensor", "look", "through", "camera", "lens", "from", "slightly", "different", "angle", "show", "recent", "work", "handheld", "plenoptic", "camera", "-lrb-", "e.g.", "-lsb-", "Ng", "et", "al.", "2005", "-rsb-", "-rrb-", "provide", "each", "sensor", "slightly", "different", "information", "which", "significantly", "affect", "imaging", "scene", "close", "camera", "previous", "spatial-beamsplitting", "method", "also", "wasteful", "light", "absorptive", "filter", "use", "achieve", "dynamic", "range", "allow", "only", "fraction", "incoming", "light", "sensor", "Watts", "radiative", "power", "enter", "aperture", "camera", "three-way", "system", "show", "fig.", "-lrb-", "configure", "same", "dynamic", "range", "ours", "-rrb-", "allow", "only", "0.3622", "Watts", "sensor", "waste", "almost", "available", "light", "Aggarwal", "Ahuja", "-lsb-", "2004", "-rsb-", "point", "out", "possible", "vary", "amount", "light", "each", "sensor", "move", "beamsplitt", "prism", "away", "from", "optical", "axis", "instead", "use", "filter", "effectively", "change", "size", "shape", "aperture", "stop", "each", "sensor", "exacerbate", "problem", "each", "sensor", "get", "different", "view", "scene", "furthermore", "shiftedoptical-axis", "spatial-beamsplitting", "method", "easily", "integrate", "standard", "camera", "lens", "require", "either", "custom", "lens", "manufacture", "lens", "modification", "work", "correctly", "another", "option", "split", "incoming", "light", "beamsplitter", "prior", "lens", "example", "McGuire", "et", "al.", "-lsb-", "2007", "-rsb-", "present", "design", "tool", "create", "efficient", "beamsplitt", "tree", "separate", "lens", "each", "sensor", "show", "example", "HDR", "imaging", "same", "concept", "demonstrate", "soviet", "Montage", "Productions", "-lsb-", "Cole", "Safai", "2010", "-rsb-", "which", "can", "implement", "3d", "film", "rig", "intraocular", "distance", "zero", "use", "beamsplitter", "provide", "different", "light", "transmission", "two", "identical", "lens", "one", "each", "sensor", "two", "lens", "must", "perfectly", "match", "however", "zoom", "focus", "iris-tracking", "can", "difficult", "maintain", "between", "they", "addition", "put", "beamsplitter", "front", "camera", "lens", "place", "limit", "field", "view", "finally", "unclear", "how", "system", "could", "develop", "single", "hand-held", "unit", "we", "system", "place", "beamsplitter", "behind", "single", "camera", "lens", "so", "do", "suffer", "from", "limitation", "finally", "early", "prototype", "hdr", "system", "industry", "eventually", "intend", "commercial", "use", "spheronvr", "hdrv", "camera", "-lsb-", "spheron", "vr", "2011", "-rsb-", "however", "method", "achieve", "HDR", "capture", "have", "be", "publish", "while", "all", "system", "we", "mention", "section", "capable", "produce", "hdr", "video", "date", "method", "produce", "high-quality", "hdr", "video", "have", "be", "demonstrate", "robust", "yet", "simple", "enough", "readily", "introduce", "wide", "commercial", "audience", "implement", "modern", "optics", "laboratory", "goal", "work", "present", "system" ],
  "content" : "The extension of the dynamic range of digital images has been the subject of significant research in both academia and industry. Despite all this previous work, however, there are currently no readilyimplemented solutions for capturing high-quality HDR video of fast-moving scenes. In this paper, we describe an end-to-end system for capturing HDR video with high pixel fidelity, using a lightefficient optical architecture that fits into a single hand-held unit. A common method for merging multiple LDR images into a single composite HDR image is the one of Debevec and Malik [1997], which first solves for the camera response curve that translates pixel values to the log of scene irradiance and then blends irradiances from the images together. During the merging process, the algorithm combines values from every exposure by weighting each contribution by a triangle filter that falls off as the pixel value approaches cutoff or saturation and peaks in the middle. The idea is to give more weight to pixels in the ?working range? of the camera, and less to the ones near the extrema of the camera?s operating range. As we describe in Sec. 4, however, this approach can suffer from undesirable artifacts when applied to widely-separated LDR images due to the blending between exposures. Following the work of Debevec and Malik, other researchers have proposed different weighting functions for merging differentlyexposed LDR images to reduce noise and improve the result (e.g., [Mitsunaga and Nayar 1999; Robertson et al. 2003; Kao 2008; Granados et al. 2010]). These approaches typically work on each pixel of the final HDR image independently and use only the information contained within the respective pixel in each of the LDR images. Unlike these approaches, we propose to use additional information available in the neighborhood of a pixel to reduce the noise in our final irradiance estimate. Finally, others have presented algorithms for fusing the LDR images together without explicitly creating an HDR image first (e.g., [Agarwala et al. 2004; Mertens et al. 2008]). These methods do not produce a true, radiometrically-correct HDR image, so the results cannot be incorporated into an HDR production workflow. 2.1 HDR Acquisition systems The process of capturing HDR images has been the focus of work by dozens of researchers and hundreds of artists and photographers. As a result, there are many published papers and patents describing methods and systems for capturing HDR images. Because of space limits, we focus only on the principal technologies currently available for HDR video and refer interested readers to texts on the subject (e.g., [Myszkowski et al. 2008]) for more information. The simplest approach for HDR imaging involves taking a series of images with different exposure times (e.g., [Mann and Picard 1995; Debevec and Malik 1997]). Although this method works well for static scenes, it is not well-suited for video because of the different moments in time and exposure lengths for each photograph, which result in varying amounts of motion blur and other timerelated effects. Nevertheless, researchers have extended this approach to video, by capturing frames with alternating bright and dark exposures [Ginosar et al. 1992; Kang et al. 2003] or using a rolling shutter with varying exposures [Unger and Gustavson 2007; Krymski 2008]. These approaches require image manipulation to register the images, which also introduces artifacts. 0.33 Q Q 0.33 Q ME prism sensor 0.33 Q 0.0272 Q 0.0016 Q LE sensor A traditional beamsplitting HDR optical system. Here a beamsplitting prism breaks up the light into three parts, one for each sensor fitted with different filters. Designs that use absorptive filters like this one make inefficient use of light. Other researchers have proposed new camera sensors for HDR imaging. Some approaches place an array of neutral-density filters over the individual pixels of the sensor with varying amounts of absorption (e.g., [Nayar and Mitsunaga 2000]), which can require complex demosaicing algorithms. These approaches are also wasteful of light entering the camera. If the sensor has a filter pattern with four differently-exposed pixels (one of the four fully exposed), then only 1 4 pixels would receive the full exposure level from the scene. Other proposed HDR sensors have a unique response to light, either by adapting their sensitivity (e.g., [Nayar and Branzoi 2003]), measuring the pixel saturation time (e.g., [Brajovic and Kanade 1996]), or having a logarithmic response to mimic the human eye (e.g., [Seger et al. 1999]). The primary problem with all of these approaches is that they require the production of a new type of camera sensor. Although commercial-scale production of these sensors may someday be realized, they are currently expensive to manufacture, rendering these methods unusable by most researchers today. Our proposed architecture, on the other hand, performs HDR imaging independent of the sensor used, which makes it realizable using today?s technology and allows us to adopt better sensor technologies (with low-light level response, faster framerates, wider spectral response, etc.), as they are developed in the future. In approaches similar to our own, the light in the camera is split with a pyramid-shaped mirror or refracting prism and redirected toward a set of sensors fitted with absorptive filters to produce images with different exposures (e.g., Harvey [1998], Aggarwal and Ahuja [2001; 2004], and Wang et al. [2005]). The designs of these previous systems all suffer from parallax error, due to the fact that the image-forming beam is split into spatially-distinct subsections; each individual sensor ?looks? through the camera lens from a slightly different angle. As shown in recent work on handheld plenoptic cameras (e.g., [Ng et al. 2005]), this provides each of the sensors with slightly different information, which significantly affects the imaging of scenes close to the camera. These previous spatial-beamsplitting methods are also wasteful of light: the absorptive filters used to achieve the dynamic range allow only a fraction of the incoming light to the sensors. If Q Watts of radiative power enters the aperture of the camera, the three-way system shown in Fig. 2 (configured for the same dynamic range as ours) allows only 0.3622Q Watts to the sensors, wasting almost 2 3 of the available light. As Aggarwal and Ahuja [2004] point out, it is possible to vary the amount of light to each sensor by moving the beamsplitting prism away from the optical axis instead of using filters. This effectively changes the size and shape of the aperture stop for each sensor, exacerbating the problem of each sensor getting different views of the scene. Furthermore, these shiftedoptical-axis spatial-beamsplitting methods are not easily integrated with standard camera lenses, and require either custom lens manufacture or lens modification to work correctly. Another option is to split the incoming light with beamsplitters prior to the lens. For example, McGuire et al. [2007] present a design tool to create efficient beamsplitting trees with separate lenses for each sensor, and show examples of HDR imaging. This same concept was demonstrated by Soviet Montage Productions [Cole and Safai 2010], which can be implemented on a 3D filming rig with an intraocular distance of zero by using a beamsplitter to provide different light transmission to two identical lenses, one for each sensor. The two lenses must be perfectly matched, however, and zoom-, focus-, and iris-tracking can be difficult to maintain between them. In addition, putting the beamsplitter in front of the camera lens places a limit on the field of view. Finally, it is unclear how such as system could be developed into a single, hand-held unit. Our system places the beamsplitter behind a single camera lens, so it does not suffer from these limitations. Finally, there are early prototype HDR systems in industry eventually intended for commercial use, such as the SpheronVR HDRv camera [Spheron VR 2011 ]. However, their method for achieving HDR capture has not been published. While all the systems we mention in this section are capable of producing HDR video, to date no method for producing high-quality HDR video has been demonstrated that is robust and yet simple enough to be readily introduced to a wide commercial audience or implemented in a modern optics laboratory. The goal of this work is to present such a system. A common method for merging multiple LDR images into a single composite HDR image is the one of Debevec and Malik [1997], which first solves for the camera response curve that translates pixel values to the log of scene irradiance and then blends irradiances from the images together. During the merging process, the algorithm combines values from every exposure by weighting each contribution by a triangle filter that falls off as the pixel value approaches cutoff or saturation and peaks in the middle. The idea is to give more weight to pixels in the ?working range? of the camera, and less to the ones near the extrema of the camera?s operating range. As we describe in Sec. 4, however, this approach can suffer from undesirable artifacts when applied to widely-separated LDR images due to the blending between exposures. Following the work of Debevec and Malik, other researchers have proposed different weighting functions for merging differentlyexposed LDR images to reduce noise and improve the result (e.g., [Mitsunaga and Nayar 1999; Robertson et al. 2003; Kao 2008; Granados et al. 2010]). These approaches typically work on each pixel of the final HDR image independently and use only the information contained within the respective pixel in each of the LDR images. Unlike these approaches, we propose to use additional information available in the neighborhood of a pixel to reduce the noise in our final irradiance estimate. Finally, others have presented algorithms for fusing the LDR images together without explicitly creating an HDR image first (e.g., [Agarwala et al. 2004; Mertens et al. 2008]). These methods do not produce a true, radiometrically-correct HDR image, so the results cannot be incorporated into an HDR production workflow. 2.1 HDR Acquisition systems The process of capturing HDR images has been the focus of work by dozens of researchers and hundreds of artists and photographers. As a result, there are many published papers and patents describing methods and systems for capturing HDR images. Because of space limits, we focus only on the principal technologies currently available for HDR video and refer interested readers to texts on the subject (e.g., [Myszkowski et al. 2008]) for more information. The simplest approach for HDR imaging involves taking a series of images with different exposure times (e.g., [Mann and Picard 1995; Debevec and Malik 1997]). Although this method works well for static scenes, it is not well-suited for video because of the different moments in time and exposure lengths for each photograph, which result in varying amounts of motion blur and other timerelated effects. Nevertheless, researchers have extended this approach to video, by capturing frames with alternating bright and dark exposures [Ginosar et al. 1992; Kang et al. 2003] or using a rolling shutter with varying exposures [Unger and Gustavson 2007; Krymski 2008]. These approaches require image manipulation to register the images, which also introduces artifacts. 0.33 Q Q 0.33 Q ME prism sensor 0.33 Q 0.0272 Q 0.0016 Q LE sensor A traditional beamsplitting HDR optical system. Here a beamsplitting prism breaks up the light into three parts, one for each sensor fitted with different filters. Designs that use absorptive filters like this one make inefficient use of light. Other researchers have proposed new camera sensors for HDR imaging. Some approaches place an array of neutral-density filters over the individual pixels of the sensor with varying amounts of absorption (e.g., [Nayar and Mitsunaga 2000]), which can require complex demosaicing algorithms. These approaches are also wasteful of light entering the camera. If the sensor has a filter pattern with four differently-exposed pixels (one of the four fully exposed), then only 1 4 pixels would receive the full exposure level from the scene. Other proposed HDR sensors have a unique response to light, either by adapting their sensitivity (e.g., [Nayar and Branzoi 2003]), measuring the pixel saturation time (e.g., [Brajovic and Kanade 1996]), or having a logarithmic response to mimic the human eye (e.g., [Seger et al. 1999]). The primary problem with all of these approaches is that they require the production of a new type of camera sensor. Although commercial-scale production of these sensors may someday be realized, they are currently expensive to manufacture, rendering these methods unusable by most researchers today. Our proposed architecture, on the other hand, performs HDR imaging independent of the sensor used, which makes it realizable using today?s technology and allows us to adopt better sensor technologies (with low-light level response, faster framerates, wider spectral response, etc.), as they are developed in the future. In approaches similar to our own, the light in the camera is split with a pyramid-shaped mirror or refracting prism and redirected toward a set of sensors fitted with absorptive filters to produce images with different exposures (e.g., Harvey [1998], Aggarwal and Ahuja [2001; 2004], and Wang et al. [2005]). The designs of these previous systems all suffer from parallax error, due to the fact that the image-forming beam is split into spatially-distinct subsections; each individual sensor ?looks? through the camera lens from a slightly different angle. As shown in recent work on handheld plenoptic cameras (e.g., [Ng et al. 2005]), this provides each of the sensors with slightly different information, which significantly affects the imaging of scenes close to the camera. These previous spatial-beamsplitting methods are also wasteful of light: the absorptive filters used to achieve the dynamic range allow only a fraction of the incoming light to the sensors. If Q Watts of radiative power enters the aperture of the camera, the three-way system shown in Fig. 2 (configured for the same dynamic range as ours) allows only 0.3622Q Watts to the sensors, wasting almost 2 3 of the available light. As Aggarwal and Ahuja [2004] point out, it is possible to vary the amount of light to each sensor by moving the beamsplitting prism away from the optical axis instead of using filters. This effectively changes the size and shape of the aperture stop for each sensor, exacerbating the problem of each sensor getting different views of the scene. Furthermore, these shiftedoptical-axis spatial-beamsplitting methods are not easily integrated with standard camera lenses, and require either custom lens manufacture or lens modification to work correctly. Another option is to split the incoming light with beamsplitters prior to the lens. For example, McGuire et al. [2007] present a design tool to create efficient beamsplitting trees with separate lenses for each sensor, and show examples of HDR imaging. This same concept was demonstrated by Soviet Montage Productions [Cole and Safai 2010], which can be implemented on a 3D filming rig with an intraocular distance of zero by using a beamsplitter to provide different light transmission to two identical lenses, one for each sensor. The two lenses must be perfectly matched, however, and zoom-, focus-, and iris-tracking can be difficult to maintain between them. In addition, putting the beamsplitter in front of the camera lens places a limit on the field of view. Finally, it is unclear how such as system could be developed into a single, hand-held unit. Our system places the beamsplitter behind a single camera lens, so it does not suffer from these limitations. Finally, there are early prototype HDR systems in industry eventually intended for commercial use, such as the SpheronVR HDRv camera [Spheron VR 2011 ]. However, their method for achieving HDR capture has not been published. While all the systems we mention in this section are capable of producing HDR video, to date no method for producing high-quality HDR video has been demonstrated that is robust and yet simple enough to be readily introduced to a wide commercial audience or implemented in a modern optics laboratory. The goal of this work is to present such a system.",
  "resources" : [ ]
}