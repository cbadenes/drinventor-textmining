{
  "uri" : "sig2007-a5-cooper_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2007/a5-cooper_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Active Learning for Real-Time Motion Controllers",
    "published" : "2007",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Seth-Cooper",
      "name" : "Seth",
      "surname" : "Cooper"
    }, {
      "uri" : "http://drinventor/Aaron-Hertzmann",
      "name" : "Aaron",
      "surname" : "Hertzmann"
    }, {
      "uri" : "http://drinventor/Zoran-Popovic",
      "name" : "Zoran",
      "surname" : "Popovic"
    } ]
  },
  "bagOfWords" : [ "paper", "describe", "approach", "build", "real-time", "highlycontrollable", "character", "active", "learning", "use", "identify", "which", "motion", "sequence", "user", "should", "perform", "next", "order", "improve", "quality", "responsiveness", "controller", "because", "motion", "clip", "select", "adaptively", "we", "avoid", "difficulty", "manually", "determine", "which", "one", "capture", "can", "build", "complex", "controller", "from", "scratch", "while", "significantly", "reduce", "number", "necessary", "motion", "sample", "human", "motion", "capture", "datum", "provide", "effective", "basis", "create", "new", "animation", "paper", "we", "consider", "animation", "model", "we", "refer", "motion", "controller", "controller", "generate", "animation", "real-time", "base", "user-specified", "task", "-lrb-", "e.g.", "user", "might", "press", "forward", "game", "controller", "specify", "task", "walk", "forward", "-rrb-", "each", "task", "parameterize", "control", "vector", "continuous", "space", "-lrb-", "e.g.", "catch", "ball", "fly", "from", "specific", "direction", "velocity", "-rrb-", "paper", "controller", "essentially", "function", "from", "combined", "space", "state", "task", "space", "motion", "Motion", "capture", "datum", "very", "time-consuming", "expensive", "acquire", "thus", "desirable", "capture", "little", "possible", "when", "build", "simplest", "controller", "designer", "can", "minimize", "amount", "datum", "capture", "carefully", "plan", "datum", "sample", "acquire", "however", "non-trivial", "task", "space", "possible", "clip", "vast", "manual", "selection", "sample", "quickly", "become", "intractable", "example", "controller", "human", "can", "walk", "dodge", "projectile", "must", "parameterize", "direction", "speed", "walk", "direction", "speed", "projectile", "because", "task", "can", "change", "any", "point", "during", "animation", "controller", "also", "need", "parameterize", "all", "possible", "pose", "configuration", "character", "example", "controller", "must", "able", "dodge", "any", "projectile", "appear", "while", "character", "walk", "turn", "recover", "from", "previous", "dodge", "determine", "which", "motion", "capture", "controller", "so", "can", "produce", "good", "motion", "huge", "space", "possible", "input", "daunting", "task", "we", "experience", "too", "difficult", "do", "manually", "uniform", "sampling", "input", "space", "would", "vastly", "inefficient", "require", "huge", "number", "sample", "capture", "store", "memory", "paper", "we", "propose", "use", "active", "learn", "address", "problem", "particular", "we", "build", "motion", "controller", "onthe-fly", "during", "datum", "acquisition", "process", "process", "yield", "highly-controllable", "real-time", "motion", "controller", "realism", "motion", "capture", "datum", "while", "require", "only", "small", "amount", "motion", "capture", "datum", "we", "emphasize", "design", "we", "system", "do", "automate", "all", "decision", "rather", "compute", "aspect", "controller", "would", "difficult", "user", "handle", "user", "leave", "specific", "decision", "which", "hard", "quantitatively", "evaluate", "paper", "we", "refer", "generic", "user", "run", "system", "practice", "some", "role", "may", "perform", "separate", "individual", "example", "human", "operator", "might", "run", "active", "learning", "software", "have", "actor", "perform", "actual", "motion", "later", "separate", "nonspecialist", "user", "-lrb-", "e.g.", "game", "player", "-rrb-", "may", "control", "motion", "learn", "controller", "we", "also", "develop", "framework", "include", "user", "input", "key", "point", "process", "include", "provide", "motion", "capture", "sample", "select", "which", "motion", "capture", "from", "few", "automatically-determined", "option", "we", "also", "develop", "cluster-based", "learning", "model", "motion", "controller", "number", "real-time", "animation", "system", "build", "motion", "capture", "datum", "well", "one", "approach", "directly", "play", "transition", "between", "clip", "from", "motion", "database", "-lsb-", "Gleicher", "et", "al.", "2003", "Lee", "et", "al.", "2002", "Lee", "et", "al.", "2006", "-rsb-", "precomputation", "can", "use", "allow", "real-time", "planning", "which", "clip", "use", "-lsb-", "Lau", "Kuffner", "2006", "Lee", "Lee", "2006", "-rsb-", "previous", "work", "assume", "corpus", "motion", "datum", "available", "advance", "user", "manually", "select", "which", "motion", "capture", "datum", "acquisition", "difficult", "expensive", "and/or", "time-consuming", "problem", "many", "discipline", "paper", "we", "present", "active", "learning", "algorithm", "motion", "controller", "single", "controller", "can", "learn", "integrate", "several", "task", "each", "specify", "value", "argument", "we", "take", "advantage", "fact", "controller", "produce", "continuous", "motion", "clip", "rather", "individual", "state", "solve", "new", "motion", "only", "when", "task", "parameter", "change", "when", "current", "motion", "finish", "we", "represent", "change", "position", "rotation", "relative", "previous", "pose?s", "local", "frame", "we", "determine", "distance", "between", "two", "state", "method", "inspire", "Kovar", "et", "al.", "-lsb-", "2002", "-rsb-", "evaluate", "distance", "between", "point", "cloud", "attach", "each", "corresponding", "pose", "give", "state", "task", "control", "vector", "apply", "controller", "entail", "two", "step", "we", "example", "we", "also", "use", "modify", "version", "controller", "employ", "inverse", "kinematic", "-lrb-", "ik", "-rrb-", "step", "further", "satisfy", "endeffector", "constraint", "-lrb-", "e.g.", "catch", "ball", "right", "hand", "-rrb-", "neighbor", "frame", "linearly", "blended", "produce", "continuous", "motion", "however", "some", "case", "may", "useful", "motion", "clip", "middle", "process", "appropriate", "all", "task", "-lrb-", "e.g.", "one", "can", "change", "trajectory", "midair", "-rrb-", "whether", "allow", "indicate", "per-task", "basis", "more", "importantly", "manual", "process", "do", "scale", "well", "control", "problem", "large", "number", "input", "dimension", "those", "describe", "result", "section", "we", "now", "describe", "how", "motion", "controller", "build", "interactively", "although", "multiple", "step", "process", "basic", "idea", "simple", "identify", "region", "control", "space", "can", "perform", "well", "improve", "they", "process", "require", "user", "first", "define", "control", "problem", "enumerate", "set", "task", "-lcb-", "-rcb-", "specify", "operational", "range", "each", "control", "vector", "u.", "each", "control", "vector", "must", "have", "finite", "valid", "domain", "-lrb-", "e.g.", "bound", "constraint", "-rrb-", "order", "limit", "range", "allowable", "task", "example", "might", "specify", "desire", "walk", "speed", "might", "range", "possible", "walking", "speed", "interface", "mouse-based", "so", "user", "can", "interact", "system", "use", "gyro", "mouse", "while", "capture", "motion", "we", "now", "describe", "step", "detail", "multiple", "error", "metric", "may", "provide", "task", "goal", "all", "should", "satisfy", "likely", "some", "region", "control", "space", "simply", "harder", "solve", "than", "other", "direct", "application", "metric", "oversample", "space", "order", "evaluate", "blend", "between", "clip", "we", "measure", "distance", "between", "current", "state", "state", "motion", "would", "very", "difficult", "do", "purely", "automatic", "evaluation", "metric", "Third", "view", "candidate", "give", "user", "good", "sense", "performance", "controller", "weight", "choose", "minimize", "sum", "task", "error", "metric", "task", "example", "we", "remove", "rotation", "invariance", "from", "all", "quantity", "order", "build", "model", "which", "character", "always", "face", "specific", "direction", "while", "wait", "next", "ball", "we", "have", "also", "allow", "user", "load", "several", "motion", "diving", "side", "place", "perform", "motion", "general", "more", "powerful", "controller", "model", "more", "active", "learning", "can", "take", "advantage", "require", "less", "sample", "produce", "effective", "controller", "however", "mean", "controller", "limit", "dive", "example", "set", "can", "e.g.", "dive", "while", "run", "since", "include", "example", "we", "believe", "nonetheless", "indicative", "difficulty", "problem", "attractiveness", "active", "learning", "approach", "active", "learning", "framework", "both", "automatically", "determine", "parameter", "each", "individual", "cluster", "determine", "necessary", "number", "relationship", "between", "different", "cluster", "dynamically", "determine", "controller", "structure", "more", "sample", "appear", "failure", "mode", "controller", "during", "synthesis", "include", "have", "cluster", "appropriate", "state", "determine", "best", "cluster", "use", "determine", "best", "weight", "within", "cluster" ],
  "content" : "This paper describes an approach to building real-time highlycontrollable characters. Active learning is used to identify which motion sequence the user should perform next, in order to improve the quality and responsiveness of the controller. Because motion clips are selected adaptively, we avoid the difficulty of manually determining which ones to capture, and can build complex controllers from scratch while significantly reducing the number of necessary motion samples. Human motion capture data provides an effective basis for creating new animations. In this paper, we consider such an animation model that we refer to as a motion controller: a controller generates animation in real-time, based on user-specified tasks (e.g., a user might press forward on a game controller to specify the task ?walk forward,?). Each task is parameterized by a control vector in a continuous space (e.g., ?catch the ball flying from a specific direction and velocity?). In this paper, a controller is essentially a function from the combined space of states and tasks to the space of motions. Motion capture data is very time-consuming and expensive to acquire, and thus it is desirable to capture as little as possible. When building the simplest controllers, a designer can minimize the amount of data captured by carefully planning the data samples to be acquired. However, for non-trivial tasks, the space of possible clips is vast, and manual selection of samples quickly becomes intractable. For example, a controller for a human that can walk and dodge projectiles must be parameterized by the direction and speed of walking, the direction and speed of the projectiles. Because the task can be changed at any point during the animation, the controller also needs to be parameterized by all possible pose configurations of the character. For example, the controller must be able to dodge any projectile that appears while the character is walking, turning, or recovering from the previous dodge. Determining which motions to capture for this controller ? so that it can produce good motions in this huge space of possible inputs ? is a daunting task, and, in our experience, is too difficult to do manually. Uniform sampling of the input space would be vastly inefficient, requiring a huge number of samples to be captured and then stored in memory. In this paper, we propose the use of active learning to address these problems. In particular, we build the motion controller onthe-fly during the data acquisition process. This process yields highly-controllable, real-time motion controllers with the realism of motion capture data, while requiring only a small amount of motion capture data. We emphasize that, by design, our system does not automate all decisions, but, rather, computes aspects of the controller that would be difficult for a user to handle. The user is left with specific decisions which are hard to quantitatively evaluate. In this paper, we refer to a generic ?user? that runs the system. In practice, some roles may be performed by separate individuals. For example, a human operator might run the active learning software, but have an actor perform the actual motions; later, a separate nonspecialist user (e.g., a game player) may control the motions with the learned controller. We also develop a framework that includes user input at key points of the process, including providing motion capture samples, and in selecting which motions to capture from a few automatically-determined options. We also develop a cluster-based learning model for motion controllers. A number of real-time animation systems build on motion capture data as well. One approach is to directly play and transition between clips from a motion database [Gleicher et al. 2003; Lee et al. 2002; Lee et al. 2006]; precomputation can be used to allow real-time planning of which clips to use [Lau and Kuffner 2006; Lee and Lee 2006]. In previous work, it is assumed that a corpus of motion data is available in advance, or that a user will manually select which motions to capture. Data acquisition is difficult, expensive, and/or time-consuming for problems in many disciplines. In this paper, we present an active learning algorithm for motion controllers. A single controller can learn and integrate several tasks, each specified by a value of the argument t. We take advantage of the fact that the controller produces continuous motion clips rather individual states, and solve for the new motion m only when the task parameters u change or when the current motion m finishes. We represent changes in position and rotation relative to the previous pose?s local frame. We determine the distance between two states with a method inspired by Kovar et al. [2002], by evaluating the distance between point clouds attached to each corresponding pose. Given a state s, a task t, and a control vector u, applying a controller entails two steps. In our examples, we also use a modified version of the controller that employs an inverse kinematics (IK) step to further satisfy endeffector constraints (e.g., catching a ball with the right hand). The neighboring frames are linearly blended to produce continuous motion. However, in some cases, it may be useful for a motion clip to start in the middle. This process is not appropriate for all tasks (e.g. , one cannot change trajectory in midair) and whether or not to allow this is indicated on a per-task basis. More importantly, the manual process does not scale well for control problems with a large number of input dimensions, such as those described in the results section. We now describe how motion controllers are built interactively. Although there are multiple steps to the process, the basic idea is simple: identify the regions of the control space that cannot be performed well, and improve them. The process requires the user to first define the control problem by enumerating the set of tasks {t k } and to specify the operational range of each control vector u. Each control vector must have a finite valid domain u ? U k (e.g., bounds constraints) in order to limit the range of allowable tasks 1 . For example, u might specify the desired walking speed, and U k might be the range of possible walking speeds. The interface is mouse-based so the user can interact with the system using a gyro mouse while capturing motions. We now describe these steps in detail. Multiple error metrics may be provided for a task, with the goal that they all should be satisfied. It is likely that some regions of control space are simply harder to solve than others, and direct application of this metric will oversample these spaces. In order to evaluate blending between clips, we measure the distance between a current state and the start state s of a motion m. This would be very difficult to do with the purely automatic evaluation metrics. Third, viewing the candidates gives the user a good sense of the performance of the controller. These weights are chosen to minimize the sum of the task error metrics for this task. For this example, we removed rotation invariance from all quantities, in order to build a model in which the character is always facing a specific direction while waiting for the next ball. We have also allowed the user to load in several motions of diving to the side in place of performing these motions. In general, the more powerful the controller model, the more active learning can take advantage of it and require less samples to produce an effective controller. However, this meant that the controller is limited to the dives in this example set, and cannot, e.g., dive while running, since this was not included in the examples. but we believe that it is nonetheless indicative of the difficulty of the problem and the attractiveness of the active learning approach. The active learning framework both automatically determines the parameters of each individual cluster and determines the necessary number and relationship between different clusters, dynamically determining the controller structure as more samples appear. The failure modes of the controller during synthesis include not having a cluster with the appropriate start state, not determining the best cluster to use, and not determining the best weights within a cluster.",
  "resources" : [ ]
}