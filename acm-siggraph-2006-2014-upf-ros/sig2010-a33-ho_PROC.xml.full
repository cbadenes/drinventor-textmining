{
  "uri" : "sig2010-a33-ho_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2010/a33-ho_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Spatial Relationship Preserving Character Motion Adaptation",
    "published" : "2010",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Edmond S. L.-Ho",
      "name" : "Edmond S. L.",
      "surname" : "Ho"
    }, {
      "uri" : "http://drinventor/Taku-Komura",
      "name" : "Taku",
      "surname" : "Komura"
    }, {
      "uri" : "http://drinventor/Chiew-Lan-Tai",
      "name" : "Chiew-Lan",
      "surname" : "Tai"
    } ]
  },
  "bagOfWords" : [ "49ce1c018883bd451ea07f8924e5eabac538e6896805329029587de441c991b9", "mi9", "10.1145", "1778765.1778770", "name", "identification", "possible", "spatial", "relationship", "preserve", "character", "Motion", "Adaptation", "Edmond", "S.L.", "Ho", "Taku", "Komura", "Chiew-Lan", "Tai", "University", "Edinburgh", "Hong", "Kong", "University", "Science", "Technology", "Figure", "we", "system", "can", "retarget", "motion", "close", "interaction", "character", "different", "morphology", "judo", "interaction", "-lrb-", "red", "orange", "pair", "-rrb-", "retarget", "character", "different", "size", "paper", "present", "new", "method", "editing", "retargeting", "motion", "involve", "close", "interaction", "between", "body", "part", "single", "multiple", "articulate", "character", "dancing", "wrestling", "sword", "fighting", "between", "character", "restricted", "environment", "get", "car", "motion", "implicit", "spatial", "relationship", "between", "body", "parts/objects", "important", "capture", "scene", "semantics", "we", "introduce", "simple", "structure", "call", "interaction", "mesh", "represent", "spatial", "relationship", "minimize", "local", "deformation", "interaction", "mesh", "animation", "frame", "relationship", "preserve", "during", "motion", "editing", "while", "reduce", "number", "inappropriate", "interpenetration", "interaction", "mesh", "representation", "general", "applicable", "various", "kind", "close", "interaction", "also", "work", "well", "interaction", "involve", "contact", "tangle", "well", "those", "without", "any", "contact", "method", "computationally", "efficient", "allow", "real-time", "character", "control", "we", "demonstrate", "its", "effectiveness", "versatility", "synthesize", "wide", "variety", "motion", "close", "interaction", "cr", "category", "i.", "3.7", "-lsb-", "Computer", "Graphics", "-rsb-", "three-dimensional", "graphic", "realism?animation", "i.", "3.5", "-lsb-", "Computer", "Graphics", "-rsb-", "computational", "geometry", "object", "modeling?curve", "surface", "solid", "object", "representation", "keyword", "Character", "Animation", "Close", "interaction", "spatial", "relationship", "Motion", "Editing", "Motion", "Retargeting", "e-mail", "edmond@edho.net", "e-mail", "tkomura@ed.ac.uk", "e-mail", "taicl@cse.ust.hk", "ACM", "Reference", "Format", "Ho", "E.", "Komura", "T.", "Tai", "C.", "2010", "spatial", "relationship", "preserve", "character", "Motion", "Adaptation", "ACM", "Trans", "graph", "29", "Article", "33", "-lrb-", "July", "2010", "-rrb-", "page", "dous", "10.1145", "1778765.1778770", "http://doi.acm.org/10.1145/1778765.1778770", "copyright", "Notice", "permission", "make", "digital", "hard", "copy", "part", "all", "work", "personal", "classroom", "use", "grant", "without", "fee", "provide", "copy", "make", "distribute", "profit", "direct", "commercial", "advantage", "copy", "show", "notice", "fus", "rst", "page", "initial", "screen", "display", "along", "full", "citation", "copyright", "component", "work", "own", "other", "than", "ACM", "must", "honor", "abstract", "credit", "permit", "copy", "otherwise", "republish", "post", "server", "redistribute", "list", "use", "any", "component", "work", "other", "work", "require", "prior", "specific", "permission", "and/or", "fee", "permission", "may", "request", "from", "Publications", "Dept.", "ACM", "Inc.", "Penn", "Plaza", "Suite", "701", "New", "York", "NY", "10121-0701", "fax", "+1", "-lrb-212-rrb-Â 869-0481", "permissions@acm.org", "2010", "ACM", "0730-0301/2010", "07-art33", "10.00", "DOI", "10.1145", "1778765.1778770", "http://doi.acm.org/10.1145/1778765.1778770", "introduction", "close", "interaction", "necessarily", "any", "contact", "between", "different", "body", "part", "single", "multiple", "character", "environment", "common", "computer", "animation", "3d", "computer", "game", "yoga", "wrestling", "dancing", "move", "through", "constrain", "environment", "some", "example", "motion", "spatial", "relationship", "between", "different", "body", "part", "character", "important", "capture", "semantics", "scene", "when", "animator", "synthesize", "edit", "movement", "special", "care", "need", "preserve", "spatial", "relationship", "example", "arch", "back", "avoid", "punch", "hand", "extend", "around", "each", "other", "two", "body", "move", "synchronously", "close", "proximity", "get", "small", "car", "bend", "down", "however", "traditionally", "spatial", "relationship", "exist", "only", "animator?s", "mind", "digitally", "embed", "datum", "although", "human", "use", "spatial", "relationship", "recognize", "semantics", "interaction", "usage", "have", "be", "consider", "much", "character", "animation", "exist", "scene", "representation", "have", "fundamental", "limitation", "handle", "close", "interaction", "currently", "motion", "typically", "describe", "term", "joint", "angle", "kinematic", "constraint", "contact", "representation", "automatically", "compute", "valid", "motion", "require", "randomize", "exploration", "significant", "computation", "collision", "detection", "animator", "also", "need", "shoulder", "burden", "specify", "all", "kinematic", "constraint", "advance", "from", "animator?s", "perspective", "impractical", "conductive", "manual", "editing", "competitive", "automatic", "solution", "require", "effective", "representation", "allow", "extraction", "spatial", "relationship", "from", "exist", "motion", "datum", "synthesis", "new", "animation", "preserve", "relationship", "representation", "only", "allow", "quantitative", "evaluation", "way", "different", "body", "part", "interact", "also", "facilitate", "qualitative", "characterization", "scene", "semantics", "paper", "we", "propose", "simple", "representation", "which", "we", "call", "interaction", "mesh", "represent", "spatial", "relationship", "between", "nearby", "body", "part", "interaction", "mesh", "volumetric", "mesh", "define", "joint", "character", "vertex", "objects/environment", "which", "character", "interact", "when", "editing", "retargeting", "movement", "motion", "automatically", "adapt", "deform", "interaction", "mesh", "all", "frame", "efficient", "laplacian", "deformation", "technique", "-lsb-", "Alexa", "2003", "Zhou", "et", "al.", "2005", "-rsb-", "high-level", "semantics", "interaction", "maintain", "through", "preserve", "local", "detail", "interaction", "mesh", "interaction", "mesh", "representation", "general", "provide", "unified", "treatment", "interact", "body", "part", "single", "multiple", "character", "well", "object", "environment", "result", "applicable", "many", "type", "scenario", "when", "single", "character?s", "action", "involve", "close", "interaction", "between", "different", "body", "part", "-lrb-", "dancing", "-rrb-", "multi-character", "interaction", "-lrb-", "wrestling", "fight", "game", "-rrb-", "additionally", "motion", "may", "either", "involve", "much", "tangling", "contact", "-lrb-", "e.g.", "judo", "fig.", "-rrb-", "little", "contact", "-lrb-", "e.g.", "lambada", "dance", "-rrb-", "additionally", "can", "apply", "either", "per-frame", "space-time", "domain", "accord", "complexity", "problem", "available", "computing", "resource", "Motion", "adaptation", "interaction", "mesh", "fully", "automatic", "when", "animator", "change", "size", "morphology", "character", "edit", "part", "motion", "system", "automatically", "deform", "interaction", "mesh", "all", "frame", "use", "spacetime", "optimization", "create", "new", "motion", "sequence", "preserve", "original", "context", "scene", "constraint", "need", "specify", "animator", "since", "all", "encode", "interaction", "mesh", "desire", "user", "may", "add", "extra", "constraint", "anchor", "body", "foot", "approach", "efficient", "allow", "real-time", "control", "character", "virtual", "environment", "specifically", "computational", "cost", "increase", "only", "linearly", "number", "frame", "complexity", "articulate", "body", "structure", "interaction", "mesh", "useful", "synthesize", "motion", "film", "computer", "game", "digital", "mannequin", "system", "we", "demonstrate", "its", "usefulness", "character", "animation", "retargeting", "capture", "human", "motion", "character", "very", "different", "proportion", "volume", "monkey", "also", "editing", "motion", "multiple", "character", "while", "preserve", "original", "context", "scene", "contribution", "we", "introduce", "new", "representation", "call", "interaction", "mesh", "encode", "spatial", "relationship", "between", "closely", "interact", "body", "part", "articulate", "character", "object", "environment", "we", "present", "automatic", "method", "use", "interaction", "mesh", "editing", "retargeting", "motion", "close", "interaction", "synthesize", "motion", "preserve", "spatial", "relationship", "thus", "scene", "semantics", "while", "reduce", "number", "inappropriate", "interpenetration", "ACM", "transaction", "Graphics", "Vol", "29", "no.", "Article", "33", "publication", "date", "July", "2010", "33:2", "E.", "Ho", "et", "al.", "figure", "posture", "articulate", "body", "retarget", "new", "morphology", "longer", "red/green", "shorter", "blue", "segment", "note", "na?ve", "approach", "joint", "angle", "result", "change", "context", "related", "work", "most", "exist", "motion", "synthesis", "method", "use", "kinematic", "constraint", "positional", "constraint", "enforce", "spatial", "relationship", "between", "character", "environment", "few", "more", "recent", "work", "character", "animation", "consider", "implicit", "spatial", "relationship", "constraint-based", "motion", "synthesis", "since", "kinematic", "constraint", "can", "usually", "represent", "single", "equation", "can", "easily", "embed", "optimization", "problem", "motion", "synthesis", "approach", "have", "be", "adopt", "physically-based", "animation", "-lsb-", "Popovi", "Witkin", "1999", "Komura", "et", "al.", "2000", "Liu", "Popovi", "??", "2002", "Fang", "Pollard", "2003", "-rsb-", "motion", "editing", "-lsb-", "Gleicher", "1997", "Callennec", "boulic", "2004", "Komura", "et", "al.", "2004", "Liu", "et", "al.", "2006", "Shum", "et", "al.", "2009", "-rsb-", "motion", "retargeting", "-lsb-", "gleicher", "1998", "Lee", "Shin", "1999", "Choi", "Ko", "2000", "-rsb-", "one", "early", "work", "gleicher", "-lsb-", "1998", "-rsb-", "handle", "close", "interaction", "multiple", "character", "he", "retarget", "close", "dancing", "motion", "two", "character", "body", "different", "size", "while", "keep", "hand", "connect", "use", "positional", "constraint", "other", "method", "avoid", "penetration", "interact", "body", "part", "use", "inequality", "constraint", "-lsb-", "Liu", "et", "al.", "2006", "-rsb-", "combination", "collision", "detection", "equality", "constraint", "-lsb-", "Xu", "et", "al.", "2007", "Shi", "et", "al.", "2007", "-rsb-", "method", "produce", "excellent", "result", "interaction", "contact", "however", "applicable", "maintain", "spatial", "relationship", "less", "explicit", "because", "represent", "they", "single", "equation", "difficult", "example", "Lambada", "dance", "dancer", "twist", "body", "around", "each", "other", "without", "necessarily", "any", "body", "contact", "handle", "motion", "where", "interaction", "condition", "largely", "implicit", "difficult", "since", "context", "scene", "must", "preserve", "while", "avoid", "penetration", "collision", "without", "good", "representation", "implicit", "spatial", "relationship", "motion", "synthesis", "require", "complex", "global", "path", "planner", "involve", "significant", "collision", "detection", "effort", "randomize", "exploration", "-lsb-", "LaValle", "Kuffner", "2001", "Yamane", "et", "al.", "2004", "Shapiro", "et", "al.", "2007", "-rsb-", "which", "difficult", "large", "number", "degree", "freedom", "character", "animation", "spatial", "relationship", "have", "be", "few", "recent", "work", "which", "take", "account", "implicit", "spatial", "relationship", "multiple", "character", "when", "synthesize", "new", "animation", "Kwon", "et", "al.", "-lsb-", "2008", "-rsb-", "handle", "spatial", "relationship", "between", "character", "group", "motion", "encode", "neighborhood", "formation", "individual", "trajectory", "laplacian", "coordinate", "when", "editing", "trajectory", "relative", "spatial", "arrangement", "character", "preserve", "apply", "laplacian", "mesh", "editing", "technique", "-lsb-", "Alexa", "2003", "Sorkine", "et", "al.", "2004", "-rsb-", "we", "method", "similar", "we", "also", "employ", "laplacian", "mesh", "editing", "technique", "we", "address", "very", "different", "problem", "individual", "character", "case", "2d", "particle", "close", "interaction", "contrast", "we", "method", "aim", "preserve", "spatial", "relationship", "between", "body", "3d", "articulate", "character", "which", "require", "consider", "connection", "joint", "rigidity", "body", "component", "penetration", "between", "they", "Ho", "Komura", "-lsb-", "2009b", "-rsb-", "use", "Gauss", "Linking", "Integral", "detect", "tangled", "limb", "encode", "they", "use", "rational", "tangle", "motion", "retrieval", "later", "propose", "new", "representation", "call", "topology", "coordinate", "represent", "tangled", "body", "part", "-lsb-", "Ho", "Komura", "2009a", "-rsb-", "apply", "synthesize", "character", "motion", "close", "contact", "method", "adequate", "handle", "motion", "involve", "tangle", "between", "1d", "manifold", "strand", "skeleton", "however", "extension", "motion", "involve", "character", "shape", "seem", "difficult", "since", "relationship", "between", "rigid", "body", "surface", "need", "encode", "further", "method", "can", "handle", "close", "interaction", "without", "any", "tangle", "propose", "method", "consider", "relationship", "among", "rigid", "body", "part", "more", "general", "since", "can", "handle", "motion", "close", "interaction", "with/without", "tangle", "recent", "work", "Zhou", "et", "al.", "-lsb-", "2010", "-rsb-", "deformation", "transfer", "represent", "spatial", "relationship", "between", "multiple", "component", "object", "euclidean", "distance", "encode", "they", "use", "minimum", "span", "tree", "since", "spatial", "relationship", "assume", "fix", "-lrb-", "same", "rest", "pose", "-rrb-", "during", "deformation", "method", "applicable", "motion", "time-varying", "spatial", "relationship", "overview", "we", "give", "overview", "we", "method", "section", "first", "datum", "original", "character", "motion", "load", "we", "sy", "tem", "each", "body", "segment", "character", "model", "surround", "bound", "volume", "which", "use", "collision", "detection", "interaction", "mesh", "compute", "every", "time", "frame", "next", "user", "edit", "retarget", "motion", "specify", "some", "following", "target", "body", "size", "morphology", "target", "position", "new", "trajectory", "some", "body", "part", "constraint", "parameter", "interpolate", "use", "morph", "original", "body", "target", "body", "every", "morph-step", "entire", "motion", "adapt", "towards", "achieve", "target", "motion", "iterative", "approach", "necessary", "since", "collision", "between", "body", "parts/objects", "need", "carefully", "monitor", "resolve", "every", "morph-step", "system", "adapt", "motion", "minimize", "laplacian", "deformation", "interaction", "mesh", "all", "animation", "frame", "-lrb-", "fix", "window", "frame", "time", "accord", "available", "computing", "resource", "-rrb-", "acceleration", "body", "frame", "-lrb-", "see", "fig.", "example", "adapt", "result", "one", "frame", "-rrb-", "spacetime", "optimization", "perform", "ensure", "temporal", "coherence", "motion", "optimization", "subject", "various", "constraint", "namely", "bone-length", "constraint", "collision", "constraint", "positional", "constraint", "collision", "detect", "between", "bound", "volume", "collision", "detect", "penetration", "depths", "evaluate", "new", "set", "collision", "constraint", "define", "resolve", "penetration", "next", "morph-step", "ACM", "transaction", "Graphics", "Vol", "29", "no.", "Article", "33", "publication", "date", "July", "2010", "spatial", "relationship", "preserve", "character", "Motion", "Adaptation", "33:3", "interaction", "mesh", "section", "we", "describe", "how", "we", "compute", "interaction", "mesh", "give", "motion", "we", "assume", "mesh", "character", "rig", "skeleton", "each", "body", "segment", "bound", "volume", "-lrb-", "we", "use", "capsule", "box", "we", "experiment", "-rrb-", "posture", "character", "represent", "position", "joint", "rather", "than", "joint", "angle", "use", "joint", "position", "parameter", "have", "advantage", "make", "constraint", "matrix", "sparse", "since", "joint", "treat", "independent", "particle", "contrast", "use", "joint", "angle", "parameter", "make", "jacobian", "matrix", "very", "dense", "joint", "near", "root", "affect", "movement", "all", "joint", "below", "hierarchy", "-lsb-", "Shi", "et", "al.", "2007", "-rsb-", "we", "compute", "volumetric", "interaction", "mesh", "every", "animation", "frame", "use", "position", "joint", "vertex", "object", "point", "cloud", "we", "apply", "Delaunay", "tetrahedralization", "-lsb-", "Si", "Gaertner", "2005", "-rsb-", "-lrb-", "see", "Figure", "-rrb-", "note", "spatial", "relationship", "which", "we", "want", "preserve", "those", "between", "body", "part", "close", "proximity", "occlude", "other", "part", "since", "Delaunay", "tetrahedralization", "favor", "connect", "part", "edge", "laplacian", "coordinate", "vertex", "which", "define", "vertex", "neighborhood", "lead", "mutual", "influence", "between", "body", "part", "nature", "laplacian", "mesh", "editing", "preserve", "local", "detail", "spatial", "relationship", "we", "interest", "maintain", "orientation", "some", "body", "segment", "can", "compute", "only", "from", "position", "joint", "bound", "segment", "example", "joint", "position", "elbow", "wrist", "insufficient", "confirm", "rotation", "around", "forearm", "order", "compute", "orientation", "we", "sample", "one", "extra", "virtual", "vertex", "surface", "each", "bound", "volume", "-lsb-", "Shi", "et", "al.", "2007", "-rsb-", "additional", "virtual", "vertex", "add", "point", "cloud", "when", "define", "interaction", "mesh", "since", "each", "virtual", "vertex", "rigidly", "constrain", "body", "part", "its", "position", "bring", "back", "original", "local", "coordinate", "frame", "once", "bone?s", "orientation", "confirm", "another", "possible", "solution", "use", "inverse", "kinematic", "orientation", "body", "segment", "can", "infer", "from", "joint", "position", "orientation", "original", "motion", "-lsb-", "Bodenheimer", "et", "al.", "1997", "-rsb-", "approach", "can", "keep", "number", "vertex", "interaction", "mesh", "low", "Spacetime", "Deformation", "section", "we", "present", "spacetime", "optimization", "problem", "we", "solve", "adapt", "motion", "each", "morph-step", "spatial", "relationship", "body", "parts/objects", "preserve", "minimize", "laplacian", "deformation", "energy", "all", "interaction", "mesh", "-lsb-", "Alexa", "2003", "Zhou", "et", "al.", "2005", "-rsb-", "subject", "constraint", "derive", "from", "morphed", "body", "size", "detect", "collision", "user-defined", "position", "constraint", "we", "also", "introduce", "acceleration", "energy", "reduce", "jaggedness", "between", "frame", "deformation", "energy", "let", "number", "vertex", "interaction", "mesh", "ij", "-lrb-", "-rrb-", "vertex", "frame", "vector", "size", "3m", "include", "all", "ij", "-lrb-", "-rrb-", "ij", "update", "vector", "after", "deformation", "deformation", "energy", "mesh", "define", "-lrb-", "-rrb-", "-lrb-", "ij", "-rrb-", "where", "operator", "compute", "laplacian", "coordinate", "from", "vertex", "location", "original", "laplacian", "coordinate", "matrix", "vector", "respectively", "compute", "expand", "eq", "-lrb-", "-rrb-", "laplacian", "coordinate", "calculate", "-lrb-", "-rrb-", "l?n", "where", "one-ring", "neighborhood", "normalize", "weight", "which", "set", "inversely", "proportional", "distance", "between", "vertex", "so", "farther", "apart", "vertex", "have", "less", "influence", "each", "other", "acceleration", "energy", "reduce", "jaggy", "jump", "between", "frame", "we", "introduce", "acceleration", "energy", "term", "which", "impose", "temporal", "relation", "between", "corresponding", "vertex", "adjacent", "frame", "specifically", "reduce", "sudden", "acceleration", "we", "minimize", "movement", "corresponding", "vertex", "adjacent", "frame", "-lrb-", "+1", "-rrb-", "2v", "+1", "where", "set", "vertex", "frame", "i.", "5.1", "constraint", "here", "we", "explain", "bone-length", "constraint", "positional", "constraint", "collision", "constraint", "impose", "spacetime", "deformation", "bone-length", "constraint", "we", "introduce", "bone-length", "constraint", "order", "morph", "bone", "length", "-lrb-", "distance", "between", "adjacent", "joint", "-rrb-", "from", "original", "scale", "target", "scale", "each", "morph-step", "each", "animation", "frame", "target", "length", "each", "bone", "compute", "linearly", "blend", "original", "final", "length", "constraint", "enforce", "target", "length", "impose", "-lrb-", "-rrb-", "where", "end", "vertex", "edge", "e.", "linearize", "all", "bone-length", "constraint", "result", "-lrb-", "-rrb-", "where", "jacobian", "matrix", "vector", "constant", "term", "ACM", "transaction", "Graphics", "Vol", "29", "no.", "Article", "33", "publication", "date", "July", "2010", "33:4", "E.", "Ho", "et", "al.", "sometimes", "bone-length", "constraint", "may", "conflict", "laplacian", "deformation", "energy", "which", "mean", "satisfy", "bone-length", "constraint", "increase", "laplacian", "deformation", "energy", "conflict", "main", "source", "slow", "convergence", "we", "cope", "problem", "exclude", "vertex", "from", "neighborhood", "vertex", "when", "compute", "laplacian", "coordinate", "edge", "connect", "correspond", "bone", "body", "positional", "constraint", "user", "can", "add", "positional", "constraint", "anchor", "some", "joint", "linear", "combination", "location", "original", "trajectory", "body", "part", "gradually", "morph", "give", "trajectory", "each", "morph-step", "we", "compute", "target", "location", "part", "use", "linear", "interpolation", "write", "positional", "constraint", "-lrb-", "-rrb-", "where", "3k", "3m", "weight", "matrix", "define", "influence", "each", "joint", "each", "positional", "constraint", "number", "positional", "constraint", "Collision", "constraint", "collision", "constraint", "prevent", "penetration", "between", "bound", "volume", "skeleton", "we", "perform", "collision", "detection", "apply", "ODE", "library", "-lsb-", "Smith", "2005", "-rsb-", "current", "configuration", "bound", "volume", "specifically", "when", "penetration", "detect", "we", "compute", "penetration", "depth", "direction", "point", "pair", "penetrate", "each", "other", "farthest", "add", "follow", "constraint", "-lrb-", "-rrb-", "where", "Jacobian", "position", "collide", "part", "respect", "joint", "position", "penetration", "depth", "multiply", "normal", "vector", "penetrate", "surface", "Jacobian", "compute", "finite", "differencing", "joint", "vertex", "move", "location", "penetrate", "point", "recompute", "accord", "posture", "we", "do", "apply", "collision", "detection", "adjacent", "body", "part", "along", "body", "tree", "structure", "self-penetration", "easily", "happen", "when", "joint", "bent", "constraint", "energy", "we", "separate", "constraint", "eq", "-lrb-", "-rrb-", "-7", "soft", "hard", "constraint", "-lrb-", "soft", "-rrb-", "-lrb-", "hard", "-rrb-", "define", "constraint", "energy", "represent", "amount", "violation", "soft", "constraint", "-lrb-", "-rrb-", "WF", "WF", "Wf", "where", "square", "diagnol", "matrix", "assign", "different", "weight", "each", "constraint", "default", "we", "set", "bone-length", "constraint", "one", "positional", "constraint", "-lrb-", "support", "foot", "-rrb-", "hard", "collision", "constraint", "rest", "positional", "constraint", "soft", "bone-length", "constraint", "set", "hard", "so", "body", "correctly", "scale", "target", "value", "soft", "collision", "constraint", "stabilize", "motion", "when", "little", "open", "space", "also", "provide", "animator", "some", "result", "when", "collision", "can", "avoid", "due", "insufficient", "open", "space", "when", "body", "enlarged", "also", "necessary", "set", "other", "positional", "constraint", "soft", "avoid", "over", "constrain", "default", "weight", "set", "4.0", "0.4", "collision", "additional", "positional", "constraint", "respectively", "constraint", "can", "switch", "between", "soft", "hard", "accord", "desire", "animation", "effect", "when", "number", "morph", "step", "small", "we", "also", "need", "set", "bone-length", "constraint", "soft", "weight", "set", "2.0", "algorithm", "Motion", "Adaptation", "interaction", "mesh", "Input", "Skeleton", "input", "motion", "sequence", "initial", "final", "body", "scale", "factor", "location", "initial/final", "positional", "constraint", "output", "target", "motion", "sequence", "-lrb-", "initialization", "-rrb-", "compute", "interaction", "mesh", "-lrb-", "vertex", "position", "connectivity", "-rrb-", "all", "input", "frame", "n.", "-lrb-", "Motion", "Adaptation", "-rrb-", "morph-step", "do", "Update", "body", "scale", "location", "positional", "constraint", "n?k", "n?k", "Update", "constraint", "matrix", "target", "value", "constraint", "eq", "-lrb-", "-rrb-", "deformation", "vector", "eq", "-lrb-", "-rrb-", "frame", "...", "Update", "vertex", "location", "solve", "eq", "-lrb-", "10", "-rrb-", "compute", "segment", "orientation", "update", "virtual", "vertex", "end", "5.2", "iterative", "morph", "every", "morph-step", "body", "size", "positional", "constraint", "update", "motion", "character", "adapt", "minimize", "sum", "deformation", "-lrb-", "eq", ".1", "-rrb-", "acceleration", "-lrb-", "eq", ".4", "-rrb-", "constraint", "energy", "-lrb-", "eq", ".9", "-rrb-", "all", "frame", "subject", "hard", "constraint", "adapt", "motion", "compute", "solve", "10", "arg", "min", "-lrb-", "i?n", "-rrb-", "-lrb-", "-rrb-", "where", "number", "frame", "set", "new", "vertex", "posius", "tion", "frame", "Lagrange", "multiplier", "constant", "weight", "-lrb-", "we", "use", "0.2", "-rrb-", "note", "define", "first", "last", "frame", "hence", "we", "set", "they", "zero", "spacetime", "optimization", "problem", "eq", "-lrb-", "10", "-rrb-", "can", "solve", "differentiate", "respect", "solve", "follow", "linear", "equation", "WF", "11", "where", "vector", "include", "-lrb-", "eq", ".2", "-rrb-", "-lrb-", "eq", ".8", "-rrb-", "all", "frame", "respectively", "i.e.", "-lrb-", "...", "-rrb-", "-lrb-", "...", "-rrb-", "-lrb-", "...", "-rrb-", "-lrb-", "??", "...", "??", "-rrb-", "-lrb-", "...", "-rrb-", "laplacian", "matrix", "soft", "constraint", "matrix", "k-th", "morph-step", "each", "which", "include", "eq", "-lrb-", "-rrb-", "eq", "-lrb-", "-rrb-", "all", "frame", "respectively", "...", "???", "...", "???", "matrix", "compute", "acceleration", "all", "frame", "from", "diag", "-lrb-", "...", "-rrb-", "constraint", "matrix", "k-th", "morph-step", "which", "include", "eq", "-lrb-", "-rrb-", "all", "frame", "we", "motion", "adaptation", "algorithm", "summarize", "algorithm", "interaction", "mesh", "define", "original", "motion", "frame", "connectivity", "keep", "unchanged", "all", "morph-step", "which", "result", "constant", "m.", "note", "re-compute", "tetrahedralization", "each", "morph-step", "would", "result", "gradual", "drift", "motion", "away", "from", "original", "sequence", "keep", "mesh", "topology", "from", "original", "motion", "help", "preserve", "spatial", "relationship", "component", "original", "motion", "possible", "artifact", "solution", "due", "non-uniform", "weighting", "edge", "drastic", "update", "morph", "parameter", "character", "size", "may", "result", "flip", "tetrahedron", "interaction", "mesh", "flip", "occur", "open", "space", "do", "cause", "noticeable", "artifact", "may", "result", "change", "context", "happen", "tetrahedron", "compose", "two", "bone", "which", "nearby", "adjacent", "each", "other", "we", "prevent", "flip", "detect", "collision", "between", "body", "part", "apply", "collision", "constraint", "-lrb-", "eq", ".7", "-rrb-", "each", "morph", "step", "however", "system", "may", "fail", "when", "linearization", "collision", "constraint", "break", "down", "which", "happen", "when", "body", "size", "very", "narrow", "penetration", "depth", "too", "large", "result", "push", "out", "penetrate", "body", "wrong", "direction", "-lrb-", "see", "Fig.", "-rrb-", "problem", "can", "avoid", "give", "enough", "volume", "body", "part", "set", "small", "morph", "step", "we", "obtain", "satisfactory", "result", "use", "10", "morph-step", "all", "example", "soft", "collision", "constraint", "can", "result", "penetration", "when", "body", "enlarged", "too", "much", "while", "limit", "open", "space", "we", "can", "alert", "user", "lack", "space", "give", "sum", "square", "penetration", "depth", "reference", "user", "can", "choose", "either", "enlarge", "environment", "stop", "scale", "system", "may", "become", "unstable", "when", "original", "motion", "contain", "movement", "where", "body", "part", "pass", "through", "each", "other", "when", "happen", "direction", "collision", "constraint", "push", "body", "away", "from", "each", "other", "turn", "opposite", "some", "moment", "result", "large", "movement", "one", "frame", "contradict", "minimization", "acceleration", "energy", "cause", "vibration", "switch", "off", "collision", "constraint", "frame", "pass", "through", "can", "remove", "artifact", "ACM", "transaction", "Graphics", "Vol", "29", "no.", "Article", "33", "publication", "date", "July", "2010", "2us", "2us", "...", "???", "spatial", "relationship", "preserve", "character", "Motion", "Adaptation", "33:5", "Figure", "flip", "tetrahedron", "during", "morph-step", "may", "lead", "change", "spatial", "context", "-lrb-", "leave", "-rrb-", "initial", "posture", "-lrb-", "middle", "-rrb-", "flip", "happen", "leave", "lower", "leg", "yellow", "character", "when", "use", "morph-step", "-lrb-", "right", "-rrb-", "flip", "avoid", "when", "use", "10", "morphstep", "experimental", "result", "section", "we", "show", "experimental", "result", "from", "apply", "we", "motion", "retargeting", "method", "character", "animation", "we", "apply", "several", "type", "motion", "close", "interaction", "namely", "between", "body", "part", "single", "character", "multiple", "character", "between", "character", "its", "environment", "we", "also", "demonstrate", "its", "usefulness", "real-time", "character", "control", "height", "foot", "all", "Figure", "snapshot", "sword", "attack", "motion", "-lrb-", "left", "-rrb-", "retarget", "character", "different", "morphology", "-lrb-", "middle", "right", "-rrb-", "Figure", "snapshot", "back", "break", "attack", "motion", "-lrb-", "left", "-rrb-", "retarget", "character", "different", "morphology", "-lrb-", "middle", "right", "-rrb-", "constrain", "original", "value", "hard", "constraint", "default", "which", "necessary", "especially", "when", "character", "stand", "ground", "reader", "refer", "supplementary", "video", "further", "detail", "6.1", "retarget", "motion", "close", "interaction", "first", "we", "show", "result", "retargeting", "motion", "involve", "only", "character", "we", "use", "motion", "involve", "much", "tangling", "contact", "judo", "well", "those", "few", "contact", "dancing", "attackers/defenders", "fight", "game", "Judo", "attack", "we", "first", "motion", "example", "judo", "Ogoshi", "throw", "which", "attacker", "hold", "arm", "waist", "defender", "throw", "defender", "carry", "him/her", "onto", "back", "we", "retarget", "motion", "thrower", "defender", "character", "various", "morphology", "we", "use", "body", "size", "character", "Allen", "et", "al.", "-lsb-", "2003", "-rsb-", "reference", "-lrb-", "see", "fig.", "-rrb-", "here", "although", "proportion", "bound", "volume", "new", "character", "completely", "different", "from", "those", "original", "character", "we", "system", "can", "still", "produce", "Ogoshi", "throw", "note", "previous", "motion", "editing/retargeting", "approach", "difficult", "apply", "kind", "close", "interaction", "since", "only", "consider", "joint", "angle", "original", "motion", "spatial", "relationship", "result", "retarget", "motion", "may", "have", "different", "context", "-lrb-", "e.g.", "arm", "extend", "other", "side", "defender?s", "body", "-rrb-", "also", "require", "animator", "manually", "specify", "all", "positional", "constraint", "all", "frame", "attacker?s", "hand", "hold", "defender?s", "body", "can", "tedious", "task", "animator", "fighting", "scene", "we", "next", "two", "motion", "example", "fight", "scene", "involve", "two", "character", "provide", "game", "company", "first", "scene", "involve", "character", "hold", "sword", "attack", "its", "enemy", "sword", "penetrate", "through", "enemy", "character", "when", "enemy", "stab", "therefore", "we", "turn", "off", "collision", "constraint", "those", "frame", "second", "scene", "from", "same", "game", "character", "hold", "sword", "break", "back", "enemy", "both", "arm", "drop", "sword", "unintentionally", "pass", "through", "arm", "defender", "some", "frame", "which", "due", "manual", "design", "again", "we", "turn", "off", "collision", "constraint", "those", "frame", "both", "attacker?s", "defender?s", "morphology", "change", "animation", "different", "combination", "body", "create", "snapshot", "original", "synthesize", "motion", "show", "Fig.", "Fig.", "respectively", "note", "manual", "editing", "would", "ACM", "transaction", "Graphics", "Vol", "29", "no.", "Article", "33", "publication", "date", "July", "2010", "33:6", "E.", "Ho", "et", "al.", "Figure", "-lrb-", "leave", "-rrb-", "posture", "turn", "kick", "interaction", "-lrb-", "middle", "right", "-rrb-", "animator", "drag", "left", "foot", "yellow", "character", "mouse", "other", "character", "move", "preserve", "spatial", "relationship", "Figure", "original", "dancing", "motion", "-lrb-", "middle", "-rrb-", "retarget", "result", "monkey", "model", "long", "arm", "use", "joint-angle", "base", "method", "-lrb-", "left", "-rrb-", "use", "we", "method", "-lrb-", "right", "-rrb-", "require", "lot", "care", "avoid", "unintentional", "penetration", "sword", "body", "we", "method", "can", "automatically", "produce", "motion", "pass", "sword", "space", "between", "enemy?s", "arm", "torso", "example", "show", "we", "method", "can", "also", "use", "manually", "design", "motion", "which", "penetration-free", "case", "context", "penetration", "-lrb-", "e.g.", "stab", "enemy", "-rrb-", "preserve", "synthesize", "result", "feedback", "from", "game", "company", "indicate", "quality", "we", "retarget", "movement", "high", "enough", "game", "usage", "interactive", "character", "control", "next", "we", "show", "demo", "use", "interaction", "mesh", "real-time", "control", "character", "pause", "animation", "interaction", "some", "frame", "we", "can", "let", "user", "interactively", "control", "body", "part", "use", "inverse", "kinematic", "while", "maintain", "its", "spatial", "relationship", "other", "character", "-lrb-", "-rrb-", "case", "we", "solve", "eq", "-lrb-", "11", "-rrb-", "single", "frame", "rather", "than", "entire", "motion", "which", "provide", "real-time", "performance", "other", "character", "-lrb-", "-rrb-", "follow", "movement", "controlled", "character", "accord", "interaction", "mesh", "frame", "controlled", "body", "part", "softly", "constrain", "additional", "positional", "constraint", "example", "editing", "posture", "turn-kick", "motion", "show", "fig.", "update", "edit", "frame", "can", "propagate", "whole", "motion", "iteratively", "solve", "eq", "-lrb-", "10", "-rrb-", "use", "edit", "posture", "constraint", "single", "character", "motion", "we", "use", "dancing", "motion", "which", "character", "perform", "arm", "cycling", "motion", "retarget", "character", "monkey", "proportion", "-lrb-", "fig.", "-rrb-", "we", "method", "can", "preserve", "context", "motion", "despite", "much", "longer", "arm", "monkey", "character", "contrast", "method", "-lsb-", "lyard", "MagnenatThalmann", "2008", "-rsb-", "result", "motion", "many", "collision", "cause", "movement", "appear", "unstable", "note", "since", "motion", "do", "involve", "any", "tangle", "topology", "coordinate", "-lsb-", "Ho", "Komura", "2009a", "-rsb-", "also", "difficult", "apply", "Figure", "snapshot", "character", "get", "ride", "car", "model", "-lrb-", "top", "-rrb-", "original", "character", "-lrb-", "bottom", "-rrb-", "tall", "fat", "character", "6.2", "Motion", "Adaptation", "Constrained", "Environment", "Motions", "constrain", "environment", "get", "out", "car", "involve", "close", "maneuver", "collision", "avoidance", "retarget", "motion", "character", "different", "size", "adapt", "motion", "environment", "different", "parameter", "-lrb-", "e.g.", "size", "car", "-rrb-", "have", "great", "demand", "CAD", "design", "digital", "mannequin", "-lsb-", "Badler", "et", "al.", "1999", "-rsb-", "here", "we", "show", "example", "use", "interaction", "mesh", "purpose", "we", "capture", "motion", "person", "get", "car", "hold", "steer", "wheel", "environment", "compose", "simple", "polyline", "represent", "car", "door", "ceiling", "floor", "seat", "steer", "wheel", "interaction", "mesh", "compose", "vertex", "environment", "skeleton", "joint", "end", "effector", "snapshot", "input", "motion", "retarget", "scale", "character", "show", "fig.", "observe", "character?s", "motion", "successfully", "adapt", "new", "character", "size", "since", "some", "interaction", "character", "car", "duck", "pass", "through", "narrow", "space", "can", "describe", "only", "explicit", "constraint", "contact", "motion", "difficult", "handle", "previous", "method", "6.3", "Computational", "cost", "main", "bottleneck", "we", "method", "solve", "large", "linear", "equation", "eq", "-lrb-", "11", "-rrb-", "we", "use", "UMFPACK", "-lsb-", "Davis", "2004", "-rsb-", "gotobla", "-lsb-", "Goto", "Van", "De", "Geijn", "2008", "-rsb-", "since", "laplacian", "matrix", "constraint", "matrix", "both", "sparse", "computation", "only", "increase", "linearly", "respect", "number", "vertex", "all", "interaction", "mesh", "therefore", "complexity", "problem", "-lrb-", "-rrb-", "where", "number", "vertex", "each", "mesh", "number", "frame", "all", "retargeting", "example", "show", "paper", "computation", "require", "each", "motion", "around", "minute", "animation", "100", "frame", "use", "one", "core", "core", "i7", "2.67", "GHz", "CPU", "since", "most", "computation", "computation", "laplacian", "constraint", "matrix", "solve", "large", "linear", "system", "-lsb-", "Bolz", "et", "al.", "2003", "-rsb-", "highly", "parallelizable", "much", "faster", "response", "can", "expect", "GPU", "implementation", "ACM", "transaction", "Graphics", "Vol", "29", "no.", "Article", "33", "publication", "date", "July", "2010", "spatial", "relationship", "preserve", "character", "Motion", "Adaptation", "33:7", "discussion", "section", "we", "compare", "we", "approach", "previous", "method", "term", "advantage", "limitation", "simply", "combine", "kinematic", "constraint", "collision", "avoidance", "do", "-lsb-", "lyard", "magnenat-thalmann", "2008", "-rsb-", "can", "preserve", "spatial", "relationship", "between", "bone", "although", "collision", "detection", "can", "avoid", "interpenetration", "body", "part", "movement", "one", "part", "do", "affect", "movement", "other", "part", "until", "collision", "occur", "moreover", "show", "fig.", "left", "collision", "do", "necessarily", "repulse", "body", "direction", "maintain", "context", "original", "scene", "result", "coordination", "between", "body", "can", "easily", "lose", "we", "method", "interaction", "mesh", "move", "all", "nearby", "bone", "together", "spatial", "relationship", "maintain", "Shi", "et", "al.", "-lsb-", "2007", "-rsb-", "apply", "cascade", "scheme", "motion", "retargeting", "speed", "up", "process", "make", "use", "GPU", "resource", "cascade", "scheme", "inapplicable", "motion", "we", "interest", "since", "may", "greatly", "update", "posture", "after", "one", "iteration", "large", "update", "may", "acceptable", "open", "posture", "standing", "reach", "out", "object", "however", "motion", "close", "interaction", "between", "body", "part", "resolve", "all", "collision", "after", "large", "update", "may", "result", "change", "context", "example", "body", "part", "may", "flip", "opposite", "side", "also", "explain", "why", "we", "need", "gradually", "morph", "morphology", "character", "size", "object", "scene", "concept", "interaction", "mesh", "very", "general", "possible", "compute", "interaction", "mesh", "use", "vertex", "freeform", "mesh", "use", "shape", "deformation", "can", "interesting", "application", "deformation", "transfer", "-lsb-", "Sumner", "Popovic", "2004", "Zayer", "et", "al.", "2005", "-rsb-", "cloth", "animation", "example", "animation", "character", "wrap", "object", "wear", "clothes", "use", "high", "resolution", "volumetric", "mesh", "one", "define", "surface", "mesh", "character", "may", "good", "solution", "intricate", "finger", "motion", "manipulate", "thread", "small", "object", "can", "represent", "detail", "interaction", "between", "finger", "surface", "object", "however", "apply", "method", "spacetime", "control", "full", "body", "character", "very", "computationally", "costly", "due", "huge", "number", "vertex", "Spacetime", "optimization", "know", "important", "tool", "create", "realistic", "character", "motion", "since", "allow", "character", "prepare", "interaction", "ahead", "along", "timeline", "-lsb-", "Liu", "et", "al.", "2006", "-rsb-", "early", "bend", "torso", "before", "enter", "car", "also", "remove", "jaggedness", "from", "movement", "which", "drawback", "frame-based", "approach", "therefore", "we", "argue", "we", "combine", "use", "volumetric", "structure", "define", "joint", "position", "spacetime", "optimization", "good", "design", "choice", "efficient", "synthesis", "realistic", "motion", "interaction", "acceleration", "energy", "term", "might", "unnecessarily", "smooth", "large", "acceleration", "from", "impact", "which", "often", "important", "feature", "motion", "experimentally", "we", "have", "find", "advantage", "use", "acceleration", "term", "outweigh", "smoothing", "high", "impulse", "movement", "one", "possible", "solution", "maintain", "feature", "high", "acceleration", "use", "inter-frame", "laplacian", "coordinate", "propose", "Kwon", "et", "al.", "-lsb-", "2008", "-rsb-", "instead", "acceleration", "energy", "Limitations", "we", "method", "may", "fail", "when", "constraint", "drastically", "different", "from", "those", "original", "motion", "when", "one", "interact", "character", "scale", "too", "small", "too", "large", "situation", "body", "part", "may", "too", "far", "apart", "maintain", "interaction", "however", "any", "method", "use", "inverse", "kinematic", "immune", "problem", "under", "extreme", "scaling", "example", "vulnerability", "when", "character", "contact", "another", "object", "many", "part", "its", "body", "example", "full", "body", "hold", "object?s", "size", "scale", "down", "laplacian", "deformation", "try", "preserve", "spatial", "relationship", "all", "contact", "area", "which", "physically", "impossible", "due", "rigidity", "body", "part", "result", "deformation", "error", "share", "among", "all", "contact", "area", "result", "loss", "all", "contact", "related", "fact", "we", "method", "do", "require", "user-specified", "contact", "constraint", "simple", "possible", "solution", "prioritize", "contact", "impose", "contact", "constraint", "area", "which", "appear", "important", "another", "solution", "may", "recompute", "interaction", "mesh", "certain", "morph-step", "when", "spatial", "relationship", "difficult", "preserve", "allow", "mesh", "drift", "from", "original", "topology", "conclusion", "future", "work", "paper", "we", "have", "present", "new", "method", "edit", "retarget", "character", "animation", "involve", "many", "close", "interaction", "introduce", "new", "representation", "call", "interaction", "mesh", "when", "update", "motion", "spatial", "relationship", "between", "different", "body", "component", "object", "can", "preserve", "apply", "spacetime", "optimization", "minimize", "deformation", "interaction", "mesh", "subject", "collision", "constraint", "well", "bone-length", "positional", "constraint", "method", "fully", "automatic", "require", "manual", "intervention", "from", "user", "we", "have", "demonstrate", "effectiveness", "propose", "method", "show", "realistic", "synthesize", "animation", "various", "type", "close", "interaction", "which", "difficult", "produce", "use", "previous", "method", "future", "work", "we", "plan", "numerically", "evaluate", "topological", "geometric", "feature", "interaction", "mesh", "introduce", "metric", "compare", "motion", "level", "interaction", "mesh", "we", "method", "can", "extend", "use", "reinforcement", "learning", "enable", "computer-controlled", "character", "smartly", "interact", "usercontrolled", "character", "closely", "interact", "environment", "another", "possible", "research", "direction", "apply", "we", "method", "control", "character", "physically-based", "environment", "combine", "balance", "keep", "technique", "-lsb-", "da", "Silva", "et", "al.", "2008", "Macchietto", "et", "al.", "2009", "-rsb-", "tackle", "problem", "may", "also", "lead", "solution", "control", "multi-biped", "robot", "cooperatively", "accomplish", "task", "carry", "object", "together", "acknowledgement", "we", "thank", "anonymous", "reviewer", "constructive", "comment", "Oscar", "Kin-Chung", "Au", "Hubert", "Pak-Ho", "Shum", "valuable", "feedback", "Adam", "Barnett", "video", "narration", "suggestion", "we", "also", "thank", "NAMCO", "BANDAI", "Games", "Inc.", "provide", "game", "motion", "datum", "work", "partially", "support", "grant", "from", "epsrc", "-lrb-", "ep/h012338/1", "-rrb-", "Hong", "Kong", "Research", "Grant", "Council", "-lrb-", "Project", "grf619908", "-rrb-", "reference", "lexa", "M.", "2003", "differential", "coordinate", "local", "mesh", "morphing", "deformation", "Visual", "Computer", "19", "2-3", "105", "114", "LLEN", "B.", "URLESS", "B.", "opovus", "Z.", "2003", "space", "human", "body", "shape", "reconstruction", "parameterization", "from", "range", "scan", "ACM", "transaction", "Graphics", "22", "-lrb-", "jul.", "-rrb-", "587", "594", "R.", "1999", "Communica", "adler", "N.", "I.", "ALMER", "M.", "S.", "INDIGANAVALE", "animation", "control", "real-time", "virtual", "human", "64", "73", "tion", "ACM", "42", "ACM", "transaction", "Graphics", "Vol", "29", "no.", "Article", "33", "publication", "date", "July", "2010", "33:8", "E.", "Ho", "et", "al.", "odenheimer", "B.", "OSE", "C.", "OSENTHAL", "S.", "ellum", "J.", "1997", "process", "motion", "capture", "deal", "datum", "computer", "animation", "simulation", "97", "318", "olz", "J.", "ARMER", "I.", "RINSPUN", "E.", "CHR", "OODER", "P.", "2003", "sparse", "matrix", "solver", "gpu", "conjugate", "gradient", "multigrid", "ACM", "transaction", "Graphics", "22", "-lrb-", "jul.", "-rrb-", "917", "924", "allennec", "B.", "L.", "OULIC", "R.", "2004", "interactive", "motion", "deformation", "prioritize", "constraint", "Proceedings", "ACM", "SIGGRAPH", "Eurographics", "Symposium", "Computer", "Animation", "163", "171", "hous", "k.-j.", "h.-s", "2000", "online", "motion", "retargeting", "Journal", "visualization", "computer", "animation", "11", "223", "235", "DA", "ILVA", "M.", "Y.", "opovus", "J.", "2008", "interactive", "simulation", "stylized", "human", "locomotion", "ACM", "transaction", "Graphics", "27", "-lrb-", "Aug.", "-rrb-", "82:1", "10", "avi", "T.", "A.", "2004", "algorithm", "832", "Umfpack", "unsymmetricpattern", "multifrontal", "method", "ACM", "transaction", "mathematical", "Software", "30", "-lrb-", "jun.", "-rrb-", "196", "199", "ang", "a.", "C.", "ollard", "N.", "S.", "2003", "efficient", "synthesis", "physically", "valid", "human", "motion", "ACM", "transaction", "Graphics", "22", "-lrb-", "jul.", "-rrb-", "417", "426", "leicher", "M.", "1997", "Motion", "editing", "spacetime", "constraint", "Proceedings", "Symposium", "interactive", "3d", "graphic", "139", "148", "leicher", "m.", "1998", "retargett", "motion", "new", "character", "Proceedings", "SIGGRAPH", "98", "ACM", "Press", "ACM", "SIGGRAPH", "M.", "Cohen", "Ed.", "Computer", "Graphics", "Proceedings", "annual", "Conference", "Series", "ACM", "33", "42", "oto", "K.", "eijn", "R.", "2008", "high-performance", "implementation", "level-3", "bla", "ACM", "transaction", "mathematical", "Software", "35", "-lrb-", "jul.", "-rrb-", "14", "E.", "S.", "L.", "OMURA", "T.", "2009", "character", "motion", "synthesis", "topology", "coordinate", "Computer", "Graphics", "Forum", "28", "299308", "E.", "S.", "L.", "OMURA", "T.", "2009", "indexing", "retrieve", "motion", "character", "close", "contact", "IEEE", "transaction", "visualization", "computer", "graphic", "15", "-lrb-", "May", "-rrb-", "481", "492", "OMURA", "T.", "hinagawa", "Y.", "UNII", "T.", "L.", "2000", "create", "retargett", "motion", "musculoskeletal", "human", "body", "model", "Visual", "Computer", "254", "270", "OMURA", "T.", "EUNG", "H.", "UFFNER", "J.", "2004", "animate", "reactive", "motion", "biped", "locomotion", "Proceedings", "ACM", "Virtual", "reality", "Software", "Technology", "32", "40", "WON", "T.", "EE", "K.", "H.", "EE", "J.", "akahashus", "S.", "2008", "Group", "motion", "editing", "ACM", "transaction", "Graphics", "27", "-lrb-", "Aug.", "-rrb-", "80:1", "ALLE", "S.", "UFFNER", "J.", "2001", "rapidly-exploring", "random", "tree", "Progress", "prospects", "Robotics", "algorithmic", "Perspective", "4th", "Int?l", "Workshop", "algorithmic", "foundation", "robotic", "293", "308", "ee", "J.", "HIN", "S.", "Y.", "1999", "hierarchical", "approach", "interactive", "motion", "editing", "human-like", "figure", "Proceedings", "SIGGRAPH", "99", "ACM", "Press", "ACM", "SIGGRAPH", "A.", "Rockwood", "Ed.", "Computer", "Graphics", "Proceedings", "annual", "Conference", "Series", "ACM", "39", "48", "iu", "C.", "K.", "opovus", "Z.", "2002", "synthesis", "complex", "dynamic", "character", "motion", "from", "simple", "animation", "ACM", "transaction", "Graphics", "21", "-lrb-", "jul.", "-rrb-", "408", "416", "iu", "C.", "K.", "ERTZMANN", "a.", "opovic", "Z.", "2006", "composition", "complex", "optimal", "multi-character", "motion", "Proceedings", "ACM", "SIGGRAPH", "Eurographics", "Symposium", "Computer", "Animation", "215", "222", "yard", "E.", "agnenat", "halmann", "N.", "2008", "Motion", "adaptation", "base", "character", "shape", "computer", "animation", "virtual", "world", "19", "3-4", "189", "198", "acchietto", "a.", "ORDAN", "V.", "HELTON", "C.", "R.", "2009", "momentum", "control", "balance", "ACM", "transaction", "Graphics", "28", "-lrb-", "Aug.", "-rrb-", "80:1", "opovus", "Z.", "ITKIN", "a.", "1999", "physically", "base", "motion", "transformation", "Proceedings", "SIGGRAPH", "99", "ACM", "Press", "ACM", "SIGGRAPH", "A.", "Rockwood", "Ed.", "Computer", "Graphics", "Proceedings", "annual", "Conference", "Series", "ACM", "11", "20", "hapiro", "a.", "ALLMANN", "M.", "aloutso", "p.", "2007", "interactive", "motion", "correction", "object", "manipulation", "Proceed", "ing", "ACM", "SIGGRAPH", "Symposium", "interactive", "3d", "graphic", "games,137-144", "hus", "X.", "HOU", "K.", "ong", "Y.", "ESBRUN", "M.", "ao", "H.", "UO", "B.", "2007", "mesh", "puppetry", "cascade", "optimization", "mesh", "deformation", "inverse", "kinematic", "ACM", "transaction", "Graphics", "26", "-lrb-", "jul.", "-rrb-", "81:1", "-9", "hum", "H.", "P.", "H.", "OMURA", "T.", "adav", "P.", "2009", "angular", "momentum", "guide", "motion", "concatenation", "computer", "animation", "virtual", "world", "20", "2-3", "385", "394", "H.", "AERTNER", "K.", "2005", "mesh", "piecewise", "linear", "complex", "constrain", "delaunay", "tetrahedralization", "Proceedings", "14th", "International", "Meshing", "Roundtable", "147", "163", "mith", "R.", "2005", "open", "dynamics", "engine", "www.ode.org", "orkine", "O.", "IPMAN", "Y.", "OHEN", "D.", "LEXA", "M.", "OSSL", "C.", "EIDEL", "h.-p", "2004", "laplacian", "surface", "editing", "Proceedings", "Eurographics/ACM", "SIGGRAPH", "Symposium", "Geometry", "Processing", "179", "188", "umner", "R.", "W.", "opovic", "J.", "2004", "deformation", "transfer", "triangle", "mesh", "ACM", "transaction", "Graphics", "23", "-lrb-", "Aug.", "-rrb-", "397", "403", "W.", "HOU", "K.", "Y.", "Q.", "ENG", "Q.", "UO", "B.", "2007", "gradient", "domain", "editing", "deform", "mesh", "sequence", "ACM", "transaction", "graphic", "26", "-lrb-", "jul.", "-rrb-", "84:1", "10", "amane", "K.", "UFFNER", "J.", "odgin", "J.", "2004", "synthesize", "animation", "human", "manipulation", "task", "ACM", "transaction", "Graphics", "23", "-lrb-", "Aug.", "-rrb-", "532", "539", "AYER", "R.", "OSSL", "C.", "ARNI", "Z.", "EIDEL", "h.-p", "2005", "harmonic", "guidance", "surface", "deformation", "Computer", "Graphics", "Forum", "24", "601", "609", "HOU", "K.", "UANG", "J.", "nyder", "J.", "IU", "X.", "ao", "H.", "UO", "B.", "hum", "h.-y", "2005", "large", "mesh", "deformation", "use", "volumetric", "graph", "laplacian", "ACM", "transaction", "Graphics", "24", "-lrb-", "jul.", "-rrb-", "496", "503", "HOU", "K.", "W.", "ong", "Y.", "ESBRUN", "M.", "2010", "deformation", "transfer", "multi-component", "object", "Computer", "Graphics", "Forum", "29", "ACM", "transaction", "Graphics", "Vol", "29", "no.", "Article", "33", "publication", "date", "July", "2010" ],
  "content" : "\n  \n    49ce1c018883bd451ea07f8924e5eabac538e6896805329029587de441c991b9\n    mi9\n    10.1145/1778765.1778770\n    Name identification was not possible. \n  \n  \n    \n      \n        Spatial Relationship Preserving Character Motion Adaptation\n      \n      Edmond S.L. Ho ? Taku Komura ? Chiew-Lan Tai ? The University of Edinburgh Hong Kong University of Science and Technology\n      \n        \n        Figure 1: Our system can retarget motions of close interactions to characters of different morphologies. A judo interaction (red / orange pair) retargeted to characters of different sizes.\n      \n      This paper presents a new method for editing and retargeting motions that involve close interactions between body parts of single or multiple articulated characters, such as dancing, wrestling, and sword fighting, or between characters and a restricted environment, such as getting into a car. In such motions, the implicit spatial relationships between body parts/objects are important for capturing the scene semantics. We introduce a simple structure called an interaction mesh to represent such spatial relationships. By minimizing the local deformation of the interaction meshes of animation frames, such relationships are preserved during motion editing while reducing the number of inappropriate interpenetrations. The interaction mesh representation is general and applicable to various kinds of close interactions. It also works well for interactions involving contacts and tangles as well as those without any contacts. The method is computationally efficient, allowing real-time character control. We demonstrate its effectiveness and versatility in synthesizing a wide variety of motions with close interactions.  CR Categories: I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism?Animation; I.3.5 [Computer Graphics]: Computational Geometry and Object Modeling?Curve, surface, solid, and object representations; Keywords: Character Animation, Close Interaction, Spatial Relationship, Motion Editing, Motion Retargeting\n      ? e-mail: edmond@edho.net ? e-mail: tkomura@ed.ac.uk ? e-mail: taicl@cse.ust.hk ACM Reference Format Ho, E., Komura, T., Tai, C. 2010. Spatial Relationship Preserving Character Motion Adaptation. ACM Trans. Graph. 29, 4, Article 33 (July 2010), 8 pages. DOI = 10.1145/1778765.1778770 http://doi.acm.org/10.1145/1778765.1778770. Copyright Notice Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or direct commercial advantage and that copies show this notice on the fi rst page or initial screen of a display along with the full citation. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers, to redistribute to lists, or to use any component of this work in other works requires prior specific permission and/or a fee. Permissions may be requested from Publications Dept., ACM, Inc., 2 Penn Plaza, Suite 701, New York, NY 10121-0701, fax +1 (212) 869-0481, or permissions@acm.org . ? 2010 ACM 0730-0301/2010/07-ART33 $10.00 DOI 10.1145/1778765.1778770 http://doi.acm.org/10.1145/1778765.1778770\n    \n    \n      \n        1 Introduction\n      \n      Close interactions, not necessarily with any contacts, between different body parts of single or multiple characters or with the environment are common in computer animation and 3D computer games. Yoga, wrestling, dancing and moving through a constrained environment are some examples. In such motions, the spatial relationships between different body parts of characters are important in capturing the semantics of the scene. When an animator synthesizes or edits such movements, special care is needed to preserve these spatial relationships, for example, ?arching back to avoid a punch?, ?hands extending around each other?, ?two bodies moving synchronously in close proximity? or ?getting into a small car by bending down?. However, traditionally, such spatial relationships exist only in the animator?s mind and are not digitally embedded into the data. Although humans use spatial relationships to recognize semantics of interactions, their usage has not been considered much in character animation.  Existing scene representations have a fundamental limitation in handling such close interactions. Currently, a motion is typically described in terms of joint angles and kinematic constraints such as contacts. With this representation, automatically computing a valid motion requires randomized exploration and significant computation for collision detection. The animator also needs to shoulder the burden of specifying all the kinematic constraints in advance. From the animator?s perspective, this is impractical and not conductive to manual editing. Competitive automatic solutions require an effective representation that allows the extraction of spatial relationships from existing motion data and synthesis of new animations that preserve these relationships. Such a representation will not only allow quantitative evaluation of the way different body parts are interacting, but also facilitate qualitative characterization of scene semantics. In this paper, we propose a simple representation which we call the interaction mesh to represent the spatial relationships between nearby body parts. The interaction mesh is a volumetric mesh defined by the joints of the characters and the vertices of the objects/environment with which the characters are interacting. When editing or retargeting the movements, the motions are automatically adapted by deforming the interaction meshes at all frames with efficient Laplacian deformation techniques [Alexa 2003; Zhou et al. 2005]. The high-level semantics of the interactions are maintained through preserving the local details of the interaction meshes. The interaction mesh representation is general. It provides a unified treatment for interacting body parts of single or multiple characters as well as objects in the environment. As a result, it is applicable to many types of scenarios, such as when single character?s actions involve close interactions between different body parts (dancing) or multi-character interactions (wrestling, fighting games). Additionally, the motions may either involve much tangling and contacts (e.g. judo, Fig. 1 ) or little contact (e.g. Lambada dance). Additionally, it can be applied either per-frame or in the space-time domain according to the complexity of the problem and the available computing resources. Motion adaptation with the interaction mesh is fully automatic. When the animator changes the size or morphology of the characters or edits parts of the motion, the system automatically deforms the interaction meshes at all the frames using a spacetime optimization and creates a new motion sequence that preserves the original context of the scene. No constraints need to be specified by the animator since they are all encoded in the interaction meshes. If desired, the user may add extra constraints such as anchoring the bodies at the feet. The approach is efficient, allowing real-time control of characters in virtual environments. Specifically, the computational cost increases only linearly in the number of frames and the complexity of the articulated body structures. The interaction mesh is useful for synthesizing motions for films, computer games and digital mannequin systems. We demonstrate its usefulness in character animation by retargeting captured human motions to characters of very different proportions and volumes, such as a monkey and also by editing the motions of multiple characters while preserving the original context of the scene. Contributions We introduce a new representation called the interaction mesh for encoding the spatial relationships between closely interacting body parts of articulated characters and objects in environment. We then present an automatic method that uses the interaction mesh for editing or retargeting motions with close interactions. The synthesized motions preserve the spatial relationships, and thus the scene semantics, while reducing the number of inappropriate interpenetrations.\n      ACM Transactions on Graphics, Vol. 29, No. 4, Article 33, Publication date: July 2010.\n      33:2 ? E. Ho et al.\n      \n        \n        Figure 2: The posture of an articulated body retargeted to a new morphology with longer red/green and shorter blue segments. Note that a na?ve approach by joint angles results in a change of context.\n      \n      \n        2 Related Work\n        Most existing motion synthesis methods use kinematic constraints such as positional constraints to enforce a spatial relationship between characters and the environment. A few more recent works on character animation consider implicit spatial relationships.  Constraint-based motion synthesis Since kinematic constraints can usually be represented by single equations, they can be easily embedded into optimization problems for motion synthesis. Such an approach has been adopted for physically-based animation [Popovi? and Witkin 1999; Komura et al. 2000; Liu and Popovi?? 2002; Fang and Pollard 2003], motion editing [Gleicher 1997; Callennec and Boulic 2004; Komura et al. 2004; Liu et al. 2006; Shum et al. 2009] and motion retargeting [Gleicher 1998; Lee and Shin 1999; Choi and Ko 2000]. One of the early works by Gleicher [1998] handles close interactions of multiple characters. He retargets close dancing motions of two characters to bodies of different sizes while keeping their hands connected using positional constraints. Other methods avoid penetrations of interacting body parts by using inequality constraints [Liu et al. 2006] or a combination of collision detections and equality constraints [Xu et al. 2007; Shi et al. 2007]. These methods produce excellent results for interactions with contacts, however, they are not applicable for maintaining spatial relationships that are less explicit, because representing them as single equations is difficult. For example, in Lambada dances, the dancers twist their bodies around each other without necessarily any body contact. Handling such motions where the interaction conditions are largely implicit is difficult since the context of the scene must be preserved while avoiding penetrations and collisions. Without a good representation of such implicit spatial relationships, the motion synthesis requires complex global path planners involving significant collision detection effort and randomized exploration [LaValle and Kuffner 2001; Yamane et al. 2004; Shapiro et al. 2007], which is difficult for large numbers of degrees of freedom. Character animation by spatial relationships There have been a few recent works which take into account the implicit spatial relationships of multiple characters when synthesizing new animations. Kwon et al. [2008] handle the spatial relationships between characters in group motions by encoding the neighborhood formations and individual trajectories as Laplacian coordinates. When editing the trajectories, the relative spatial arrangements of characters are preserved by applying Laplacian mesh editing techniques [Alexa 2003; Sorkine et al. 2004]. Our method is similar in that we also employ Laplacian mesh editing technique, but we are addressing a very different problem. The individual characters in their case are 2D particles with no close interactions. In contrast, our method aims to preserve the spatial relationships between the bodies of 3D articulated characters, which requires considering the connections at the joints, rigidity of the body components and penetrations between them. Ho and Komura [2009b] use Gauss Linking Integral to detect tangled limbs and encode them using rational tangles for motion retrieval. They later proposed a new representation called topology coordinates for representing tangled body parts [Ho and Komura 2009a] and applied it to synthesize character motions in close contact. These methods are adequate for handling motions involving tangles between 1D manifolds such as strands or skeletons. However, extension to motions involving character shapes seems difficult since relationships between rigid bodies or surfaces need to be encoded. Further, these methods cannot handle close interactions without any tangles. The proposed method considers the relationships among rigid body parts and is more general since it can handle motions of close interactions with/without tangles. A recent work by Zhou et al. [2010] for deformation transfer represents the spatial relationships between multiple components of an object by Euclidean distance and encode them using a minimum spanning tree. Since the spatial relationships are assumed to be fixed (same as rest pose) during deformation, the method is not applicable to motions with time-varying spatial relationships.\n      \n      \n        3 Overview\n        We give an overview of our method in this section. First, the data of the original characters and the motion is loaded into our sys tem. Each body segment of the character model is surrounded by a bounding volume which will be used for collision detection. The interaction mesh is then computed for every time frame. Next, the user edits or retargets the motion by specifying some of the following: the target body sizes, morphology, target positions or new trajectories of some body parts. These constraint parameters are then interpolated and used to morph the original bodies to the target bodies. At every morph-step, the entire motion is adapted towards achieving the target motion. This iterative approach is necessary since the collisions between the body parts/objects need to be carefully monitored and resolved. At every morph-step, the system adapts the motion by minimizing the Laplacian deformation of the interaction meshes at all the animation frames (or a fixed window of frames at a time, according to available computing resources) and the acceleration of the bodies in these frames (see Fig. 2 for an example of the adapted result of one frame). This spacetime optimization is performed to ensure temporal coherence of the motion. The optimization is subject to various constraints, namely, bone-length constraints, collision constraints and positional constraints. Collisions are then detected between the bounding volumes. If collisions are detected, the penetration depths are evaluated and a new set of collision constraints are defined to resolve the penetrations in the next morph-step.\n        ACM Transactions on Graphics, Vol. 29, No. 4, Article 33, Publication date: July 2010.\n        Spatial Relationship Preserving Character Motion Adaptation ? 33:3\n      \n      \n        4 Interaction Mesh\n        In this section, we describe how we compute the interaction meshes for a given motion. We assume that the mesh characters are rigged with skeletons, and each body segment is bounded by a volume (we use capsules and boxes in our experiments). The postures of the characters are represented by the positions of the joints, rather than the joint angles. Using the joint positions as parameters has the advantage of making the constraint matrix sparse since the joints are treated as independent particles. In contrast, using the joint angles as parameters makes the Jacobian matrix very dense, as the joints near the root affect the movements of all the joints below in the hierarchy [Shi et al. 2007]. We compute the volumetric interaction mesh for every animation frame. Using the positions of joints and vertices of objects as a point cloud, we apply Delaunay tetrahedralization [Si and Gaertner 2005] (see Figure 2 ). Note that the spatial relationships which we want to preserve are those between body parts that are in close proximity and are not occluded by other parts. Since the Delaunay tetrahedralization favors connecting such parts with edges, the Laplacian coordinates of vertices which are defined by vertex neighborhood will lead to mutual influence between these body parts. By the nature of Laplacian mesh editing in preserving local details, the spatial relationships of our interest will be maintained. The orientation of some body segments cannot be computed only from the positions of joints bounding that segment. For example, the joint positions of the elbow and the wrist are insufficient to confirm the rotation around the forearm. In order to compute such orientations, we sample one extra virtual vertex on the surface of each bounding volume, as in [Shi et al. 2007]. These additional virtual vertices are added to the point cloud when defining the interaction mesh. Since each virtual vertex is not rigidly constrained to the body parts, its position is brought back to the original local coordinate frame once the bone?s orientation is confirmed. Another possible solution is to use inverse kinematics. The orientation of the body segments can be inferred from the joint positions and the orientation in the original motion [Bodenheimer et al. 1997]. Such an approach can keep the number of vertices in the interaction mesh low.\n      \n      \n        5 Spacetime Deformation\n        In this section we present the spacetime optimization problem that we solve to adapt the motion at each morph-step. The spatial relationships of the body parts/objects are preserved by minimizing the Laplacian deformation energy of all the interaction meshes [Alexa 2003; Zhou et al. 2005] subject to constraints derived from the morphed body sizes, detected collision and user-defined position constraints. We also introduce an acceleration energy to reduce jaggedness between frames.  Deformation energy Let m be the number of vertices in the interaction mesh, p ij (1 ? j ? m) be the vertices at frame i, V i be a vector of size 3m that includes all p ij such that V i = (p i 1 ? , ? ? ? , p i m ? ), and p ij ? and V ? i be the updated vectors after the deformation. The deformation energy of the mesh is defined as\n        \n          1\n          E L (V ? i ) = 1 2 ? j ? L(p ij ? ) 2 j\n        \n        \n          2\n          = 1 2 V i ? ? M i ? M i V ? i ? b ? i M i V i ? + 1 2 b ? i b i\n        \n        where L is the operator to compute the Laplacian coordinates from the vertex locations V i , ? j is the original Laplacian coordinate, and M i , b i are the matrix and vector, respectively, computed by expanding Eq.(1). The Laplacian coordinates are calculated by:\n      \n      \n        L(p = w\n        \n          3\n          j j ) p j ? l p l\n        \n        l?N j\n        j where N j is the one-ring neighborhood of p j and w l are the normalized weights which are set as inversely proportional to the distance between the vertices so that farther apart vertices have less influence on each other.  Acceleration energy To reduce jaggy jumps between frames, we introduce an acceleration energy term E A which imposes temporal relations between corresponding vertices in adjacent frames. Specifically, to reduce sudden acceleration, we minimize the movement of the corresponding vertices in adjacent frames:\n      \n      \n        E\n        \n          4\n          A (V ? i?1 , V ? i , V i+1 ? ) = 2 1 V ? i?1 ? 2V ? i + V ? i+1 2\n        \n        where V ? is the set of vertices at frame i\n      \n      \n        i.\n        5.1 Constraints\n        Here we explain the bone-length constraints, positional constraints and collision constraints imposed in the spacetime deformation.  Bone-length constraints We introduce the bone-length constraints in order to morph the bone lengths (distance between adjacent joints) from the original scales to the target scales. In each morph-step and each animation frame, the target length l e for each bone e is computed by linearly blending the original and final lengths. Then, a constraint enforcing the target length is imposed as ( p 1 e ? ? p 2 e ? ? l e ) 2 where p 1 e ? , p 2 e ? are the end vertices of the edge e. Linearizing all the bone-length constraints result in\n      \n      \n        C\n        \n          5\n          B (V i ? ) = B i V ? i ? l,\n        \n        where B i is the Jacobian matrix and l is a vector of constant terms.\n        ACM Transactions on Graphics, Vol. 29, No. 4, Article 33, Publication date: July 2010.\n        33:4 ? E. Ho et al.\n        Sometimes the bone-length constraints may conflict with the Laplacian deformation energy which means satisfying the bone-length constraints increases the Laplacian deformation energy. This conflict is the main source of slow convergence. We cope with this problem by excluding the vertex p b from the neighborhood of vertex p a when computing the Laplacian coordinate of p a if the edge connecting p a and p b corresponds to a bone of the body.  Positional constraints The user can add positional constraints by anchoring some joints or a linear combination of their locations. The original trajectories of these body parts are gradually morphed to the given trajectories in each morph-step. We compute the target locations of these parts, P i , using linear interpolation, and write the positional constraints as:\n      \n      \n        C\n        \n          6\n          K (V i ? ) = K i V i ? ? P i\n        \n        where K is a 3k ? 3m weight matrix that defines the influence of each joint in each positional constraint, and k is the number of positional constraints.  Collision constraints The collision constraints prevent penetration between the bounding volumes of the skeleton. We perform collision detection by applying the ODE library [Smith 2005] to the current configuration of the bounding volumes. Specifically, when a penetration is detected, we compute the penetration depth, directions and the point pair penetrating each other the farthest and add the following constraints:\n      \n      \n        C\n        \n          7\n          C (V ? i ) = J i V ? i ? d i\n        \n        where J i is the Jacobian of the positions of the colliding parts with respect to the joint positions, and d i is the penetration depth multiplied to the normal vectors of the penetrated surface. The Jacobian is computed by finite differencing. The joint vertices are moved and the locations of the penetrating points are recomputed according to the posture. We do not apply collision detection to adjacent body parts along the body tree structure as self-penetrations easily happen when the joints are bent.  Constraint energy We separate the constraints in Eq.(5)-7 into soft and hard constraints:\n        \n          8\n          F i V ? i = f i (soft), H i V ? i = h i (hard)\n        \n        and define a constraint energy that represents the amount of violation of the soft constraints:\n        \n          9\n          E C (V i ? ) = 2 1 V ? i ? F i ? WF i V i ? ? f i ? WF i V ? i + 1 2 f i ? Wf i .\n        \n        where W is a square diagnol matrix that assigns a different weight to each constraint. By default, we set the bone-length constraints and one positional constraint (supporting foot) hard, and the collision constraints and the rest of positional constraints soft. The bone-length constraints are set hard so that the bodies are correctly scaled to the target values. Soft collision constraints stabilize the motion when there is little open space. It also provides the animator some results when collisions cannot be avoided due to insufficient open space when bodies are enlarged. It is also necessary to set the other positional constraints soft to avoid over constraining. By default, the weights in W are set 4.0 and 0.4 for the collision and additional positional constraints, respectively. The constraints can be switched between soft and hard according to the desired animation effect. When the number of morph steps is small, we also need to set the bone-length constraints soft, and their weights are set to 2.0.\n        Algorithm 1 Motion Adaptation by Interaction Mesh Input: Skeleton and input motion sequence initial / final body scaling factors: s 0 , s f locations of initial/final positional constraints: p 0 , p f Output: Target motion sequence (Initialization) Compute the interaction meshes (vertex positions and connectivity) of all input frames.\n      \n      \n        k=1 N\n      \n      \n        i = n.\n        (Motion Adaptation) for to morph-steps do Update body scale / location of positional constraints: s k ? N?k N s 0 + N k s f , p j ? N?k N p 0 + N k p f Update the constraint matrices F i , H i , the target values of the constraints f i , h i in Eq.(8) and the deformation vector b i in Eq.(2) for frames 1, ..., Update the vertex locations by solving Eq.(10). Compute segment orientations and update virtual vertices. end for\n        5.2 Iterative Morphing\n        At every morph-step, the body sizes and the positional constraints are updated, and the motions of the characters are adapted by minimizing the sum of the deformation (Eq.1), acceleration (Eq.4) and constraint energy (Eq.9) of all frames subject to the hard constraints. The adapted motion is computed by solving n\n      \n      \n        E + w ? E + E\n        \n          10\n          arg min V i ? ,? i (1?i?n) L A C + ? ? i (H i V i ? ? h i )\n        \n        i where n is the number of frames, V ? is the set of new vertex posii tions at frame i, ? i are the Lagrange multipliers and w ? is a constant weight (we use 0.2). Note that E A is not defined for the first and last frames, hence we set them to zero. The spacetime optimization problem in Eq.(10) can be solved by differentiating it with respect to V i ? and ? i , and solving the following linear equation:\n      \n      \n        w\n        M ? M + ? A ? A + F k ? WF k C k ? V C k 0 ?\n      \n      \n        f\n        \n          11\n          M ? B + F k ? W = H\n        \n        where B, H, f , V and ? are vectors that include b i (in Eq.2), h i , f i (in Eq.8), V ? i and ? i for all the frames, respectively, i.e. B = (b ? 1 , ...b ? n ) ? , H = (h 1 ? , ...h n ? ) ? , f = (f 1 ? , ...f n ? ) ? , V = (V 1 ?? , ...V ?? n ) ? , ? = (? 1 ? , ...? n ? ) ? and M is the Laplacian matrix, F k is a soft constraint matrix at the k-th morph-step, each of which includes M i in Eq.(2), and F i in Eq.(8) for all the frames, respectively: M = ? ? ? ? ? ? ? ? ? ? ? ? M 0 . . . 1 ??? .. . M 0 n ? ? ? ? ? ? ? ? ? ? ? ? , F k = ? ? ? ? ? ? ? ? ? ? ? ? ? F 0 . . . 1 k ??? .. . F 0 k n ? ? ? ? ? ? ? ? ? ? ? ? ? , and A is a matrix that computes the acceleration for all the frames from V, W = diag(W, ..., W), and C k is the constraint matrix at the k-th morph-step, which includes H i in Eq.(8) for all the frames:  Our motion adaptation algorithm is summarized in Algorithm 1. The interaction meshes are defined for the original motion frames and their connectivities are kept unchanged at all the morph-steps, which results in a constant M. Note that re-computing the tetrahedralization at each morph-step would result in gradual drifting of the motion away from the original sequence. Keeping the mesh topology from the original motion helps to preserve the spatial relationships of the components in the original motion. Possible artifacts and solutions Due to the non-uniform weighting of the edges, drastic updates of the morphing parameters such as the character sizes may result in flipping of the tetrahedra in the interaction meshes. Such flipping, if it occurs in an open space does not cause noticeable artifacts, but may result in a change of context if it happens with a tetrahedron composed of two bones which are nearby but not adjacent to each other. We prevent the flipping by detecting collisions between the body parts and applying the collision constraints (Eq.7) at each morph step. However, the system may fail when the linearization of the collision constraints breaks down, which happens when the body sizes are very narrow and the penetration depth is too large. This results in pushing out the penetrating body in the wrong direction (see Fig. 3 ). The problem can be avoided by giving enough volume to the body parts and setting small morph steps. We obtained satisfactory results using 10 morph-steps for all the examples. The soft collision constraints can result in penetrations when the bodies are enlarged too much while there is limited open space. We can alert the user of the lack of space by giving the sum of the squares of penetration depth for reference. The user can then choose to either enlarge the environment or stop scaling. The system may become unstable when the original motion contains movements where the body parts pass through each other. When this happens, the direction the collision constraint pushes the bodies away from each other will turn opposite at some moment, resulting in a large movement in one frame. This contradicts the minimization of acceleration energy and causes vibrations. Switching off the collision constraints at the frames of these pass throughs can remove such artifacts.\n        ACM Transactions on Graphics, Vol. 29, No. 4, Article 33, Publication date: July 2010.\n        0 A = ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? I ?2I .. I I . ?2I 0 I ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? , C k = ? ? ? ? ? ? ? ? ? ? ? ? ? H 0 . . . k 1 ??? .. . H 0 n k ? ? ? ? ? ? ? ? ? ? ? ? ? .\n        Spatial Relationship Preserving Character Motion Adaptation ? 33:5\n        \n          \n          Figure 3: Flipping of a tetrahedron during a morph-step may lead to a change of spatial context: (left) initial posture, (middle) flipping happens at the left lower leg of the yellow character when using 5 morph-steps, (right) flipping avoided when using 10 morphsteps.\n        \n      \n      \n        6 Experimental Results\n        In this section, we show experimental results from applying our motion retargeting method to character animation. We apply it to several types of motions with close interactions, namely, between body parts of a single character or multiple characters, and between a character and its environment. We also demonstrate its usefulness for real-time character control. The heights of the feet are all\n        \n          \n          Figure 4: Snapshots of a sword attacking motion (left) retargeted to characters of different morphologies (middle, right).\n        \n        \n          \n          Figure 5:\n        \n        Snapshots of a back breaking attacking motion (left) retargeted to characters of different morphologies (middle, right).\n        constrained to the original values by hard constraints by default, which are necessary especially when the characters are standing on the ground. The readers are referred to the supplementary video for further details.\n        \n          6.1 Retargeting Motions of Close Interactions\n          First we show the results of retargeting motions involving only characters. We use motions involving much tangling and contacts, such as judo, as well as those with few contacts, such as dancing and attackers/defenders in fighting games.  Judo attacks Our first motion example is a judo ?Ogoshi throw? in which the attacker holds the arm and the waist of the defender and throws the defender by carrying him/her onto the back. We retarget the motions of the thrower and the defender to characters of various morphologies. We use the body sizes of characters in Allen et al. [2003] as reference (See Fig. 1 ). Here, although the proportions and the bounding volumes of the new characters are completely different from those of the original characters, our system can still produce the Ogoshi throw. Note that previous motion editing/retargeting approaches are difficult to apply to this kind of close interactions since they only consider the joint angles of the original motion but not the spatial relationships. As a result, the retargeted motion may have a different context (e.g. the arms extend to the other side of the defender?s body). They also require the animators to manually specify all the positional constraints in all the frames, such as the attacker?s hand holding the defender?s body. This can be a tedious task for the animator. Fighting scenes Our next two motion examples are fighting scenes involving two characters provided by a game company. The first scene involves a character holding a sword attacking its enemy. The sword penetrates through the enemy character when the enemy is stabbed, and therefore, we turned off the collision constraint in those frames. The second scene is from the same game. The character holding the sword breaks the back of the enemy with both arms and drops it. The sword unintentionally passes through the arm of the defender in some of the frames, which is due to the manual design. Again, we turned off the collision constraint in those frames. Both the attacker?s and defender?s morphologies are changed and animations of different combination of bodies are created. Snapshots of the original and synthesized motions are shown in Fig. 4 and Fig. 5 , respectively. Note that manual editing would\n          ACM Transactions on Graphics, Vol. 29, No. 4, Article 33, Publication date: July 2010.\n          33:6 ? E. Ho et al.\n          \n            \n            Figure 6:\n          \n          (left) A posture of a turn kick interaction. (middle, right) The animator drags the left foot of the yellow character by mouse and the other character moves to preserve the spatial relationship.\n          \n            \n            Figure 7:\n          \n          Original dancing motion (middle) and the retargeted results to a monkey model with long arms using a joint-angle based method (left) and using our method (right).\n          require a lot of care to avoid unintentional penetrations of the sword into the body. Our method can automatically produce the motion of passing the sword into the space between the enemy?s arm and torso. These examples show that our method can also be used for manually designed motions which are not penetration-free. In such cases, the context of the penetrations (e.g. stabbing the enemy) are preserved in the synthesized results. Feedback from the game company indicates that the quality of our retargeted movements is high enough for games usage.  Interactive character control Next, we show a demo of using the interaction mesh for real-time control of characters. Pausing the animation of interaction at some frame, we can let the user interactively control a body part using inverse kinematics while maintaining its spatial relationships with the other character(s). In such cases, we solve Eq.(11) for a single frame rather than for the entire motion, which provides real-time performance. The other character(s) will follow the movements of the controlled character according to the interaction mesh at that frame. The controlled body part is softly constrained by an additional positional constraint. An example of editing a posture in a turn-kick motion is shown in Fig. 6 . The updates in the edited frame can be propagated to the whole motion by iteratively solving Eq.(10) using the edited posture as a constraint. Single character motions We use a dancing motion in which the character performs an arms cycling motion and retarget it to a character with monkey proportions ( Fig. 7 ). Our method can preserve the context of the motion despite the much longer arms of the monkey character. In contrast, the method of [Lyard and MagnenatThalmann 2008] results in a motion with many collisions, causing the movements to appear unstable. Note that since this motion does not involve any tangles, the topology coordinates [Ho and Komura 2009a] are also difficult to apply.\n          \n            \n            Figure 8:\n          \n          Snapshots of a character getting into and riding a car model; (top) original character and (bottom) a tall fat character.\n          6.2 Motion Adaptation in a Constrained Environment\n          Motions in a constrained environment, such as getting in and out of a car, involve close maneuvers and collision avoidance. Retargeting such motions to characters of different sizes or adapting the motions to environment with different parameters (e.g. size of car) has a great demand in CAD design and digital mannequins [Badler et al. 1999]. Here we show examples of using the interaction mesh for such a purpose. We captured the motion of a person getting into a car and holding the steering wheel. The environment is composed of simple polylines representing the car doors, ceiling, floor, seats, and steering wheel. The interaction mesh is composed of the vertices of the environment and the skeleton joints and end effectors. Snapshots of the input motion and that retargeted to a scaled character are shown in Fig. 8 . Observe that the character?s motion is successfully adapted to the new character size. Since some of the interactions of the character with the car, such as ducking and passing through the narrow space, cannot be described only with explicit constraints such as contacts, these motions are difficult to handle for previous methods.\n        \n        \n          6.3 Computational Costs\n          The main bottleneck of our method is solving the large linear equation in Eq.(11). We use UMFPACK [Davis 2004] and GotoBLAS [Goto and Van De Geijn 2008]. Since the Laplacian matrix M and the constraint matrix C k are both sparse, the computation only increases linearly with respect to the number of vertices in all the interaction meshes. Therefore, the complexity of the problem is O(m ? n), where m is the number of vertices in each mesh and n is the number of frames. For all the retargeting examples shown in this paper, the computation required for each motion is around 1 minute for an animation of 100 frames, using one core of a Core i7 2.67GHz CPU. Since most of the computation, such as the computation of the Laplacian and constraint matrices and solving the large linear system [Bolz et al. 2003] are highly parallelizable, much faster response can be expected with GPU implementations.\n          ACM Transactions on Graphics, Vol. 29, No. 4, Article 33, Publication date: July 2010.\n          Spatial Relationship Preserving Character Motion Adaptation ? 33:7\n        \n      \n      \n        7 Discussions\n        In this section, we compare our approach with previous methods in terms of advantages and limitations. Simply combining the kinematic constraints and collision avoidance as is done in [Lyard and Magnenat-Thalmann 2008] cannot preserve spatial relationships between bones. Although collision detection can avoid interpenetration of body parts, the movement of one part does not affect the movements of the other parts until collision occurs. Moreover, as shown in Fig. 7 , left, the collision does not necessarily repulse the body in the direction that maintains the context of the original scene. As a result, coordination between the bodies can easily be lost. With our method, the interaction mesh moves all the nearby bones together such that their spatial relationships are maintained. Shi et al. [2007] apply a cascading scheme for motion retargeting to speed up the process and make use of the GPU resources. Such a cascading scheme is inapplicable to the motions of our interest since it may greatly update the posture after one iteration. Large updates may be acceptable for open postures such as standing and reaching out for an object, however for motions with close interactions between body parts, resolving all the collisions after a large update may result in a change of context, for example, the body parts may be flipped to the opposite side. This also explains why we need to gradually morph the morphology of the characters and sizes of objects in the scene. The concept of the interaction mesh is very general. It is possible to compute the interaction mesh using vertices of freeform meshes and use it for shape deformation. This can be an interesting application of deformation transfer [Sumner and Popovic 2004; Zayer et al. 2005] and cloth animation. For example, animation of a character wrapping an object or wearing clothes. Using a high resolution volumetric mesh, such as one defined by the surface of a mesh character, may be a good solution for intricate finger motions, such as manipulating a thread or small object, as it can represent the details of the interaction between the fingers? surface and the object. However, applying such a method for spacetime control of a full body character will be very computationally costly due to the huge number of vertices. Spacetime optimization is known to be an important tool for creating realistic character motions since it allows the characters to prepare for the interactions ahead along the timeline [Liu et al. 2006], such as an early bending of the torso before entering a car. It also removes jaggedness from the movements, which is a drawback of frame-based approaches. Therefore, we argue that our combined use of a volumetric structure defined by joint positions and the spacetime optimization is a good design choice for efficient synthesis of realistic motions of interactions. The acceleration energy term might unnecessarily smooth the large accelerations from impacts, which is often an important feature of motions. Experimentally, we have found the advantage of using the acceleration term outweigh the smoothing of high impulse movements. One possible solution for maintaining the features of high acceleration is to use inter-frame Laplacian coordinates proposed in Kwon et al. [2008] instead of the acceleration energy. Limitations Our method may fail when the constraints are drastically different from those in the original motion, such as when one of the interacting characters is scaled too small or too large. In such situations, the body parts may be too far apart to maintain the interactions. However, any methods that use inverse kinematics are not immune to such a problem under extreme scaling. An example of this vulnerability is when a character is in contact with another object at many parts of its body, for example, a full body hold. If the object?s size is scaled down, the Laplacian deformation will try to preserve the spatial relationship at all the contact areas, which is physically impossible due to the rigidity of the body parts. As a result, the deformation error will be shared among all the contact areas, resulting in the loss of all contacts. This is related to the fact that our method does not require user-specified contact constraints. A simple possible solution is to prioritize such contacts and impose contact constraints at areas which appear to be important. Another solution may be to recompute the interaction meshes at certain morph-steps when the spatial relationship is difficult to preserve and allow the mesh to drift from the original topology.\n      \n      \n        8 Conclusion and Future Work\n        In this paper, we have presented a new method to edit and retarget character animation that involves many close interactions by introducing a new representation called interaction mesh. When updating the motion, the spatial relationships between different body components and objects can be preserved by applying a spacetime optimization to minimize the deformation of the interaction meshes subject to collision constraints as well as bone-length and positional constraints. The method is fully automatic, not requiring manual intervention from the user. We have demonstrated the effectiveness of the proposed method by showing realistic synthesized animations of various types of close interactions, which are difficult to produce using previous methods. As a future work, we plan to numerically evaluate the topological and geometric features of the interaction meshes, and introduce a metric to compare motions at the level of interaction meshes. Our method can then be extended for use in reinforcement learning, enabling computer-controlled characters to smartly interact with usercontrolled characters in closely interacting environments. Another possible research direction is to apply our method for controlling characters in physically-based environments, such as by combining it with the balance keeping techniques in [da Silva et al. 2008; Macchietto et al. 2009]. Tackling such a problem may also lead to solutions for controlling multi-biped robots to cooperatively accomplish tasks such as carrying objects together.\n      \n      \n        Acknowledgement\n        We thank the anonymous reviewers for their constructive comments, Oscar Kin-Chung Au and Hubert Pak-Ho Shum for valuable feedback and Adam Barnett for the video narration and suggestions. We also thank NAMCO BANDAI Games Inc. for providing the game motion data. This work was partially supported by grants from EPSRC (EP/H012338/1) and the Hong Kong Research Grant Council (Project No. GRF619908).\n      \n      \n        References\n        \n          A LEXA , M. 2003. Differential coordinates for local mesh morphing and deformation. The Visual Computer 19, 2-3, 105?114.\n          A LLEN , B., C URLESS , B., AND P OPOVI C  ? , Z. 2003. The space of human body shapes: reconstruction and parameterization from range scans. ACM Transactions on Graphics 22, 3 (Jul.), 587? 594. , R. 1999.\n        \n      \n      \n        Communica-\n        B ADLER , N. I., P ALMER , M. S., AND B INDIGANAVALE Animation control for real-time virtual humans. 8, 64?73.\n      \n      \n        tions of the ACM 42,\n        ACM Transactions on Graphics, Vol. 29, No. 4, Article 33, Publication date: July 2010.\n        33:8 ? E. Ho et al.\n        B ODENHEIMER , B., R OSE , C., R OSENTHAL , S., AND P ELLA ., J. 1997. The process of motion capture: Dealing with the data. In Computer Animation and Simulation 97, 318. B OLZ , J., F ARMER , I., G RINSPUN , E., AND S CHR OODER  ? , P. 2003. Sparse matrix solvers on the gpu: conjugate gradients and multigrid. ACM Transactions on Graphics 22, 3 (Jul.), 917?924. C ALLENNEC , B. L., AND B OULIC , R. 2004. Interactive motion deformation with prioritized constraints. In Proceedings of ACM\n      \n      \n        SIGGRAPH / Eurographics Symposium on Computer Animation,\n        163?171. C HOI , K.-J., AND K O , H.-S. 2000. Online motion retargeting. Journal of Visualization and Computer and Animation 11, 5, 223?235. DA S ILVA , M., A BE , Y., AND P OPOVI C  ? , J. 2008. Interactive simulation of stylized human locomotion. ACM Transactions on Graphics 27, 3 (Aug.), 82:1?10. D AVIS , T. A. 2004. Algorithm 832: Umfpack, an unsymmetricpattern multifrontal method. ACM Transactions on Mathematical Software 30, 2 (Jun.), 196?199. F ANG , A. C., AND P OLLARD , N. S. 2003. Efficient synthesis of physically valid human motion. ACM Transactions on Graphics 22, 3 (Jul.), 417?426. G LEICHER , M. 1997. Motion editing with spacetime constraints. In Proceedings of Symposium on Interactive 3D Graphics, 139? 148. G LEICHER , M. 1998. Retargetting motion to new characters. In Proceedings of SIGGRAPH 98, ACM Press / ACM SIGGRAPH, M. Cohen, Ed., Computer Graphics Proceedings, Annual Conference Series, ACM, 33?42. G OTO , K., AND V AN D E G EIJN , R. 2008. High-performance implementation of the level-3 blas. ACM Transactions on Mathematical Software 35, 1 (Jul.), 1?14. H O , E. S. L., AND K OMURA , T. 2009. Character motion synthesis by topology coordinates. Computer Graphics Forum 28, 2, 299308. H O , E. S. L., AND K OMURA , T. 2009. Indexing and retrieving motions of characters in close contact. IEEE Transactions on Visualization and Computer Graphics 15, 3 (May), 481?492. K OMURA , T., S HINAGAWA , Y., AND K UNII , T. L. 2000. Creating and retargetting motion by the musculoskeletal human body model. The Visual Computer, 5, 254?270. K OMURA , T., L EUNG , H., AND K UFFNER , J. 2004. Animating reactive motions for biped locomotion. In Proceedings of ACM Virtual Reality Software and Technology, 32?40. K WON , T., L EE , K. H., L EE , J., AND T AKAHASHI , S. 2008. Group motion editing. ACM Transactions on Graphics 27, 3 (Aug.), 80:1?8. L A V ALLE , S., AND K UFFNER , J. 2001. Rapidly-exploring random trees: Progress and prospects. In Robotics: The Algorithmic\n      \n      \n        Perspective. 4th Int?l Workshop on the Algorithmic Foundations\n        of Robotics, 293?308. L EE , J., AND S HIN , S. Y. 1999. A hierarchical approach to interactive motion editing for human-like figures. In Proceedings of SIGGRAPH 99, ACM Press / ACM SIGGRAPH, A. Rockwood, Ed., Computer Graphics Proceedings, Annual Conference Series, ACM, 39?48.  L IU , C. K., AND P OPOVI C  ? ?, Z. 2002. Synthesis of complex dynamic character motion from simple animations. ACM Transactions on Graphics 21, 3 (Jul.), 408?416. L IU , C. K., H ERTZMANN , A., AND P OPOVIC , Z. 2006. Composition of complex optimal multi-character motions. In Proceedings\n      \n      \n        of ACM SIGGRAPH / Eurographics Symposium on Computer\n        Animation, 215?222. L YARD , E., AND M AGNENAT -T HALMANN , N. 2008. Motion adaptation based on character shape. Computer Animation and Virtual Worlds 19, 3-4, 189?198. M ACCHIETTO , A., Z ORDAN , V., AND S HELTON , C. R. 2009. Momentum control for balance. ACM Transactions on Graphics 28, 3 (Aug.), 80:1?8. P OPOVI C  ? , Z., AND W ITKIN , A. 1999. Physically based motion transformation. In Proceedings of SIGGRAPH 99, ACM Press / ACM SIGGRAPH, A. Rockwood, Ed., Computer Graphics Proceedings, Annual Conference Series, ACM, 11?20. S HAPIRO , A., K ALLMANN , M., AND F ALOUTSOS , P. 2007. Interactive motion correction and object manipulation. In Proceed-\n      \n      \n        ings of ACM SIGGRAPH Symposium on Interactive 3D graphics and Games,137-144.\n        S HI , X., Z HOU , K., T ONG , Y., D ESBRUN , M., B AO , H., AND G UO , B. 2007. Mesh puppetry: Cascading optimization of mesh deformation with inverse kinematics. ACM Transactions on Graphics 26, 3 (Jul.), 81:1-9 S HUM , H. P. H., K OMURA , T., AND Y ADAV , P. 2009. Angular momentum guided motion concatenation. Computer Animation and Virtual Worlds 20, 2-3, 385?394. S I , H., AND G AERTNER , K. 2005. Meshing piecewise linear complexes by constrained delaunay tetrahedralizations. In Proceedings of the 14th International Meshing Roundtable, 147?163. S MITH , R. 2005. Open dynamics engine. www.ode.org. S ORKINE , O., L IPMAN , Y., C OHEN -O R , D., A LEXA , M., R OSSL  ? , C., AND S EIDEL , H.-P. 2004. Laplacian surface editing. In Proceedings of the Eurographics/ACM SIGGRAPH Symposium on Geometry Processing, 179?188. S UMNER , R. W., AND P OPOVIC , J. 2004. Deformation transfer for triangle meshes. ACM Transactions on Graphics 23, 3 (Aug.), 397?403. X U , W., Z HOU , K., Y U , Y., T AN , Q., P ENG , Q., AND G UO , B. 2007. Gradient domain editing of deforming mesh sequences. ACM Transactions on Graphics, 26, 3 (Jul.), 84:1?10. Y AMANE , K., K UFFNER , J., AND H ODGINS , J. 2004. Synthesizing animations of human manipulation tasks. ACM Transactions on Graphics 23, 3 (Aug.), 532?539. Z AYER , R., R OSSL  ? , C., K ARNI , Z., AND S EIDEL , H.-P. 2005. Harmonic guidance for surface deformation. Computer Graphics Forum 24, 3, 601?609. Z HOU , K., H UANG , J., S NYDER , J., L IU , X., B AO , H., G UO , B., AND S HUM , H.-Y. 2005. Large mesh deformation using the volumetric graph laplacian. ACM Transactions on Graphics 24, 3 (Jul.), 496?503. Z HOU , K., X U , W., T ONG , Y., AND D ESBRUN , M. 2010. Deformation transfer to multi-component objects. Computer Graphics Forum 29, 2.\n        ACM Transactions on Graphics, Vol. 29, No. 4, Article 33, Publication date: July 2010.\n      \n    \n  ",
  "resources" : [ ]
}