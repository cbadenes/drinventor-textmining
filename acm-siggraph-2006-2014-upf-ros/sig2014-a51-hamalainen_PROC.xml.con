{
  "uri" : "sig2014-a51-hamalainen_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2014/a51-hamalainen_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Online Motion Synthesis Using Sequential Monte Carlo",
    "published" : null,
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ ]
  },
  "bagOfWords" : [ "we", "have", "test", "we", "method", "three", "way", "-rrb-", "throw", "sphere", "character", "-rrb-", "add", "sudden", "impulse", "body", "part", "disturb", "balance", "throw", "character", "around", "-rrb-", "trigger", "simulated", "explosion", "add", "impulse", "all", "body", "part", "figure", "10", "11", "14", "illustrate", "test", "test", "character", "able", "avoid", "sphere", "avoidance", "behavior", "implicitly", "cause", "jerk", "minimization", "goal", "recover", "lose", "balance", "creative", "way", "roll", "over", "shoulder", "land", "back", "its", "foot", "get", "up", "when", "throw", "ground", "we", "describe", "result", "both", "qualitatively", "-lrb-", "section", "5.1", "-rrb-", "quantitatively", "-lrb-", "section", "5.2", "-rrb-", "follow", "we", "refer", "supplemental", "video", "use", "time", "parenthesis", "-lrb-", "mm", "ss", "-rrb-", "Performance", "supplemental", "video", "capture", "real-time", "-lrb-", "use", "Fraps", "www.fraps.com", "-rrb-", "Windows", "pc", "Intel", "Core", "i7-4930k", "3.40", "GHz", "CPU", "-lrb-", "12", "logical", "core", "-rrb-", "NVIDIA", "GeForce", "GTX", "480", "GPU", "computer", "optimizer", "run", "approximately", "20", "fp", "1/30s", "physics", "time", "step", "25", "sample", "per", "frame", "planning", "horizon", "seconds", "2012", "MacBook", "pro", "laptop", "2.4", "GHz", "processor", "same", "setting", "yield", "6-10", "fp", "enough", "interactive", "experiment", "parameter", "tuning", "which", "we", "consider", "one", "best", "aspect", "system", "show", "video", "25", "sample", "enough", "synthesize", "variety", "movement", "whereas", "use", "100", "sample", "-lrb-", "01:39", "-rrb-", "slow", "simulation", "down", "considerably", "other", "hand", "use", "fewer", "sample", "per", "frame", "shorter", "planning", "horizon", "yield", "fully", "real-time", "unreliable", "result", "-lrb-", "01:21", "-rrb-", "system", "show", "considerable", "creativity", "adapt", "surprising", "situation", "utilize", "environment", "example", "character", "dodge", "sphere", "use", "pirouette", "jump", "-lrb-", "02:22", "-rrb-", "slide", "dodge", "rolling", "sphere", "use", "hand", "keep", "sphere", "away", "-lrb-", "00:32", "-rrb-", "when", "character?s", "head", "punch", "ground", "continue", "movement", "cartwheel", "sort", "rise", "up", "-lrb-", "00:49", "-rrb-", "take", "step", "emerge", "avoidance", "strategy", "-lrb-", "02:42", "Figure", "11", "-rrb-", "although", "always", "successfully", "-lrb-", "01:48", "-rrb-", "character", "also", "often", "land", "its", "foot", "when", "throw", "air", "-lrb-", "00:00", "00:38", "-rrb-", "top", "left", "corner", "video", "show", "which", "alternative", "objective", "function", "component", "give", "highest", "score", "best", "score", "sample", "balance", "correspond", "get", "up", "use", "2", "plan", "horizon", "sampler", "often", "able", "find", "balancing", "strategy", "while", "still", "roll", "ground", "after", "impact", "-lrb-", "01:02", "01:12", "-rrb-", "main", "drawback", "system", "movement", "sometimes", "stiff", "have", "unnecessary", "joint", "contortion", "-lrb-", "02:18", "-rrb-", "stiffness", "probably", "cause", "we", "parameterization", "use", "target", "angle", "instead", "joint", "torque", "torque", "limit", "optimization", "do", "help", "e.g.", "soften", "landing", "however", "sampling", "and/or", "goal", "able", "relax", "character?s", "hand", "many", "case", "character", "also", "often", "keep", "hand", "greedily", "close", "target", "pose", "even", "when", "nearly", "balanced", "we", "experiment", "shoulder", "elbow", "torque", "minimization", "goal", "easily", "lead", "other", "extreme", "hand", "hang", "limp", "which", "do", "look", "natural", "we", "fighter", "character", "heuristic", "balancing", "initial", "guess", "can", "also", "cause", "character", "assume", "target", "pose", "prematurely", "while", "still", "move", "-lrb-", "02:03", "-rrb-", "sometimes", "appear", "almost", "unphysical", "character", "uncannily", "know", "although", "sway", "ultimately", "end", "up", "balanced", "without", "heuristic", "machine", "learning", "guess", "however", "character", "keep", "hower", "about", "target", "pose", "illustrate", "typically", "slow", "final", "convergence", "global", "sampling", "method", "combine", "global", "sampling", "local", "refinement", "clearly", "topic", "future", "work", "future", "one", "easy", "way", "improve", "naturalness", "movement", "could", "script", "learn", "control", "gaze", "head", "orientation", "example", "real", "human", "typically", "follow", "fly", "object", "gaze", "try", "look", "expect", "landing", "spot", "while", "airborne", "hand", "foot", "contact", "ground", "could", "also", "fine-tuned", "e.g.", "so", "character", "always", "exert", "force", "ground", "use", "palm", "instead", "fingertip", "we", "expect", "can", "do", "use", "purely", "visual", "correction", "base", "inverse", "kinematic", "instead", "modify", "optimization", "remain", "future", "work", "we", "have", "also", "test", "two", "other", "balance", "pose", "asymmetric", "Taido", "-lrb-", "martial", "art", "-rrb-", "ready", "stance", "regular", "standing", "position", "both", "pose", "work", "although", "regular", "standing", "appear", "more", "difficult", "less", "stable", "support", "polygon", "smaller", "COM", "higher", "system", "stochastic", "hence", "may", "occasionally", "provide", "good", "result", "even", "just", "few", "sample", "ensure", "we", "result", "representative", "we", "have", "run", "quantitative", "balancing", "avoidance", "test", "vary", "parameter", "each", "test", "100", "sphere", "throw", "character", "from", "random", "direction", "sphere", "3x", "heavier", "than", "character", "i.e.", "failure", "avoid", "ball", "almost", "certainly", "lead", "character", "fall", "down", "we", "measure", "percentage", "time", "character", "balanced", "seconds", "after", "ball", "throw", "determine", "threshold", "objective", "function", "value", "succeed", "character", "could", "either", "dodge", "ball", "get", "successfully", "up", "after", "fail", "dodge", "test", "also", "save", "screenshot", "each", "failure", "case", "most", "typical", "case", "wide", "split", "lie", "back", "supplementary", "video", "show", "difficult", "situation", "-lrb-", "01:33", "01:48", "-rrb-", "left", "side", "Figure", "12", "show", "success", "percentage", "function", "optimizer", "sample", "per", "frame", "four", "condition", "st", "denote", "standard", "setup", "use", "capture", "supplemental", "video", "-lrb-", "2s", "planning", "horizon", "lightweight", "character", "model", "-rrb-", "st+ml", "FLANN", "prediction", "be", "generate", "each", "frame", "from", "dataset", "100k", "training", "vector", "which", "yield", "better", "result", "low", "sample", "budget", "indicate", "we", "system", "can", "utilize", "machine", "learning", "intend", "hv", "curve", "denote", "heavier", "character", "model", "change", "compare", "st", "which", "yield", "abysmal", "success", "rate", "low", "sample", "budget", "Performance", "better", "hv2", "case", "where", "we", "activate", "roll", "away", "from", "back", "goal", "use", "3.5", "plan", "horizon", "measure", "success", "after", "longer", "seconds", "after", "each", "ball", "throw", "right", "side", "Figure", "12", "show", "successful", "attempt", "function", "greedy", "sampling", "parameter", "appear", "sweet", "spot", "25-50", "greedy", "sample", "all", "we", "test", "supplemental", "video", "capture", "use", "25", "Figure", "13", "show", "successful", "attempt", "function", "number", "sample", "length", "planning", "horizon", "one", "can", "see", "2", "horizon", "use", "supplementary", "video", "reasonable", "default", "longer", "horizon", "do", "produce", "considerable", "benefit", "system", "show", "considerable", "creativity", "adapt", "surprising", "situation", "utilize", "environment", "example", "character", "dodge", "sphere", "use", "pirouette", "jump", "-lrb-", "02:22", "-rrb-", "slide", "dodge", "rolling", "sphere", "use", "hand", "keep", "sphere", "away", "-lrb-", "00:32", "-rrb-", "when", "character?s", "head", "punch", "ground", "continue", "movement", "cartwheel", "sort", "rise", "up", "-lrb-", "00:49", "-rrb-", "take", "step", "emerge", "avoidance", "strategy", "-lrb-", "02:42", "Figure", "11", "-rrb-", "although", "always", "successfully", "-lrb-", "01:48", "-rrb-", "character", "also", "often", "land", "its", "foot", "when", "throw", "air", "-lrb-", "00:00", "00:38", "-rrb-", "top", "left", "corner", "video", "show", "which", "alternative", "objective", "function", "component", "give", "highest", "score", "best", "score", "sample", "balance", "correspond", "get", "up", "use", "2", "plan", "horizon", "sampler", "often", "able", "find", "balancing", "strategy", "while", "still", "roll", "ground", "after", "impact", "-lrb-", "01:02", "01:12", "-rrb-", "main", "drawback", "system", "movement", "sometimes", "stiff", "have", "unnecessary", "joint", "contortion", "-lrb-", "02:18", "-rrb-", "stiffness", "probably", "cause", "we", "parameterization", "use", "target", "angle", "instead", "joint", "torque", "torque", "limit", "optimization", "do", "help", "e.g.", "soften", "landing", "however", "sampling", "and/or", "goal", "able", "relax", "character?s", "hand", "many", "case", "character", "also", "often", "keep", "hand", "greedily", "close", "target", "pose", "even", "when", "nearly", "balanced", "we", "experiment", "shoulder", "elbow", "torque", "minimization", "goal", "easily", "lead", "other", "extreme", "hand", "hang", "limp", "which", "do", "look", "natural", "we", "fighter", "character", "heuristic", "balancing", "initial", "guess", "can", "also", "cause", "character", "assume", "target", "pose", "prematurely", "while", "still", "move", "-lrb-", "02:03", "-rrb-", "sometimes", "appear", "almost", "unphysical", "character", "uncannily", "know", "although", "sway", "ultimately", "end", "up", "balanced", "without", "heuristic", "machine", "learning", "guess", "however", "character", "keep", "hower", "about", "target", "pose", "illustrate", "typically", "slow", "final", "convergence", "global", "sampling", "method", "combine", "global", "sampling", "local", "refinement", "clearly", "topic", "future", "work", "future", "one", "easy", "way", "improve", "naturalness", "movement", "could", "script", "learn", "control", "gaze", "head", "orientation", "example", "real", "human", "typically", "follow", "fly", "object", "gaze", "try", "look", "expect", "landing", "spot", "while", "airborne", "hand", "foot", "contact", "ground", "could", "also", "fine-tuned", "e.g.", "so", "character", "always", "exert", "force", "ground", "use", "palm", "instead", "fingertip", "we", "expect", "can", "do", "use", "purely", "visual", "correction", "base", "inverse", "kinematic", "instead", "modify", "optimization", "remain", "future", "work", "we", "have", "also", "test", "two", "other", "balance", "pose", "asymmetric", "Taido", "-lrb-", "martial", "art", "-rrb-", "ready", "stance", "regular", "standing", "position", "both", "pose", "work", "although", "regular", "standing", "appear", "more", "difficult", "less", "stable", "support", "polygon", "smaller", "COM", "higher", "system", "stochastic", "hence", "may", "occasionally", "provide", "good", "result", "even", "just", "few", "sample", "ensure", "we", "result", "representative", "we", "have", "run", "quantitative", "balancing", "avoidance", "test", "vary", "parameter", "each", "test", "100", "sphere", "throw", "character", "from", "random", "direction", "sphere", "3x", "heavier", "than", "character", "i.e.", "failure", "avoid", "ball", "almost", "certainly", "lead", "character", "fall", "down", "we", "measure", "percentage", "time", "character", "balanced", "seconds", "after", "ball", "throw", "determine", "threshold", "objective", "function", "value", "succeed", "character", "could", "either", "dodge", "ball", "get", "successfully", "up", "after", "fail", "dodge", "test", "also", "save", "screenshot", "each", "failure", "case", "most", "typical", "case", "wide", "split", "lie", "back", "supplementary", "video", "show", "difficult", "situation", "-lrb-", "01:33", "01:48", "-rrb-", "left", "side", "Figure", "12", "show", "success", "percentage", "function", "optimizer", "sample", "per", "frame", "four", "condition", "st", "denote", "standard", "setup", "use", "capture", "supplemental", "video", "-lrb-", "2s", "planning", "horizon", "lightweight", "character", "model", "-rrb-", "st+ml", "FLANN", "prediction", "be", "generate", "each", "frame", "from", "dataset", "100k", "training", "vector", "which", "yield", "better", "result", "low", "sample", "budget", "indicate", "we", "system", "can", "utilize", "machine", "learning", "intend", "hv", "curve", "denote", "heavier", "character", "model", "change", "compare", "st", "which", "yield", "abysmal", "success", "rate", "low", "sample", "budget", "Performance", "better", "hv2", "case", "where", "we", "activate", "roll", "away", "from", "back", "goal", "use", "3.5", "plan", "horizon", "measure", "success", "after", "longer", "seconds", "after", "each", "ball", "throw", "right", "side", "Figure", "12", "show", "successful", "attempt", "function", "greedy", "sampling", "parameter", "appear", "sweet", "spot", "25-50", "greedy", "sample", "all", "we", "test", "supplemental", "video", "capture", "use", "25", "Figure", "13", "show", "successful", "attempt", "function", "number", "sample", "length", "planning", "horizon", "one", "can", "see", "2", "horizon", "use", "supplementary", "video", "reasonable", "default", "longer", "horizon", "do", "produce", "considerable", "benefit", "we", "have", "demonstrate", "Sequential", "Monte", "Carlo", "-lrb-", "SMC", "-rrb-", "sampling", "viable", "approach", "online", "synthesis", "complex", "human", "movement", "without", "reliance", "animation", "motion", "capture", "datum", "central", "feature", "system", "use", "kd-tree", "sampling", "non-uniform", "spline", "pose", "interpolation", "rigid", "body", "physics", "engine", "custom", "modification", "ensure", "reproducible", "simulation", "while", "key", "component", "adaptive", "sequential", "sampling", "method", "allow", "easy", "integration", "machine", "learn", "draw", "previous", "experience", "we", "surprise", "performance", "sampler", "even", "without", "machine", "learning", "use", "dimensionality", "reduction", "method", "constrain", "search", "space", "we", "have", "integrate", "we", "system", "unity3d", "state-of-the-art", "commercial", "game", "engine", "result", "release", "open", "source", "however", "we", "believe", "we", "sampler", "simple", "enough", "also", "implement", "from", "scratch", "we", "see", "improve", "performance", "control", "style", "synthesize", "movement", "two", "main", "item", "future", "work", "we", "expect", "both", "can", "address", "precompute", "suitable", "prior", "sampling", "and/or", "develop", "interactive", "training", "application", "where", "user", "may", "instruct", "machine", "learning", "system", "learn", "most", "interesting", "movement", "have", "emerge", "we", "parameterization", "also", "allow", "pose-space", "dimensionality", "reduction", "accord", "we", "initial", "experiment", "do", "make", "abnormal", "pose", "less", "frequent", "however", "heavy", "dimensionality", "reduction", "use", "small", "training", "set", "easily", "overconstrain", "movement", "while", "larger", "training", "set", "allow", "character", "use", "pose", "abnormal", "context", "e.g.", "kick", "while", "balancing", "Contextual", "temporal", "information", "could", "incorporate", "e.g.", "use", "offline", "optimization", "generate", "training", "set", "control", "spline", "follow", "motion", "capture", "trajectory", "similar", "-lsb-", "Muico", "et", "al.", "2009", "-rsb-", "future", "we", "also", "plan", "explore", "novel", "interaction", "game", "mechanic", "utilize", "motion", "synthesis", "investigate", "whether", "sequential", "sampling", "competitive", "also", "offline", "synthesis", "where", "function", "landscape", "change", "over", "time", "when", "animator", "interactively", "adjust", "parameter", "could", "also", "interesting", "simulate", "muscle", "animation", "breathing", "grunt", "etc.", "base", "predict", "near-future", "exertion", "-lrb-", "e.g.", "i?ll", "jump", "breathe", "out", "one", "second", "better", "breath", "now", "-rrb-" ],
  "content" : "We have tested our method in three ways: 1) throwing spheres at the character, 2) adding sudden impulses to body parts to disturb balance and throw the character around, and 3) triggering simulated explosions that add impulses to all body parts. Figures 1, 10, 11, and 14 illustrate these tests. In the tests, the character is able to avoid the spheres ? the avoidance behavior implicitly caused by the jerk minimization goal ? recover lost balance in creative ways, such as rolling over the shoulders to land back on its feet, and get up when thrown to the ground. We describe the results both qualitatively (Section 5.1) and quantitatively (Section 5.2). In the following, we refer to the supplemental video using the time in parenthesis (mm:ss). Performance The supplemental video was captured in real-time (using Fraps, www.fraps.com) on a Windows 7 PC with Intel Core i7-4930k 3.40GHz CPU (12 logical cores), and an NVIDIA GeForce GTX 480 GPU. On this computer, the optimizer runs at approximately 20 fps with a 1/30s physics time step, N = 25 samples per frame, and a planning horizon of 2 seconds. On a 2012 MacBook Pro laptop with a 2.4GHz processor, the same settings yield 6-10 fps, enough for interactive experimenting and parameter tuning, which we consider one of the best aspects of the system. As shown in the video, 25 samples is enough to synthesize a variety of movements, whereas using 100 samples (01:39) slows the simulation down considerably. On the other hand, using fewer samples per frame or a shorter planning horizon yields fully real-time but unreliable results (01:21). The system shows considerable creativity in adapting to surprising situations and utilizing the environment. For example, the character dodges the spheres using pirouette jumps (02:22) and slides to dodge a rolling sphere, using a hand to keep the sphere away (00:32). When the character?s head is punched to the ground, it continues the movement as a cartwheel of sorts and rises up (00:49). Taking steps emerges as an avoidance strategy (02:42, Figure 11 ), although not always successfully (01:48). The character also often lands on its feet when thrown in the air (00:00, 00:38). The top left corner of the video shows which of the alternative objective function components gives the highest score for the best scoring sample. ?Balancing? corresponds to f b and ?Getting up? to w u f u . Using the 2s planning horizon, the sampler is often able to find a balancing strategy while still rolling on the ground after an impact (01:02, 01:12). The main drawbacks of the system are that movement is sometimes stiff and has unnecessary joint contortions (02:18). The stiffness is probably caused by our parameterization using target angles instead of joint torques. The torque limit optimization does help, e.g., in softening landings; however, the sampling and/or the goals are not able to relax the character?s hands in many cases. The character also often keeps the hands greedily close to the target pose even when not nearly balanced. We experimented with shoulder and elbow torque minimization goals, but this easily leads to the other extreme of the hands hanging limp, which does not look natural for our fighter character. The heuristic balancing initial guess can also cause the character to assume the target pose prematurely while still moving (02:03). Sometimes this appears almost unphysical, as the character uncannily knows that although it is swaying, it will ultimately end up balanced. Without the heuristic or machine learning guesses, however, the character keeps howering about the target pose, illustrating a typically slow final convergence of global sampling methods. Combining global sampling with local refinement is clearly a topic for future work. In the future, one easy way to improve the naturalness of the movements could be scripted or learned control of gaze and head orientation. For example, real humans typically follow flying objects with their gaze, and try to look at the expected landing spot while airborne. The hand and foot contacts with the ground could also be fine-tuned, e.g., so that the character always exerts forces on the ground using the palm instead of fingertips. We expect that this can be done using purely visual corrections based on inverse kinematics instead of modifying the optimization, but this remains future work. We have also tested two other balancing poses an asymmetric Taido (a martial art) ready stance and a regular standing position. Both poses work, although the regular standing appears more difficult it is less stable as the support polygon is smaller and COM is higher. The system is stochastic, and hence may occasionally provide good results even with just a few samples. To ensure that our results are representative, we have run a quantitative balancing and avoidance test with varying parameters. In each test, 100 spheres are thrown at the character from random directions. The spheres are 3x heavier than the character, i.e., failure to avoid the ball almost certainly leads to the character falling down. We measured the percentage of times the character was balanced 5 seconds after the ball was thrown, determined by thresholding the objective function value. To succeed, the character could either dodge the ball, or get successfully up after a failed dodge. The test also saves a screenshot of each failure case. The most typical cases are wide splits and lying on the back. The supplementary video shows that these are difficult situations (01:33, 01:48). The left side of Figure 12 shows the success percentage as a function of optimizer samples per frame in four conditions. ST denotes the ?standard? setup used in capturing the supplemental video (2s planning horizon, lightweight character model). In ST+ML, 3 FLANN predictions were generated in each frame from a dataset of 100k training vectors, which yielded better results at low sample budgets. This indicates that our system can utilize machine learning as intended. The HV curve denotes the heavier character model with no changes compared to ST, which yields abysmal success rates at low sample budgets. Performance is better in the HV2 case, where we activated the ?roll away from back? goal, used a 3.5s planning horizon, and measured success after a longer period of 8 seconds after each ball throw. The right side of Figure 12 shows the successful attempts as a function of the greedy sampling parameter N g . There appears to be a sweet spot of 25-50% greedy samples. All our tests and the supplemental video capturing use N g = 25%. Figure 13 shows the successful attempts as a function of the number of samples and the length of the planning horizon. One can see that the 2s horizon used in the supplementary video is a reasonable default, and longer horizons do not produce considerable benefit. The system shows considerable creativity in adapting to surprising situations and utilizing the environment. For example, the character dodges the spheres using pirouette jumps (02:22) and slides to dodge a rolling sphere, using a hand to keep the sphere away (00:32). When the character?s head is punched to the ground, it continues the movement as a cartwheel of sorts and rises up (00:49). Taking steps emerges as an avoidance strategy (02:42, Figure 11 ), although not always successfully (01:48). The character also often lands on its feet when thrown in the air (00:00, 00:38). The top left corner of the video shows which of the alternative objective function components gives the highest score for the best scoring sample. ?Balancing? corresponds to f b and ?Getting up? to w u f u . Using the 2s planning horizon, the sampler is often able to find a balancing strategy while still rolling on the ground after an impact (01:02, 01:12). The main drawbacks of the system are that movement is sometimes stiff and has unnecessary joint contortions (02:18). The stiffness is probably caused by our parameterization using target angles instead of joint torques. The torque limit optimization does help, e.g., in softening landings; however, the sampling and/or the goals are not able to relax the character?s hands in many cases. The character also often keeps the hands greedily close to the target pose even when not nearly balanced. We experimented with shoulder and elbow torque minimization goals, but this easily leads to the other extreme of the hands hanging limp, which does not look natural for our fighter character. The heuristic balancing initial guess can also cause the character to assume the target pose prematurely while still moving (02:03). Sometimes this appears almost unphysical, as the character uncannily knows that although it is swaying, it will ultimately end up balanced. Without the heuristic or machine learning guesses, however, the character keeps howering about the target pose, illustrating a typically slow final convergence of global sampling methods. Combining global sampling with local refinement is clearly a topic for future work. In the future, one easy way to improve the naturalness of the movements could be scripted or learned control of gaze and head orientation. For example, real humans typically follow flying objects with their gaze, and try to look at the expected landing spot while airborne. The hand and foot contacts with the ground could also be fine-tuned, e.g., so that the character always exerts forces on the ground using the palm instead of fingertips. We expect that this can be done using purely visual corrections based on inverse kinematics instead of modifying the optimization, but this remains future work. We have also tested two other balancing poses an asymmetric Taido (a martial art) ready stance and a regular standing position. Both poses work, although the regular standing appears more difficult it is less stable as the support polygon is smaller and COM is higher. The system is stochastic, and hence may occasionally provide good results even with just a few samples. To ensure that our results are representative, we have run a quantitative balancing and avoidance test with varying parameters. In each test, 100 spheres are thrown at the character from random directions. The spheres are 3x heavier than the character, i.e., failure to avoid the ball almost certainly leads to the character falling down. We measured the percentage of times the character was balanced 5 seconds after the ball was thrown, determined by thresholding the objective function value. To succeed, the character could either dodge the ball, or get successfully up after a failed dodge. The test also saves a screenshot of each failure case. The most typical cases are wide splits and lying on the back. The supplementary video shows that these are difficult situations (01:33, 01:48). The left side of Figure 12 shows the success percentage as a function of optimizer samples per frame in four conditions. ST denotes the ?standard? setup used in capturing the supplemental video (2s planning horizon, lightweight character model). In ST+ML, 3 FLANN predictions were generated in each frame from a dataset of 100k training vectors, which yielded better results at low sample budgets. This indicates that our system can utilize machine learning as intended. The HV curve denotes the heavier character model with no changes compared to ST, which yields abysmal success rates at low sample budgets. Performance is better in the HV2 case, where we activated the ?roll away from back? goal, used a 3.5s planning horizon, and measured success after a longer period of 8 seconds after each ball throw. The right side of Figure 12 shows the successful attempts as a function of the greedy sampling parameter N g . There appears to be a sweet spot of 25-50% greedy samples. All our tests and the supplemental video capturing use N g = 25%. Figure 13 shows the successful attempts as a function of the number of samples and the length of the planning horizon. One can see that the 2s horizon used in the supplementary video is a reasonable default, and longer horizons do not produce considerable benefit. We have demonstrated that Sequential Monte Carlo (SMC) sampling is a viable approach for online synthesis of complex human movements without reliance on animation or motion capture data. The central features of the system are the use of kD-trees for sampling, non-uniform splines for pose interpolation, and a rigid body physics engine with custom modifications to ensure reproducible simulations. While the key component, an adaptive sequential sampling method, allows easy integration of machine learning to draw on previous experience, we are surprised by the performance of the sampler even without machine learning or using dimensionality reduction methods to constrain the search space. We have integrated our system with Unity3D, a state-of-the-art commercial game engine. The results will be released as open source. However, we believe our sampler is simple enough to also implement from scratch. We see improving performance and controlling the style of synthesized movement as the two main items for future work. We expect that both can be addressed by precomputing a suitable prior for the sampling, and/or developing an interactive training application where the user may instruct a machine learning system to learn the most interesting movements that have emerged. Our parameterization also allows for pose-space dimensionality reduction, and according to our initial experiments, it does make abnormal poses less frequent. However, heavy dimensionality reduction using a small training set easily overconstrains the movement while a larger training set allows the character to use poses in abnormal contexts, e.g., kicking while balancing. Contextual and temporal information could be incorporated, e.g., by using offline optimization to generate a training set of control splines that follow motion capture trajectories, similar to [Muico et al. 2009]. In the future, we also plan to explore novel interactions and game mechanics utilizing the motion synthesis, and investigate whether sequential sampling is competitive also in offline synthesis, where the function landscape changes over time when the animator interactively adjusts parameters. It could also be interesting to simulate muscle animation, breathing, grunting etc. based on the predicted near-future exertion (e.g., ?I?ll jump and breathe out in one second, better breath in now?).",
  "resources" : [ ]
}