{
  "uri" : "sig2013-a78-liu_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2013/a78-liu_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Bundled Camera Paths for Video Stabilization",
    "published" : "2013",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Shuaicheng-Liu",
      "name" : "Shuaicheng",
      "surname" : "Liu"
    }, {
      "uri" : "http://drinventor/Lu-Yuan",
      "name" : "Lu",
      "surname" : "Yuan"
    }, {
      "uri" : "http://drinventor/Ping-Tan",
      "name" : "Ping",
      "surname" : "Tan"
    }, {
      "uri" : "http://drinventor/Jian Sun-null",
      "name" : "Jian Sun",
      "surname" : null
    } ]
  },
  "bagOfWords" : [ "we", "present", "novel", "video", "stabilization", "method", "which", "model", "camera", "motion", "bundle", "-lrb-", "multiple", "-rrb-", "camera", "path", "propose", "model", "base", "mesh-based", "spatially-variant", "motion", "representation", "adaptive", "space-time", "path", "optimization", "we", "motion", "representation", "allow", "we", "fundamentally", "handle", "parallax", "roll", "shutter", "effect", "while", "do", "require", "long", "feature", "trajectory", "sparse", "3d", "reconstruction", "we", "introduce", "as-similaras-possible", "idea", "make", "motion", "estimation", "more", "robust", "cr", "category", "i.", "4.3", "-lsb-", "image", "processing", "computer", "Vision", "-rsb-", "enhancement?registration", "keyword", "video", "stabilization", "image", "warping", "camera", "path", "Links", "dl", "pdf", "video", "capture", "hand-held", "device", "-lrb-", "e.g.", "cell-phone", "portable", "camcorder", "-rrb-", "often", "appear", "remarkably", "shaky", "undirected", "Digital", "video", "stabilization", "improve", "video", "quality", "remove", "unwanted", "camera", "motion", "great", "practical", "importance", "because", "device", "-lrb-", "mobile", "phone", "tablet", "camcorder", "-rrb-", "capable", "capture", "video", "have", "become", "widespread", "online", "sharing", "so", "ubiquitous", "prior", "video", "stabilization", "method", "synthesize", "new", "stabilize", "video", "estimate", "smooth", "2d", "camera", "motion", "-lsb-", "Matsushita", "et", "al.", "2006", "Grundmann", "et", "al.", "2011", "-rsb-", "3d", "camera", "motion", "-lsb-", "Liu", "et", "al.", "2009", "Liu", "et", "al.", "2012", "-rsb-", "general", "2d", "method", "more", "robust", "faster", "because", "only", "estimate", "linear", "transformation", "-lrb-", "affine", "homography", "-rrb-", "between", "consecutive", "frame", "2d", "linear", "motion", "model", "too", "weak", "fundamentally", "handle", "parallax", "cause", "non-trivial", "depth", "variation", "scene", "contrary", "3d", "method", "can", "deal", "parallax", "principle", "generate", "strongly", "stabilize", "result", "however", "motion", "model", "estimation", "less", "robust", "various", "degeneration", "feature", "tracking", "failure", "motion", "blur", "camera", "zooming", "rapid", "rotation", "some", "recent", "method", "-lsb-", "Liu", "et", "al.", "2011", "Goldstein", "Fattal", "2012", "-rsb-", "have", "successfully", "combine", "advantage", "two", "kind", "method", "nevertheless", "require", "long", "feature", "tracking", "-lrb-", "typically", "over", "20", "frame", "-rrb-", "make", "difficult", "handle", "more", "challenging", "case", "-lrb-", "e.g.", "rapid", "motion", "fast", "scene", "transition", "large", "occlusion", "-rrb-", "consumer", "video", "paper", "aim", "same", "goal", "robust", "high-quality", "result", "from", "opposite", "direction", "we", "propose", "more", "powerful", "2d", "camera", "motion", "model", "other", "word", "each", "different", "location", "video", "have", "its", "own", "camera", "path", "same", "time", "model", "enjoy", "robustness", "simplicity", "2d", "method", "because", "only", "require", "feature", "correspondence", "between", "two", "consecutive", "frame", "first", "component", "represent", "motion", "between", "two", "consecutive", "frame", "mesh-based", "spatially-variant", "homography", "-lrb-", "figure", "-lrb-", "-rrb-", "-rrb-", "as-similar-aspossible", "regularization", "constraint", "-lsb-", "Igarashi", "et", "al.", "2005", "Schaefer", "et", "al.", "2006", "-rsb-", "constraint", "critical", "because", "estimate", "model", "high", "degree", "freedom", "usually", "risky", "case", "insufficient", "feature", "large", "occlusion", "best", "we", "knowledge", "first", "work", "employ", "mesh-based", "as-similar-aspossible", "regularization", "spatially-variant", "motion", "estimation", "video", "stabilization", "we", "directly", "use", "mesh", "vertex", "motion", "model", "itself", "intermediate", "representation", "use", "3d", "reconstruction", "-lsb-", "Liu", "et", "al.", "2009", "-rsb-", "subspace", "-lsb-", "Liu", "et", "al.", "2011", "-rsb-", "base", "propose", "motion", "representation", "we", "construct", "bundle", "camera", "path", "each", "which", "concatenation", "local", "homography", "same", "grid", "cell", "over", "time", "-lrb-", "figure", "-lrb-", "-rrb-", "-rrb-", "furthermore", "avoid", "excessive", "cropping/geometrical", "distortion", "approximate", "cinematography", "favor", "path", "we", "adopt", "discontinuity-preserving", "idea", "similar", "bilateral", "filter", "-lsb-", "Tomasi", "Manduchi", "1998", "-rsb-", "adaptively", "control", "strength", "smoothing", "we", "show", "we", "new", "2d", "method", "comparable", "outperform", "other", "competitive", "2d", "3d", "method", "2d", "method", "estimate", "2d", "transformation", "between", "consecutive", "video", "frame", "smooth", "they", "over", "time", "generate", "steady", "video", "some", "method", "assume", "prior", "motion", "model", "polynomial", "curve", "-lsb-", "Chen", "et", "al.", "2008", "-rsb-", "desire", "camera", "trajectory", "Grundmann", "et", "al.", "-lsb-", "2012", "-rsb-", "further", "adopt", "homography-array-based", "motion", "model", "deal", "roll", "shutter", "effect", "two", "technique", "have", "be", "integrate", "Google", "YouTube", "robust", "follow", "cinematography", "rule", "perform", "well", "many", "consumer", "video", "we", "method", "belong", "category", "Liu", "et", "al.", "-lsb-", "2009", "-rsb-", "develop", "first", "successful", "3d", "video", "stabilization", "system", "first", "introduce", "content-preserving", "warp", "stabilization", "Liu", "et", "al.", "-lsb-", "2011", "-rsb-", "smooth", "some", "basis", "trajectory", "-lrb-", "preferably", "longer", "than", "50", "frame", "-rrb-", "subspace", "form", "feature", "track", "address", "occlusion", "issue", "Lee", "et", "al.", "-lsb-", "2009", "-rsb-", "introduce", "feature", "pruning", "choose", "robust", "feature", "trajectory", "smoothing", "we", "method", "do", "encounter", "issue", "since", "only", "compute", "relative", "motion", "between", "consecutive", "frame", "Motion", "Estimation", "compute", "transition", "between", "two", "image", "view", "overlap", "local", "alignment", "-lsb-", "shum", "Szeliski", "2000", "-rsb-", "dual-homography", "model", "-lsb-", "Gao", "et", "al.", "2011", "-rsb-", "can", "reduce", "alignment", "error", "cause", "parallax", "however", "its", "current", "motion", "estimation", "technique", "slow", "-lrb-", "may", "take", "minute", "process", "720p", "frame", "-rrb-", "very", "efficient", "estimate", "we", "motion", "model", "-lrb-", "may", "take", "only", "50", "millisecond", "process", "720p", "frame", "-rrb-", "so", "we", "do", "need", "separate", "rolling", "shutter", "correction", "step", "we", "stabilization", "section", "we", "introduce", "we", "warping-based", "motion", "model", "bundle", "camera", "path", "we", "propose", "use", "image", "warping", "model", "represent", "motion", "between", "consecutive", "video", "frame", "which", "provide", "stronger", "modeling", "power", "than", "conventional", "single", "2d", "linear", "transformation", "though", "more", "general", "model", "moving-least-square", "-lsb-", "Schaefer", "et", "al.", "2006", "-rsb-", "parameterized", "optical", "flow", "-lsb-", "Nir", "et", "al.", "2008", "-rsb-", "might", "use", "however", "estimate", "model", "high", "degree", "freedom", "very", "risky", "because", "we", "may", "have", "sufficient", "feature", "-lrb-", "due", "textureless", "region", "occlusion", "-rrb-", "every", "cell", "regularization", "address", "challenge", "we", "propose", "impose", "shape-preserving", "-lrb-", "i.e.", "as-similar-as-possible", "-lsb-", "Igarashi", "et", "al.", "2005", "-rsb-", "-rrb-", "constraint", "can", "help", "propagate", "fill", "information", "from", "region", "sufficient", "feature", "other", "region", "Data", "term", "show", "figure", "suppose", "-lcb-", "-rcb-", "p-th", "match", "feature", "pair", "from", "frame", "frame", "solve", "determine", "warping", "grid", "we", "discuss", "how", "adaptively", "determine", "later", "we", "further", "generalize", "we", "motion", "estimation", "make", "more", "robust", "adaptive", "regularization", "good", "regularization", "should", "adaptive", "image", "content", "so", "we", "system", "automatically", "choose", "large", "-lrb-", "3.0", "-rrb-", "ensure", "consistent", "local", "motion", "reach", "desire", "balance", "we", "propose", "optimization-based", "framework", "take", "all", "factor", "account", "crop", "distortion", "control", "above", "adaptive", "term", "can", "give", "we", "certain", "amount", "ability", "control", "crop", "distortion", "may", "too", "complex", "solve", "reproduce", "work", "we", "resort", "simple", "effective", "method", "adaptively", "adjust", "parameter", "each", "frame", "any", "frame", "do", "satisfy", "user", "requirement", "-lrb-", "crop", "ratio", "distortion", "smaller", "than", "pre-defined", "threshold", "-rrb-", "we", "decrease", "its", "parameter", "step", "-lrb-", "1/10", "-rrb-", "re-run", "optimization", "sometimes", "slight", "distortion", "-lrb-", "e.g.", "seam", "about", "1-pixel", "width", "-rrb-", "which", "case", "we", "perform", "bilinear", "interpolation", "fix", "they", "motion", "estimation", "we", "always", "divide", "video", "frame", "16", "16", "cell", "because", "parallax", "make", "global", "homography", "motion", "model", "invalid", "therefore", "some", "image", "region", "can", "stabilize", "very", "well", "Designing", "good", "metric", "non-trivial", "because", "hard", "compare", "two", "different", "video", "know", "strength", "weakness", "method", "different", "situation", "we", "roughly", "divide", "we", "datum", "category", "base", "camera", "motion", "scene", "type", "here", "we", "wish", "examine", "its", "robustness", "automatic", "tool", "fix", "its", "parameter", "category", "-lrb-", "ii?iii", "-rrb-", "contain", "quick", "rotation", "zooming", "which", "challenging", "case", "method", "require", "long", "feature", "tracking", "alleviate", "problem", "we", "try", "interactively", "tune", "its", "smoothing", "parameter", "comparison", "we", "adaptive", "camera", "path", "smoothing", "technique", "can", "automatically", "adjust", "smoothness", "strength", "consider", "discontinuity", "distortion", "necessary", "we", "could", "apply", "strategy", "-lsb-", "gleicher", "Liu", "2007", "-rsb-", "post-process", "solve", "problem" ],
  "content" : "We present a novel video stabilization method which models camera motion with a bundle of (multiple) camera paths. The proposed model is based on a mesh-based, spatially-variant motion representation and an adaptive, space-time path optimization. Our motion representation allows us to fundamentally handle parallax and rolling shutter effects while it does not require long feature trajectories or sparse 3D reconstruction. We introduce the ?as-similaras-possible? idea to make motion estimation more robust. CR Categories: I.4.3 [Image Processing and Computer Vision]: Enhancement?Registration Keywords: video stabilization, image warping, camera paths\n      Links: DL PDF A video captured with a hand-held device (e.g., a cell-phone or a portable camcorder) often appears remarkably shaky and undirected. Digital video stabilization improves the video quality by removing unwanted camera motion. It is of great practical importance because the devices (mobile phones, tablets, camcorders) capable  of capturing video have become widespread and online sharing is so ubiquitous. Prior video stabilization methods synthesized a new stabilized video by estimating and smoothing 2D camera motion [Matsushita et al. 2006; Grundmann et al. 2011] or 3D camera motion [Liu et al. 2009; Liu et al. 2012]. In general, 2D methods are more robust and faster because they only estimate a linear transformation (affine or homography) between consecutive frames. But the 2D linear motion model is too weak to fundamentally handle the parallax caused by non-trivial depth variation in the scene. On the contrary, the 3D methods can deal with the parallax in principle and generate strongly stabilized results. However, their motion model estimation is less robust to various degenerations such as feature tracking failure, motion blur, camera zooming, and rapid rotation. Some recent methods [Liu et al. 2011; Goldstein and Fattal 2012] have successfully combined the advantages of these two kinds of methods. Nevertheless, requiring long feature tracking (typically over 20 frames) makes it difficult to handle more challenging cases (e.g., rapid motion, fast scene transition, large occlusion) in the consumer videos. This paper aims at the same goal of robust high-quality result but from an opposite direction: we propose a more powerful 2D camera motion model. In other words, each different location in the video has its own camera path. At the same time, the model enjoys the robustness and simplicity of 2D methods, because it only requires feature correspondences between two consecutive frames. The first component represents the motion between two consecutive frames by mesh-based, spatially-variant homographies ( Figure 1(b) ) with a ?as-similar-aspossible? regularization constraint [Igarashi et al. 2005; Schaefer et al. 2006]. This constraint is critical because estimating a model with such a high degree of freedom is usually risky in the cases of insufficient features or large occlusions. To the best of our knowledge, this is the first work to employ the mesh-based ?as-similar-aspossible? regularization for spatially-variant motion estimation in video stabilization. But we directly use the mesh vertices as the motion model itself. No intermediate representation is used, such as 3D reconstruction [Liu et al. 2009] or subspace [Liu et al. 2011]. Based on the proposed motion representation, we construct a bundle of camera paths, each of which is the concatenation of local homographies at the same grid cell over time ( Figure 1(b) ). Furthermore, to avoid excessive cropping/geometrical distortion and approximate cinematography favored path, we adopt a discontinuity-preserving idea similar to bilateral filtering [Tomasi and Manduchi 1998] to adaptively control the strength of smoothing. We show that our new 2D method is comparable to or outperforms other competitive 2D or 3D methods. 2D Methods estimate 2D transformations between consecutive video frames and smooth them over time to generate a steady video. Some methods assume prior motion models such as polynomial curves [Chen et al. 2008] for desired camera trajectories. Grundmann et al. [2012] further adopt a homography-array-based motion model to deal with rolling shutter effects. These two techniques have been integrated into Google YouTube. It is robust, follows cinematography rules, and performs well on many consumer videos. Our method belongs to this category. Liu et al. [2009] develop the first successful 3D video stabilization system and are the first to introduce ?content-preserving? warping for stabilization. Liu et al. [2011] smooth some basis trajectories (preferably longer than 50 frames) of the subspace formed by the feature tracks. To address the occlusion issue, Lee et al. [2009] introduce feature pruning to choose robust feature trajectories for smoothing. Our method does not encounter this issue since it only computes relative motion between consecutive frames. Motion Estimation computes the transition between two images with view overlap. Local alignment [Shum and Szeliski 2000] or a dual-homography model [Gao et al. 2011] can reduce alignment error caused by parallax. However, its current motion estimation technique is slow (may take 8 minutes to process a 720p frame). It is very efficient to estimate our motion model (may take only 50 milliseconds to process a 720p frame). So we do not need a separate rolling shutter correction step in our stabilization. In this section, we introduce our warping-based motion model and bundled camera paths. We propose using an image warping model to represent the motion between consecutive video frames, which provides stronger modeling power than conventional single, 2D linear transformations. though more general models such as ?moving-least-square? [Schaefer et al. 2006] or parameterized optical flow [Nir et al. 2008] might be used. However, estimating a model with such a high degree of freedom is very risky because we may not have sufficient features (due to textureless regions or occlusions) in every cell. Regularization To address this challenge, we propose imposing a shape-preserving (i.e., ?as-similar-as-possible? [Igarashi et al. 2005]) constraint. They can help to propagate or fill in information from regions with sufficient features to other regions. Data term As shown in Figure 2 , suppose {p, p} is the p-th matched feature pair from frame t to frame t + 1. Solving V ? determines the warping of the grid. We will discuss how to adaptively determine it later. We further generalize our motion estimation to make it more robust. Adaptive regularization A good regularization should be adaptive to image content. So our system will automatically choose a large ?(=3.0) to ensure consistent local motion. To reach a desired balance, we propose an optimization-based framework taking all factors into account. Cropping and distortion control The above adaptive term ? t,r can give us a certain amount of ability to control cropping and distortion. But it may be too complex to be solved or reproduced. In this work, we resort to a simple but effective method adaptively adjust the parameter ? t for each frame. For any frame that does not satisfy the user requirements (cropping ratio or distortion is smaller than a pre-defined threshold), we decrease its parameter ? t by a step (1/10? t ) and re-run the optimization. Sometimes, there are slight distortions (e.g., seams of about 1-pixel width), in which case we perform a bilinear interpolation to fix them. For motion estimation, we always divide the video frame to 16 ? 16 cells. This is because the parallax makes the global homography motion model invalid, therefore some image regions cannot be stabilized very well. Designing a good metric is non-trivial because it is hard to compare two different videos. To know the strength and weakness of a method in different situations, we roughly divide our data into 7 categories based on camera motion and scene type. Here, we wish to examine its robustness as an automatic tool by fixing its parameters. Categories (II?III) contain quick rotation or zooming, which are challenging cases for methods requiring long feature tracking. To alleviate this problem, we try to interactively tune its smoothing parameters. In comparison, our adaptive camera  path smoothing technique can automatically adjust the smoothness strength by considering discontinuity and distortion. If necessary, we could apply the strategy in [Gleicher and Liu 2007] as a post-process to solve this problem.",
  "resources" : [ ]
}