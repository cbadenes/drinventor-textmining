{
  "uri" : "sig2011-a31-shiratori_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2011/a31-shiratori_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Motion Capture from Body-Mounted Cameras",
    "published" : "2011",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Takaaki-Shiratori",
      "name" : "Takaaki",
      "surname" : "Shiratori"
    }, {
      "uri" : "http://drinventor/Hyun Soo-Park",
      "name" : "Hyun Soo",
      "surname" : "Park"
    }, {
      "uri" : "http://drinventor/Leonid-Sigal",
      "name" : "Leonid",
      "surname" : "Sigal"
    }, {
      "uri" : "http://drinventor/Yaser-Sheikh",
      "name" : "Yaser",
      "surname" : "Sheikh"
    }, {
      "uri" : "http://drinventor/Jessica K.-Hodgins",
      "name" : "Jessica K.",
      "surname" : "Hodgins"
    } ]
  },
  "bagOfWords" : [ "Motion", "capture", "technology", "generally", "require", "recording", "perform", "laboratory", "closed", "stage", "set", "control", "lighting", "restriction", "preclude", "capture", "motion", "require", "outdoor", "setting", "traversal", "large", "area", "paper", "we", "present", "theory", "practice", "use", "body-mounted", "camera", "reconstruct", "motion", "subject", "optimization", "objective", "function", "incorporate", "term", "image", "matching", "error", "temporal", "continuity", "motion", "global", "motion", "estimate", "drift", "control", "match", "capture", "set", "video", "reference", "imagery", "we", "show", "result", "setting", "where", "capture", "would", "difficult", "impossible", "traditional", "motion", "capture", "system", "include", "walk", "outside", "swing", "monkey", "bar", "capture", "realistic", "motion", "scene", "actor", "ride", "horse", "robotic", "mockup", "expansive", "motion", "capture", "studio", "require", "large", "number", "camera", "Coverage", "lighting", "problem", "often", "prevent", "director", "from", "capture", "motion", "natural", "setting", "other", "large", "environment", "paper", "we", "present", "wearable", "system", "outward-looking", "camera", "allow", "reconstruction", "relative", "global", "motion", "actor", "outside", "laboratory", "closed", "stage", "camera", "can", "mount", "casual", "clothing", "-lrb-", "figure", "-lrb-", "-rrb-", "-rrb-", "easily", "mount", "remove", "use", "velcro", "attachment", "lightweight", "enough", "allow", "unimpeded", "movement", "reconstruct", "camera", "skeleton", "-lrb-", "figure", "-lrb-", "-rrb-", "-rrb-", "use", "initialization", "overall", "optimization", "compute", "root", "position", "orientation", "joint", "angle", "while", "minimize", "image", "match", "error", "we", "render", "motion", "skin", "character", "apply", "recover", "skeletal", "motion", "-lrb-", "figure", "-lrb-", "-rrb-", "-rrb-", "estimate", "camera", "pose", "global", "relative", "motion", "actor", "can", "capture", "outdoors", "under", "wide", "variety", "lighting", "condition", "extended", "indoor", "region", "without", "any", "additional", "equipment", "we", "also", "avoid", "some", "miss", "datum", "problem", "introduce", "occlusion", "between", "marker", "camera", "traditional", "optical", "motion", "capture", "because", "we", "system", "any", "visually", "distinctive", "feature", "world", "can", "serve", "marker", "traditional", "system", "by-product", "capture", "process", "sparse", "3d", "structure", "scene", "give", "expect", "continuation", "technological", "trend", "we", "believe", "system", "one", "propose", "here", "become", "viable", "alternative", "traditional", "motion", "capture", "technology", "advantage", "disadvantage", "different", "design", "discuss", "several", "survey", "-lrb-", "e.g.", "-lsb-", "Welch", "Foxlin", "2002", "Moeslund", "et", "al.", "2006", "-rsb-", "-rrb-", "Motion", "capture", "system", "can", "classify", "outside-in", "-lsb-", "Welch", "Foxlin", "2002", "-rsb-", "rely", "sensor", "mount", "environment", "passive", "any", "marker", "body", "inside-out", "system", "-lsb-", "Welch", "Foxlin", "2002", "-rsb-", "rely", "sensor", "body", "recover", "3d", "pose", "we", "approach", "fall", "latter", "category", "here", "we", "review", "most", "relevant", "method", "system", "Optical", "system", "require", "indoor", "setup", "typically", "cost", "between", "ten", "hundred", "thousand", "dollar", "marker-less", "method", "most", "often", "use", "regular", "video", "camera", "simple", "-lrb-", "e.g.", "chromakey", "-rrb-", "background", "reconstruct", "voxel", "representation", "body", "over", "time", "fit", "skeletal", "model", "voxel", "representation", "similar", "paradigm", "use", "system", "develop", "Organic", "Motion", "-lrb-", "www.organicmotion.com", "-rrb-", "Hasler", "colleague", "-lsb-", "2009", "-rsb-", "introduce", "approach", "capture", "motion", "actor", "outdoor", "environment", "from", "multiple", "inward-looking", "move", "camera", "markerless", "method", "require", "image", "segmentation", "3d", "scan", "actor", "system", "consist", "exoskeleton", "suit", "embedded", "lightweight", "rod", "articulate", "performer?s", "bone", "potentiometer", "joint", "measure", "angular", "rotation", "rod", "convert", "joint", "angle", "use", "kinematic", "model", "system", "while", "capable", "directly", "measure", "motion", "subject", "intrusive", "uncomfortable", "wear", "system", "portable", "can", "take", "outside", "however", "only", "able", "measure", "orientation", "body", "part", "motion", "body", "world", "Alternatives", "battle", "drift", "include", "data-driven", "approach", "base", "motion", "capture", "datum", "stabilize", "accelerometer", "estimate", "-lsb-", "Slyper", "Hodgins", "2008", "Xie", "et", "al.", "2008", "Kelly", "et", "al.", "2010", "Tautges", "et", "al.", "2011", "-rsb-", "we", "work", "first", "reconstruct", "3d", "motion", "set", "camera", "relate", "underlie", "articulate", "structure", "lens", "focal", "length", "fix", "camera", "estimate", "need", "compute", "only", "once", "re-usable", "across", "capture", "appropriate", "estimate", "human", "motion", "across", "time", "we", "SfM", "solution", "consider", "articulation", "body-mounted", "camera", "underlie", "skeleton", "actor", "fit", "they", "image", "measurement", "we", "develop", "pipeline", "show", "Figure", "user", "can", "optionally", "refine", "skeleton", "change", "pose", "camera", "respect", "joint", "through", "graphical", "user", "interface", "significant", "difference", "view", "between", "reference", "image", "record", "video", "some", "camera", "may", "reconstruct", "we", "call", "iterative", "process", "relative", "camera", "registration", "repeat", "process", "until", "most", "camera", "reconstruct", "fundamental", "matrix", "estimation", "base", "ransac", "-lsb-", "fischler", "Bolles", "1981", "-rsb-", "enable", "we", "obtain", "geometrically", "consistent", "match", "we", "incrementally", "add", "image", "have", "greatest", "number", "inlier", "3d-2d", "correspondence", "among", "remain", "image", "once", "extrinsic", "parameter", "new", "camera", "reconstruct", "2d-2d", "correspondence", "between", "reconstructed", "image", "newly", "add", "image", "reconstruct", "3d", "process", "continue", "until", "most", "reference", "image", "register", "process", "enable", "we", "reconstruct", "pose", "remain", "camera", "situation", "occur", "example", "when", "actor", "perform", "fast", "motion", "run", "image", "blurry", "one", "more", "camera", "associate", "each", "link", "kinematic", "structure", "show", "figure", "-lrb-", "-rrb-", "we", "do", "currently", "consider", "biomechanical", "constraint", "under", "condition", "camera", "pose", "can", "reconstruct", "very", "noisy", "virtual", "camera", "reduce", "occlusion", "problem", "significantly", "allow", "skeletal", "motion", "reconstruct", "robustly", "initial", "guess", "body", "pose", "set", "register", "camera", "pose", "homography", "levenberg-marquardt", "method", "apply", "refine", "pose", "Smoothness", "term", "can", "also", "consider", "obtain", "smooth", "motion", "mean", "median", "error", "3.0093", "1.8076", "respectively", "minimum", "maximum", "error", "0.038", "9.52", "respectively", "thus", "we", "could", "convert", "three", "marker", "position", "motion", "capture", "datum", "camera", "pose", "we", "also", "test", "ability", "capture", "fast", "motion", "run", "motion", "street", "-lrb-", "figure", "-lrb-", "-rrb-", "-rrb-", "Figure", "show", "reconstructed", "long", "walking", "motion", "along", "wind", "path", "uneven", "terrain", "Automatic", "white", "balancing", "which", "can", "disable", "many", "commercial", "camera", "include", "ours", "also", "make", "finding", "correspondence", "challenge", "when", "lighting", "condition", "change", "rapidly", "large", "scale", "model", "can", "directly", "utilize", "we", "system", "contextualize", "long-term", "motion", "compose", "motion", "multiple", "people", "single", "geometrically", "coherent", "environment", "we", "would", "like", "thank", "Takeo", "Kanade", "Irfan", "Essa", "Srinivasa", "Narasimhan", "useful", "discussion", "project" ],
  "content" : "Motion capture technology generally requires that recordings be performed in a laboratory or closed stage setting with controlled lighting. This restriction precludes the capture of motions that require an outdoor setting or the traversal of large areas. In this paper, we present the theory and practice of using body-mounted cameras to reconstruct the motion of a subject. The optimization objective function incorporates terms for image matching error and temporal continuity of motion. Global motion is estimated and drift is controlled by matching the captured set of videos to reference imagery. We show results in settings where capture would be difficult or impossible with traditional motion capture systems, including walking outside and swinging on monkey bars. To capture realistic motion for such scenes, the actors rode horses and robotic mockups in an expansive motion capture studio requiring a large number of cameras. Coverage and lighting problems often prevent directors from capturing motion in natural settings or in other large environments. In this paper, we present a wearable system of outward-looking cameras that allow the reconstruction of the relative and the global motion of an actor outside of a laboratory or closed stage. The cameras can be mounted on casual clothing ( Figure 1(a) ), are easily mounted and removed using Velcro attachments, and are lightweight enough to allow unimpeded movement. The reconstructed cameras and skeleton ( Figure 1(b) ) are used as an initialization for an overall optimization to compute the root position, orientation, and joint angles while minimizing the image matching error. We render the motion of a skinned character by applying the recovered skeletal motion ( Figure 1(c) ). By estimating the camera poses, the global and relative motion of an actor can be captured outdoors under a wide variety of lighting conditions or in extended indoor regions without any additional equipment. We also avoid some of the missing data problems introduced by occlusions between the markers and cameras in traditional optical motion capture, because, in our system, any visually distinctive feature in the world can serve as a marker in the traditional systems. A by-product of the capture process is a sparse 3D structure of the scene. Given the expected continuation of these technological trends, we believe that systems such as the one proposed here, will become viable alternatives to traditional motion capture technologies. The advantages and disadvantages of the different designs are discussed in several surveys (e.g., [Welch and Foxlin 2002; Moeslund et al. 2006]). Motion capture systems can be classified as outside-in [Welch and Foxlin 2002], in that they rely on sensors mounted in the environment and passive, if any, markers on the body. Inside-out systems [Welch and Foxlin 2002] rely on sensors on the body to recover the 3D pose. Our approach falls into the latter category. Here, we review the most relevant methods and systems. Optical systems require indoor setups that typically cost between tens and hundreds of thousands of dollars. Marker-less methods most often use regular video cameras with simple (e.g., chromakey) backgrounds to reconstruct a voxel representation of the body over time and then fit a skeletal model to the voxel representations. A similar paradigm is used by the system developed by Organic Motion (www.organicmotion.com). Hasler and colleagues [2009] introduced an approach to capture the motion of an actor in outdoor environments from multiple inward-looking moving cameras. The markerless methods require image segmentation, or a 3D scan of the actor. Such systems consist of an exoskeleton suit with embedded lightweight rods that articulate with the performer?s bones. Potentiometers at the joints measure the angular rotation of the rods, and are converted to joint angles using a kinematic model. Such systems, while capable of directly measuring the motion of the subject, are intrusive and uncomfortable to wear. These systems are portable and can be taken outside; however, they are only able to measure the orientation of body parts, not the motion of the body in the world. Alternatives for battling drift include data-driven approaches based on motion capture data to stabilize accelerometer estimates [Slyper and Hodgins 2008; Xie et al. 2008; Kelly et al. 2010; Tautges et al. 2011]. Our work is the first to reconstruct the 3D motion of a set of cameras related by an underlying articulated structure. As the lens and focal length are fixed for the cameras, these estimates need to be computed only once and are re-usable across captures. appropriate estimates of human motion across time, our SfM solution considers the articulation of body-mounted cameras with the underlying skeleton of the actor and fits them to image measurements: We develop the pipeline shown in Figure 3 . The user can optionally refine the skeleton by changing the pose of the camera with respect to the joint through a graphical user interface. If there are significant differences in view between the reference images and the recorded videos, some cameras may not be reconstructed. We call this iterative process relative camera registration, and repeat the process until most of cameras are reconstructed. The fundamental matrix estimation based on RANSAC [Fischler and Bolles 1981] enables us to obtain geometrically consistent matches. We incrementally add an image that has the greatest number of inlier 3D-2D correspondences, among the remaining images. Once the extrinsic parameters for the new camera are reconstructed, 2D-2D correspondences between reconstructed images and the newly added image are reconstructed in 3D. This process continues until most of the reference images are registered. This process enables us to reconstruct the poses of the remaining cameras. This situation occurs, for example, when an actor performs a fast motion such as running and the images are blurry. One or more cameras are associated with each link in the kinematic structure, as shown in Figure 2(c) . We do not currently consider biomechanical constraints. Under such conditions, the camera poses cannot be reconstructed or are very noisy. The virtual camera reduces the occlusion problem significantly and allows skeletal motion to be reconstructed robustly. The initial guess of the body pose is set with the registered camera poses and homographies, and the Levenberg-Marquardt method is applied to refine the poses. Smoothness Terms: E O and E A can be also considered to obtain smooth motion. The mean and median errors are 3.0093 ? and 1.8076 ? , respectively, and the minimum and the maximum errors are 0.038 ? and 9.52 ? , respectively. Thus we could convert the three marker positions in the motion capture data to the camera poses. We also tested the ability to capture fast motions with a running motion on a street ( Figure 8(c) ). Figure 9 shows a reconstructed long walking motion along the winding path on an uneven terrain. Automatic white balancing, which cannot be disabled on many commercial cameras including ours, also makes finding correspondences challenging when lighting conditions are changing rapidly. Such large scale models can be directly utilized in our system to contextualize long-term motions and compose motions of multiple people in a single geometrically coherent environment. We would like to thank Takeo Kanade, Irfan Essa, and Srinivasa Narasimhan for useful discussions on this project.",
  "resources" : [ ]
}