{
  "uri" : "sig2008a-a112-ye_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2008a/a112-ye_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Animating Responsive Characters with Dynamic Constraints in Near-Unactuated Coordinates",
    "published" : "2008",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Yuting-Ye",
      "name" : "Yuting",
      "surname" : "Ye"
    }, {
      "uri" : "http://drinventor/C. Karen-Liu",
      "name" : "C. Karen",
      "surname" : "Liu"
    } ]
  },
  "bagOfWords" : [ "create", "virtual", "character", "realistically", "respond", "physical", "perturbation", "interactive", "environment", "remain", "challenging", "problem", "physics-based", "approach", "generate", "motion", "consistent", "simulated", "environment", "inherently", "difficult", "design", "tune", "produce", "realistic", "motion", "across", "wide", "variety", "scenario", "many", "interactive", "application", "video", "game", "simpler", "more", "widely", "use", "approach", "kinematically", "control", "character", "mimic", "she", "dynamic", "reaction", "play", "back", "pre-scripted", "motion", "response", "predefined", "stimulus", "responsiveness", "character", "thus", "largely", "depend", "quality", "scope", "pre-scripted", "motion", "type", "interaction", "allow", "consequently", "most", "application", "only", "focus", "perturbation", "have", "large", "impact", "character", "since", "virtually", "impossible", "predefine", "all", "possible", "perturbation", "animated", "response", "contrast", "large", "perturbation", "often", "force", "character", "re-plan", "she", "high-level", "behavior", "interfere", "balance", "state", "character", "more", "likely", "encounter", "small", "perturbation", "disrupt", "motion", "pattern", "momentarily", "do", "change", "course", "synthesize", "responsive", "character", "animation", "important", "research", "topic", "broad", "range", "application", "researcher", "have", "explore", "different", "approach", "build", "physics-based", "controller", "guide", "kinematically", "specify", "motion", "datum", "various", "tracking", "controller", "have", "be", "apply", "produce", "responsive", "movement", "under", "physical", "perturbation", "include", "upper", "body", "motion", "-lsb-", "Zordan", "Hodgins", "2002", "Yin", "et", "al.", "2003", "-rsb-", "manipulation", "task", "-lsb-", "abe", "Popovi", "2006", "-rsb-", "stand", "motion", "-lsb-", "Kokkevis", "et", "al.", "1996", "Abe", "et", "al.", "2007", "-rsb-", "cyclic", "biped", "motion", "-lsb-", "Sok", "et", "al.", "2007", "Yin", "et", "al.", "2007", "-rsb-", "proper", "physical", "parameter", "controller", "method", "can", "generate", "realistic", "reactive", "motion", "consistent", "simulated", "virtual", "world", "however", "many", "method", "require", "fine", "tuning", "physical", "parameter", "expensive", "pre-computation", "specific", "target", "motion", "skeletal", "model", "da", "Silva", "et", "al.", "-lsb-", "2008", "-rsb-", "introduce", "systematic", "method", "derive", "balance", "controller", "tailor", "input", "motion", "reduce", "effort", "parameter", "tuning", "we", "method", "also", "produce", "responsive", "motion", "preserve", "style", "input", "motion", "however", "we", "approach", "do", "involve", "any", "active", "body", "control", "thereby", "physical", "parameter", "tuning", "require", "furthermore", "we", "focus", "type", "perturbation", "significantly", "disrupt", "upper", "body", "pose", "dynamics", "have", "limit", "effect", "whole-body", "balance", "kinematically", "control", "character", "animation", "more", "preferable", "many", "online", "application", "because", "easier", "implement", "provide", "precise", "user", "controllability", "create", "dynamic", "response", "under", "external", "impact", "Komura", "et", "al.", "-lsb-", "2004", "2005", "-rsb-", "directly", "change", "motion", "respect", "change", "momentum", "biped", "motion", "Oshita", "Makinouchi", "-lsb-", "2001", "-rsb-", "modify", "joint", "acceleration", "base", "dynamic", "control", "balance", "comfort", "combine", "advantage", "kinematic", "motion", "physical", "simulation", "many", "researcher", "have", "also", "propose", "idea", "switching", "between", "dynamic", "simulation", "motion", "capture", "datum", "whenever", "necessary", "-lsb-", "Zordan", "et", "al.", "2005", "Shapiro", "et", "al.", "2003", "Mandel", "2004", "-rsb-", "particular", "Zordan", "et", "al.", "propose", "framework", "use", "minimal", "simulation", "interval", "after", "impact", "rely", "motion", "capture", "alone", "when", "perturbation", "present", "we", "method", "also", "take", "hybrid", "approach", "synthesis", "responsive", "motion", "however", "instead", "divide", "kinematic", "dynamic", "control", "time", "domain", "we", "divide", "they", "spatially", "transform", "space", "span", "set", "basis", "represent", "joint", "actuation", "original", "motion", "directly", "apply", "motion", "capture", "datum", "produce", "natural", "human", "mo", "tion", "rich", "detail", "many", "technique", "have", "successfully", "demonstrate", "pre-recorded", "datum", "can", "adapt", "new", "situation", "response", "online", "user", "control", "-lsb-", "treuille", "et", "al.", "2007", "McCann", "Pollard", "2007", "Cooper", "et", "al.", "2007", "Shin", "oh", "2006", "-rsb-", "few", "method", "extend", "data-driven", "approach", "synthesize", "responsive", "motion", "balance", "recovery", "against", "external", "force", "-lsb-", "Arikan", "et", "al.", "2005", "Yin", "et", "al.", "2005", "-rsb-", "method", "collect", "set", "specific", "interaction", "advance", "procedurally", "generate", "small", "deformation", "from", "record", "motion", "respond", "predefined", "user", "interaction", "we", "method", "synthesize", "responsive", "motion", "via", "dynamic", "constraint", "instead", "motion", "blending", "thereby", "completely", "remove", "dependency", "motion", "database", "moreover", "we", "allow", "direct", "kinematic", "control", "additional", "objective", "PCA", "have", "be", "frequently", "use", "process", "motion", "datum", "application", "computer", "graphic", "robotic", "computer", "vision", "computer", "animation", "pca", "typically", "use", "reduce", "dimensionality", "configuration", "space", "motion", "blending", "recognition", "modeling", "-lsb-", "brand", "hertzmann", "2000", "Jenkins", "Matari", "2002", "Safonova", "et", "al.", "2004", "Barbic", "et", "al.", "2004", "Chai", "Hodgins", "2007", "-rsb-", "biomechanic", "researcher", "have", "apply", "dimension", "reduction", "technique", "muscle", "activation", "datum", "measure", "from", "behavioral", "experiment", "-lsb-", "Tresch", "et", "al.", "2006", "Ting", "2007", "Alexandrov", "et", "al.", "2005", "-rsb-", "ting", "suggest", "limited", "set", "muscle", "synergy", "define", "low-dimensional", "module", "form", "muscle", "activate", "synchrony", "use", "control", "center", "mass", "after", "postural", "perturbation", "we", "method", "inspire", "ting?s", "work", "we", "formulate", "dynamic", "equation", "space", "muscle", "synergy", "rather", "than", "space", "joint", "configuration", "however", "we", "do", "use", "PCA", "tool", "dimension", "reduction", "we", "only", "apply", "pca", "identify", "principle", "component", "correspond", "lower", "eigenvalue", "because", "principle", "component", "represent", "dimension", "motion", "where", "active", "body", "control", "do", "play", "important", "role" ],
  "content" : "Creating virtual characters that realistically respond to physical perturbations in an interactive environment remains a challenging problem. Physics-based approaches generate motions consistent with the simulated environment, but are inherently difficult to design and tune to produce realistic motion across a wide variety of scenarios. For many interactive applications, such as video games, a simpler and more widely used approach is to kinematically control a character but mimic her dynamic reactions by playing back a pre-scripted motion in response to predefined stimuli. The responsiveness of a character thus largely depends on the quality and scope of the pre-scripted motions and the types of interactions allowed. Consequently, most applications only focus on perturbations that have a large impact on the character since it is virtually impossible to predefine all possible perturbations and animated responses. In contrast to large perturbations that often force the character to re-plan her high-level behaviors or interfere with the balance state, the character is more likely to encounter small perturbations that disrupt motion patterns momentarily but do not change the course Synthesizing responsive character animation is an important research topic with a broad range of applications. Researchers have explored different approaches to building physics-based controllers guided by kinematically specified motion data. Various tracking controllers have been applied to produce responsive movements under physical perturbations, including upper body motions [Zordan and Hodgins 2002; Yin et al. 2003], manipulation tasks [Abe and Popovi? 2006], standing motions [Kokkevis et al. 1996; Abe et al. 2007] or cyclic biped motions [Sok et al. 2007; Yin et al. 2007]. With the proper physical parameters for the controllers, these methods can generate realistic reactive motions consistent with the simulated virtual world. However, many of these methods require fine tuning of physical parameters or expensive pre-computation specific to the target motion and skeletal model. da Silva et al. [2008] introduced a systematic method to derive a balance controller tailored to the input motion, reducing the effort on parameter tuning. Our method also produces responsive motion that preserves the ?style? of the input motion. However, our approach does not involve any active body control, thereby no physical parameter tuning is required. Furthermore, we focus on the type of perturbations that significantly disrupt the upper body poses and dynamics, but have limited effect on the whole-body balance. Kinematically controlled character animation is more preferable in many online applications because it is easier to implement and provides precise user controllability. To create dynamic responses under external impacts, Komura et al. [2004; 2005] directly changed the motion with respect to the change of momentum of a biped motion. Oshita and Makinouchi [2001] modified the joint acceleration based on dynamic control of balance and comfort. To combine the advantages of kinematics motion and the physical simulation, many researchers have also proposed the idea of switching between dynamic simulation and motion capture data whenever necessary [Zordan et al. 2005; Shapiro et al. 2003; Mandel 2004]. In particular, Zordan et al. proposed a framework that uses minimal simulation interval after the impact and relies on the motion capture alone when perturbations are not presented. Our method also takes a hybrid approach to synthesis of responsive motions. However, instead of dividing the kinematic and dynamic control in the time domain, we divide them spatially in a transformed space, spanned by a set of basis representing the joint actuation in the original motion. Directly applying motion capture data produces natural human mo tions with rich details. Many techniques have successfully demonstrated that pre-recorded data can be adapted to new situations in response to online user control [Treuille et al. 2007; McCann and Pollard 2007; Cooper et al. 2007; Shin and Oh 2006]. A few methods extended data-driven approaches to synthesizing responsive motions, such as balance recovery against external forces [Arikan et al. 2005; Yin et al. 2005]. These methods collect a set of specific interactions in advance, and procedurally generate small deformations from the recorded motions to respond to predefined user interactions. Our method synthesizes responsive motions via dynamic constraints instead of motion blending, thereby completely removing the dependency on a motion database. Moreover, we allow for direct kinematics control with additional objectives. PCA has been frequently used to process motion data for applications in computer graphics, robotics, and computer vision. In computer animation, PCA is typically used to reduce the dimensionality of the configuration space for motion blending, recognition, or modeling [Brand and Hertzmann 2000; Jenkins and Matari? 2002; Safonova et al. 2004; Barbic et al. 2004; Chai and Hodgins 2007]. Biomechanics researchers have applied dimension reduction techniques to the muscle activation data measured from behavioral experiments [Tresch et al. 2006; Ting 2007; Alexandrov et al. 2005]. Ting suggested that a limited set of muscle synergies, defined as low-dimensional modules formed by muscles activated in synchrony, are used to control the center of mass after postural perturbations. Our method is inspired by Ting?s work in that we formulate the dynamic equations in the space of muscle synergies, rather than the space of joint configurations. However, we do not use PCA as a tool for dimension reduction. We only apply PCA for identifying the principle components corresponding to lower eigenvalues because these principle components represent the dimensions of the motion where active body control does not play an important role.",
  "resources" : [ ]
}