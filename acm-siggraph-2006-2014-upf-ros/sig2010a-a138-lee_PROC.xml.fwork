{
  "uri" : "sig2010a-a138-lee_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2010a/a138-lee_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Motion Fields for Interactive Character Locomotion",
    "published" : "2014",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Yongjoon-Lee",
      "name" : "Yongjoon",
      "surname" : "Lee"
    }, {
      "uri" : "http://drinventor/Kevin-Wampler",
      "name" : "Kevin",
      "surname" : "Wampler"
    }, {
      "uri" : "http://drinventor/Gilbert-Bernstein",
      "name" : "Gilbert",
      "surname" : "Bernstein"
    }, {
      "uri" : "http://drinventor/Jovan-Popovic",
      "name" : "Jovan",
      "surname" : "Popovic"
    }, {
      "uri" : "http://drinventor/Zoran-Popovic",
      "name" : "Zoran",
      "surname" : "Popovic"
    } ]
  },
  "bagOfWords" : [ "cr", "category", "i.", "3.7", "-lsb-", "Computer", "Graphics", "-rsb-", "three-dimensional", "graphic", "realism?animation", "keyword", "animation", "motion", "representation", "data-driven", "anima", "tion", "more", "specifically", "motion", "field", "mapping", "which", "associate", "each", "possible", "configuration", "character", "set", "motion", "describe", "how", "character", "able", "move", "from", "current", "state", "motion", "character", "thus", "flow", "through", "state", "space", "accord", "integration", "process", "similar", "particle", "flow", "through", "force", "field", "use", "reinforcement", "learn", "choose", "between", "possibility", "runtime", "direction", "flow", "can", "alter", "allow", "character", "respond", "optimally", "user", "command", "past", "ten", "year", "bag-of-clip", "datum", "structure", "motion", "graph", "have", "emerge", "primary", "source", "realistic", "character", "controller", "-lsb-", "Lee", "et", "al.", "2002", "Arikan", "Forsyth", "2002", "Kovar", "et", "al.", "2002", "-rsb-", "unfortunately", "discretization", "also", "obscure", "continuous", "property", "motion", "second", "because", "motion", "restricted", "clip", "which", "constitute", "graph", "difficult", "couple", "method", "physical", "simulator", "other", "technique", "which", "perturb", "state", "away", "from", "state", "representable", "graph", "although", "number", "method", "have", "be", "propose", "alleviate", "some", "representational", "weakness", "pure", "graph-based", "controller", "include", "parameterized", "motion", "graph", "-lsb-", "Shin", "oh", "2006", "Heck", "Gleicher", "2007", "-rsb-", "increase", "number", "possible", "transition", "-lsb-", "Arikan", "et", "al.", "2005", "Yin", "et", "al.", "2005", "Zhao", "Safonova", "2008", "-rsb-", "splicing", "rag", "doll", "dynamics", "graph", "structure", "-lsb-", "Zordan", "et", "al.", "2005", "-rsb-", "fundamental", "issue", "remain", "unless", "representation", "prescribe", "motion", "every", "continuous", "state", "way", "controllable", "real", "time", "movement", "character", "remain", "restricted", "another", "group", "method", "use", "nonparametric", "model", "learn", "dynamics", "character", "motion", "fully", "continuous", "space", "-lsb-", "Wang", "et", "al.", "2008", "ye", "Liu", "2010", "Chai", "Hodgins", "2005", "-rsb-", "we", "work", "combine", "concept", "near-optimal", "character", "control", "present", "graph-based", "method", "those", "nonparametric", "motion", "estimation", "technique", "furthermore", "because", "always", "multiple", "motion", "datum", "consult", "character", "constantly", "have", "variety", "way", "make", "quick", "change", "motion", "where", "some", "arbitrary", "unit", "length", "vector", "-lrb-", "-rrb-", "mean", "rotation", "weight", "root", "...", "tunable", "scalar", "parameter", "we", "call", "weight", "-lsb-", "...", "-rsb-", "use", "interpolation", "similarity", "weight", "since", "measure", "similarity", "current", "state", "where", "ith", "neighbor", "-lrb-", "-rrb-", "normalization", "factor", "ensure", "weight", "sum", "control", "use", "action", "weight", "describe", "section", "each", "possible", "state", "character", "motion", "field", "set", "action", "which", "character", "can", "choose", "from", "order", "determine", "motion", "over", "next", "frame", "mdp", "consist", "four", "part", "-lrb-", "-rrb-", "state", "space", "-lrb-", "-rrb-", "action", "perform", "each", "state", "-lrb-", "-rrb-", "means", "determine", "state", "transition", "produce", "action", "-lrb-", "-rrb-", "reward", "occupy", "desire", "state", "perform", "desire", "action", "action", "each", "task", "state", "-lrb-", "-rrb-", "character", "motion", "field", "have", "set", "action", "-lrb-", "-rrb-", "choose", "from", "order", "determine", "how", "move", "over", "next", "frame", "-lrb-", "section", "-rrb-", "na?ve", "approach", "problem", "would", "pick", "action", "which", "yield", "largest", "immediate", "reward", "greedy", "policy", "write", "compute", "lookahead", "policy", "involve", "solve", "only", "optimal", "next", "action", "also", "infinite", "sequence", "optimal", "future", "action", "order", "calculate", "value", "-lrb-", "-rrb-", "task", "state", "database", "we", "interpolate", "over", "neighboring", "motion", "state", "use", "similarity", "weight", "over", "task", "parameter", "multilinearly", "fit", "value", "iteration", "operate", "first", "note", "equation", "12", "can", "use", "write", "definition", "value", "function", "recursive", "form", "where", "-lrb-", "-rrb-", "define", "equation", "12", "-lrb-", "-lrb-", "-rrb-", "-rrb-", "compute", "via", "interpolation", "exploit", "idea", "we", "only", "store", "value", "function", "every", "th", "motion", "state", "interpolate", "value", "function", "other", "database", "motion", "state", "-lrb-", "see", "Figure", "-rrb-" ],
  "content" : "CR Categories: I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism?Animation Keywords: animation, motion representation, data-driven anima-\n      tion More specifically, a motion field is a mapping which associates each possible configuration of a character with a set of motions describing how the character is able to move from their current state. The motion of the character thus ?flows? through the state space according to the integration process, similar to a particle flowing through a force field. By using reinforcement learning to choose between these possibilities at runtime the direction of the flow can be altered, allowing the character to respond optimally to user commands. In the past ten years, the bag-of-clips data structures such as motions graphs have emerged as primary sources of realistic character controllers [Lee et al. 2002; Arikan and Forsyth 2002; Kovar et al. 2002]. Unfortunately, this discretization also obscures continuous properties of motion. Second, because the motions are restricted to the clips which constitute the graph it is difficult to couple these methods to physical simulators and other techniques which perturb the state away from states representable by the graph. Although a number of methods have been proposed to alleviate some of the representational weaknesses of pure graph-based controllers, including parameterized motion graphs [Shin and Oh 2006; Heck and Gleicher 2007], increasing the numbers of possible transitions [Arikan et al. 2005; Yin et al. 2005; Zhao and Safonova 2008] and splicing rag doll dynamics in the graph structure [Zordan et al. 2005], the fundamental issue remains: unless the representation prescribes motion at every continuous state in a way that is controllable in real time, the movement of characters will remain restricted. Another group of methods use nonparametric models to learn the dynamics of character motion in a fully continuous space [Wang et al. 2008; Ye and Liu 2010; Chai and Hodgins 2005]. Our work combines the concepts of near-optimal character control present in graph-based methods with those of nonparametric motion estimation techniques. Furthermore, because there are always multiple motion data to consult, the character constantly has a variety of ways to make quick changes in motion. where u is some arbitrary unit length vector; p( u) means the rotation of u by p; and the weights ? root , ? 0 , ? 1 , . . . , ? n are tunable scalar parameters. We call the weights [w 0 , . . . , w k ] used for such interpolation similarity weights since they measure similarity to the current state m: where m i is the ith neighbor of m and ? = P i d(m,m 1 i ) 2 is a normalization factor to ensure the weights sum to 1. Control using action weights. As described in section 3, at each possible state of the character a motion field there is a set of actions which the character can choose from in order to determine their motion over the next frame. An MDP consists of four parts: (1) a state space, (2) actions to perform at each state, (3) a means of determining the state transition produced by an action, and (4) rewards for occupying desired states and performing desired actions. Actions At each task state s = (m, ? T ) a character in a motion field has a set of actions A(m) to choose from in order to determine how they will move over the next frame (section 3). A na?ve approach to this problem would be to pick the action which yields the largest immediate reward: the greedy policy. As written, computing the lookahead policy involves solving for not only the optimal next action, but also an infinite sequence of optimal future actions. In order to calculate the value V (s) of a task state not in the database, we interpolate over neighboring motion states using the similarity weights and over the task parameters multilinearly. Fitted value iteration operates by first noting that equation 12 can be used to write the definition of the value function in a recursive form. where ? L (s i ) is as defined in equation 12 and V (I s (s i , a)) is computed via interpolation. Exploiting this idea, we only store value functions at every N -th motion state, and interpolate the value functions for other database motion states (See Figure 4 ).",
  "resources" : [ ]
}