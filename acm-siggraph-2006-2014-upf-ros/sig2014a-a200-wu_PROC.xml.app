{
  "uri" : "sig2014a-a200-wu_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2014a/a200-wu_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Real-time Shading-based Refinement for Consumer Depth Cameras",
    "published" : "2014",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Shahram-Izadi",
      "name" : "Shahram",
      "surname" : "Izadi"
    } ]
  },
  "bagOfWords" : [ "we", "present", "first", "real-time", "method", "refinement", "depth", "datum", "use", "shape-from-shading", "general", "uncontrolled", "scene", "per", "frame", "we", "real-time", "algorithm", "take", "raw", "noisy", "depth", "datum", "align", "RGB", "image", "input", "approximate", "time-varying", "incident", "lighting", "which", "use", "geometry", "refinement", "lead", "dramatically", "enhance", "depth", "map", "30Hz", "we", "conclude", "application", "we", "higher", "quality", "depth", "map", "improve", "real-time", "surface", "reconstruction", "performance", "capture", "Consumer", "depth", "camera", "have", "open", "up", "many", "new", "real-time", "application", "field", "computer", "graphic", "vision", "robotic", "human-computer", "interaction", "include", "gestural", "interface", "live", "3d", "scanning", "augment", "reality", "robot", "navigation", "however", "noise", "resolution", "limitation", "even", "recent", "depth", "camera", "result", "only", "coarse", "geometry", "acquisition", "per", "frame", "ability", "capture", "higher", "fidelity", "geometry", "real-time", "could", "open", "up", "many", "new", "scenario", "track", "detailed", "feature", "user", "-lrb-", "e.g.", "facial", "expression", "clothing", "etc.", "-rrb-", "real-time", "performance", "capture", "other", "interactive", "scenario", "well", "ability", "scan", "higher", "quality", "3d", "model", "real-world", "object", "show", "previously", "input", "from", "stereo", "camera", "shape-fromshading", "-lrb-", "sf", "-rrb-", "can", "use", "capture", "detailed", "model", "result", "approach", "laser", "scan", "quality", "-lsb-", "Wu", "et", "al.", "2011", "Han", "et", "al.", "2013", "Yu", "et", "al.", "2013", "Beeler", "et", "al.", "2010", "-rsb-", "so", "far", "possible", "real", "time", "refinement", "technique", "have", "yet", "use", "interactively", "due", "performance", "bottleneck", "researcher", "have", "develop", "alternative", "heuristic", "fusion", "strategy", "enhance", "depth", "camera", "datum", "real", "time", "-lsb-", "Richardt", "et", "al.", "2012", "-rsb-", "many", "they", "use", "variant", "joint", "bilateral", "upsampling", "-lsb-", "Kopf", "et", "al.", "2007", "-rsb-", "lift", "depth", "datum", "pixel", "grid", "resolution", "concurrently", "acquire", "align", "RGB", "image", "while", "computation", "fast", "result", "base", "purely", "heuristic", "assumption", "about", "co-occurrence", "discontinuity", "RGB", "depth", "datum", "consequence", "reconstruction", "may", "look", "plausible", "estimated", "detail", "may", "metrically", "accurate", "further", "heuristic", "underpinning", "lead", "commonly", "know", "artifact", "texture", "copying", "where", "spatial", "albedo", "variation", "mistake", "geometric", "detail", "paper", "we", "propose", "new", "real-time", "method", "enhancement", "depth", "datum", "use", "sf", "general", "uncontrolled", "scene", "start", "from", "raw", "depth", "datum", "align", "RGB", "image", "algorithm", "estimate", "real", "time", "time-varying", "incident", "lighting", "distribution", "which", "use", "considerably", "enhance", "reconstruct", "geometric", "detail", "contrast", "previous", "fusion-based", "enhancement", "approach", "we", "reconstruction", "only", "plausible", "more", "metrically", "faithful", "avoid", "some", "texture-copy", "artifact", "see", "previously", "we", "rephrase", "shadingbased", "refinement", "problem", "fully", "exploit", "regular", "connectivity", "image", "grid", "instead", "use", "off-the-shelf", "conventional", "solver", "we", "introduce", "novel", "patch-based", "gauss-newton", "solver", "run", "GPU", "which", "specifically", "design", "we", "energy", "function", "adaptive", "shape", "refinement", "strategy", "reduce", "texture-copy", "artifact", "analyze", "approximate", "albedo", "image", "Range", "image", "enhancement", "sensor", "fusion", "several", "method", "denoise", "enhance", "depth", "datum", "leverage", "higher", "pixel", "resolution", "one", "two", "concurrently", "capture", "rgb", "image", "Yang", "et", "al", "-lsb-", "2007", "-rsb-", "create", "cost", "space", "from", "depth", "map", "filter", "joint-bilaterally", "use", "stereo", "image", "raise", "resolution", "while", "above", "method", "run", "offline", "variant", "joint-bilateral", "multilateral", "filter", "depth", "upsampling", "can", "run", "real-time", "-lsb-", "Chan", "et", "al.", "2008", "Dolson", "et", "al.", "2010", "Richardt", "et", "al.", "2012", "-rsb-", "mathematics", "sf", "well-understood", "particularly", "when", "surface", "reflectance", "light", "source", "position", "know", "while", "physics", "sf", "well", "know", "problem", "inherently", "ill-posed", "achieve", "compelling", "result", "require", "strong", "scene", "lighting", "assumption", "computationally", "complex", "algorithm", "particularly", "solve", "hard", "inverse", "rendering", "optimization", "real-time", "performance", "have", "rarely", "be", "demonstrate", "however", "approach", "require", "complex", "control", "lighting", "setup", "which", "available", "many", "standard", "scenario", "more", "data-driven", "approach", "solve", "sf", "problem", "have", "also", "be", "propose", "Khan", "et", "al.", "-lsb-", "2009", "-rsb-", "learn", "weighting", "parameter", "complex", "sf", "model", "aid", "facial", "reconstruction", "again", "none", "approach", "achieve", "real-time", "performance", "achieve", "goal", "we", "reformulate", "complex", "inverse", "problem", "estimate", "illumination", "albedo", "refine", "geometry", "which", "so", "far", "have", "only", "be", "solve", "offline", "highly", "parallelized", "non-linear", "optimization", "problem", "which", "we", "solve", "efficiently", "GPU", "use", "new", "patch-based", "gauss-newton", "solver", "from", "coarse", "depth", "RGB", "datum", "initial", "estimate", "illumination", "find", "-lrb-", "Sect", "high-dimensional", "non-linear", "optimization", "problem", "depth", "refinement", "solve", "use", "new", "gpu-based", "iterative", "gauss-newton", "solver", "-lrb-", "sect", "fig.", "highlight", "main", "step", "pipeline", "solve", "geometry", "lighting", "albedo", "from", "single", "rgbd", "image", "highly", "underconstrained", "order", "stabilize", "lighting", "order", "evaluate", "shade", "constraint", "w.r.t.", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "10", "-rrb-", "smoothness", "constraint", "shading-based", "refinement", "from", "single", "image", "ill-posed", "we", "employ", "geometric", "regularization", "constrain", "solution", "use", "normal", "from", "previous", "frame", "constrain", "depth", "current", "frame", "define", "-lrb-", "-rrb-", "-lrb-", "-lrb-", "-lrb-", "-rrb-", "-rrb-", "-lrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-rrb-", "-rrb-", "shade", "constraint", "reliable", "along", "silhouette", "we", "also", "search", "depth", "discontinuity", "set", "corresponding", "weight", "zero", "-rrb-", "its", "high", "number", "unknown", "real-time", "challenge", "next", "section", "we", "describe", "how", "solve", "optimization", "use", "novel", "gpu-based", "gaussnewton", "solver", "work", "patch", "subdivision", "image", "space", "optimize", "non-linear", "objective", "high", "number", "unknown", "real-time", "rate", "we", "exploit", "massively", "parallel", "architecture", "modern", "gpus", "minimize", "respect", "unknown", "parameter", "non-linear", "least", "square", "problem", "can", "rewrite", "we", "reformulate", "we", "objective", "term", "its", "residual", "vector", "obtain", "classical", "Gauss-Newton", "form", "result", "optimization", "problem", "linear", "least", "square", "problem", "argmin", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "unknown", "optimal", "update", "solve", "we", "develop", "approach", "can", "cope", "larger", "number", "variable", "exploit", "implicit", "topology", "depth", "mesh", "able", "perform", "all", "computation", "share", "memory", "include", "shade", "gradient", "energy", "smoothness", "energy", "we", "additionally", "have", "read", "two-pixel", "wide", "depth", "datum", "each", "patch", "boundary", "so", "computation", "can", "efficiently", "perform", "from", "local", "datum", "decouple", "patch", "split", "set", "parameter", "unconstrained", "inner", "-lrb-", "-rrb-", "constrain", "boundary", "-lrb-", "-rrb-", "variable", "per-patch", "problem", "solve", "use", "iterative", "pcg", "solver", "which", "explain", "next", "section", "process", "repeat", "time", "until", "convergence", "term", "convergence", "problem", "however", "approach", "become", "non-deterministic", "prolongation", "restriction", "we", "use", "bi-linear", "interpolation", "sample", "since", "video", "RGB", "datum", "frame", "synchronize", "Kinect", "one", "camera", "need", "move", "slowly", "order", "prevent", "artifact", "instance", "texture-copy", "artifact", "introduce", "high-frequency", "albedo", "change", "cause", "problem", "both", "online", "offline", "method", "-lsb-", "Richardt", "et", "al.", "2012", "Han", "et", "al.", "2013", "Yu", "et", "al.", "2013", "-rsb-" ],
  "content" : "We present the first real-time method for refinement of depth data using shape-from-shading in general uncontrolled scenes. Per frame, our real-time algorithm takes raw noisy depth data and an aligned RGB image as input, and approximates the time-varying incident lighting, which is then used for geometry refinement. This leads to dramatically enhanced depth maps at 30Hz. We conclude with applications of our higher quality depth maps for improved real-time surface reconstruction and performance capture. Consumer depth cameras have opened up many new real-time applications in the field of computer graphics and vision, robotics and human-computer interaction; including gestural interfaces, live 3D scanning, augmented reality, and robot navigation. However, the noise and resolution limitations of even recent depth cameras, result in only coarse geometry acquisition per frame. The ability to capture higher fidelity geometry in real-time could open up many new scenarios, such as tracking detailed features of the user (e.g., facial expressions, clothing etc.) for real-time performance capture or other interactive scenarios, as well as the ability to scan higher quality 3D models of real-world objects. As shown previously, input from a stereo camera and shape-fromshading (SfS) can be used to capture detailed models with results approaching laser scan quality [Wu et al. 2011; Han et al. 2013; Yu et al. 2013; Beeler et al. 2010]. So far, this was not possible in real time, and as such refinement techniques have yet to be used interactively. Due to this performance bottleneck, researchers have developed alternative heuristic fusion strategies to enhance depth camera data in real time [Richardt et al. 2012]. Many of them use variants of joint bilateral upsampling [Kopf et al. 2007] to lift the depth data to the pixel grid resolution of a concurrently acquired and aligned RGB image. While computation is fast, the results are based on a purely heuristic assumption about the co-occurrence of discontinuities in RGB and depth data. In consequence, reconstructions may look plausible but estimated detail may not be metrically accurate. Further, the heuristic underpinning leads to commonly known artifacts, such as texture copying, where spatial albedo variations are mistaken for geometric detail. In this paper, we propose a new real-time method for enhancement of depth data using SfS in general uncontrolled scenes. Starting from the raw depth data and an aligned RGB image, the algorithm estimates ? in real time ? the time-varying incident lighting distribution, which is then used to considerably enhance the reconstructed geometric detail. In contrast to previous fusion-based enhancement approaches, our reconstructions are not only plausible but more metrically faithful, and avoid some of the texture-copy artifacts seen previously. As such, we rephrase the shadingbased refinement problem to fully exploit the regular connectivity of image grids. Instead of using an off-the-shelf conventional solver, we introduce a novel patch-based Gauss-Newton solver running on the GPU, which is specifically designed for our energy function. ? an adaptive shape refinement strategy that reduces texture-copy artifacts by analyzing an approximate albedo image. Range Image Enhancement and Sensor Fusion Several methods to denoise and enhance depth data leverage the higher pixel resolution of one or two concurrently captured RGB images. Yang et al [2007] create  a cost space from the depth map, and filter it joint-bilaterally using a stereo image to raise resolution. While the above methods run offline, variants of joint-bilateral or multilateral filtering for depth upsampling can run in real-time [Chan et al. 2008; Dolson et al. 2010; Richardt et al. 2012]. The mathematics of SfS is well-understood, particularly when surface reflectance and light source positions are known. While the physics of SfS is well known, the problem is inherently ill-posed, and achieving compelling results requires strong scene and lighting assumptions, and computationally complex algorithms, particularly to solve hard inverse rendering optimizations. As such, real-time performance has rarely been demonstrated. However, these approaches require complex controlled lighting setups, which are not available in many standard scenarios. More data-driven approaches for solving the SfS problem have also been proposed. Khan et al. [2009] learn weighting parameters for complex SfS models to aid facial reconstruction. Again, none of these approaches achieves real-time performance. To achieve this goal, we reformulate the complex inverse problem for estimating illumination, albedo and refined geometry, which so far has only been solved offline, into a highly parallelized non-linear optimization problem, which we solve efficiently on the GPU using a new patch-based Gauss-Newton solver. From the coarse depth and the RGB data, an initial estimate of illumination is found (Sect. The high-dimensional non-linear optimization problem for depth refinement is solved using a new GPU-based iterative Gauss-Newton solver (Sect. Fig. 2 highlights these main steps in the pipeline. Solving for geometry, lighting, and albedo from a single RGBD image is highly underconstrained. In order to stabilize the lighting In order to evaluate the shading constraint w.r.t. ? f x ? n x (i,j)(u x ?i) + n y (i,j)(u y ?j) ? D(i?1,j)D(i,j?1) f x f y f x f y (10)\n          Smoothness Constraint As shading-based refinement from a single image is ill-posed, we employ geometric regularization to constrain the solution. This uses the normals from the previous frame to constrain the depth in the current frame, and is defined as: E r (i, j) = (n p (c(i, j)) ? (p(i, j) ? p(i ? 1, j))) 2 As the shading constraint is not reliable along silhouettes, we also search for depth discontinuities and set the corresponding weights to zero. 6) with its high number of unknowns in real-time is challenging. In the next section, we describe how to solve this optimization using a novel GPU-based GaussNewton solver that works on a patch subdivision in image space. To optimize a non-linear objective with such a high number of unknowns at real-time rates, we exploit the massively parallel architecture of modern GPUs. Minimizing E with respect to the unknown parameters is a non-linear least squares problem that can be rewritten as: M We reformulate our objective E in terms of its residual vector N ? M to obtain the classical Gauss-Newton form: The resulting optimization problem is a linear least squares problem ? ? = argmin ||F (d k ) + J(d k )?|| 2 , ? in the unknown optimal updates ? ? . To solve this, we develop an approach that can cope with the larger number of variables by exploiting the implicit topology of the depth mesh. To be able to perform all computations in shared memory, including the shading gradient energy and the smoothness energy, we additionally have to read a two-pixel wide depth data for each patch boundary, so that the computation can be efficiently performed from local data. This decouples the patches and splits the set of parameters into unconstrained inner (d i ) and constrained boundary (d b ) variables: The per-patch problem is solved using an iterative PCG solver, which is explained in the next section. The process is repeated N e times or until convergence. In terms of convergence, this is not a problem; however, the approach becomes non-deterministic. For prolongation and restriction, we use a bi-linear interpolation of the samples. Since video and RGB data are not frame synchronized in the Kinect One, the camera needs to be moved slowly in order to prevent artifacts. For instance, texture-copy artifacts are introduced by high-frequency albedo changes, causing problems for both online and offline methods [Richardt et al. 2012; Han et al. 2013; Yu et al. 2013].",
  "resources" : [ ]
}