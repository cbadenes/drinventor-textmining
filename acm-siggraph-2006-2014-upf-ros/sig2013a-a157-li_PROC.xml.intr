{
  "uri" : "sig2013a-a157-li_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2013a/a157-li_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Analyzing Growing Plants from 4D Point Cloud Data",
    "published" : "2013",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Yangyan-Li",
      "name" : "Yangyan",
      "surname" : "Li"
    }, {
      "uri" : "http://drinventor/Xiaochen-Fan",
      "name" : "Xiaochen",
      "surname" : "Fan"
    }, {
      "uri" : "http://drinventor/Niloy J.-Mitra",
      "name" : "Niloy J.",
      "surname" : "Mitra"
    }, {
      "uri" : "http://drinventor/Daniel A.-Chamovitz",
      "name" : "Daniel A.",
      "surname" : "Chamovitz"
    }, {
      "uri" : "http://drinventor/Daniel-Cohen-Or",
      "name" : "Daniel",
      "surname" : "Cohen-Or"
    }, {
      "uri" : "http://drinventor/Baoquan-Chen",
      "name" : "Baoquan",
      "surname" : "Chen"
    } ]
  },
  "bagOfWords" : [ "study", "growth", "process", "organic", "life", "form", "have", "long", "history", "science", "traditionally", "study", "rely", "manual", "recording", "growth", "stage", "image-based", "measurement", "take", "sparse", "interval", "workflow", "tedious", "prone", "measurement", "bias", "difficult", "scale", "large-scale", "observation", "both", "space", "time", "advance", "affordable", "3d", "acquisition", "device", "provide", "new", "opportunity", "plant", "growth", "fundamentally", "different", "from", "animal", "growth", "most", "animal", "bear", "all", "body", "organ", "which", "grow", "mature", "age", "contrast", "plant", "grow", "develop", "throughout", "life", "cycle", "constantly", "produce", "new", "tissue", "structure", "-lsb-", "Chen", "Laux", "2012", "-rsb-", "study", "development", "involve", "detect", "specific", "growth", "event", "-lrb-", "e.g.", "bud", "leaf", "see", "figure", "-rrb-", "quantify", "event", "track", "subsequent", "evolution", "over", "time", "beyond", "difficulty", "arise", "from", "motion", "key", "challenge", "track", "continuous", "shape", "change", "geometry", "topology", "albeit", "very", "slow", "rate", "due", "growth", "possibly", "due", "decay", "different", "from", "typical", "motion", "capture", "setup", "study", "human", "movement", "recent", "research", "acquisition", "method", "have", "lead", "rapid", "advance", "recover", "dynamic", "geometry", "acquisition", "while", "account", "miss", "datum", "outlier", "movement", "-lrb-", "e.g.", "rigid", "articulate", "nonrigid", "-rrb-", "among", "multiple", "scan", "across", "time", "all", "method", "however", "assume", "underlie", "object", "incompressible", "i.e.", "object", "can", "deform", "grow", "-lrb-", "decay", "-rrb-", "thus", "tracking", "plant", "growth", "-lrb-", "any", "growth", "larger", "context", "-rrb-", "require", "fundamentally", "different", "datum", "analysis", "algorithm", "we", "propose", "interleaved", "spatial", "temporal", "analysis", "4d", "where", "challenge", "accurately", "locate", "bud", "bifurcation", "event", "end", "we", "present", "forward-backward", "analysis", "where", "move", "forward", "time", "we", "identify", "after-affect", "i.e.", "we", "extract", "easier", "detect", "future", "event", "pull", "back", "time", "accurately", "locate", "event", "while", "still", "its", "infancy", "-lrb-", "see", "section", "-rrb-", "we", "show", "necessity", "forward-backward", "process", "its", "effectiveness", "accurately", "locate", "-lrb-", "morphological", "-rrb-", "event", "lead", "novel", "automate", "quantitative", "measurement", "analysis", "study", "plant", "growth", "-lrb-", "see", "Figure", "-rrb-", "we", "validate", "we", "method", "synthetic", "dataset", "successfully", "detect", "growth", "-lrb-", "decay", "-rrb-", "event", "scan", "sequence", "variety", "plant", "species", "-lrb-", "e.g.", "Anthurium", "Dishlia", "etc.", "-rrb-", "often", "acquire", "over", "day", "week", "-lrb-", "section", "-rrb-", "beyond", "implication", "study", "underlie", "growth", "law", "plant", "recover", "growth", "parameter", "immediately", "useful", "animate", "plant", "growth", "simulate", "which", "otherwise", "very", "tedious", "work", "artist", "-lrb-", "section", "-rrb-", "we", "use", "evolve", "organ", "consistently", "segmented", "out", "from", "4d", "point", "cloud", "synthesize", "live", "plant", "model", "both", "growth", "motion", "organ", "information", "well", "property", "associate", "each", "organ", "can", "feed", "plant", "simulator", "produce", "simulation", "accurately", "mimic", "observe", "motion", "reality", "3d", "4d", "reconstruction", "raw", "output", "3d", "scanner", "suffer", "from", "various", "imperfection", "include", "noise", "miss", "datum", "outlier", "different", "method", "have", "be", "develop", "improve", "quality", "corresponding", "reconstructed", "model", "-lrb-", "e.g.", "-lsb-", "Curless", "1999", "Alexa", "et", "al.", "2001", "Kazhdan", "et", "al.", "2006", "Huang", "et", "al.", "2009", "-rsb-", "reference", "therein", "-rrb-", "method", "mostly", "factor", "out", "camera", "movement", "consolidate", "scan", "across", "different", "viewpoint", "while", "assume", "scan", "object", "static", "when", "addition", "camera", "motion", "object", "move", "deform", "time", "information", "become", "critical", "hence", "4d", "reconstruction", "time", "be", "fourth", "dimension", "use", "accurate", "capture", "human", "motion", "facial", "expression", "while", "ensure", "spatio-temporal", "coherence", "across", "frame", "common", "approach", "fit", "pre-defined", "shape", "template", "which", "encode", "topology", "sometimes", "also", "coarse", "geometry", "capture", "shape", "while", "solve", "perframe", "pose", "variation", "-lsb-", "Ahmed", "et", "al.", "2008", "de", "Aguiar", "et", "al.", "2008", "Vlasic", "et", "al.", "2008", "Bradley", "et", "al.", "2008", "Pons-Moll", "et", "al.", "2011", "-rsb-", "when", "successive", "scan", "have", "small", "relative", "deformation", "share", "large", "overlap", "region", "adequate", "feature", "correspondence", "can", "find", "between", "consecutive", "frame", "case", "shape", "deformation", "can", "directly", "recover", "without", "need", "any", "prior", "template", "prior", "-lsb-", "Mitra", "et", "al.", "2007", "Liao", "et", "al.", "2009", "Wand", "et", "al.", "2009", "Popa", "et", "al.", "2010", "Tevs", "et", "al.", "2012", "Akhter", "et", "al.", "2012", "-rsb-", "case", "video", "sequence", "Beeler", "et", "al.", "-lsb-", "2011", "-rsb-", "find", "predefined", "anchor", "frame", "propagate", "information", "both", "forward", "backward", "establish", "frame", "correspondence", "addition", "deform", "plant", "also", "grow", "-lrb-", "both", "discrete", "continuous", "-rrb-", "over", "time", "thus", "violate", "key", "assumption", "all", "above", "method", "incompressible", "model", "fix", "topology", "many", "application", "scan", "object", "preserve", "volume", "-lrb-", "i.e.", "incompressible", "-rrb-", "even", "under", "deformation", "articulation", "hence", "Sharf", "et", "al.", "-lsb-", "2008", "-rsb-", "use", "incompressibility", "assumption", "perform", "volumetric", "reconstruction", "modeling", "material", "flow", "similarly", "consistency", "topology", "can", "use", "regularize", "registration", "reduce", "deformable", "model", "Chang", "et", "al.", "-lsb-", "2009", "2011", "-rsb-", "consensus", "skeleton", "across", "frame", "Zheng", "et", "al.", "-lsb-", "2010", "-rsb-", "temporally", "coherent", "hole", "fill", "Li", "et", "al.", "-lsb-", "2012", "-rsb-", "while", "shape", "template", "incompressibility", "topology", "consistency", "prior", "valid", "many", "object", "hence", "effective", "reconstruction", "often", "do", "apply", "plant", "specifically", "plant", "evolve", "continuously", "organ", "emerge", "build", "up", "wither", "result", "significant", "change", "shape", "-lrb-", "e.g.", "leaf", "curling", "-rrb-", "volume", "-lrb-", "e.g.", "leaf", "expansion", "bud", "formation", "-rrb-", "topology", "-lrb-", "e.g.", "stem", "bifurcation", "-rrb-", "recently", "Bojsen-Hansen", "et", "al.", "-lsb-", "2012", "-rsb-", "present", "method", "recover", "temporally", "coherent", "deform", "triangle", "mesh", "arbitrarily", "change", "topology", "from", "incoherent", "sequence", "static", "closed", "mesh", "surface", "medical", "imaging", "setting", "Lu", "et", "al.", "-lsb-", "2012", "-rsb-", "estimate", "probability", "detect", "tumor", "MRI", "scan", "use", "non-rigid", "registration", "bayesian", "setting", "we", "only", "focus", "deform", "shape", "also", "change", "topology", "necessary", "accurately", "capture", "growth-related", "activity", "plant", "modeling", "simulation", "procedural", "generation", "plant", "have", "receive", "much", "attention", "computer", "graphic", "-lrb-", "-lsb-", "Rozenberg", "Salomaa", "1980", "Prusinkiewicz", "Lindenmayer", "1996", "-rsb-", "-rrb-", "while", "possible", "create", "very", "realistic", "look", "plant", "use", "l-system", "we", "interested", "capture", "both", "form", "dynamics", "real", "plant", "growth", "analyze", "datum", "can", "turn", "use", "re-create", "high", "quality", "geometry", "animate", "procedural", "plant", "accurately", "realistically", "which", "very", "tedious", "achieve", "manually", "variety", "method", "have", "be", "develop", "generate", "static", "plant", "model", "from", "different", "datum", "source", "-lsb-", "Quan", "et", "al.", "2006", "Xu", "et", "al.", "2007", "Neubert", "et", "al.", "2007", "Livny", "et", "al.", "2010", "-rsb-", "M?ndermann", "et", "al.", "-lsb-", "2005", "-rsb-", "present", "approach", "recover", "descriptive", "developmental", "model", "Arabidopsis", "large", "amount", "measurement", "datum", "from", "sparsely", "time-lapse", "image", "Fernandez", "et", "al.", "-lsb-", "2010", "-rsb-", "propose", "semi-manual", "approach", "track", "plant", "growth", "cell", "resolution", "from", "4d", "confocal", "datum", "focus", "segment", "cell", "each", "frame", "compute", "cell", "lineage", "between", "frame", "we", "refer", "reader", "comprehensive", "survey", "-lsb-", "Prusinkiewicz", "Runions", "2012", "-rsb-", "we", "work", "more", "related", "recent", "work", "Li", "et", "al.", "-lsb-", "2011", "-rsb-", "who", "model", "generate", "move", "tree", "from", "video", "Pirk", "et", "al.", "-lsb-", "2012b", "-rsb-", "who", "leverage", "dynamic", "tree", "modeling", "representation", "adapt", "complex", "tree", "model", "environment", "interactively", "Pirk", "et", "al.", "-lsb-", "2012a", "-rsb-", "who", "compute", "developmental", "stage", "tree", "method", "approximate", "tree", "natural", "growth", "follow", "botanic", "growth", "model", "allometric", "rule", "although", "we", "target", "similar", "goal", "we", "capture", "live", "plant", "directly", "track", "growth", "without", "assume", "access", "underlie", "growth", "template", "bifurcation", "rule", "recently", "Zhao", "Barbi", "-lsb-", "2013", "-rsb-", "propose", "technique", "interactively", "author", "plant", "model", "simulation-ready", "decompose", "polygon", "soup", "domain", "build", "hierarchy", "between", "they", "while", "very", "challenging", "often", "ambiguous", "automatically", "segment", "plant", "individual", "organ", "from", "isolate", "plant", "model", "we", "demonstrate", "segmentation", "can", "robustly", "extract", "from", "raw", "4d", "point", "cloud", "make", "resultant", "model", "directly", "useable", "simulation", "framework", "thus", "provide", "complementary", "way", "generate", "simulation-ready", "model", "event", "detection", "apart", "from", "reconstruction", "time", "lapse", "2d", "image", "3d", "point", "cloud", "contain", "valuable", "datum", "can", "ana", "lyze", "detect", "understand", "particular", "event", "occur", "during", "capture", "time", "Brendel", "et", "al.", "-lsb-", "2011", "-rsb-", "Gaur", "et", "al.", "-lsb-", "2011", "-rsb-", "convert", "training", "video", "spatio-temporal", "preserving", "representation", "allow", "detection", "localization", "relevant", "activity", "match", "they", "training", "datum", "Pirsiavash", "et", "al.", "-lsb-", "2012", "-rsb-", "present", "first-person", "view", "camera", "involve", "long-scale", "temporal", "structure", "complex", "object", "interaction", "well", "analysis", "detect", "activity", "datum", "set", "Kevin", "et", "al.", "-lsb-", "2012", "-rsb-", "utilize", "conditional", "model", "able", "automatically", "discover", "discriminative", "interesting", "segment", "video", "Shotton", "et", "al.", "-lsb-", "2011", "-rsb-", "recognize", "human", "pose", "instance", "per-pixel", "classification", "problem", "towards", "real-time", "solution", "instead", "supervised", "approach", "we", "directly", "detect", "bud", "event", "analyze", "morphology", "inspect", "plant", "without", "access", "any", "training", "set", "Kalal", "et", "al.", "-lsb-", "2010", "-rsb-", "measure", "track", "quality", "base", "forwardbackward", "error", "instead", "error", "only", "from", "neighbor", "frame", "thus", "achieve", "robustness", "against", "local", "ambiguity", "we", "also", "propose", "forward-backward", "analysis", "accurately", "detect", "track", "event", "which", "often", "subtle", "automatically", "identify", "early", "stage", "thus", "best", "we", "knowledge", "we", "present", "first", "attempt", "focus", "event", "detection", "raw", "point", "cloud", "analyze", "growth", "pattern", "both", "geometry", "change", "topology", "across", "time", "context", "grow", "-lrb-", "decay", "-rrb-", "plant" ],
  "content" : "Studying growth processes in organic life forms has a long history in science. Traditionally, such studies rely on manual recordings of growth stages, or image-based measurements taken at sparse intervals. Such workflows are tedious, prone to measurement bias, and difficult to scale to large-scale observations, both in space and time. Advances in affordable 3D acquisition devices provide new opportunities. Plant growth is fundamentally different from animal growth. Most animals are born with all their body organs, which grow and mature with age. In contrast, plants grow and develop throughout their life cycle, constantly producing new tissues and structures [Chen and Laux 2012]. Studying such developments involves detecting specific growth events (e.g., budding of a leaf, see Figure 2 ), quantifying these events, and tracking their subsequent evolution over time. Beyond difficulties arising from motion, the key challenge is to track the continuous shape changes in geometry and topology, albeit at a very slow rate, due to growth, and possibly due to decay. This is different from typical motion capture setups studying human movements. Recent research in acquisition methods has led to rapid advances in recovering dynamic geometry acquisition while accounting for missing data, outliers, and movements (e.g., rigid, articulated, nonrigid) among multiple scans across time. All these methods, however, assume the underlying object to be incompressible, i.e., objects can deform but not grow (or decay). Thus, tracking plant growth (or any growth in a larger context) requires fundamentally different data analysis algorithms. We propose an interleaved spatial and temporal analysis in 4D, where the challenge is to accurately locate budding and bifurcation events. To that end, we present a forward-backward analysis, where moving forward in time we identify the ?after-affect?, i.e., we extract an easier to detect future event and pull it back in time to accurately locate the event while still in its infancy (see Sections 4 and 5). We show the necessity of this forward-backward process, and its effectiveness in accurately locating (morphological) events leading to novel automated quantitative measurement and analysis for studying plant growth (see Figure 2 ). We validated our method on synthetic datasets and successfully detected growth (and decay) events in scan sequences of a variety of plant species (e.g., Anthurium, Dishlia, etc.) often acquired over a period of days and weeks (Section 6). Beyond implications in studying the underlying growth laws of plants, the recovered growth parameters are immediately useful for animating plant growth and simulating, which are otherwise very tedious work for artists (Section 7). We use the evolving organs consistently segmented out from the 4D point cloud to synthesize live plant models with both growth and motion. The organ information as well as the properties associated with each organ can be fed into plant simulators to produce simulations that accurately mimic observed motions in reality. 3D and 4D reconstruction. Raw output of 3D scanners suffers from various imperfections including noise, missing data, and outliers. Different methods have been developed to improve the quality of the corresponding reconstructed models (e.g., [Curless 1999; Alexa et al. 2001; Kazhdan et al. 2006; Huang et al. 2009] and references therein). Such methods mostly factor out camera movements and consolidate the scans across different viewpoints while assuming the scanned object to be static. When, in addition to camera motion, objects move or deform, time information becomes critical. Hence, 4D reconstruction with time being the fourth dimension is used for accurate capture of human motion or facial expressions while ensuring spatio-temporal coherence across frames. A common approach is to fit pre-defined shape templates, which encode the topology and sometimes also the coarse geometry of the captured shape, while solving for perframe pose variations [Ahmed et al. 2008; de Aguiar et al. 2008; Vlasic et al. 2008; Bradley et al. 2008; Pons-Moll et al. 2011]. When successive scans have small relative deformation and share large overlapping regions, adequate feature correspondences can be found between consecutive frames. In such cases, shapes and deformations can be directly recovered without the need for any prior template priors [Mitra et al. 2007; Liao et al. 2009; Wand et al. 2009; Popa et al. 2010; Tevs et al. 2012; Akhter et al. 2012]. In the case of video sequences, Beeler et al. [2011] find predefined anchor frames and propagate the information both forward and backward to establish frame correspondence. In addition to deforming, plants also grow (both discrete and continuous) over time and thus violates a key assumption in all the above methods. Incompressible models and fixed topology. In many applications, the scanned objects preserve volumes (i.e., incompressible) even under deformations and articulation. Hence, Sharf et al. [2008] use an incompressibility assumption to perform volumetric reconstruction by modeling the material flow. Similarly, consistency in topology can be used to regularize the registration, such as reduced deformable models in Chang et al. [2009; 2011], consensus skeleton across frames in Zheng et al. [2010], or temporally coherent hole filling in Li et al. [2012]. While shape templates, incompressibility, and topology consistency priors are valid for many objects, and hence effective for their reconstructions, they often do not apply to plants. Specifically, plants evolve continuously as organs emerge, build up and wither, resulting in significant changes in shape (e.g., leaf curling), volume (e.g., leaf expansion and bud formation), and topology (e.g., stem bifurcation). Recently, Bojsen-Hansen et al. [2012] presented a method to recover a temporally coherent, deforming triangle mesh with arbitrarily changing topology from an incoherent sequence of static closed mesh surfaces. In the medical imaging setting, Lu et al. [2012] estimate the probability of detected tumors in MRI scans using non-rigid registration in a Bayesian setting. We not only focus on deforming shapes but also on changing topologies as necessary to accurately capture growth-related activities. Plant modeling and simulation. Procedural generation of plants has received much attention in computer graphics ( [Rozenberg and Salomaa 1980; Prusinkiewicz and Lindenmayer 1996]). While it is possible to create very realistic looking plants using L-systems, we are interested in capturing both form and dynamics of real plant growth. The analyzed data can be in turn used to re-create high quality geometry or ?animate? procedural plants accurately and realistically, which is very tedious to achieve manually. A variety of methods have been developed to generate static plant models from different data sources [Quan et al. 2006; Xu et al. 2007; Neubert et al. 2007; Livny et al. 2010]. M?ndermann et al. [2005] presented an approach to recover a descriptive developmental model for Arabidopsis with a large amount of measurement data from sparsely time-lapse images. Fernandez et al. [2010] proposed a semi-manual approach to track plant growth at cell resolution from 4D confocal data, focusing on segmenting cells of each frame and computing the cell lineages between frames. We refer the reader to the comprehensive survey of [Prusinkiewicz and Runions 2012]. Our work is more related to the recent work of Li et al. [2011], who model and generate moving trees from video, Pirk et al. [2012b], who leverage dynamic tree modeling and representation for adapting complex tree models to their environment interactively, and Pirk et al. [2012a], who compute developmental stages of a tree. The methods approximate trees? natural growth following botanic growth models and allometric rules. Although we target a similar goal, we capture live plants and directly track their growth without assuming access to an underlying growth template or bifurcation rules. Recently, Zhao and Barbi c [2013] proposed a technique to interactively author plant models to be simulation-ready by decomposing the polygon soup into domains and building a hierarchy between them. While it is very challenging and often ambiguous to automatically segment plants into individual organs from isolated plant models, we demonstrate that such segmentation can be robustly extracted from a raw 4D point cloud, making the resultant models directly useable by their simulation framework, and thus providing a complementary way to generate simulation-ready models. Event detection. Apart from reconstruction, time lapse of 2D images or 3D point clouds contain valuable data that can be ana- lyzed to detect and understand particular events that occurred during the captured time periods. Brendel et al. [2011] and Gaur et al. [2011] convert training videos into spatio-temporal preserving representations, to allow the detection and localization of relevant activities by matching them to the training data. Pirsiavash et al. [2012] presented a first-person view camera involving long-scale temporal structure and complex object interactions as well as analysis on detecting activities in the data set. Kevin et al. [2012] utilize a conditional model that is able to automatically discover discriminative and interesting segments of video. Shotton et al. [2011] recognize human pose as an instance of per-pixel classification problem towards a real-time solution. Instead of a supervised approach, we directly detect budding events by analyzing the morphology of the inspected plant, without access to any training set. Kalal et al. [2010] measure tracking quality based on a forwardbackward error instead of errors only from neighboring frames, thus achieving robustness against local ambiguities. We also propose a forward-backward analysis but for accurately detecting and tracking events, which are often subtle to automatically identify in their early stages. Thus, to the best of our knowledge, we present the first attempt focusing on event detection in raw point clouds, and analyzing growth patterns, both in geometry and changing topology across time, in the context of growing (and decaying) plants.",
  "resources" : [ ]
}