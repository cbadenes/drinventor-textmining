{
  "uri" : "sig2012-a51-lehtinen_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2012/a51-lehtinen_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Reconstructing the Indirect Light Field for Global Illumination",
    "published" : "2012",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Jaakko-Lehtinen",
      "name" : "Jaakko",
      "surname" : "Lehtinen"
    }, {
      "uri" : "http://drinventor/Timo-Aila",
      "name" : "Timo",
      "surname" : "Aila"
    }, {
      "uri" : "http://drinventor/Samuli-Laine",
      "name" : "Samuli",
      "surname" : "Laine"
    }, {
      "uri" : "http://drinventor/Fr?do-Durand",
      "name" : "Fr?do",
      "surname" : "Durand"
    } ]
  },
  "bagOfWords" : [ "we", "result", "show", "dramatic", "improvement", "image", "quality", "while", "use", "very", "sparse", "input", "sampling", "we", "contribute", "method", "adapt", "sampling", "rate", "nonuniform", "sparse", "uncontrolled", "input", "both", "space", "angle", "spatio-angular", "anisotropic", "reconstruction", "method", "filter", "radiance", "from", "sparse", "sample", "robust", "method", "reasoning", "about", "occlusion", "base", "only", "input", "ray", "give", "we", "crucial", "advantage", "performance", "only", "weakly", "dependent", "scene", "sense", "we", "algorithm", "can", "see", "advanced", "image", "filter", "we", "algorithm", "produce", "megapixel", "image", "glossy", "reflection", "global", "illumination", "ambient", "occlusion", "few", "minute", "mean", "sample", "draw", "one", "pixel", "tell", "we", "something", "about", "integrand", "other", "pixel", "well", "which", "enable", "reconstruction", "better", "image", "from", "same", "sample", "make", "we", "algorithm", "much", "less", "intrusive", "original", "renderer", "geometric", "resampling", "we", "method", "reasoning", "about", "occlusion", "base", "sample", "from", "initial", "sampling", "have", "also", "connection", "ray", "trace", "point-based", "geometry", "-lsb-", "schaufler", "Wann", "Jensen", "2000", "Christensen", "2008", "Ritschel", "et", "al.", "2009", "-rsb-", "reuse", "facilitate", "anisotropy", "exhibit", "incident", "light", "field", "-lsb-", "Durand", "et", "al.", "2005", "-rsb-", "provide", "we", "can", "quantify", "visibility", "angular", "effect", "radiance", "leave", "point", "along", "ray", "provide", "information", "about", "radiance", "carry", "other", "nearby", "ray", "algorithm", "overview", "first", "pass", "we", "use", "standard", "path", "tracer", "only", "draw", "few", "sample", "per", "pixel", "typically", "16", "after", "we", "compute", "each", "input", "sample", "spatial", "radius", "influence", "determine", "how", "far", "contribute", "light", "field", "reconstruction", "adapt", "density", "input", "sample", "both", "space", "angle", "-lrb-", "section", "2.2", "-rrb-", "furthermore", "we", "need", "treat", "visibility", "carefully", "avoid", "fattening", "small", "feature", "silhouette", "when", "perform", "reconstruction", "second", "pass", "we", "evaluate", "shade", "equation", "each", "visible", "point", "use", "high-sampling-rate", "reconstruction", "incoming", "hemisphere", "key", "operation", "reconstruction", "4d", "incoming", "light", "field", "along", "give", "ray", "we", "find", "all", "input", "ray", "whose", "spatial", "radius", "overlap", "ray", "group", "they", "apparent", "surface", "use", "visibility", "heuristic", "-lrb-", "section", "2.3.2", "-rrb-", "radiance", "from", "point", "towards", "camera", "compute", "support", "angular", "variation", "outgoing", "illumination", "glossy", "surface", "we", "also", "store", "measure", "angular", "bandwidth", "determine", "from", "outgoing", "slice", "brdf", "hit", "point", "we", "use", "unnormalized", "spherical", "von", "mises-fisher", "distribution", "give", "sample", "record", "first", "pass", "second", "pass", "evaluate", "each", "primary", "hit", "input", "sample", "function", "econstruct", "-lrb-", "-rrb-", "perform", "upsampling", "incident", "light", "field", "base", "input", "sample", "because", "we", "can", "hope", "recover", "feature", "present", "input", "we", "make", "assumption", "input", "sample", "faithfully", "represent", "true", "indirect", "light", "field", "i.e.", "capture", "its", "frequency", "content", "density", "input", "sample", "complex", "function", "scene", "its", "material", "sampler", "use", "original", "renderer", "we", "do", "reason", "about", "priori", "instead", "discover", "local", "sampling", "rate", "modify", "k-nearest-neighbor", "search", "-lrb-", "section", "2.2", "-rrb-", "we", "use", "variant", "where", "uv", "coordinate", "measure", "relative", "st", "coordinate", "-lsb-", "Chai", "et", "al.", "2000", "Durand", "et", "al.", "2005", "-rsb-", "essentially", "form", "linearized", "angle", "we", "seek", "reconstruct", "ray", "within", "arbitrary", "location", "direction", "scene", "we", "internally", "store", "ray", "segment", "use", "3d", "hit", "point", "dynamically", "reparameterize", "light", "field", "around", "we", "reconstruction", "ray", "-lsb-", "Isaksen", "et", "al.", "2000", "-rsb-", "order", "perform", "meaningful", "reconstruction", "we", "have", "adapt", "sampling", "rate", "both", "space", "angle", "glossy", "surface", "where", "radiance", "vary", "over", "angle", "we", "might", "need", "go", "further", "space", "find", "input", "sample", "whose", "direction", "better", "match", "reconstruction", "ray", "along", "line", "previous", "point-based", "rendering", "algorithm", "we", "treat", "input", "sample", "circular", "disk", "-lrb-", "splat", "-rrb-", "3d", "individual", "tangent", "plane", "we", "determine", "size", "analyze", "local", "sample", "density", "set", "spatial", "support", "sample", "we", "search", "its", "kth", "nearest", "neighbor", "space", "around", "its", "secondary", "hit", "point", "only", "consider", "sample", "whose", "direction", "fall", "close", "enough", "angle", "threshold", "determine", "from", "require", "-lrb-", "-rrb-", "0.5", "illustrate", "effect", "first", "consider", "almost", "diffuse", "surface", "radiance", "vary", "slowly", "over", "outgoing", "direction", "almost", "constant", "angle", "-lrb-", "angular", "bandwidth", "low", "consequently", "small", "-rrb-", "search", "simplify", "regular", "k-nn", "space", "consequently", "spatial", "support", "small", "-lrb-", "figure", "leave", "-rrb-", "more", "glossy", "surface", "angular", "bandwidth", "higher", "cause", "k-nn", "search", "disregard", "spatially", "close-by", "sample", "favor", "those", "closer", "angle", "consequently", "support", "wider", "space", "-lrb-", "figure", "right", "-rrb-", "we", "use", "metric", "penalize", "movement", "direction", "normal", "encourage", "search", "support", "favor", "sample", "lie", "locally", "flat", "region", "specifically", "we", "use", "Mahalanobis", "distance", "squash", "distance", "along", "normal", "each", "splat", "factor", "-lrb-", "we", "use", "-rrb-", "implement", "simply", "compute", "euclidean", "length", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-lrb-", "-rrb-", "-rrb-", "where", "normal", "addition", "spatial", "filter", "circular", "splat", "use", "resolve", "visibility", "when", "perform", "reconstruction", "we", "need", "gather", "all", "input", "sample", "whose", "spatial", "support", "intersect", "reconstruction", "ray", "reminiscent", "previous", "point-based", "rendering", "algo", "rithm", "-lsb-", "schaufler", "Wann", "Jensen", "2000", "-rsb-", "accelerate", "we", "organize", "secondary", "hit", "point", "-lcb-", "-rcb-", "motion", "bound", "volume", "hierarchy", "-lsb-", "glassner", "1988", "-rsb-", "use", "streaming", "algorithm", "Kontkanen", "et", "al.", "-lsb-", "2011", "-rsb-", "during", "reconstruction", "hierarchy", "use", "standard", "fashion", "walk", "bvh", "intersect", "reconstruction", "ray", "splat", "intersected", "leaf", "node", "order", "we", "reconstruction", "accurate", "visibility", "function", "induce", "splat", "should", "resemble", "true", "occlusion", "scene", "however", "precede", "k-nn", "procedure", "do", "guarantee", "consistency", "original", "sampling", "small", "geometric", "feature", "-lrb-", "e.g.", "leave", "plant", "-rrb-", "might", "only", "hit", "few", "input", "sample", "when", "get", "enlarged", "k-nn", "procedure", "some", "ray", "present", "input", "might", "erroneously", "intersect", "they", "force", "representation", "consistent", "input", "we", "observe", "input", "ray", "carry", "exact", "information", "about", "point-wise", "visibility", "scene", "we", "know", "certainty", "ray", "from", "terminate", "without", "be", "block", "between", "inspire", "we", "retrace", "all", "input", "ray", "use", "bvh", "shrink", "splat", "intersect", "ray", "should", "finally", "bound", "box", "bvh", "node", "recompute", "accommodate", "new", "size", "conclude", "preprocessing", "input", "sample", "result", "splat", "faithfully", "represent", "visibility", "determine", "original", "secondary", "ray", "while", "adapt", "local", "density", "cause", "spurious", "occlusion", "cf.", "figure", "once", "have", "be", "find", "sample", "sort", "accord", "distance", "from", "ray", "origin", "group", "apparent", "surface", "group", "proceeds", "greedily", "add", "next", "sample", "open", "surface", "long", "do", "conflict", "any", "sample", "already", "surface", "term", "visibility", "when", "visibility", "conflict", "detect", "-lrb-", "see", "below", "-rrb-", "new", "surface", "start", "note", "operation", "entirely", "local", "do", "make", "use", "sample", "whose", "support", "intersect", "reconstruction", "ray", "addition", "we", "ray", "originate", "from", "terminate", "arbitrary", "3d", "point", "scene", "we", "visibility", "heuristic", "work", "consider", "positive", "halfspace", "i.e.", "point", "where", "-lrb-", "-rrb-", "define", "hit", "point", "normal", "each", "input", "sample", "intersection", "point", "lie", "within", "positive", "halfspace", "both", "sample", "conflict", "declare", "cf.", "Figure", "approach", "detect", "conflict", "when", "two", "surface", "top", "each", "other", "allow", "blending", "sample", "come", "from", "same", "locally", "flat", "convex", "concave", "surface", "once", "visibility", "heuristic", "have", "be", "evaluate", "sample", "group", "apparent", "surface", "sample", "nearest", "apparent", "surface", "input", "ray", "whose", "hit", "point", "determine", "visible", "from", "origin", "reconstruction", "ray", "require", "adapt", "anisotropy", "bandwidth", "light", "field", "around", "reconstruction", "ray", "consider", "situation", "where", "reconstruction", "ray", "intersect", "spatial", "support", "three", "sample", "-lrb-", "figure", "leave", "-rrb-", "local", "two-plane", "parameterization", "stuv", "construct", "around", "reconstruction", "ray", "reconstruction", "ray", "correspond", "point", "origin", "-lrb-", "figure", "middle", "-rrb-", "each", "input", "ray", "correspond", "single", "point", "each", "input", "sample", "set", "all", "ray", "intersect", "spatial", "support", "form", "set", "planar", "boundary", "-lrb-", "figure", "middle", "-rrb-", "clearly", "reconstruction", "ray", "belong", "set", "diffuse", "surface", "where", "angular", "bandwidth", "zero", "reconstruction", "simple", "we", "evaluate", "spatial", "filter", "-lrb-", "tent", "we", "implementation", "-rrb-", "intersection", "reconstruction", "ray", "splat", "take", "weighted", "average", "among", "all", "sample", "local", "coordinate", "system", "center", "each", "sample", "-lrb-", "figure", "leave", "-rrb-", "correspond", "separable", "4d", "filter", "product", "tent", "space", "constant", "angle", "-lrb-", "correspond", "zero", "angular", "bandwidth", "-rrb-", "reparameterization", "stuv", "coordinate", "around", "reconstruction", "ray", "shears", "filter", "anisotropic", "shape", "show", "-lrb-", "Figure", "middle", "-rrb-", "radiance", "leave", "glossy", "surface", "vary", "over", "outgoing", "angle", "we", "need", "account", "reuse", "sample", "whose", "direction", "similar", "we", "reconstruction", "ray", "non-zero", "angular", "bandwidth", "glossy", "sample", "lead", "wider", "spatial", "support", "result", "bandwidth-aware", "k-nn", "search", "local", "coordinate", "system", "orient", "each", "sample", "visible", "narrower", "angular", "filter", "wider", "space", "-lrb-", "figure", "right", "-rrb-", "when", "filter", "transform", "stuv", "coordinate", "system", "we", "obtain", "anisotropic", "shape", "orient", "similarly", "diffuse", "filter", "-lrb-", "figure", "right", "-rrb-", "we", "perform", "reconstruction", "evaluate", "transform", "filter", "stuv", "origin", "pick", "sample", "whose", "filter", "have", "largest", "magnitude", "can", "see", "anisotropic", "nearest", "neighbor", "filter", "we", "use", "nearest", "neighbor", "glossy", "surface", "mitigate", "effect", "highly", "non-uniform", "angular", "distribution", "we", "input", "sample", "use", "linear", "angular", "filter", "noticeably", "shift", "reconstruction", "towards", "denser", "sampling", "which", "visible", "final", "image", "shift", "highlight", "angular", "shift", "result", "spatial", "shift", "after", "propagation", "necessary", "diffuse", "reflectance", "where", "outgoing", "angle", "play", "role", "discussion", "we", "filter", "scheme", "account", "both", "spatial", "angular", "bandwidth", "outgoing", "light", "field", "input", "sample", "spatial", "angular", "dimension", "balance", "k-nn", "algorithm", "use", "determine", "spatial", "support", "sample", "we", "sample", "lie", "actual", "curved", "surface", "we", "input", "whole", "contain", "effect", "we", "input", "do", "carry", "information", "about", "curvature", "property", "incident", "light", "field", "reconstruction", "filter", "individual", "sample", "can", "account", "additional", "shears", "regardless", "we", "treatment", "allow", "faithful", "reconstruction", "glossy", "surface", "reflect", "off", "other", "glossy", "surface", "demonstrate", "result", "when", "reconstruction", "ray", "point", "towards", "fronto-parallel", "surface", "uniform", "angular", "sampling", "we", "reconstruction", "procedure", "correspond", "perform", "nearest", "neighbor", "space", "have", "be", "warped", "use", "Mahalanobis", "distance", "align", "anisotropy", "light", "field", "render", "isocontour", "filter", "locally", "isotropic", "we", "prototype", "implementation", "we", "support", "Torrance-Sparrow", "BRDF", "model", "Blinn", "microfacet", "distribution", "-lrb-", "metal", "material", "pbrt", "-rrb-", "take", "1/r", "where", "roughness", "parameter", "Blinn", "distribution", "-lsb-", "pharr", "Humphreys", "2010", "-rsb-", "formulum", "choose", "empirically", "since", "pbrt", "treat", "geometric", "primitive", "two-sided", "we", "need", "do", "same", "when", "reconstruction", "ray", "hit", "back-facing", "splat", "contribute", "visibility", "similarly", "front-facing", "splat", "however", "back-facing", "splat", "contribute", "radiance", "only", "all", "splat", "first", "surface", "back-facing", "otherwise", "radiance", "contribution", "ignore", "rare", "occasion", "reconstruction", "ray", "may", "hit", "surface", "consist", "only", "one", "two", "sample", "although", "k-nn", "search", "try", "guarantee", "never", "happen", "subsequent", "shrinking", "may", "affect", "result", "happen", "instance", "inside", "dense", "foliage", "where", "individual", "leaf", "may", "hit", "only", "one", "input", "sample", "avoid", "over-estimate", "occlusion", "we", "empirically", "reduce", "splat", "size", "single-sample", "surface", "two-sample", "sur2", "face", "when", "undersampling", "detect", "treatment", "affect", "less", "than", "reconstruction", "ray", "we", "scene", "we", "have", "implement", "we", "algorithm", "standalone", "library", "take", "buffer", "sample", "input", "modify", "pbrt", "-lsb-", "pharr", "Humphreys", "2010", "-rsb-", "generate", "input", "we", "have", "produce", "both", "multicore", "CPU", "GPU", "implementation", "reconstruction", "algorithm", "we", "test", "platform", "3.2", "GHz", "quad", "core", "Intel", "Core", "i7", "NVIDIA", "GTX480", "all", "result", "image", "be", "render", "1280", "720", "-lrb-", "720p", "-rrb-", "section", "we", "first", "test", "reconstruction", "indirect", "illumination", "diffuse", "scene", "follow", "glossy", "reflection", "we", "perform", "more", "target", "test", "demonstrate", "we", "occlusion", "heuristic", "allow", "faithful", "reproduction", "visibility", "we", "use", "ambient", "occlusion", "test", "case", "because", "its", "quality", "directly", "determine", "accuracy", "visibility", "finally", "we", "show", "result", "defocus", "motion", "blur", "we", "focus", "quality", "reconstructed", "image", "postpone", "discussion", "about", "scalability", "memory", "consumption", "extension", "Section", "we", "compare", "we", "result", "method", "similarly", "we", "reconstruct", "image", "base", "small", "number", "fat", "sample", "-lsb-", "Lehtinen", "et", "al.", "2011", "Dammertz", "et", "al.", "2010", "Sen", "Darabi", "2012", "-rsb-", "auxiliary", "material", "contain", "all", "uncompressed", "image", "show", "refer", "section", "we", "reconstruct", "multi-bounce", "diffuse", "global", "illumination", "iguel", "light", "area", "light", "source", "-lrb-", "figure", "-rrb-", "input", "contain", "sample", "per", "pixel", "-lrb-", "leftmost", "inset", "-rrb-", "we", "reconstruct", "incident", "light", "field", "over", "hemisphere", "visible", "point", "integrate", "produce", "result", "-lrb-", "third", "inset", "from", "left", "-rrb-", "per", "equation", "we", "pay", "special", "attention", "fact", "radiance", "input", "sample", "contain", "noise", "due", "multiple", "bounce", "render", "path", "tracer", "we", "reconstruction", "more", "true", "ground", "truth", "-lrb-", "second", "left", "-rrb-", "than", "comparison", "method", "a-trous", "wavelet", "-lsb-", "Dammertz", "et", "al.", "2010", "-rsb-", "-lrb-", "fourth", "inset", "from", "leave", "-rrb-", "random", "parameter", "filter", "-lrb-", "rpf", "last", "one", "right", "-rrb-", "-lsb-", "Sen", "Darabi", "2012", "-rsb-", "we", "use", "both", "comparison", "method", "reconstruct", "incident", "irradiance", "i.e.", "before", "multiplication", "texture", "render", "spp", "input", "pbrt", "take", "36.6", "we", "reconstruction", "256", "reconstruction", "ray", "per", "pixel", "GPU", "take", "189.5", "s.", "preprocessing", "include", "build", "bvh", "size", "sample", "use", "k-nn", "shrink", "sample", "use", "input", "ray", "take", "9.5", "rest", "spend", "reconstruction", "ray", "considerably", "more", "efficient", "than", "render", "similar-quality", "512", "spp", "image", "pbrt", "which", "take", "3910.5", "18x", "longer", "than", "combine", "input", "reconstruction", "we", "256", "spp", "result", "exhibit", "significantly", "less", "noise", "than", "pbrt?s", "256", "spp", "rendering", "thanks", "we", "spatial", "filter", "sample", "Notice", "we", "ability", "perform", "image", "antialiasing", "limit", "number", "primary", "hit", "input", "sample", "supplemental", "video", "contain", "short", "animation", "render", "from", "input", "sample", "per", "pixel", "use", "512", "reconstruction", "ray", "per", "pixel", "each", "frame", "process", "isolation", "temporal", "filter", "any", "kind", "employ", "result", "demonstrate", "temporal", "stability", "we", "reconstruction", "even", "from", "severely", "noisy", "input", "comparison", "method", "A-Trous", "iterative", "approximation", "cross-bilateral", "filter", "twist", "when", "spatial", "support", "widen", "between", "iteration", "range", "filter", "tighten", "allow", "application", "very", "large", "spatial", "filter", "without", "disproportionate", "blur", "original", "implementation", "use", "three", "range", "filter", "color", "normal", "world-space", "position", "since", "we", "input", "very", "noisy", "we", "do", "wish", "clamp", "input", "sample", "energy", "we", "choose", "use", "color", "range", "filter", "-lrb-", "use", "give", "worse", "result", "-rrb-", "while", "quality", "leave", "some", "room", "improvement", "a-trous", "filter", "efficient", "we", "CPU", "implementation", "take", "58", "scene", "since", "reference", "implementation", "random", "parameter", "filter", "-lrb-", "rpf", "-rrb-", "available", "we", "reimplement", "follow", "author", "detailed", "guideline", "-lsb-", "Sen", "Darabi", "2011", "-rsb-", "rpf", "sophisticated", "cross-bilateral", "filter", "automatically", "tune", "weight", "each", "feature", "each", "pixel", "base", "mutual", "information", "between", "domain", "variable", "scene", "feature", "-lrb-", "position", "normal", "texture", "etc.", "-rrb-", "radiance", "input", "sample", "almost", "identical", "ours", "unfortunately", "original", "formulation", "rpf", "make", "heavy", "use", "color", "channel", "range", "filter", "require", "special", "treatment", "bright", "sample", "-lrb-", "hdr", "clamp", "-rrb-", "which", "essentially", "discard", "high-energy", "spike", "lose", "significant", "amount", "energy", "up", "50", "we", "test", "we", "modify", "algorithm", "reinsert", "lose", "energy", "evenly", "all", "sample", "within", "pixel", "we", "reasonably", "tune", "CPU", "implementation", "filter", "image", "2895", "roughly", "line", "result", "we", "estimate", "10x", "possible", "speedup", "from", "GPU", "port", "we", "use", "parameter", "recommend", "author", "guideline", "Figure", "show", "onkey", "ead", "scene", "three", "statuette", "decrease", "gloss", "glossy", "ground", "plane", "scene", "light", "single-bounce", "indirect", "illumination", "from", "distant", "point", "light", "source", "-lrb-", "direct", "illumination", "show", "-rrb-", "consequently", "input", "sample", "noise-free", "input", "contain", "sample", "per", "pixel", "we", "result", "compute", "use", "512", "reconstruction", "ray", "per", "pixel", "a-trous", "rpf", "result", "show", "below", "we", "notice", "result", "a-trous", "roughness", "0.01", "0.05", "0.25", "statuette", "0.01", "ground", "plane", "could", "significantly", "improve", "introduce", "additional", "range", "filter", "over", "normal", "secondary", "hit", "which", "conveniently", "present", "we", "datum", "we", "present", "extension", "we", "comparison", "result", "addition", "original", "algorithm", "we", "result", "significantly", "closer", "grind", "truth", "than", "either", "comparison", "method", "both", "visually", "term", "psnr", "-lrb-", "38.6", "db", "vs.", "31", "33db", "-rrb-", "full-size", "image", "provide", "auxiliary", "material", "closer", "inspection", "particular", "we", "reconstruct", "position", "sharpness", "reflection", "faithfully", "thanks", "4d", "treatment", "input", "sample", "account", "both", "space", "angle", "Figure", "10", "demonstrate", "importance", "accounting", "angular", "effect", "while", "comparison", "method", "produce", "smooth", "result", "reflection", "have", "shift", "noticeably", "sharp", "should", "note", "unlike", "comparison", "method", "we", "use", "render", "system", "-lrb-", "pbrt", "-rrb-", "evaluate", "brdf", "final", "bounce", "towards", "eye", "per", "equation", "while", "closely", "match", "ground", "truth", "we", "algorithm", "currently", "2.6", "slower", "scene", "than", "reference", "method", "mainly", "due", "extreme", "geometric", "simplicity", "scene", "which", "play", "we", "disadvantage", "because", "we", "algorithm", "scale", "weakly", "scene", "complexity", "-lrb-", "section", "-rrb-", "we", "spatial", "hierarchy", "do", "currently", "include", "angular", "subdivision", "-lsb-", "Arvo", "Kirk", "1987", "-rsb-", "we", "may", "therefore", "process", "redundant", "splat", "glossy", "surface", "where", "spatial", "support", "larger", "-lrb-", "section", "2.2", "-rrb-", "another", "possible", "improvement", "discuss", "section", "regardless", "result", "demonstrate", "information", "require", "reconstruct", "high-quality", "reflection", "present", "sparse", "input", "we", "algorithm", "correctly", "extract", "produce", "high-quality", "result", "we", "algorithm", "can", "easily", "use", "render", "ambient", "occlusion", "bypass", "radiance", "filter", "threshold", "distance", "closest", "apparent", "surface", "find", "Figure", "show", "we", "ambient", "occlusion", "reconstruction", "iguel", "although", "scene", "contain", "fine", "geometric", "feature", "groove", "vegetation", "we", "reconstruction", "from", "only", "input", "sample", "per", "pixel", "very", "close", "agreement", "ground", "truth", "compute", "use", "2048", "sample", "per", "pixel", "case", "image", "antialiasing", "particularly", "limit", "since", "input", "contain", "only", "primary", "hit", "per", "pixel", "GPU", "execution", "time", "145", "seconds", "256", "reconstruction", "ray", "per", "pixel", "720p", "contrast", "ambient", "occlusion", "technique", "Egan", "et", "al.", "-lsb-", "2011a", "-rsb-", "we", "do", "resort", "brute", "force", "Monte", "Carlo", "sampling", "original", "scene", "all", "finally", "we", "demonstrate", "generality", "we", "reconstruction", "apply", "motion", "blur", "defocus", "-lrb-", "figure", "11", "-rrb-", "we", "use", "utterfly", "dataset", "from", "Lehtinen", "et", "al.", "-lsb-", "2011", "-rsb-", "compare", "against", "publicly", "available", "implementation", "we", "result", "slightly", "more", "accurate", "approx", "db", "term", "pnsr", "image", "available", "supplemental", "material", "we", "better", "result", "explain", "we", "better", "adaptation", "input", "sampling", "rate", "use", "worst-case", "radius", "derive", "from", "dispersion", "sampling", "pattern", "which", "tend", "blur", "in-focus", "geometry", "slightly", "may", "still", "result", "lack", "support", "region", "temporal", "light", "field", "contain", "feature", "visible", "from", "only", "small", "fraction", "lens", "shutter", "interval", "contrast", "we", "k-nn", "approach", "adapt", "local", "sampling", "density", "lead", "sharp", "result", "well", "input", "-lrb-", "spp", "-rrb-", "we", "reconstruction", "we", "reconstruction", "a-trous", "rpf", "ground", "truth", "-lrb-", "2048", "spp", "-rrb-", "sample", "area", "better", "support", "lower", "sampling", "density", "area", "demonstrate", "Figure", "12", "we", "reconstruction", "take", "4x", "longer", "than", "algorithm", "Lehtinen", "et", "al.", "primarily", "because", "use", "specialize", "2d", "hierarchy", "post-perspective", "space", "essentially", "tailor", "datum", "structure", "known", "distribution", "reconstruction", "ray", "-lrb-", "all", "originate", "from", "lens", "-rrb-", "we", "focus", "reconstruct", "incident", "light", "field", "arbitrary", "point", "scene", "we", "use", "true", "3d", "hierarchy", "we", "result", "angular", "bandwidth", "scalability", "memory", "consumption", "execution", "time", "we", "algorithm", "scale", "linearly", "number", "reconstruction", "ray", "only", "very", "weakly", "affect", "structure", "scene", "number", "input", "sample", "example", "increase", "number", "input", "sample", "from", "iguel", "increase", "execution", "time", "only", "about", "40", "also", "iguel", "take", "only", "80", "longer", "reconstruct", "than", "ornell", "same", "parameter", "even", "though", "original", "model", "contain", "about", "order", "magnitude", "more", "geometry", "have", "much", "more", "challenging", "structure", "-lrb-", "foliage", "vs.", "straight", "wall", "-rrb-", "memory", "consumption", "almost", "completely", "determine", "number", "input", "sample", "each", "sample", "consist", "30", "floating-point", "number", "total", "up", "1gb", "720p", "input", "sample", "per", "pixel", "independent", "scene", "structure", "addition", "bvh", "consume", "about", "80mb", "parameter", "again", "almost", "independently", "scene", "structure", "all", "other", "memory", "usage", "negligible", "recursive", "filter", "very", "low", "input", "sampling", "rate", "artifact", "can", "appear", "near", "corner", "when", "we", "integrate", "over", "hemisphere", "large", "fraction", "reconstruction", "ray", "may", "hit", "same", "few", "sample", "sample", "noisy", "reconstructed", "image", "can", "suffer", "from", "structured", "artifact", "demonstrate", "Figure", "13", "example", "ornell", "render", "up", "eight-bounce", "indirect", "illumination", "from", "point", "light", "1024", "1024", "only", "one", "sample", "per", "pixel", "multiple", "bounce", "lead", "noise", "sample", "radiance", "we", "implement", "experimental", "step", "reduce", "variance", "perform", "quick", "reconstruction", "incident", "lighting", "secondary", "hit", "replace", "secondary", "hit", "radiance", "Lehtinen", "et", "al.", "-lsb-", "2011", "-rsb-", "do", "adapt", "local", "density", "input", "sample", "fail", "reconstruct", "marked", "region", "we", "novel", "visibility", "heuristic", "reproduce", "correct", "visibility", "reconstructed", "value", "before", "reconstruct", "incident", "lighting", "primary", "hit", "scene", "perform", "step", "16", "reconstruction", "ray", "add", "less", "than", "10", "execution", "time", "almost", "completely", "remove", "artifact", "result", "we", "reconstruction", "match", "ground", "truth", "closely", "accurately", "preserve", "boundary", "indirect", "shadow", "image", "antialiasing", "still", "miss", "because", "we", "have", "only", "one", "primary", "ray", "per", "pixel", "Notice", "black", "border", "near", "corner", "present", "ground", "truth", "pbrt", "render", "well", "glossy", "gi", "noisy", "sample", "should", "possible", "generalize", "recursive", "filter", "more", "reliable", "handling", "highly", "specular", "surface", "extreme", "clearly", "very", "useful", "reconstruct", "incident", "radiance", "onto", "mirror", "from", "sparse", "sample", "instead", "would", "make", "more", "sense", "reconstruct", "next", "path", "segment", "remove", "noise", "surface", "see", "mirror", "information", "content", "we", "find", "interesting", "even", "very", "sparse", "input", "sampling", "can", "contain", "nearly", "all", "relevant", "information", "about", "visibility", "light", "transport", "particularly", "diffuse", "scene", "example", "diffuse", "ornell", "one", "input", "path", "per", "pixel", "allow", "essentially", "perfect", "reconstruction", "indirect", "illumination", "even", "much", "more", "complex", "iguel", "four", "sample", "per", "pixel", "yield", "very", "good", "reconstruction", "multi-layer", "material", "most", "realistic", "material", "model", "build", "from", "multiple", "layer", "example", "varnished", "wood", "consist", "almost-diffuse", "base", "layer", "specular", "top", "layer", "two", "mixed", "accord", "fresnel", "term", "treat", "two", "layer", "separately", "would", "allow", "very", "broad", "reuse", "sample", "from", "base", "layer", "while", "glossy", "top", "layer", "could", "only", "use", "from", "narrow", "set", "direction", "overall", "would", "allow", "broader", "reuse", "than", "collapse", "layer", "beforehand", "select", "maximum", "bandwidth", "sample", "sheared", "filter", "contrast", "sheared", "reconstruction", "-lrb-", "temporal", "-rrb-", "light", "field", "-lsb-", "Egan", "et", "al.", "2009", "Egan", "et", "al.", "2011b", "-rsb-", "where", "reconstruction", "integration", "combine", "single", "large", "filter", "we", "perform", "integration", "over", "incident", "angle", "numerically", "allow", "we", "reason", "about", "anisotropy", "each", "input", "sample", "individually", "input", "-lrb-", "spp", "-rrb-", "ground", "truth", "-lrb-", "2048", "spp", "-rrb-", "we", "without", "recursive", "step", "we", "recursive", "step", "prevent", "clean", "frequency", "analysis", "due", "non-translationinvariant", "nature", "we", "reconstruction", "filter", "however", "simple", "uniformly", "sample", "planar", "scenario", "we", "filter", "reduce", "earlier", "linear", "sheared", "formulation", "failure", "case", "propose", "algorithm", "can", "fail", "scene", "contain", "higher-frequency", "shading", "visibility", "than", "what", "input", "sampling", "rate", "can", "capture", "example", "sparse", "sampling", "hair", "probably", "suffice", "accurately", "describe", "its", "visibility", "shading", "case", "result", "reconstruction", "consistent", "input", "sampling", "may", "faithful", "original", "scene", "foliage", "we", "diffuse", "result", "example", "difficult", "visibility", "handle", "gracefully", "low", "sampling", "rate", "also", "distribution", "input", "ray", "which", "drive", "reflectance", "primary", "hit", "may", "insufficient", "capture", "very", "high-frequency", "angular", "effect", "-lrb-", "e.g.", "mirror", "-rrb-", "secondary", "hit", "would", "lead", "slight", "blur", "reconstructed", "light", "field", "Specialized", "hierarchy", "we", "bandwidth-aware", "k-nn", "produce", "hierarchy", "serve", "two", "purpose", "use", "resolve", "visibility", "also", "guarantee", "we", "find", "nearby", "splat", "similar", "angular", "support", "design", "visibility", "hierarchy", "would", "ignore", "angular", "bandwidth", "implement", "shrink", "step", "second", "hierarchy", "would", "take", "bandwidth", "account", "omit", "shrink", "slightly", "more", "complicated", "approach", "could", "improve", "execution", "speed", "case", "very", "glossy", "material", "we", "thank", "Guillermo", "Lleal", "Laguna", "San", "Miguel", "scene", "Fr?do", "Durand", "support", "National", "Science", "Foundation" ],
  "content" : "Our results show dramatic improvement in image quality while using very sparse input samplings. We contribute a method for adapting to the sampling rate of nonuniform, sparse, uncontrolled input in both space and angle, a spatio-angular anisotropic reconstruction method for filtering radiance from the sparse samples, and a robust method for reasoning about occlusion based on only the input rays. This gives us the crucial advantage that performance is only weakly dependent on the scene. In this sense, our algorithm can be seen as an advanced image filter. Our algorithm produces megapixel images with glossy reflection, global illumination, and ambient occlusion in a few minutes. This means that samples drawn at one pixel tell us something about the integrand at other pixels as well, which enables reconstruction of better images from the same samples. This makes our algorithm much less intrusive for the original renderer. Geometric resampling Our method for reasoning about occlusion based on samples from the initial sampling has also connections to ray tracing point-based geometry [Schaufler and Wann Jensen 2000; Christensen 2008; Ritschel et al. 2009]. The reuse is facilitated by the anisotropy exhibited by the incident light field [Durand et al. 2005]: provided we can quantify visibility and angular effects, radiance leaving a point along a ray provides information about radiance carried by other, nearby rays. Algorithm overview In a first pass, we use a standard path tracer, but only draw few samples per pixel, typically 4?16. After this, we compute, for each input sample, a spatial radius of influence that determines how far it will contribute to light field reconstructions, adapting to the density of input samples in both space and angle (Section 2.2). Furthermore, we need to treat visibility carefully to avoid the ?fattening? of small features and silhouettes when performing reconstruction. In the second pass, we evaluate the shading equation at each visible point using a high-sampling-rate reconstruction of the incoming hemisphere. The key operation is a reconstruction of the 4D incoming light field along a given ray. For this, we find all input rays whose spatial radius overlaps the ray and group them into apparent surfaces using a visibility heuristic (Section 2.3.2). The radiance L from point p towards the camera c is computed by To support angular variation of outgoing illumination on glossy surfaces, we also store a measure of the angular bandwidth determined from the outgoing slice of the BRDF at the hit point. We use an unnormalized spherical von Mises-Fisher distribution Given the samples recorded in the first pass, the second pass evaluates for each primary hit in the input samples, with N 1. The function R ECONSTRUCT (p, ?) performs the upsampling of the incident light field based on the input samples. Because we cannot hope to recover features not present in the input, we make the assumption that the input samples faithfully represent the true indirect light field, i.e., that they capture its frequency content. As the density of the input samples is a complex function of the scene, its materials, and the sampler used in the original renderer, we do not reason about it a priori, but instead discover the local sampling rate by a modified k-nearest-neighbors search (Section 2.2). We use the variant where uv coordinates are measured relative to the st coordinates [Chai et al. 2000; Durand et al. 2005] and essentially form a linearized angle. As we seek to reconstruct rays within arbitrary locations and directions in the scene, we internally store the ray segments using their 3D hit point, and dynamically reparameterize the light field around our reconstruction rays [Isaksen et al. 2000]. In order to perform meaningful reconstructions, we have to adapt to this sampling rate in both space and angle. For glossy surfaces, where radiance varies over angle, we might need to go further in space to find an input sample whose direction better matches that of the reconstruction ray. Along the lines of previous point-based rendering algorithms, we treat the input samples as circular disks (splats) in 3D on their individual tangent planes. We determine their size by analyzing the local sample density. To set the spatial support w i for sample s i , we search for its kth nearest neighbor in space around its secondary hit point h i , but only considering samples s j whose direction ? j falls close enough to ? i . The angle threshold is determined from ? i by requiring A i (? j ) ? 0.5. To illustrate the effect, first consider an almost diffuse surface. As the radiance varies slowly over outgoing direction, A i is almost constant in angle (angular bandwidth is low and consequently ? is small), and the search simplifies to a regular k-NN in space. Consequently, the spatial support will be small ( Figure 3 , left). On a more glossy surface, the angular bandwidth is higher, causing the k-NN search to disregard spatially close-by samples in favor of those closer in angle. Consequently, the support will be wider in space ( Figure 3 , right). We use a metric that penalizes movement in the direction of the normal to encourage the search for support to favor samples lying on locally flat regions. Specifically, we use a Mahalanobis distance that squashes the distance along the normal of each splat by a factor of ? (we use ? = 3). This is implemented simply as computing the Euclidean length of (p ? q) + (? ? 1)((p ? q) ? n)n, where n is the normal. In addition to spatial filtering, the circular splats are used for resolving visibility. When performing reconstruction, we need to gather all input samples whose spatial support is intersected by the reconstruction ray, reminiscent of previous point-based rendering algo- rithms [Schaufler and Wann Jensen 2000]. To accelerate this, we organize the secondary hit points {h i } into a motion bounding volume hierarchy [Glassner 1988] using the streaming algorithm of Kontkanen et al. [2011]. During reconstruction, the hierarchy is used in a standard fashion by walking the BVH and intersecting the reconstruction ray with the splats in the intersected leaf nodes. In order for our reconstructions to be accurate, the visibility function induced by the splats should resemble true occlusion in the scene. However, the preceding k-NN procedure does not guarantee consistency with the original sampling. Small geometric features (e.g. leaves of a plant) might only be hit by few input samples, and when these get enlarged by the k-NN procedure, some rays present in the input might erroneously intersect them. To force the representation to be consistent with the input, we observe that the input rays carry exact information about point-wise visibility in the scene: we know, with certainty, that a ray from o i terminated at h i without being blocked in between. Inspired by this, we retrace all the input rays using the BVH and shrink splats that intersect rays they should not. Finally, the bounding boxes of the BVH nodes are recomputed to accommodate the new sizes. This concludes the preprocessing of the input samples. The resulting splats faithfully represent the visibility as determined by the original secondary rays, while adapting to their local density and causing no spurious occlusions, cf. Figure 4 . Once these have been found, the samples are sorted according to distance from the ray origin, and then grouped into apparent surfaces. The grouping proceeds greedily by adding the next sample to the open surface as long as it does not conflict with any of the samples already in the surface in terms of visibility. When a visibility conflict is detected (see below), a new surface is started. Note that the operation is entirely local: it does not make use of samples whose supports are not intersected by the reconstruction ray. In addition, our rays originate from and terminate at arbitrary 3D points in the scene. Our visibility heuristic works by considering the positive halfspaces, i.e., points x where (x ? h) ? n h > 0, defined by the hit point and normal of each input sample. If the intersection point lies within the positive halfspaces of both samples, a conflict is declared, cf. Figure 5 . This approach detects a conflict when two surfaces that are on top of each other, but allows blending of samples that come from the same locally flat, convex, or concave surface. Once the visibility heuristic has been evaluated and the samples grouped into apparent surfaces, the samples in the nearest apparent surface are input rays whose hit points are determined to be visible from the origin of the reconstruction ray. This requires adapting to the anisotropy and bandwidth of the light field around the reconstruction ray. Consider a situation where a reconstruction ray intersects the spatial supports of three samples ( Figure 6 , left). In a local two-plane parameterization stuv constructed around the reconstruction ray, the reconstruction ray corresponds to a point at the origin ( Figure 6 , middle), and each input ray corresponds to a single point. For each input sample, the set of all rays that intersect the spatial support forms a set with planar boundaries ( Figure 6 , middle). Clearly, the reconstruction ray belongs to this set. For a diffuse surface, where angular bandwidth is zero, reconstruction is simple: we evaluate a spatial filter (tent in our implementation) at the intersection of the reconstruction ray and the splat, and take a weighted average among all samples. In a local coordinate system centered at each sample ( Figure 3 , left), this corresponds to a separable 4D filter that is the product of a tent in space and a constant in angle (corresponding to the zero angular bandwidth), and reparameterization to the stuv coordinates around the reconstruction ray shears this filter into the anisotropic shape shown ( Figure 6 , middle). Radiance leaving glossy surfaces varies over outgoing angle, and we need to account for it by reusing samples whose direction is similar to that of our reconstruction ray. The non-zero angular bandwidth of glossy samples leads to a wider spatial support as a result of the bandwidth-aware k-NN search. In a local coordinate system oriented with each sample, this is visible as a narrower angular filter that is wider in space ( Figure 3 , right). When this filter is transformed into the stuv coordinate system, we obtain anisotropic shapes oriented similarly to the diffuse filters ( Figure 6 , right). We perform reconstruction by evaluating the transformed filters at the stuv origin, and picking the sample whose filter has the largest magnitude. This can be seen as an anisotropic nearest neighbor filter. We use nearest neighbor for glossy surfaces to mitigate the effects of the highly non-uniform angular distribution of our input samples. Using a linear angular filter noticeably shifts the reconstruction towards the denser sampling, which is visible in the final image as shifting highlights: angular shifting results in spatial shifts after propagation. This is not necessary for diffuse reflectance where outgoing angle plays no role. Discussion Our filtering scheme accounts for both spatial and angular bandwidth of the outgoing light field at the input samples. The spatial and angular dimensions are balanced by the k-NN algorithm used for determining the spatial supports for the samples. As our samples lie on the actual curved surfaces, our input as a whole contains these effects. But as our input does not carry information about the curvature and the properties of the incident light field, the reconstruction filters of the individual samples cannot account for the additional shears. Regardless, our treatment allows faithful reconstruction of glossy surfaces reflecting off other glossy surfaces. This is demonstrated in the results. When the reconstruction ray points towards a fronto-parallel surface with uniform angular sampling, our reconstruction procedure corresponds to performing nearest neighbor in space that has been warped using a Mahalanobis distance aligned with the anisotropy of the light field ? this renders the isocontours of the filters locally isotropic. In our prototype implementation, we support the Torrance-Sparrow BRDF model with the Blinn microfacet distribution (the ?Metal? material in PBRT), and take ? = 4 1/r where r is the roughness parameter of the Blinn distribution [Pharr and Humphreys 2010]. The formula is chosen empirically. Since PBRT treats geometric primitives as two-sided, we need to do the same. When a reconstruction ray hits a back-facing splat, it contributes to visibility similarly to front-facing splats. However, back-facing splats contribute to radiance only if all splats of the first surface are back-facing, otherwise their radiance contribution is ignored. In rare occasions, a reconstruction ray may hit a surface that consists of only one or two samples. Although the k-NN search tries to guarantee that this never happens, the subsequent shrinking may affect the result. This happens, for instance, inside dense foliage where individual leaves may be hit by only one input sample. To avoid over-estimating the occlusion, we empirically reduce the splat size by 1 for single-sample surfaces and by 1 for two-sample sur2 3 faces when such undersampling is detected. This treatment affects less than 1% of the reconstruction rays in our scenes. We have implemented our algorithm as a standalone library that takes a buffer of samples as input, and modified PBRT [Pharr and Humphreys 2010] to generate the input. We have produced both a multicore CPU and a GPU implementation of the reconstruction algorithm, and our test platform is a 3.2GHz quad core Intel Core i7 and NVIDIA GTX480. All result images were rendered at 1280?720 (720p). In this section, we first test reconstruction of indirect illumination in diffuse scenes, followed by glossy reflections. We then perform more targeted tests and demonstrate that our occlusion heuristic allows faithful reproduction of visibility. We use ambient occlusion as a test case because its quality is directly determined by the accuracy of visibility. Finally, we show results for defocus and motion blur. We focus on the quality of the reconstructed images, and postpone discussion about scalability, memory consumption, and extensions to Section 4. We compare our results to methods that, similarly to us, reconstruct the image based on a small number of ?fat? samples [Lehtinen et al. 2011; Dammertz et al. 2010; Sen and Darabi 2012]. The auxiliary material contains all of the uncompressed images that are shown or referred to in this section. We reconstruct multi-bounce diffuse global illumination in S AN M IGUEL lit with an area light source ( Figure 7 ). The input contains 8 samples per pixel (leftmost inset). We reconstruct the incident light field over the hemisphere at visible points, and integrate to produce the result (third inset from the left), as per Equation 3. We pay no special attention to the fact that the radiances L of the input samples contain noise due to the multiple bounces rendered by the path tracer. Our reconstruction is more true to ground truth (second left) than the comparison methods, A-Trous wavelets [Dammertz et al. 2010] (fourth inset from left) and random parameter filtering (RPF, last one on right) [Sen and Darabi 2012]. We use both comparison methods for reconstructing incident irradiance, i.e., before multiplication by texture. Rendering the 8 spp input with PBRT takes 36.6s. Our reconstruction with 256 reconstruction rays per pixel on the GPU takes 189.5s. Of this, preprocessing, including building the BVH, sizing the samples using k-NN, and shrinking the samples using the input rays takes 9.5s. The rest is spent on reconstruction rays. This is considerably more efficient than rendering the similar-quality 512 spp image with PBRT, which takes 3910.5s, or 18x longer than combined input+reconstruction. Our 256 spp result exhibits significantly less noise than PBRT?s 256 spp rendering, thanks to our spatial filtering of the samples. Notice that our ability to perform image antialiasing is limited by the number of primary hits in the input samples. The supplemental video contains a short animation rendered from 8 input samples per pixel using 512 reconstruction rays per pixel. Each frame is processed in isolation; no temporal filtering of any kind is employed. The result demonstrates the temporal stability of our reconstruction even from severely noisy input. Comparison methods A-Trous is an iterative approximation to a cross-bilateral filter, with the twist that when spatial support widens between iterations, the range filters tighten. This allows the application of a very large spatial filter without disproportionate blurring. The original implementation uses three range filters: color, normal, and world-space position. Since our input is very noisy, and we do not wish to clamp the input samples? energies, we chose not to use color as a range filter (using it gave worse results). While the quality leaves some room for improvement, the A-Trous filter is efficient: our CPU implementation takes 58s in this scene. Since no reference implementation of random parameter filtering (RPF) is available, we reimplemented it by following the authors? detailed guidelines [Sen and Darabi 2011]. RPF is a sophisticated cross-bilateral filter that automatically tunes the weights for each feature, at each pixel, based on mutual information between domain variables, scene features (position, normal, texture, etc.), and radiance. Their input samples are almost identical to ours. Unfortunately, the original formulation of RPF makes heavy use of the color channel as a range filter, requiring special treatment for bright samples (?HDR clamp?), which essentially discards high-energy spikes. This loses a significant amount of energy, up to 50% in our tests. We modified their algorithms to reinsert the lost energy evenly to all samples within the pixel. Our reasonably tuned CPU implementation filters the image in 2895s, roughly in line with their results. We estimate a 10x possible speedup from a GPU port. We use the parameters recommended in the authors? guidelines. Figure 9 shows M ONKEY H EADS , a scene with three statuettes of decreasing gloss 2 on a glossy ground plane. The scene is lit by single-bounce indirect illumination from a distant point light source (direct illumination not shown), and consequently the input samples are noise-free. The input contains 8 samples per pixel. Our result is computed using 512 reconstruction rays per pixel. A-Trous and RPF results are shown below. We noticed the results for A-Trous\n        2 The roughnesses are 0.01, 0.05 and 0.25 for the statuettes and 0.01 for the ground plane. could be significantly improved by introducing an additional range filter over the normal of the secondary hit, which is conveniently present in our data. We present this extension in our comparison results in addition to the original algorithm. Our results are significantly closer to ground truth than either comparison method both visually and in terms of PSNR (38.6dB vs. 31?33dB). The full-size images are provided in the auxiliary material for closer inspection. In particular, we reconstruct the position and sharpness of the reflections faithfully, thanks to the 4D treatment of the input samples that accounts for both space and angle. Figure 10 demonstrates the importance of accounting for angular effects. While the comparison methods produce smooth results, the reflections have shifted noticeably and are not as sharp as they should. Note that unlike the comparison methods, we use the rendering system (PBRT) to evaluate the BRDFs of the final bounce towards the eye, as per Equation 3. While closely matching ground truth, our algorithm is currently 2.6x slower in this scene than the reference method. This is mainly due to the extreme geometric simplicity of the scene, which plays to our disadvantage because our algorithm scales weakly with scene complexity (Section 4). Our spatial hierarchy does not currently include angular subdivisions [Arvo and Kirk 1987], and we may therefore process redundant splats on glossy surfaces, where the spatial supports are larger (Section 2.2). Another possible improvement is discussed in Section 4. Regardless, the result demonstrates that the information required for reconstructing high-quality reflections is present in the sparse input, and that our algorithm correctly extracts it to produce a high-quality result. Our algorithm can be easily used for rendering ambient occlusion by bypassing the radiance filter and thresholding the distance to the closest apparent surface found. Figure 8 shows our ambient occlusion reconstruction in S AN M IGUEL . Although the scene contains fine geometric features such as grooves and vegetation, our reconstruction from only 4 input samples per pixel is in very close agreement with the ground truth computed using 2048 samples per pixel. In this case, image antialiasing is particularly limited since the input contains only 4 primary hits per pixel. The GPU execution time was 145 seconds for 256 reconstruction rays per pixel at 720p. In contrast to the ambient occlusion technique of Egan et al. [2011a], we do not resort to brute force Monte Carlo sampling of the original scene at all. Finally, we demonstrate the generality of our reconstruction by applying it to motion blur and defocus ( Figure 11 ). We use the B UTTERFLIES dataset from Lehtinen et al. [2011] and compare against their publicly available implementation. Our result is slightly more accurate, approx. 1 dB in terms of PNSR. The images are available in the supplemental material. Our better result is explained by our better adaptation to the input sampling rate. They use a worst-case radius derived from the dispersion of the sampling pattern, which tends to blur in-focus geometry slightly, but may still result in lack of support in regions of the temporal light field that contain features that are visible from only a small fraction of the lens and shutter interval. In contrast, our k-NN approach adapts to the local sampling density, leading to sharp results in well- Input (4 spp)\n        Our reconstruction Our reconstruction A-Trous RPF\n        Ground truth (2048 spp) sampled areas, and better support for the lower sampling density areas, as demonstrated in Figure 12 . Our reconstruction takes 3?4x longer than the algorithm of Lehtinen et al., primarily because they use a specialized 2D hierarchy in post-perspective space, essentially tailoring the data structure to the known distribution of reconstruction rays (they all originate from the lens). As our focus is reconstructing the incident light field at arbitrary points in the scene, we use a true 3D hierarchy. Our result No angular bandwidth Scalability and memory consumption The execution time of our algorithm scales linearly with the number of reconstruction rays, but is only very weakly affected by the structure of the scene and the number of input samples. For example, increasing the number of input samples from 1 to 8 in S AN M IGUEL increases the execution time by only about 40%. Also, S AN M IGUEL takes only 80% longer to reconstruct than C ORNELL with the same parameters, even though the original model contains about 5?6 orders of magnitude more geometry, and has much more challenging structure (foliage vs. straight walls). Memory consumption is almost completely determined by the number of input samples. Each sample consists of 30 floating-point numbers, totaling up to ?1GB at 720p with 8 input samples per pixel, independent of scene structure. In addition, the BVH consumes about 80MB with these parameters, again almost independently of the scene structure. All other memory usage is negligible. Recursive filtering With very low input sampling rates, artifacts can appear near corners: when we integrate over the hemisphere, a large fraction of the reconstruction rays may hit the same few samples. If the samples are noisy, the reconstructed image can suffer from structured artifacts, as demonstrated in Figure 13 . In this example, C ORNELL was rendered with up to eight-bounce indirect illumination from a point light at 1024?1024 with only one sample per pixel. The multiple bounces lead to noise in the samples? radiances. We implemented an experimental step that reduces variance by performing a quick reconstruction of the incident lighting at the secondary hits and replacing the secondary hits? radiances Lehtinen et al. [2011] do not adapt to the local density of the input samples and fail to reconstruct the marked regions. Our novel visibility heuristic reproduces the correct visibility. with the reconstructed values before reconstructing incident lighting at the primary hits. In this scene, performing this step with 16 reconstruction rays adds less than 10% to execution time, and almost completely removes the artifacts. As a result, our reconstruction matches the ground truth closely, accurately preserving the boundaries of indirect shadows. Image antialiasing is still missing, because we have only one primary ray per pixel. Notice that the black borders near the corners are present in the ground truth PBRT rendering as well. Glossy GI with noisy samples It should be possible to generalize the recursive filtering to more reliable handling of highly specular surfaces. In the extreme, it is clearly not very useful to reconstruct incident radiance onto a mirror from sparse samples. Instead it would make more sense to reconstruct at the next path segment to remove the noise on the surface seen in the mirror. Information content We find it interesting that even very sparse input samplings can contain nearly all of the relevant information about visibility and light transport, particularly in diffuse scenes. For example, in diffuse C ORNELL one input path per pixel allows an essentially perfect reconstruction of indirect illumination, and even in the much more complex S AN M IGUEL four samples per pixel yields very good reconstructions. Multi-layer materials Most realistic material models are built from multiple layers. For example, a varnished wood consists of an almost-diffuse base layer, a specular top layer, and the two are mixed according to a Fresnel term. Treating the two layers separately would allow very broad reuse of the samples from the base layer, while the glossy top layer could only be used from a narrow set of directions. Overall this would allow broader reuse than collapsing the layers beforehand and selecting the maximum bandwidth for the sample. Sheared filters In contrast to sheared reconstruction of (temporal) light fields [Egan et al. 2009; Egan et al. 2011b] where reconstruction and integration are combined to a single, large filter, we perform integration over incident angle numerically. This allows us to reason about the anisotropy of each input sample individually, Input (1 spp) Ground truth (2048 spp)\n        Our without recursive step Our with recursive step but prevents a clean frequency analysis due to the non-translationinvariant nature of our reconstruction filters. However, in simple uniformly sampled planar scenarios, our filter reduces to earlier linear sheared formulations. Failure cases The proposed algorithm can fail if the scene contains higher-frequency shading and visibility than what the input sampling rate can capture. For example, a sparse sampling of hair will probably not suffice to accurately describe its visibility and shading. In these cases the resulting reconstruction is consistent with the input sampling, but may not be faithful to the original scene. The foliage in our diffuse results is an example of difficult visibility that is handled gracefully at low sampling rates. Also, the distribution of input rays, which is driven by reflectance at the primary hits, may be insufficient to capture very high-frequency angular effects (e.g., a mirror) at the secondary hits. This would lead to slight blurring in the reconstructed light field. Specialized hierarchies Our bandwidth-aware k-NN produces a hierarchy that serves two purposes: it is used to resolve visibility and also to guarantee that we find the nearby splats with similar angular support. In that design, the visibility hierarchy would ignore angular bandwidth and implement the shrinking step. The second hierarchy would take bandwidth into account and omit shrinking. This slightly more complicated approach could improve the execution speed in case of very glossy materials. We thank Guillermo Lleal Laguna for the San Miguel scene. Fr?do Durand is supported by the National Science Foundation.",
  "resources" : [ ]
}