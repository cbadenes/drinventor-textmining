{
  "uri" : "sig2011-a31-shiratori_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2011/a31-shiratori_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Motion Capture from Body-Mounted Cameras",
    "published" : "2011",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Takaaki-Shiratori",
      "name" : "Takaaki",
      "surname" : "Shiratori"
    }, {
      "uri" : "http://drinventor/Hyun Soo-Park",
      "name" : "Hyun Soo",
      "surname" : "Park"
    }, {
      "uri" : "http://drinventor/Leonid-Sigal",
      "name" : "Leonid",
      "surname" : "Sigal"
    }, {
      "uri" : "http://drinventor/Yaser-Sheikh",
      "name" : "Yaser",
      "surname" : "Sheikh"
    }, {
      "uri" : "http://drinventor/Jessica K.-Hodgins",
      "name" : "Jessica K.",
      "surname" : "Hodgins"
    } ]
  },
  "bagOfWords" : [ "quality", "motion", "reconstruction", "evaluate", "compare", "we", "result", "against", "motion", "capture", "datum", "produce", "commercially", "available", "optical", "system", "inertial", "system", "one", "describe", "Vlasic", "colleague", "-lsb-", "2007", "-rsb-", "allow", "capture", "occur", "outdoor", "space", "design", "recover", "only", "relative", "motion", "joint", "global", "root", "motion", "structure", "useful", "guide", "define", "ground", "geometry", "first", "sketch", "scene", "3d", "animator", "director", "we", "evaluate", "we", "approach", "against", "motion", "capture", "datum", "generate", "Vicon", "optical", "motion", "capture", "system", "report", "mean", "joint", "position", "error", "1.76", "cm", "mean", "joint", "angle", "error", "3.01", "full", "range-of-motion", "sequence", "use", "skeleton", "estimation", "we", "result", "demonstrate", "system", "can", "reconstruct", "action", "difficult", "capture", "traditional", "motion", "capture", "system", "include", "outdoor", "activity", "direct", "sunlight", "activity", "occlude", "near", "proximal", "structure", "extend", "indoor", "activity", "we", "prototype", "first", "we", "knowledge", "employ", "camera", "sensor", "motion", "capture", "measure", "environment", "estimate", "motion", "set", "camera", "relate", "underlie", "articulate", "structure", "we", "approach", "continue", "benefit", "from", "consumer", "trend", "drive", "camera", "become", "cheaper", "smaller", "faster", "more", "pervasive", "variety", "motion", "capture", "technology", "currently", "available", "both", "commercially", "prototype", "portability", "allow", "use", "both", "indoor", "outdoor", "environment", "while", "system", "inspirational", "we", "utilize", "simplify", "photosensor", "camera", "wear", "body", "fundamentally", "different", "from", "we", "approach", "because", "require", "transmitter", "environment", "method", "use", "audio", "synchronize", "camera", "fit", "3d", "scan", "actor", "silhouette", "estimate", "each", "move", "camera", "inertial", "motion", "capture", "system", "-lrb-", "e.g.", "Xsens", "MVN", "www.xsens.com", "-rrb-", "measure", "rotation", "body", "part", "world", "use", "accelerometer", "gyroscope", "we", "system", "camera-based", "therefore", "rely", "rich", "datum", "detailed", "view", "environment", "we", "use", "image", "from", "camera", "along", "estimate", "3d", "geometry", "environment", "recover", "3d", "limb", "position", "orientation", "world", "over", "time", "thus", "we", "build", "substantial", "prior", "work", "sfm", "-lsb-", "Hartley", "Zisserman", "2004", "Pollefeys", "et", "al.", "2004", "Snavely", "et", "al.", "2006", "-rsb-", "visual", "simultaneous", "localization", "mapping", "-lrb-", "slam", "-rrb-", "-lsb-", "Welch", "et", "al.", "1999", "Davison", "et", "al.", "2007", "Klein", "Murray", "2007", "-rsb-", "approach", "have", "be", "use", "estimate", "motion", "move", "platform", "-lsb-", "Ballan", "et", "al.", "2010", "N?ster", "et", "al.", "2006", "-rsb-", "even", "human", "-lsb-", "Oskiper", "et", "al.", "2007", "Zhu", "et", "al.", "2007", "Zhu", "et", "al.", "2008", "-rsb-", "subject", "perform", "range-of-motion", "trial", "skeleton", "estimation", "perform", "desire", "activity", "capture", "video", "datum", "download", "from", "camera", "after", "capture", "processing", "we", "system", "produce", "skeleton", "actor", "root", "position", "orientation", "joint", "angle", "across", "time", "also", "3d", "structure", "scene", "by-product", "we", "use", "16", "more", "commercially", "available", "wide-angle", "-lrb-", "170", "field", "view", "-rrb-", "sport", "action", "camera", "call", "HD", "Hero", "from", "GoPro", "-lrb-", "www.goprocamera.com", "-rrb-", "cost", "250", "dollar", "per", "camera", "make", "we", "entire", "setup", "approximately", "5,000", "dollar", "camera", "lightweight", "94", "have", "small", "form", "factor", "-lrb-", "42", "mm", "60", "mm", "30", "mm", "-rrb-", "hd", "hero", "camera", "equip", "CMOS", "sensor", "capable", "variety", "resolution/frame", "rate", "setting", "we", "record", "720p", "-lrb-", "1280", "720", "-rrb-", "resolution", "60", "frame", "per", "second", "camera", "some", "body", "segment", "often", "occluded", "limb", "-lrb-", "e.g.", "waist", "torso", "-rrb-", "we", "use", "additional", "camera", "provide", "robustness", "create", "wider", "aggregate", "field", "view", "all", "camera", "calibrate", "advance", "use", "fisheye", "lens", "distortion", "model", "-lsb-", "devernay", "faugeras", "2000", "-rsb-", "provide", "estimate", "focal", "length", "principal", "point", "distortion", "coefficient", "order", "compute", "we", "use", "clapper", "board", "produce", "loud", "clap", "beginning", "end", "each", "trial", "we", "find", "peak", "audio", "signal", "result", "movie", "file", "from", "all", "camera", "look", "most", "consistent", "duration", "between", "peak", "use", "simple", "form", "clustering", "exhaustive", "search", "-lsb-", "Hasler", "et", "al.", "2009", "-rsb-", "where", "time-series", "datum", "root", "position", "joint", "angle", "respectively", "consider", "smoothness", "result", "motion", "after", "datum", "capture", "we", "reconstruct", "3d", "structure", "scene", "from", "reference", "image", "use", "SfM", "while", "step", "optional", "principle", "substantially", "reduce", "drift", "reconstructed", "motion", "we", "choose", "perform", "all", "we", "capture", "new", "skeleton", "require", "subject", "ask", "perform", "standard", "range-of-motion", "exercise", "beginning", "capture", "session", "skeleton", "automatically", "generate", "-lrb-", "see", "appendix", "-rrb-", "use", "reconstruct", "whole", "body", "pose", "from", "camera", "-lrb-", "section", "4.2", "-rrb-", "finally", "motion", "refine", "use", "image-based", "non-linear", "optimization", "incorporate", "temporal", "smoothing", "-lrb-", "section", "4.3", "-rrb-", "we", "call", "process", "absolute", "camera", "registration", "we", "handle", "situation", "add", "new", "structure", "point", "newly", "register", "camera", "rerun", "camera", "registration", "estimate", "extrinsic", "parameter", "camera", "we", "choose", "initial", "pair", "image", "have", "significant", "number", "match", "can", "account", "homography", "from", "those", "match", "we", "estimate", "relative", "camera", "orientation", "translation", "extract", "essential", "matrix", "triangulate", "location", "match", "feature", "point", "3d", "use", "direct", "Linear", "Transform", "algorithm", "-lsb-", "Hartley", "Zisserman", "2004", "-rsb-", "follow", "two-image", "bundle", "adjustment", "-lsb-", "Lourakis", "Argyros", "2009", "-rsb-", "from", "correspondence", "we", "reconstruct", "camera", "pose", "use", "perspective-n-point", "-lrb-", "pnp", "-rrb-", "algorithm", "-lsb-", "Lepetit", "et", "al.", "2009", "-rsb-", "inside", "ransac", "procedure", "accuracy", "we", "exclude", "3d", "point", "follow", "criterion", "any", "point", "have", "high", "reprojection", "error", "-lrb-", "pixel", "-rrb-", "any", "point", "when", "angle", "subtend", "ray", "use", "triangulation", "small", "-lrb-", "-rrb-", "once", "structure", "have", "be", "update", "sparse", "bundle", "adjustment", "run", "refine", "entire", "model", "use", "ransac", "pnp", "we", "find", "best", "extrinsic", "camera", "parameter", "produce", "less", "than", "pixel", "reprojection", "error", "when", "number", "inlier", "3d-2d", "correspondence", "sufficient", "-lrb-", "50", "-rrb-", "once", "camera", "parameter", "estimate", "new", "3d", "point", "triangulate", "use", "2d-2d", "correspondence", "between", "newly", "register", "image", "previously", "register", "image", "reduce", "computational", "cost", "keypoint", "matching", "new", "3d", "point", "we", "ignore", "camera", "pair", "whose", "optical", "axis", "have", "more", "than", "90", "orientation", "difference", "criterion", "add", "new", "point", "same", "those", "use", "SfM", "process", "relative", "Camera", "Registration", "reconstruction", "from", "absolute", "camera", "registration", "may", "sparse", "particularly", "when", "view", "angle", "reference", "image", "different", "from", "those", "image", "from", "body-mounted", "camera", "increase", "density", "reconstruction", "body-mounted", "camera", "pose", "we", "find", "match", "between", "image", "from", "absolute-registered", "camera", "image", "from", "unregistered", "camera", "because", "unregistered", "camera", "close", "absolute-registered", "camera", "viewpoint", "similar", "relative", "camera", "registration", "process", "iterate", "until", "camera", "registration", "satisfactory", "figure", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "show", "result", "absolute", "relative", "camera", "registration", "while", "absolute", "camera", "registration", "produce", "gap", "fifth", "iteration", "relative", "camera", "registration", "fill", "most", "gap", "homography", "Unregistered", "Cameras", "after", "iterative", "camera", "registration", "may", "still", "unregistered", "camera", "particular", "window", "time", "deal", "remain", "unregistered", "camera", "we", "estimate", "relative", "camera", "orientation", "between", "consecutive", "frame", "use", "homography", "here", "we", "assume", "camera", "center", "difference", "between", "two", "consecutive", "frame", "small", "enough", "neglect", "compare", "distance", "between", "3d", "point", "camera", "center", "we", "extract", "2d-2d", "match", "base", "sift", "keypoint", "descriptor", "robustly", "find", "consistent", "homography", "use", "ransac", "once", "homography", "estimate", "relative", "orientation", "can", "obtain", "where", "intrinsic", "parameter", "matrix", "avoid", "drift", "cause", "one-way", "camera", "orientation", "estimation", "homography", "we", "take", "average", "forward", "backward", "interpolation", "camera", "position", "also", "need", "linear", "interpolation", "position", "between", "registered", "camera", "use", "interpolation", "provide", "initialization", "joint", "angle", "root", "position", "inlier", "2d-2d", "correspondence", "use", "homography", "computation", "use", "image", "measurement", "subsequent", "optimization", "beginning", "capture", "actor", "ask", "perform", "predefined", "range-of-motion", "exercise", "which", "he", "exercise", "each", "joint", "through", "its", "full", "range", "motion", "we", "extract", "underlie", "skeleton", "structure", "from", "image", "record", "during", "range-of-motion", "performance", "common", "commercial", "motion", "capture", "system", "like", "Vicon", "we", "use", "predefined", "kinematic", "structure", "root", "skeleton", "have", "six", "degree", "freedom", "-lrb-", "dof", "-rrb-", "joint", "have", "three", "dof", "we", "apply", "method", "o?brien", "colleague", "-lsb-", "2000", "-rsb-", "estimate", "skeleton", "3d", "spatial", "relationship", "each", "camera", "kinematic", "structure", "-lrb-", "see", "appendix", "-rrb-", "forward", "kinematic", "from", "Camera", "pose", "skeleton", "provide", "range-of-motion", "exercise", "parameterize", "root", "position", "root", "orientation", "joint", "angle", "root", "position", "orientation", "take", "coincident", "root", "camera", "hence", "give", "skeleton", "we", "can", "obtain", "pose", "each", "time", "instant", "apply", "waist", "camera", "pose", "root", "segment", "directly", "apply", "relative", "orientation", "between", "pair", "camera", "along", "kinematic", "chain", "joint", "note", "position", "camera", "pose", "use", "except", "waist", "camera", "equation", "-lrb-", "-rrb-", "consider", "skeleton", "hard", "constraint", "refinement", "forward", "kinematic", "enable", "we", "maintain", "constraint", "estimate", "camera", "position", "respect", "skeleton", "where", "orientation", "corresponding", "camera", "position", "joint", "respectively", "where", "vector", "from", "parent", "joint", "child", "joint", "formulation", "allow", "we", "estimate", "hierarchical", "joint", "position", "recursively", "where", "-lrb-", "-rrb-", "camera", "center", "attach", "j-th", "joint", "time", "W.", "Virtual", "Cameras", "Robust", "Limb", "pose", "estimation", "estimate", "body-attached", "camera", "pose", "from", "SfM", "while", "body", "move", "sometimes", "difficult", "because", "motion", "blur", "roll", "shutter", "effect", "occlusion", "limb", "lack", "texture", "background", "-lrb-", "e.g.", "sky", "-rrb-", "when", "camera", "pose", "mis-estimated", "result", "motion", "skeleton", "incorrect", "alleviate", "problem", "we", "attach", "multiple", "camera", "limb", "estimate", "limb", "motion", "from", "virtual", "camera", "which", "take", "robust", "average", "those", "camera", "-lrb-", "estimate", "use", "sfm", "-rrb-", "we", "use", "virtual", "camera", "where", "occlusion", "occur", "frequently", "where", "precise", "estimation", "essential", "-lrb-", "e.g.", "root", "-rrb-", "where", "camera", "registration", "difficult", "-lrb-", "e.g.", "chest", "account", "non-rigidity", "shin", "deal", "inhomogeneous", "representation", "p.", "fast", "motion", "impact", "result", "imaging", "artifact", "-rrb-", "virtual", "camera", "pose", "can", "estimate", "from", "motion", "over", "time", "here", "we", "assume", "three", "physical", "camera", "tightly", "connect", "single", "limb", "one", "camera", "e.g.", "select", "reference", "camera", "show", "Figure", "-lrb-", "-rrb-", "average", "relative", "transform", "from", "other", "two", "camera", "reference", "camera", "can", "estimate", "across", "time", "once", "average", "transform", "estimate", "inverse", "average", "transform", "use", "transform", "from", "virtual", "camera", "physical", "camera", "i.e.", "virtual", "camera", "pose", "can", "obtain", "again", "take", "average", "transform", "now", "transform", "from", "virtual", "camera", "each", "physical", "camera", "know", "which", "imply", "all", "physical", "camera", "can", "parameterize", "virtual", "camera", "pose", "-lrb-", "Figure", "-lrb-", "-rrb-", "-rrb-", "parameterization", "use", "when", "reprojection", "error", "compute", "subsequent", "optimization", "final", "step", "optimize", "body", "pose", "minimize", "objective", "function", "equation", "-lrb-", "-rrb-", "instead", "we", "use", "short", "time", "window", "sequentially", "optimize", "pose", "shift", "window", "camera", "rigidly", "connect", "average", "relative", "transform", "exactly", "same", "relative", "transform", "each", "time", "instant", "where", "-lrb-", "-rrb-", "camera", "projection", "function", "-lrb-", "-rrb-", "function", "apply", "homography", "between", "consecutive", "image", "image", "measurement", "index", "camera", "time", "3d", "point", "2d", "measurement", "homography", "respectively", "2d", "measurement", "after", "lens", "distortion", "correction", "homography", "first", "term", "consider", "reprojection", "error", "3d", "point", "2d", "measurement", "register", "camera", "minimization", "different", "from", "typical", "bundle", "adjustment", "SfM", "camera", "pose", "constrain", "skeleton", "use", "projection", "matrix", "-lrb-", "-rrb-", "camera", "associate", "j-th", "joint", "projection", "function", "represent", "where", "-lrb-", "-rrb-", "distort", "reprojected", "position", "use", "fisheye", "lens", "distortion", "parameter", "j-th", "camera", "i-th", "row", "projection", "matrix", "second", "term", "camera", "can", "register", "through", "absolute", "relative", "registration", "inlier", "2d-2d", "correspondence", "detect", "ransacbased", "homography", "estimation", "use", "image", "measurement", "difference", "root", "position", "joint", "angle", "between", "consecutive", "frame", "minimize", "section", "we", "evaluate", "we", "system", "quantitatively", "use", "conventional", "motion", "capture", "system", "ground", "truth", "show", "additional", "result", "collect", "out", "door", "first", "we", "evaluate", "effect", "global", "optimization", "step", "Figure", "-lrb-", "-rrb-", "show", "comparison", "between", "camera", "center", "estimate", "Vicon", "marker", "we", "reconstruction", "before", "global", "optimization", "after", "camera", "center", "be", "adjust", "base", "estimate", "skeleton", "Figure", "-lrb-", "-rrb-", "show", "reduction", "error", "after", "global", "optimization", "smoothness", "term", "Figure", "-lrb-", "-rrb-", "compare", "joint", "angle", "trajectory", "obtain", "we", "system", "measurement", "from", "Vicon", "motion", "capture", "system", "top", "row", "show", "joint", "angle", "trajectory", "upper", "body", "bottom", "row", "show", "joint", "angle", "trajectory", "lower", "body", "joint", "angle", "illustrate", "figure", "angle", "axis-angle", "representation", "normalize", "angle", "first", "frame", "capture", "session", "standard", "deviation", "2.1891", "because", "error", "parent", "joint", "angle", "propagate", "child", "joint", "joint", "angle", "error", "may", "sufficient", "characterize", "error", "overall", "system", "therefore", "we", "also", "evaluate", "error", "joint", "position", "-lrb-", "figure", "-lrb-", "-rrb-", "-rrb-", "error", "do", "propagate", "significantly", "because", "optimization", "equation", "-lrb-", "-rrb-", "find", "solution", "all", "camera", "satisfy", "image", "measurement", "mean", "median", "position", "error", "1.76", "cm", "1.42", "cm", "respectively", "minimum", "maximum", "error", "0.053", "cm", "12.24", "cm", "respectively", "standard", "deviation", "1.26", "cm", "method", "comparison", "we", "now", "describe", "how", "we", "obtain", "quantitative", "comparison", "we", "system", "produce", "camera", "pose", "SfM", "space", "while", "motion", "capture", "system", "output", "3d", "marker", "position", "motion", "capture", "space", "we", "attach", "three", "marker", "each", "camera", "several", "marker", "static", "object", "collect", "image", "from", "camera", "corresponding", "marker", "position", "from", "motion", "capture", "system", "subject", "move", "use", "3d", "position", "static", "marker", "motion", "capture", "space", "corresponding", "image", "measurement", "specify", "manually", "camera", "center", "position", "orientation", "motion", "capture", "space", "be", "estimate", "recover", "similarity", "transform", "from", "SfM", "space", "motion", "capture", "space", "we", "estimate", "scale", "from", "distance", "between", "camera", "center", "pair", "both", "space", "we", "estimate", "translation", "orientation", "from", "SfM", "space", "motion", "capture", "space", "apply", "iterative", "closest", "point", "algorithm", "two", "set", "camera", "center", "parameter", "be", "use", "similarity", "transform", "after", "non-linear", "refinement", "major", "benefit", "we", "system", "portable", "selfcontained", "allow", "prolonged", "capture", "outdoor", "environment", "illustrate", "benefit", "we", "capture", "two", "sequence", "local", "playground", "result", "illustrate", "figure", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "top", "row", "show", "photo", "subject", "perform", "motion", "bottom", "row", "illustrate", "pose", "skin", "character", "use", "joint", "angle", "estimate", "we", "system", "some", "motion", "be", "quite", "dynamic", "we", "observe", "faster", "than", "2.4", "m/s", "instantaneous", "velocity", "camera", "swing", "run", "sequence", "though", "motion", "result", "image", "blur", "roll", "shutter", "effect", "we", "be", "able", "properly", "reconstruct", "sequence", "subject", "traverse", "considerable", "distance", "far", "greater", "than", "what", "would", "possible", "traditional", "indoor", "motion", "capture", "setup", "we", "superimpose", "sparse", "3d", "structure", "manually", "match", "view", "angle", "photo", "take", "during", "capture", "reference", "sparse", "structure", "provide", "context", "motion", "show", "path", "along", "which", "subject", "have", "walk", "we", "introduce", "novel", "system", "capture", "human", "motion", "both", "indoor", "outdoor", "environment", "we", "system", "consist", "16", "more", "consumer", "video", "camera", "attach", "body", "segment", "we", "estimate", "motion", "respect", "world", "geometry", "through", "SfM", "algorithm", "we", "relate", "refine", "camera", "skeletal", "motion", "through", "non-linear", "optimization", "procedure", "we", "system", "have", "number", "advantage", "over", "traditional", "optical", "imu-based", "system", "because", "-lrb-", "-rrb-", "require", "instrumentation", "environment", "can", "easily", "take", "outside", "-lrb-", "ii", "-rrb-", "stable", "do", "suffer", "from", "drift", "-lrb-", "iii", "-rrb-", "provide", "sparse", "3d", "reconstruction", "world", "contextual", "replay", "scene", "creation", "principal", "cause", "failure", "we", "system", "motion", "blur", "automatic", "white", "balancing", "roll", "shutter", "effect", "motion", "scene", "low", "light", "cropped-frame", "format", "find", "many", "commercially", "available", "camera", "can", "introduce", "motion", "blur", "camera", "move", "quickly", "blur", "make", "difficult", "estimate", "correspondence", "across", "frame", "most", "cmo", "chip", "employ", "rolling", "shutter", "become", "noticeable", "high", "impact", "motion", "substantial", "motion", "scene", "may", "occur", "example", "when", "record", "forest", "windy", "day", "also", "likely", "present", "challenge", "violate", "intrinsic", "assumption", "make", "SfM", "despite", "limitation", "however", "we", "illustrate", "we", "system", "capable", "capture", "everyday", "motion", "outdoors", "extended", "time", "without", "noticeable", "drift", "occlusion", "other", "body", "part", "can", "cause", "error", "motion", "estimation", "practice", "three", "mitigation", "strategy", "use", "-lrb-", "-rrb-", "swing", "monkey", "bar", "-lrb-", "-rrb-", "swinging", "swing", "-lrb-", "-rrb-", "run", "street", "ity", "self-occlusion", "from", "body", "part", "instance", "camera", "thigh", "shin", "place", "look", "outward", "right", "side", "leg", "second", "body", "part", "likely", "occluded", "pelvis", "we", "place", "multiple", "camera", "redundancy", "allow", "we", "estimate", "motion", "even", "when", "some", "camera", "experience", "self-occlusion", "finally", "ransac", "provide", "robustness", "case", "minor", "occlusion", "we", "system", "require", "significant", "computation", "power", "compare", "other", "motion", "capture", "system", "bulk", "processing", "time", "involve", "sift", "keypoint", "detection/matching", "minute", "capture", "step", "may", "require", "day", "processing", "all", "camera", "after", "match", "each", "sequence", "require", "approximately", "10", "hour", "10", "iteration", "absolute", "relative", "camera", "registration", "final", "optimization", "can", "take", "up", "hour", "however", "process", "highly", "parallelizable", "GPU", "should", "very", "effective", "speed", "up", "computation", "consumer", "demand", "continue", "push", "camera", "price", "lower", "quality", "higher", "motion", "capture", "use", "body-mounted", "camera", "may", "become", "setup", "choice", "outdoor", "capture", "smaller", "camera", "reduce", "motion", "camera", "relative", "its", "limb", "also", "we", "camera", "produce", "approximately", "1000", "SIFT", "match", "approximately", "300", "inlier", "per", "image", "permit", "other", "attachment", "technology", "camera", "already", "small", "enough", "embedded", "invisibly", "clothing", "ALLAN", "L.", "uwein", "J.", "ROSTOW", "G.", "olletey", "M.", "2010", "unstructured", "video-based", "rendering", "interactive", "exploration", "casually", "capture", "video", "ACM", "transaction", "Graphics", "29", "heung", "G.", "K.", "AKER", "S.", "ANADE", "T.", "2003", "shapefrom-silhouette", "articulated", "object", "its", "use", "human", "body", "kinematic", "estimation", "motion", "capture", "recognition", "77", "84", "orazza", "S.", "UNDERMANN", "L.", "HAUDHARI", "A.", "EMAT", "TIO", "T.", "OBELLI", "C.", "NDRIACCHI", "T.", "2006", "markerless", "motion", "capture", "system", "study", "musculoskeletal", "biomechanic", "visual", "hull", "simulated", "annealing", "approach", "annals", "Biomedical", "Engineering", "34", "1019", "1029", "orazza", "S.", "AMBARETTO", "E.", "UNDERMANN", "L.", "DRIACCHI", "T.", "2010", "Automatic", "generation", "subject-specific", "model", "accurate", "markerless", "motion", "capture", "biomechanical", "application", "IEEE", "transaction", "Biomedical", "Engineering", "57", "806", "812", "AVISON", "a.", "eid", "i.", "olton", "N.", "TASSE", "O.", "2007", "MonoSLAM", "real-time", "single", "camera", "slam", "IEEE", "transaction", "Pattern", "Analysis", "Machine", "Intelligence", "29", "1052", "1067", "eutscher", "J.", "eid", "i.", "2005", "articulate", "body", "motion", "capture", "stochastic", "search", "International", "Journal", "Computer", "Vision", "61", "185", "205", "evernay", "F.", "augera", "O.", "2000", "straight", "line", "have", "straight", "machine", "Vision", "application", "13", "14", "24", "UNCAN", "J.", "2010", "cinefex", "120", "-lrb-", "January", "-rrb-", "68", "146", "ischler", "m.", "olle", "R.", "1981", "Random", "sample", "consensus", "paradigm", "model", "fitting", "application", "image", "analysis", "automate", "cartography", "Communications", "ACM", "24", "381", "395", "rahm", "J.-M.", "EORGEL", "P.", "ALLUP", "D.", "OHNSON", "T.", "AGURAM", "R.", "C.", "EN", "Y.-H.", "UNN", "E.", "LIPP", "B.", "AZEBNIK", "S.", "ollefey", "M.", "2010", "building", "Rome", "cloudless", "day", "european", "conference", "computer", "Vision", "368", "381", "artley", "R.", "I.", "isserman", "a.", "2004", "multiple", "View", "Geometry", "Computer", "Vision", "Cambridge", "University", "Press", "asler", "N.", "OSENHAHN", "B.", "HORM", "AHLEN", "T.", "M.", "all", "J.", "EIDEL", "h.-p", "2009", "markerless", "motion", "capture", "unsynchronized", "move", "camera", "IEEE", "Computer", "tion", "224", "231", "ELLY", "P.", "ONAIRE", "C.", "O.", "o?c", "onnor", "N.", "E.", "2010", "human", "motion", "reconstruction", "use", "wearable", "accelerometer", "LEIN", "G.", "urray", "D.", "2007", "parallel", "tracking", "mapping", "small", "ar", "workspace", "ieee", "ACM", "International", "Symposium", "Mixed", "augmented", "reality", "225", "234", "epetit", "V.", "oreno", "oguer", "F.", "ua", "P.", "2009", "EPnP", "accurate", "-lrb-", "-rrb-", "solution", "pnp", "problem", "International", "Journal", "Computer", "Vision", "81", "155", "166", "ouraki", "M.", "A.", "RGYROS", "A.", "2009", "sba", "software", "package", "generic", "sparse", "bundle", "adjustment", "ACM", "transaction", "mathematical", "Software", "36", "30", "owe", "D.", "2004", "distinctive", "image", "feature", "from", "scale-invariant", "key", "point", "International", "Journal", "Computer", "Vision", "60", "91", "110", "oeslund", "T.", "B.", "ILTON", "a.", "UGER", "V.", "2006", "survey", "advance", "vision-based", "human", "motion", "capture", "analysis", "computer", "Vision", "image", "understand", "104", "90", "126", "uja", "m.", "owe", "D.", "G.", "2009", "fast", "approximate", "nearest", "neighbor", "automatic", "algorithm", "configuration", "cation", "331", "340", "ster", "D.", "ARODITSKY", "O.", "ERGEN", "J.", "2006", "visual", "odometry", "ground", "vehicle", "application", "Journal", "Field", "Robotics", "23", "20", "O?B", "RIEN", "J.", "F.", "ODENHEIMER", "R.", "E.", "ROSTOW", "G.", "J.", "odgin", "J.", "K.", "2000", "Automatic", "joint", "parameter", "estimation", "from", "magnetic", "motion", "capture", "datum", "Graphics", "Interface", "53", "60", "skiper", "T.", "HU", "Z.", "amarasekera", "S.", "UMAR", "R.", "2007", "visual", "odometry", "system", "use", "multiple", "stereo", "camera", "inertial", "measurement", "unit", "IEEE", "Computer", "Society", "ollefey", "M.", "OOL", "L.", "V.", "ERGAUWEN", "M.", "ERBIEST", "F.", "ORNELIS", "K.", "op", "J.", "OCH", "R.", "2004", "visual", "modeling", "hand-held", "camera", "International", "Journal", "Computer", "Vision", "59", "207", "232", "askar", "R.", "II", "H.", "de", "ecker", "B.", "ASHIMOTO", "Y.", "UM", "met", "J.", "oore", "D.", "HAO", "Y.", "ESTHUES", "J.", "IETZ", "P.", "nami", "M.", "AYAR", "S.", "ARNWELL", "J.", "OLAND", "M.", "EKAERT", "P.", "RANZOI", "V.", "run", "E.", "2007", "Prakash", "lighting-aware", "motion", "capture", "use", "photosense", "marker", "multiplexed", "illuminator", "ACM", "transaction", "Graphics", "26", "chwarz", "L.", "A.", "ateus", "D.", "avab", "N.", "2010", "multipleactivity", "human", "body", "tracking", "unconstrained", "environment", "Action", "capture", "accelerometer", "navely", "N.", "eitz", "S.", "M.", "ZELISKI", "R.", "2006", "Photo", "tourism", "explore", "photo", "collection", "3d", "ACM", "transaction", "Graphics", "25", "835", "846", "autge", "J.", "inke", "a.", "UGER", "B.", "AUMANN", "J.", "BER", "A.", "ELTEN", "T.", "ULLER", "M.", "eidel", "h.-p.", "berhardt", "B.", "2011", "Motion", "reconstruction", "use", "sparse", "accelerometer", "datum", "ACM", "transaction", "Graphics", "30", "lasic", "D.", "DELSBERGER", "R.", "ANNUCCI", "G.", "ARNWELL", "J.", "ROSS", "M.", "atusik", "W.", "opovus", "J.", "2007", "Practical", "motion", "capture", "everyday", "surroundings", "ACM", "transaction", "Graphics", "26", "35", "ELCH", "G.", "oxlin", "E.", "2002", "Motion", "tracking", "silver", "bullet", "respectable", "arsenal", "IEEE", "Computer", "Graphics", "application", "22", "24", "38", "ELCH", "G.", "ISHOP", "G.", "ICCI", "L.", "RUMBACK", "S.", "ELLER", "K.", "oluccus", "D.", "1999", "HiBall", "tracker", "Highperformance", "wide-area", "tracking", "virtual", "augmented", "environment", "ACM", "Symposium", "Virtual", "reality", "Software", "Technology", "10", "OLTRING", "H.", "1974", "New", "possibility", "human", "motion", "study", "real-time", "light", "spot", "position", "measurement", "Biotelemetry", "ie", "L.", "UMAR", "M.", "ao", "Y.", "RACANIN", "D.", "UEK", "F.", "2008", "data-driven", "motion", "estimation", "low-cost", "sensor", "hang", "Z.", "Z.", "HEN", "J.", "J.-K", "2009", "ubiquitous", "human", "body", "motion", "capture", "use", "micro-sensor", "hu", "Z.", "SKIPER", "T.", "amarasekera", "S.", "awhney", "H.", "UMAR", "R.", "2007", "ten-fold", "improvement", "visual", "odometry", "use", "landmark", "matching", "International", "Conference", "HU", "Z.", "SKIPER", "T.", "amarasekera", "S.", "UMAR", "R.", "AWHNEY", "H.", "2008", "real-time", "global", "localization", "prebuilt", "visual", "landmark", "database", "IEEE", "Computer", "Society", "Joints", "point", "connect", "parent", "child", "limb", "limb", "associate", "parent", "camera", "child", "camera", "while", "joint", "position", "world", "coordinate", "system", "change", "over", "time", "joint", "position", "parent", "child", "camera", "coordinate", "system", "constant", "-lsb-", "o?brien", "et", "al.", "2000", "-rsb-", "-lrb-", "Figure", "10", "-lrb-", "-rrb-", "-rrb-", "where", "euclidean", "transformation", "matrix", "from", "parent", "child", "camera", "coordinate", "system", "world", "coordinate", "system", "respectively", "equation", "-lrb-", "12", "-rrb-", "follow", "-lrb-", "-rrb-", "one-dof", "joint", "produce", "family", "solution", "joint", "position", "lie", "axis", "rotation", "assume", "rest", "pose", "fully", "extend", "extremity", "where", "both", "limb", "coincident", "joint", "co-linear", "joint", "position", "can", "regularize", "thus", "collect", "equation", "-lrb-", "13", "-rrb-", "j-th", "joint", "across", "time", "provide", "homogeneous", "equation", "two", "three-dof", "ball", "joint", "right", "null", "vector", "obtain", "singular", "value", "decomposition", "-lrb-", "svd", "-rrb-", "solution", "can", "also", "compute", "similar", "way", "obtain", "skeleton", "whole", "body", "-lrb-", "+1", "-rrb-", "th", "joint", "position", "from", "parent", "joint", "corresponding", "camera", "coordinate", "system", "compute", "each", "limb", "where", "inhomogeneous", "coordinate", "joint", "coordinate", "system", "additional", "constraint", "knee", "knee", "one-dof", "hinge", "joint", "equation", "-lrb-", "14", "-rrb-", "become", "undetermined", "system", "two", "null", "vector", "can", "obtain", "from", "knee", "joint", "position", "thigh", "camera", "coordinate", "system", "linear", "combination", "null", "vector", "-lrb-", "figure", "10", "-lrb-", "-rrb-", "-rrb-", "where", "matrix", "consist", "two", "null", "vector", "2d", "coefficient", "vector", "null", "vector", "determine", "we", "consider", "collinearity", "constraint", "cause", "straight", "knee", "rest", "pose", "collinearity", "constraint", "represent", "where", "hip", "ankle", "joint", "position", "-lsb-", "-rsb-", "skew-symmetric", "representation", "vector", "cross", "product", "collinearlity", "constraint", "enable", "unique", "solution", "knee", "joint", "position" ],
  "content" : "The quality of the motion reconstruction is evaluated by comparing our results against motion capture data produced by a commercially available optical system. Inertial systems, such as the one described by Vlasic and colleagues [2007], allow capture to occur in outdoor spaces but are designed to recover only the relative motion of the joints, not the global root motion. This structure is useful as a guide for defining the ground geometry and as a first sketch of the scene for 3D animators and directors. We evaluate our approach against motion capture data generated by a Vicon optical motion capture system and report a mean joint position error of 1.76 cm and a mean joint angle error of 3.01 ? on the full range-of-motion sequence used for skeleton estimation. Our results demonstrate that the system can reconstruct actions that are difficult to capture with traditional motion capture systems, including outdoor activities in direct sunlight, activities that are occluded by near by proximal structures, and extended indoor activities. Our prototype is the first, to our knowledge, to employ camera sensors for motion capture by measuring the environment and to estimate the motion of a set of cameras that are related by an underlying articulated structure. Our approach will continue to benefit from consumer trends that are driving cameras to become cheaper, smaller, faster, and more pervasive. There are a variety of motion capture technologies currently available both commercially and as prototypes. This portability allows their use in both indoor and outdoor environments. While their system was inspirational for us in that it utilized a simplified photosensor as a ?camera? worn on the body, it is fundamentally different from our approach, because it requires transmitters in the environment. The method uses audio to synchronize the cameras and fits a 3D scan of the actor to silhouettes estimated in each of the moving cameras. Inertial motion capture systems (e.g., Xsens MVN, www.xsens.com) measure the rotation of body parts in the world using accelerometers and gyroscopes. Our system is camera-based and therefore relies on the rich data in a detailed view of the environment. We use the images from the cameras along with the estimated 3D geometry of the environment to recover the 3D limb positions and orientations in the world over time. Thus, we build on substantial prior work in SfM [Hartley and Zisserman 2004; Pollefeys et al. 2004; Snavely et al. 2006] and visual Simultaneous Localization and Mapping (SLAM) [Welch et al. 1999; Davison et al. 2007; Klein and Murray 2007]. These approaches have been used for estimating the motion of moving platforms [Ballan et al. 2010; N?ster et al. 2006] and even humans [Oskiper et al. 2007; Zhu et al. 2007; Zhu et al. 2008]. The subject performs a range-of-motion trial for skeleton estimation and then performs the desired activity for capture. The video data are downloaded from the cameras after the capture for processing. Our system produces the skeleton of the actor, root position, and orientation and joint angles across time and also the 3D structure of the scene as a by-product. We use 16 or more commercially available wide-angle (170 ? field of view) sport action cameras called HD Hero from GoPro (www.goprocamera.com) at a cost of 250 dollars per camera; making our entire setup approximately 5,000 dollars. The cameras are lightweight at 94 g and have a small form factor (42 mm ? 60 mm ? 30 mm). HD Hero cameras are equipped with a CMOS sensor and are capable of a variety of resolution/frame rate settings; we record at 720p (1280 ? 720) resolution at 60 frames per second. If cameras on some body segments are often occluded by limbs (e.g., waist, torso), we use additional cameras to provide robustness by creating a wider aggregate field of view. All the cameras are calibrated in advance using a fisheye lens distortion model [Devernay and Faugeras 2000] to provide estimates of focal length, principal point, and the distortion coefficient. In order to compute\n        1 We use a clapper board to produce a loud clap at the beginning and end of each trial. We find peaks in the audio signal of resulting movie files from all the cameras and look for the most consistent duration between peaks using a simple form of clustering and exhaustive search [Hasler et al. 2009]. where O and A are the time-series data of the root position and the joint angles, respectively. E O and E A consider the smoothness of resulting motion. After the data are captured, we reconstruct the 3D structure of the scene from reference images using SfM. While this step is optional in principle, it substantially reduces the drift in the reconstructed motions, and we chose to perform it for all our captures. If a new skeleton is required, the subject is asked to perform a standard range-of-motion exercise at the beginning of the capture session. The skeleton is automatically generated (see Appendix) and is used to reconstruct whole body poses from the cameras (Section 4.2). Finally, the motion is refined using an image-based non-linear optimization that incorporates temporal smoothing (Section 4.3). We call this process absolute camera registration. We handle this situation by adding new structure points with newly registered cameras, and rerun the camera registration. To estimate the extrinsic parameters of the cameras, we choose an initial pair of images that has a significant number of matches that cannot be accounted for by a homography. From those matches, we estimate the relative camera orientation and translation extracted by the essential matrix and triangulate the location of the matched feature points in 3D using the Direct Linear Transform algorithm [Hartley and Zisserman 2004], followed by a two-image bundle adjustment [Lourakis and Argyros 2009]. From these correspondences, we reconstruct the camera pose using a Perspective-n-Point (PnP) algorithm [Lepetit et al. 2009] inside a RANSAC procedure. For accuracy, we exclude 3D points with the following criteria: any point that has high reprojection error (>1 pixel) and any point when the angle subtended by the rays used for triangulation is small (<2 ? ). Once the structure has been updated, a sparse bundle adjustment is run to refine the entire model. Using RANSAC with PnP, we find the best extrinsic camera parameters that produce less than 1 pixel reprojection error when the number of inlier 3D-2D correspondences is sufficient (>50). Once the camera parameters are estimated, new 3D points are triangulated using 2D-2D correspondences between the newly registered image and the previously registered images. To reduce the computational cost of keypoint matching for new 3D points, we ignore camera pairs whose optical axes have more than 90 ? orientation difference. The criteria for adding a new point are the same as those used in the SfM process. Relative Camera Registration: The reconstruction from the absolute camera registration may be sparse, particularly when the viewing angles of the reference images are different from those of images from the body-mounted cameras. To increase the density of the reconstruction for the body-mounted camera poses, we find matches between the images from the absolute-registered camera and the images from the unregistered cameras. Because the unregistered cameras are close to the absolute-registered cameras, the viewpoints are similar. The relative camera registration processes are iterated until camera registration is satisfactory. Figures 4(b) and 4(c) show the results of absolute and relative camera registration. While the absolute camera registration produces gaps, the fifth iteration of the relative camera registration fills most of the gaps. Homographies for Unregistered Cameras: After the iterative camera registration, there may still be unregistered cameras for particular windows of time. To deal with the remaining unregistered cameras, we estimate relative camera orientation between consecutive frames C 1 and C 2 using a homography. Here, we assume that the camera center difference between two consecutive frames is small enough to neglect, compared to the distance between the 3D points and the camera centers. We extract 2D-2D matches based on the SIFT keypoint descriptors and robustly find the consistent homography using RANSAC. Once the homography H is estimated, the relative orientation, C 2 R C 1 , can be obtained by where K is an intrinsic parameter matrix. To avoid drift caused by one-way camera orientation estimation with homographies, we take an average of forward and backward interpolation. If camera positions are also needed, linear interpolation of the positions between registered cameras is used. This interpolation provides the initialization of joint angles and root positions. The inlier 2D-2D correspondences used for the homography computation are used as image measurements in the subsequent optimization. At the beginning of the capture, the actor is asked to perform a predefined range-of-motion exercise, in which he exercises each joint through its full range of motion. We extract the underlying skeleton structure from the images recorded during the range-of-motion performance. As is common with commercial motion capture systems like Vicon, we use a predefined kinematic structure. The root of the skeleton has six degrees of freedom (DOFs), and the joints have three DOFs. We apply the method of O?Brien and colleagues [2000] to estimate the skeleton and the 3D spatial relationship of each camera to the kinematic structure (see Appendix). Forward Kinematics from Camera Poses: The skeleton provided by the range-of-motion exercise is parameterized by the root position, root orientation and joint angles. The root position and orientation are taken to be coincident with the root camera. Hence given the skeleton, we can obtain a pose for each time instant by applying the waist camera pose to the root segment directly and applying the relative orientations between pairs of cameras, along the kinematic chain, to the joints. Note that positions of the camera poses are not used except for the waist cameras. Equation (1) considers the skeleton as a hard constraint for refinement. Forward kinematics enables us to maintain this constraint by estimating camera positions with respect to the skeleton. where W R J and W p j are the orientation of the corresponding camera and the position of the joint in W, respectively 2 . where J q is a vector from the parent joint to the child joint in J . This formulation allows us to estimate the hierarchical joint position, recursively. where W C j (t) is a camera center attached to the j-th joint at time t in W. Virtual Cameras for Robust Limb Pose Estimation: Estimating body-attached camera poses from SfM while the body is moving is sometimes difficult because of motion blur, the rolling shutter effect, occlusion by limbs, and lack of texture in the background (e.g., sky). When camera poses are mis-estimated, the resulting motion of the skeleton is incorrect. To alleviate this problem, we attach multiple cameras to the limb and estimate the limb motion from a virtual camera, which takes a robust average of those cameras (estimated using SfM). We use a virtual camera where occlusion occurs frequently, where a precise estimation is essential (e.g., for the root), or where camera registration is difficult (e.g., for the chest to account for non-rigidity, or shin to deal with 2 p is an inhomogeneous representation of p.  fast motion and impacts that result in imaging artifacts). The virtual camera poses can be estimated from motion over time. Here, we assume that there are three physical cameras, C 1 , C 2 , and C 3 , tightly connected to a single limb. One camera, e.g., C 1 , is selected as a reference camera. As shown in Figure 5(a) , the average relative transforms from the other two cameras to the reference camera 3 , C 1 T  ? C 2 and C 1 T  ? C 3 , can be estimated across time, Once the average transform is estimated, the inverse of the average transform is used as a transform from the virtual camera, V, to the physical cameras, i.e., Then, the virtual camera pose can be obtained by again taking an average of the transforms for C 1 , C 2 , and C 3 . Now the transforms from the virtual camera to each physical camera are known, which implies all physical cameras can be parameterized by the virtual camera pose ( Figure 5(b) ). This parameterization will be used when reprojection errors are computed in the subsequent optimization. The final step is to optimize body poses and by minimizing the objective function in Equation (1). Instead, we use a short time window and sequentially optimize the poses by shifting the window. 3 If the cameras are rigidly connected, the average relative transforms are exactly the same as the relative transform at each time instant. where P (?) is a camera projection function, H(?) is a function to apply a homography between consecutive images to an image measurement, and j, t, p, and h are indices of cameras, time, 3D points and 2D measurements for homographies, respectively. x is a 2D measurement after lens distortion correction for the homography. The first term considers the reprojection errors of the 3D points with the 2D measurements for the registered cameras. This minimization is different from typical bundle adjustment of SfM in that the camera poses are constrained by the skeleton. Using the projection matrix, P j (t), of the camera associated with the j-th joint, the projection function P j is represented as where L j (?) distorts the reprojected position using the fisheye lens distortion parameter of the j-th camera, and P j:i is the i-th row of the projection matrix P j . The second term is for the cameras that cannot be registered through the absolute and relative registration. The inlier 2D-2D correspondences detected in the RANSACbased homography estimation are used as image measurements. The differences of the root positions and joint angles between consecutive frames are minimized as In this section, we evaluate our system quantitatively using a conventional motion capture system as ground truth, and show additional results collected out of doors. First, we evaluate the effect of the global optimization step. Figure 6(a) shows the comparison between the camera centers estimated by the Vicon markers and our reconstruction before the global optimization but after the camera centers were adjusted based on the estimated skeleton. Figure 6(b) shows the reduction in error after global optimization with the smoothness terms. Figure 7(a) compares the joint angle trajectories obtained by our system with the measurements from the Vicon motion capture system. The top row shows the joint angle trajectories of the upper body and the bottom row shows the joint angle trajectories of the lower body. The joint angles illustrated in the figure are the angle of the axis-angle representation normalized by the angle of the first frame in the capture session. The standard deviation is 2.1891 ? . Because the error of a parent joint angle propagates to a child joint, the joint angle errors may not be sufficient to characterize the error of the overall system. Therefore, we also evaluate the errors of the joint positions ( Figure 7(b) ). The error does not propagate significantly, because the optimization of Equation (1) finds a solution such that all cameras satisfy the image measurements. The mean and median position errors are 1.76 cm and 1.42 cm, respectively, and the minimum and the maximum errors are 0.053 cm and 12.24 cm, respectively. The standard deviation is 1.26 cm. Method of Comparison: We now describe how we obtained these quantitative comparisons. Our system produces camera poses in the SfM space, while the motion capture system outputs 3D marker positions in the motion capture space. We attached three markers on each of the cameras and several markers on static objects and collected images from the cameras and the corresponding marker positions from the motion capture system as the subject moved. Using the 3D positions of the static markers in the motion capture space and the corresponding image measurements specified manually, the camera center positions and orientations in the motion capture space were estimated. To recover the similarity transform from the SfM space to the motion capture space, we estimated a scale from the distances between the camera center pairs in both of the spaces. Then, we estimated translation and orientation from the SfM space to the motion capture space by applying the iterative closest point algorithm to the two sets of the camera centers. The parameters were used for the similarity transform after non-linear refinement. The major benefit of our system is that it is portable and selfcontained, allowing prolonged captures in outdoor environments. To illustrate these benefits we captured two sequences in the local playground; the results are illustrated in Figures 8(a) and 8(b). The top rows show the photos of the subject performing the motions, and the bottom rows illustrate a posed skinned character using the joint angles estimated by our system. Some of these motions were quite dynamic and we observed faster than 2.4 m/s instantaneous velocity of a camera in the swing and running sequences. Though these motions resulted in image blur, and the rolling shutter effect, we were able to properly reconstruct the sequences. The subject traversed a considerable distance that is far greater than what would be possible in a traditional indoor motion capture setup. We superimposed the sparse 3D structure and manually matched the viewing angle to a photo taken during the capture for reference. The sparse structure provides the context for the motion by showing the path along which the subject has walked. We introduce a novel system for capturing human motion in both indoor and outdoor environments. Our system consists of 16 or  more consumer video cameras attached to body segments. We estimate their motion with respect to the world geometry through a SfM algorithm. We then relate and refine camera and skeletal motion through a non-linear optimization procedure. Our system has a number of advantages over traditional optical and IMU-based systems, because it: (i) requires no instrumentation of the environment and can easily be taken outside, (ii) is stable and does not suffer from drift, and (iii) provides sparse 3D reconstruction of the world for contextual replay or scene creation. The principal causes of failure for our system are motion blur, automatic white balancing, rolling shutter effects, and motion in the scene. Low light and the cropped-frame formats found in many commercially available cameras can introduce motion blur as the camera moves quickly. The blur makes it difficult to estimate correspondences across frames. Most CMOS chips employ a rolling shutter that becomes noticeable in high impact motions. Substantial motion in the scene, that may occur, for example, when recording in a forest on a windy day, are also likely to present challenges as they violate the intrinsic assumptions made by SfM. Despite these limitations, however, as we illustrate, our system is capable of capturing everyday motions outdoors for extended periods of time and without noticeable drift. Occlusion by other body parts can cause errors in motion estimation. In practice, three mitigation strategies are used. (a) Swinging on a monkey bar (b) Swinging on a swing (c) Running on a street ity of self-occlusion from body parts. For instance, the cameras on the thighs and shins are placed looking outward on the right side of the leg. Second, for body parts that are likely to be occluded such as the pelvis, we place multiple cameras. This redundancy allows us to estimate motion even when some cameras experience self-occlusion. Finally, RANSAC provides robustness in the case of minor occlusions. Our system requires significant computation power compared to other motion capture systems. The bulk of processing time involves SIFT keypoint detection/matching. For a minute of capture, this step may require a day of processing for all cameras 4 . After matching, each sequence requires approximately 10 hours for 10 iterations of absolute and relative camera registration. The final optimization can take up to 4 hours. However, this process is highly parallelizable and a GPU should be very effective in speeding up this computation. As consumer demand continues to push camera prices lower and quality higher, motion capture using body-mounted cameras may become the setup of choice for outdoor capture. Smaller cameras will reduce the motion of the camera relative to its limb and also 4 Our cameras produce approximately 1000 SIFT matches and approximately 300 inliers per image. permit other attachment technologies. Cameras are already small enough to be embedded invisibly in clothing. B ALLAN , L., P UWEIN , J., B ROSTOW , G., AND P OLLETEYS , M. 2010. Unstructured video-based rendering: Interactive exploration of casually captured videos. ACM Transactions on Graphics 29, 4. C HEUNG , G. K., B AKER , S., AND K ANADE , T. 2003. Shapefrom-silhouette of articulated objects and its use for human body kinematics estimation and motion capture. Recognition, 77?84. C ORAZZA , S., M UNDERMANN  ? , L., C HAUDHARI , A., D EMAT TIO , T., C OBELLI , C., AND A NDRIACCHI , T. 2006. A markerless motion capture system to study musculoskeletal biomechanics: Visual hull and simulated annealing approach. Annals of Biomedical Engineering 34, 6, 1019?1029. C ORAZZA , S., G AMBARETTO , E., M UNDERMANN  ? , L., AND A N DRIACCHI , T. 2010. Automatic generation of a subject-specific model for accurate markerless motion capture and biomechanical applications. IEEE Transactions on Biomedical Engineering 57, 4, 806?812. D AVISON , A., R EID , I., M OLTON , N., AND S TASSE , O. 2007. MonoSLAM: Real-time single camera SLAM. IEEE Transactions on Pattern Analysis and Machine Intelligence 29, 6, 1052? 1067. D EUTSCHER , J., AND R EID , I. 2005. Articulated body motion capture by stochastic search. International Journal of Computer Vision 61, 2, 185?205. D EVERNAY , F., AND F AUGERAS , O. 2000. Straight lines have to be straight. Machine Vision and Applications 13, 1, 14?24. D UNCAN , J. 2010. Cinefex 120 (January), 68?146. F ISCHLER , M., AND B OLLES , R. 1981. Random sample consensus: A paradigm for model fitting with applications to image analysis and automated cartography. Communications of the ACM 24, 6, 381?395. F RAHM , J.-M., G EORGEL , P., G ALLUP , D., J OHNSON , T., R AGURAM , R., W U , C., J EN , Y.-H., D UNN , E., C LIPP , B., L AZEBNIK , S., AND P OLLEFEYS , M. 2010. Building Rome on a cloudless day. European Conference on Computer Vision, 368?381. H ARTLEY , R. I., AND Z ISSERMAN , A. 2004. Multiple View Geometry in Computer Vision. Cambridge University Press. H ASLER , N., R OSENHAHN , B., T HORM AHLEN  ? , T., W AND , M., G ALL , J., AND S EIDEL , H.-P. 2009. Markerless motion capture with unsynchronized moving cameras. IEEE Computer tion, 224?231. K ELLY , P., C ONAIRE , C. O.,  ? AND O?C ONNOR , N. E. 2010. Human motion reconstruction using wearable accelerometers. K LEIN , G., AND M URRAY , D. 2007. Parallel tracking and mapping for small AR workspaces. IEEE and ACM International Symposium on Mixed and Augmented Reality, 225?234. L EPETIT , V., M ORENO -N OGUER , F., AND F UA , P. 2009. EPnP: An accurate O(n) solution to the PnP problem. International Journal of Computer Vision 81, 2, 155?166. L OURAKIS , M. A., AND A RGYROS , A. 2009. SBA: A software package for generic sparse bundle adjustment. ACM Transactions on Mathematical Software 36, 1, 1?30. L OWE , D. 2004. Distinctive image features from scale-invariant key points. International Journal of Computer Vision 60, 2, 91? 110. M OESLUND , T. B., H ILTON , A., AND K R UGER  ? , V. 2006. A survey of advances in vision-based human motion capture and analysis. Computer Vision and Image Understanding 104, 90? 126. M UJA , M., AND L OWE , D. G. 2009. Fast approximate nearest neighbors with automatic algorithm configuration. cation, 331?340. N ? STER , D., N ARODITSKY , O., AND B ERGEN , J. 2006. Visual odometry for ground vehicle applications. Journal of Field Robotics 23, 1, 3?20. O?B RIEN , J. F., B ODENHEIMER , R. E., B ROSTOW , G. J., AND H ODGINS , J. K. 2000. Automatic joint parameter estimation from magnetic motion capture data. Graphics Interface, 53?60. O SKIPER , T., Z HU , Z., S AMARASEKERA , S., AND K UMAR , R. 2007. Visual odometry system using multiple stereo cameras and inertial measurement unit. IEEE Computer Society P OLLEFEYS , M., G OOL , L. V., V ERGAUWEN , M., V ERBIEST , F., C ORNELIS , K., T OPS , J., AND K OCH , R. 2004. Visual modeling with a hand-held camera. International Journal of Computer Vision 59, 3, 207?232. R ASKAR , R., N II , H., DE D ECKER , B., H ASHIMOTO , Y., S UM MET , J., M OORE , D., Z HAO , Y., W ESTHUES , J., D IETZ , P., I NAMI , M., N AYAR , S., B ARNWELL , J., N OLAND , M., B EKAERT , P., B RANZOI , V., AND B RUNS , E. 2007. Prakash: Lighting-aware motion capture using photosensing markers and multiplexed illuminators. ACM Transactions on Graphics 26, 3. S CHWARZ , L. A., M ATEUS , D., AND N AVAB , N. 2010. Multipleactivity human body tracking in unconstrained environments. Action capture with accelerometers. S NAVELY , N., S EITZ , S. M., AND S ZELISKI , R. 2006. Photo tourism: Exploring photo collections in 3D. ACM Transactions on Graphics 25, 3, 835?846. T AUTGES , J., Z INKE , A., K R UGER  ? , B., B AUMANN , J., W E BER , A., H ELTEN , T., M ULLER  ? , M., S EIDEL , H.-P., AND E BERHARDT , B. 2011. Motion reconstruction using sparse accelerometer data. ACM Transactions on Graphics 30, 3. V LASIC , D., A DELSBERGER , R., V ANNUCCI , G., B ARNWELL , J., G ROSS , M., M ATUSIK , W., AND P OPOVI ? , J. 2007. Practical motion capture in everyday surroundings. ACM Transactions on Graphics 26, 3, 35. W ELCH , G., AND F OXLIN , E. 2002. Motion tracking: No silver bullet, but a respectable arsenal. IEEE Computer Graphics and Applications 22, 6, 24?38. W ELCH , G., B ISHOP , G., V ICCI , L., B RUMBACK , S., K ELLER , K., AND C OLUCCI , D. 1999. The HiBall tracker: Highperformance wide-area tracking for virtual and augmented environments. ACM Symposium on Virtual Reality Software and Technology, 1?10. W OLTRING , H. 1974. New possibilities for human motion studies by real-time light spot position measurement. Biotelemetry 1, 3. X IE , L., K UMAR , M., C AO , Y., G RACANIN , D., AND Q UEK , F. 2008. Data-driven motion estimation with low-cost sensors. Z HANG , Z., W U , Z., C HEN , J., AND W U , J.-K. 2009. Ubiquitous human body motion capture using micro-sensors. Z HU , Z., O SKIPER , T., S AMARASEKERA , S., S AWHNEY , H., AND K UMAR , R. 2007. Ten-fold improvement in visual odometry using landmark matching. International Conference Z HU , Z., O SKIPER , T., S AMARASEKERA , S., K UMAR , R., AND S AWHNEY , H. 2008. Real-time global localization with a prebuilt visual landmark database. IEEE Computer Society Joints are a point that connects the parent and child limbs, and these limbs are associated to the parent camera P and the child camera C. While the joint positions in the world coordinate system, W p j , change over time, the joint positions in the parent and child camera coordinate systems, P p j and C p j , are constant [O?Brien et al. 2000] ( Figure 10(a) ): where W T P and W T C are 4?4 Euclidean transformation matrices from the parent and child camera coordinate systems to the world coordinate system, respectively. Equation (12) follows that (b) One-DOF joints produce a family of solutions for a joint position that lie on the axis of rotation. By assuming the rest pose is a fully extended extremity, where both limbs coincident at the joint are co-linear, joint position can be regularized. Thus, collecting Equation (13) for the j-th joint across time provides the homogeneous equation for C p j , For two or three-DOF ball joints, the right null vector of ?T obtained with singular value decomposition (SVD) is a solution of C p j . P p j can be also computed in a similar way. To obtain the skeleton for the whole body, the (j+1)-th joint position from the parent joint in the corresponding camera coordinate system, J q, is computed for each limb as where p is an inhomogeneous coordinate of p, and J is the joint coordinate system. Additional Constraint on Knees: Knees are one-DOF hinge joints, and Equation (14) becomes an undetermined system: two null vectors can be obtained from ?T, and the knee joint position in the thigh camera coordinate system, C T p K , is a linear combination of the null vectors ( Figure 10(b) ): where V K is a matrix consisting of the two null vectors of ?T and c is a 2D coefficient vector for the null vectors. To determine c, we consider the collinearity constraint caused by straight knees in the rest pose. This collinearity constraint is represented as where W p H and W p A are the hip and ankle joint positions, and [?] ? is the skew-symmetric representation for vector cross product. The collinearlity constraint enables a unique solution of the knee joint positions.",
  "resources" : [ ]
}