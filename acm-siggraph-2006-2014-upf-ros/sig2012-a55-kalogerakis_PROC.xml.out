{
  "uri" : "sig2012-a55-kalogerakis_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2012/a55-kalogerakis_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "A Probabilistic Model for Component-Based Shape Synthesis",
    "published" : "2012",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Evangelos-Kalogerakis",
      "name" : "Evangelos",
      "surname" : "Kalogerakis"
    }, {
      "uri" : "http://drinventor/Siddhartha-Chaudhuri",
      "name" : "Siddhartha",
      "surname" : "Chaudhuri"
    }, {
      "uri" : "http://drinventor/Daphne-Koller",
      "name" : "Daphne",
      "surname" : "Koller"
    }, {
      "uri" : "http://drinventor/Vladlen-Koltun",
      "name" : "Vladlen",
      "surname" : "Koltun"
    } ]
  },
  "bagOfWords" : [ "we", "demonstrate", "two", "application", "present", "model", "first", "can", "use", "amplify", "exist", "shape", "database", "second", "model", "enable", "interactive", "shape", "synthesis", "interface", "allow", "rapid", "creation", "plausible", "shape", "subject", "high-level", "constraint", "pioneering", "modeling", "example", "system", "Funkhouser", "et", "al.", "-lsb-", "2004", "-rsb-", "use", "database", "segmented", "shape", "enable", "interactive", "assembly", "new", "shape", "from", "retrieve", "component", "none", "technique", "allow", "automatic", "synthesis", "plausible", "new", "shape", "novel", "structure", "from", "complex", "domain", "describe", "only", "set", "example", "while", "probabilistic", "model", "can", "use", "assemble", "complete", "novel", "shape", "plausibility", "synthesize", "shape", "severely", "limit", "however", "we", "model", "operate", "image", "pixel", "patch", "geometric", "semantic", "feature", "three-dimensional", "shape", "component", "we", "probabilistic", "model", "design", "represent", "componentbased", "structure", "shape", "complex", "domain", "furniture", "aircraft", "vehicle", "etc.", "we", "key", "observation", "structural", "variability", "domain", "often", "characterize", "presence", "multiple", "underlying", "type", "shape", "component", "example", "expect", "set", "component", "present", "chair?as", "well", "geometry?differs", "markedly", "between", "office", "chair", "dine", "chair", "cantilever", "chair", "observation", "allow", "we", "design", "compact", "hierarchical", "model", "can", "effectively", "train", "small", "dataset", "we", "model", "incorporate", "latent", "variable", "parameterize", "type", "shape", "domain", "well", "style", "individual", "component", "model", "train", "set", "compatibly", "segmented", "shape", "we", "implementation", "we", "use", "compatible", "segmentation", "labeling", "technique", "Kalogerakis", "et", "al.", "-lsb-", "2010", "-rsb-", "assist", "manual", "segmentation", "labeling", "Random", "variable", "we", "model", "illustrate", "figure", "hierarchical", "mixture", "distribution", "over", "attribute", "shape", "component", "single", "latent", "variable", "root", "variable", "can", "interpret", "overall", "type", "shape", "include", "number", "component", "from", "category", "vector", "continuous", "geometric", "feature", "component", "from", "category", "vector", "discrete", "geometric", "feature", "component", "from", "category", "we", "implementation", "continuous", "feature", "include", "curvature", "histogram", "shape", "diameter", "histogram", "scale", "parameter", "spin", "image", "pca-based", "descriptor", "lightfield", "descriptor", "specifically", "feature", "specify", "number", "component", "from", "each", "category", "adjacent", "component", "from", "category", "l.", "illustrative", "example", "Figure", "show", "small", "dataset", "compatibly", "segmented", "table", "probabilistic", "model", "learn", "dataset", "we", "model", "learn", "two", "dominant", "style", "onelegged", "table", "four-legged", "table", "each", "style", "model", "represent", "conditional", "distribution", "over", "number", "component", "from", "each", "category", "specifically", "number", "tabletop", "-lrb-", "top", "-rrb-", "number", "leg", "-lrb-", "leg", "-rrb-", "example", "model", "learn", "two", "dominant", "tabletop", "style", "rectangular", "tabletop", "roughly", "circular", "tabletop", "variable", "top", "leg", "represent", "continuous", "geometric", "feature", "respective", "component", "category", "while", "top", "leg", "represent", "discrete", "geometric", "feature", "one-legged", "table", "conditional", "probability", "distribution", "associate", "leg", "indicate", "horizontal", "extent", "base", "leg", "positively", "correlate", "horizontal", "extent", "tabletop", "model", "represent", "joint", "probability", "distribution", "-lrb-", "-rrb-", "over", "all", "random", "variable", "-lcb-", "-rcb-", "distribution", "factorize", "product", "conditional", "probability", "distribution", "-lrb-", "cpd", "-rrb-", "follow", "where", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "set", "observe", "random", "variable", "link", "lateral", "edge", "parametrization", "cpd", "discrete", "variable", "cpd", "discrete", "random", "variable", "-lcb-", "-rcb-", "model", "can", "represent", "conditional", "probability", "table", "-lrb-", "cpt", "-rrb-", "value", "-lcb-", "-rcb-", "comprise", "parameter", "CPT", "random", "variable", "which", "have", "parent", "we", "simply", "store", "probability", "table", "-lrb-", "-rrb-", "when", "discrete", "random", "variable", "have", "set", "multiple", "parent", "-lcb-", "...", "-rcb-", "we", "use", "sigmoid", "function", "instead", "CPT", "parametrize", "its", "CPD", "sigmoid", "function", "reduce", "complexity", "model", "improve", "generalization", "since", "number", "parameter", "sigmoid", "cpd", "increase", "linearly", "number", "domain", "size", "parent", "random", "variable", "while", "number", "parameter", "cpt", "increase", "exponentially", "sigmoid", "cpd", "express", "follow", "where", "-lcb-", "...", "-rcb-", "assignment", "parent", "variable", "-lcb-", ",0", "-rcb-", "t?t", "parameter", "sigmoid", "-lrb-", "-rrb-", "-lcb-", "-lrb-", "-rrb-", "-rcb-", "vector-valued", "binary", "indicator", "function", "each", "parent", "variable", "parametrization", "cpd", "continuous", "variable", "CPD", "each", "continuous", "random", "variable", "express", "conditional", "linear", "multivariate", "Gaussian", "let", "-lcb-", "...", "-rcb-", "discrete", "-lcb-", "...", "-rcb-", "continuous", "parent", "conditional", "linear", "Gaussian", "define", "where", "-lcb-", "-rcb-", "-lcb-", "-rcb-", "parameter", "conditional", "Gaussian", "each", "value", "space", "vector", "assignment", "continuous", "parent", "Z.", "specifically", "parameter", ",0", "conditional", "mean", "covariance", "matrix", "respectively", "while", "remain", "parameter", "regression", "coefficient", "have", "continuous", "parent", "CPD", "become", "we", "now", "describe", "offline", "procedure", "learn", "structure", "parameter", "probabilistic", "model", "input", "set", "compatibly", "segmented", "shape", "each", "component", "we", "compute", "its", "geometric", "attribute", "describe", "appendix", "we", "training", "datum", "thus", "set", "feature", "vector", "-lcb-", "...", "-rcb-", "where", "-lcb-", "-rcb-", "assume", "uniform", "prior", "-lrb-", "-rrb-", "over", "possible", "structure", "maximize", "-lrb-", "-rrb-", "reduce", "maximize", "marginal", "likelihood", "-lrb-", "-rrb-", "we", "choice", "prior", "discuss", "supplementary", "material", "above", "expression", "marginal", "likelihood", "involve", "summing", "over", "all", "possible", "assignment", "latent", "variable", "thus", "number", "integral", "exponentially", "large", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "here", "parameter", "estimate", "give", "fictitious", "dataset", "comprise", "training", "datum", "approximate", "statistics", "value", "latent", "variable", "search", "proceed", "follow", "we", "domain", "size", "correspond", "single", "shape", "style", "each", "component", "style", "each", "category", "we", "evaluate", "score", "domain", "size", "correspond", "single", "component", "style", "since", "value", "denote", "absence", "component", "from", "category", "we", "gradually", "increase", "domain", "size", "evaluate", "score", "each", "step", "score", "decrease", "previous", "value", "-lrb-", "local", "maximum", "-rrb-", "retain", "domain", "size", "search", "move", "next", "component", "category", "after", "search", "iterate", "over", "all", "variable", "we", "increase", "domain", "size", "repeat", "procedure", "search", "terminate", "when", "score", "reach", "local", "maximum", "do", "improve", "over", "10", "subsequent", "iteration", "domain", "size", "set", "value", "yield", "highest", "score", "domain", "size", "all", "variable", "set", "corresponding", "locally", "maximal", "value", "we", "retain", "graph", "structure", "yield", "highest", "score", "along", "corresponding", "parameter", "all", "cpd", "model", "compute", "describe", "below", "parameter", "estimation", "give", "structure", "we", "perform", "maximum", "posteriorus", "-lrb-", "map", "-rrb-", "estimation", "parameter", "thus", "map", "estimate", "find", "expectation-maximization", "-lrb-", "em", "-rrb-", "algorithm", "detail", "EM", "algorithm", "discuss", "supplementary", "material", "along", "computation", "three", "term", "-lrb-", "-rrb-", "all", "computation", "involve", "probability", "perform", "log-space", "avoid", "numerical", "error", "model", "train", "set", "shape", "describe", "section", "can", "use", "synthesize", "new", "shape", "synthesis", "proceed", "two", "stage", "first", "stage", "we", "enumerate", "high-probability", "instantiation", "model", "each", "instantiation", "specify", "set", "component", "second", "stage", "we", "optimize", "placement", "component", "produce", "cohesive", "shape", "instantiation", "model", "correspond", "set", "component", "can", "find", "through", "forward", "sampling", "however", "random", "sampling", "process", "bias", "towards", "higher-probability", "assignment", "random", "variable", "forward", "sampling", "thus", "unsuitable", "efficiently", "enumerate", "all", "instantiation", "have", "non-negligible", "probability", "instead", "we", "use", "simple", "deterministic", "procedure", "first", "we", "topologically", "sort", "node", "model", "note", "style", "variable", "always", "appear", "before", "other", "variable", "complete", "order", "depend", "learn", "graph", "structure", "next", "we", "create", "tree", "whose", "node", "correspond", "partial", "assignment", "random", "variable", "tree", "initialize", "empty", "root", "node", "child", "root", "all", "possible", "assignment", "tree", "continue", "expand", "create", "node", "next", "partial", "assignment", "base", "value", "next", "random", "variable", "sort", "list", "when", "algorithm", "reach", "continuous", "variable", "partial", "assignment", "could", "principle", "take", "any", "value", "dim", "-lrb-", "-rrb-", "which", "would", "make", "search", "infeasible", "however", "only", "specific", "value", "variable", "correspond", "geometric", "feature", "component", "extract", "from", "training", "set", "therefore", "we", "expand", "partial", "assignment", "only", "those", "value", "correspond", "exist", "component", "from", "category", "l.", "branch", "contain", "assignment", "have", "extremely", "low", "probability", "density", "-lrb-", "less", "than", "10", "12", "we", "implementation", "-rrb-", "prune", "from", "tree", "assist", "placement", "certain", "region", "each", "component", "mark", "slot", "specify", "where", "component", "can", "attach", "other", "component", "each", "slot", "store", "category", "label", "component", "can", "attach", "also", "store", "simple", "automatically", "extract", "symmetry", "relationship", "allow", "correct", "relative", "placement", "symmetric", "group", "bilistic", "least-square", "model", "optimize", "component", "optimization", "component", "placement", "draw", "align", "from", "all", "-lrb-", "-rrb-", "pair", "source", "three", "adjacent", "shape", "source", "shape", "show", "component", "from", "left", "chair", "initially", "correspond", "database", "leg", "slot", "slot", "back", "highlight", "place", "relative", "red", "-lrb-", "-rrb-", "set", "seat", "accord", "component", "transformation", "new", "chair", "synthesize", "store", "seat?s", "probaslot", "-lrb-", "-rrb-", "final", "synthesize", "chair", "component", "place", "scale", "adjacent", "component", "example", "show", "Figure", "chair", "seat", "have", "two", "slot", "front", "leg", "two", "slot", "back", "leg", "symmetry", "information", "store", "seat", "slot", "specify", "leg", "place", "front", "right", "slot", "seat", "symmetric", "counterpart", "leg", "place", "front", "leave", "slot", "reflect", "one", "symmetry", "plane", "seat", "note", "relationship", "property", "seat", "leg", "thus", "different", "leg", "new", "chair", "can", "place", "consistently", "around", "same", "seat", "give", "we", "deterministic", "procedure", "place", "each", "component", "vis-a-vi", "its", "adjacent", "component", "match", "slot", "apply", "store", "symmetry", "transform", "initial", "placement", "further", "refine", "optimization", "step", "align", "all", "pair", "adjacent", "component", "point", "contact", "optimization", "minimize", "square", "error", "term", "over", "slot", "which", "penalize", "discrepancy", "position", "relative", "size", "between", "each", "pair", "adjacent", "slot", "express", "function", "translation", "scale", "parameter", "corresponding", "component", "ensure", "component", "drastically", "distort", "scale", "optimization", "penalize", "deviation", "from", "original", "component", "scale", "weighting", "error", "each", "parameter", "learn", "variance", "scale", "finally", "error", "term", "also", "penalize", "deviation", "from", "symmetry", "ground", "contact", "-lrb-", "ground", "contact", "point", "extract", "describe", "Appendix", "a.", "-rrb-", "we", "use", "same", "objective", "term", "weight", "all", "domain", "we", "evaluation", "linear", "least-square", "solver", "nonnegativity", "constraint", "scale", "parameter", "use", "minimize", "error", "enhance", "visual", "appearance", "synthesize", "shape", "we", "glue", "adjacent", "component", "organic", "shape", "match", "adjacent", "edge", "loop", "shift", "local", "neighborhood", "smooth", "falloff", "apply", "final", "laplacian", "smoothing", "filter", "vehicle", "chair", "ship", "creature", "training", "shape", "100", "22", "88", "42", "69", "category", "14", "11", "30", "11", "component", "881 122 504 639", "593", "synth", "shape", "1267 253 870 199", "563", "we", "describe", "two", "application", "present", "model", "first", "amplification", "input", "shape", "database", "second", "constrain", "shape", "synthesis", "base", "high-level", "specification", "provide", "interactively", "user", "shape", "database", "amplification", "first", "application", "direct", "result", "apply", "learning", "inference", "procedure", "describe", "precede", "section", "give", "input", "dataset", "compatibly", "segmented", "labeled", "shape", "we", "train", "model", "describe", "section", "we", "synthesize", "all", "instantiation", "model", "have", "non-negligible", "probability", "optimize", "result", "shape", "describe", "section", "we", "identify", "reject", "instantiation", "very", "similar", "shape", "input", "dataset", "previous", "instantiation", "note", "pruning", "optional", "since", "instantiation", "still", "correspond", "plausible", "shape", "we", "experiment", "we", "simply", "seek", "avoid", "visually", "redundant", "shape", "generate", "shuffling", "very", "similar", "component", "around", "we", "also", "reject", "synthesize", "shape", "which", "component", "placement", "optimization", "fail", "constrain", "shape", "synthesis", "we", "model", "can", "also", "use", "synthesize", "shape", "subject", "interactively", "specify", "constraint", "interface", "allow", "combine", "multiple", "type", "constraint", "demonstrate", "accompany", "video", "synthesize", "shape", "subject", "provide", "constraint", "we", "perform", "deterministic", "search", "procedure", "describe", "section", "5.1", "modification", "partial", "assignment", "constrain", "random", "variable", "assume", "value", "only", "from", "range", "correspond", "specify", "constraint", "we", "evaluate", "present", "model", "five", "shape", "dataset", "obtain", "from", "publicly", "available", "3d", "model", "library", "-lrb-", "Digimation", "Model", "Bank", "Dosch", "3D", "furniture", "database", "Wessel", "et", "al.", "-lsb-", "2009", "-rsb-", "-rrb-", "dataset", "be", "compatibly", "segmented", "label", "use", "technique", "Kalogerakis", "et", "al.", "-lsb-", "2010", "-rsb-", "assist", "manual", "segmentation", "labeling", "Table", "give", "number", "shape", "each", "dataset", "number", "component", "category", "number", "individual", "component", "extract", "from", "each", "dataset", "number", "new", "shape", "synthesize", "each", "dataset", "we", "model", "synthesize", "shape", "show", "alongside", "training", "shape", "figure", "14", "15", "16", "17", "well", "accompany", "video", "Figure", "show", "histogram", "number", "component", "use", "per", "synthesize", "shape", "histogram", "number", "source", "shape", "contribute", "component", "per", "synthesize", "shape", "generalization", "performance", "key", "question", "evaluation", "probabilistic", "model", "how", "well", "generalize", "from", "training", "datum", "successful", "generative", "model", "able", "only", "reproduce", "instance", "from", "training", "datum", "synthesize", "genuinely", "novel", "plausible", "instance", "from", "domain", "exemplify", "dataset", "standard", "technique", "evaluate", "generalization", "performance", "holdout", "validation", "where", "dataset", "randomly", "split", "training", "set", "test", "set", "test", "set", "withhold", "only", "training", "set", "use", "train", "model", "trained", "model", "evaluate", "test", "set", "compute", "probability", "assign", "model", "instance", "test", "set", "higher", "probability", "test", "set", "correspond", "better", "generalization", "performance", "Components", "from", "multiple", "source", "shape", "-lrb-", "right", "-rrb-", "combine", "probabilistic", "model", "yield", "plausible", "new", "shape", "-lrb-", "left", "blue", "-rrb-", "utilize", "component", "highlight", "color", "source", "shape", "repeat", "procedure", "three", "random", "80-20", "training-test", "split", "dataset", "take", "geometric", "mean", "result", "probability", "we", "compare", "present", "model", "weaker", "model", "which", "some", "component", "present", "model", "disabled", "result", "show", "Figure", "each", "bar", "figure", "correspond", "negative", "logarithm", "probability", "assign", "test", "datum", "we", "model", "weaker", "variant", "lower", "value", "correspond", "better", "generalization", "performance", "we", "have", "also", "evaluate", "performance", "model", "impoverished", "dataset", "end", "we", "gradually", "change", "split", "ratio", "from", "80-20", "-lrb-", "train", "80", "datum", "test", "remain", "20", "-rrb-", "20-80", "-lrb-", "train", "20", "datum", "test", "remain", "80", "-rrb-", "result", "plot", "figure", "generalization", "performance", "degrade", "when", "dataset", "make", "available", "training", "become", "less", "representative", "overall", "domain", "rapid", "degradation", "construction", "vehicle", "due", "small", "size", "dataset", "20", "datum", "case", "correspond", "have", "only", "four", "example", "comparison", "prior", "work", "probabilistic", "model", "develop", "Chaudhuri", "et", "al.", "-lsb-", "2011", "-rsb-", "can", "also", "use", "synthesize", "complete", "novel", "shape", "although", "design", "purpose", "we", "experiment", "generally", "produce", "shape", "low", "plausibility", "-lrb-", "figure", "-rrb-", "quantitative", "evaluation", "against", "prior", "model", "we", "could", "use", "holdout", "validation", "since", "model", "Chaudhuri", "et", "al.", "have", "different", "parameterization", "from", "ours", "logprobability", "model", "ours", "directly", "comparable", "instead", "we", "conduct", "informal", "perceptual", "evaluation", "107", "student", "volunteer", "recruit", "through", "university", "mailing", "list", "each", "volunteer", "perform", "30", "pairwise", "comparison", "web-based", "survey", "each", "comparison", "between", "image", "two", "shape", "from", "same", "randomly", "choose", "domain", "shape", "be", "randomly", "sample", "from", "three", "set", "original", "training", "shape", "shape", "synthesize", "we", "model", "optimize", "procedure", "describe", "section", "5.2", "shape", "synthesize", "model", "Chaudhuri", "et", "al.", "optimize", "same", "procedure", "each", "comparison", "involve", "image", "shape", "from", "two", "three", "set", "image", "be", "sample", "from", "complete", "set", "321", "image", "training", "shape", "complete", "set", "3152", "image", "shape", "synthesize", "we", "model", "672", "image", "shape", "synthesize", "model", "Chaudhuri", "et", "al.", "participant", "be", "ask", "choose", "which", "two", "present", "object", "more", "plausible", "indicate", "lack", "preference", "total", "3210", "pairwise", "comparison", "be", "perform", "result", "visualize", "Figure", "10", "shape", "produce", "we", "model", "be", "see", "more", "plausible", "than", "shape", "produce", "prior", "model", "strong", "statistical", "significance", "content", "learn", "latent", "variable", "we", "model", "distinguish", "its", "use", "latent", "variable", "compactly", "parameterize", "underlie", "cause", "structural", "variability", "complex", "domain", "we", "visualize", "style", "learn", "two", "variable", "set", "chair", "figure", "12", "13", "Figure", "12", "show", "high-probability", "shape", "sample", "fix", "root", "variable", "learn", "model", "each", "its", "possible", "value", "107", "volunteer", "perform", "pairwise", "comparison", "evaluate", "plausibility", "shape", "produce", "we", "model", "against", "original", "training", "shape", "shape", "produce", "prior", "model", "Chaudhuri", "et", "al.", "result", "mark", "strongly", "statistically", "significant", "-lrb-", "10", "-rrb-", "accord", "two-tailed", "single", "sample", "t-test", "lateral", "edge", "lateral", "edge", "capture", "strong", "correlation", "between", "feature", "different", "component", "category", "construction", "vehicle", "show", "Figure", "-lrb-", "-rrb-", "synthesize", "model", "without", "lateral", "edge", "have", "bumper", "instead", "front", "scoop", "another", "appropriate", "front", "tool", "likewise", "chair", "dataset", "learn", "lateral", "edge", "connect", "geometric", "feature", "front", "leg", "geometric", "feature", "back", "leg", "chair", "Figure", "-lrb-", "-rrb-", "synthesize", "model", "without", "lateral", "edge", "have", "incompatible", "front", "back", "leg", "overall", "number", "lateral", "edge", "learn", "full", "model", "correlate", "number", "component", "category", "complexity", "domain", "learn", "edge", "vehicle", "24", "creature", "35", "chair", "36", "plane", "89", "ship", "computational", "complexity", "run", "time", "score", "evaluation", "-lrb-", "include", "parameter", "estimation", "-rrb-", "have", "complexity", "-lrb-", "lk", "-rrb-", "where", "number", "component", "category", "number", "input", "shape", "total", "complexity", "learning", "-lrb-", "-rrb-", "take", "account", "greedy", "search", "domain", "size", "hidden", "variable", "lateral", "edge", "we", "implementation", "parallelize", "execute", "single", "core", "Intel", "i7-740", "CPU", "Learning", "take", "about", "0.5", "hour", "construction", "vehicle", "hour", "creature", "hour", "chair", "20", "hour", "plane", "70", "hour", "ship", "shape", "synthesis", "enumerate", "all", "possible", "instantiation", "learn", "model", "take", "less", "than", "hour", "all", "case", "final", "assembly", "each", "shape", "take", "few", "seconds", "we", "present", "probabilistic", "model", "component-based", "shape", "structure", "can", "use", "synthesize", "new", "shape", "from", "domain", "demonstrate", "set", "example", "shape", "we", "processing", "pipeline", "assume", "training", "shape", "compatibly", "segmented", "furthermore", "extraction", "geometric", "feature", "use", "training", "assume", "shape", "upright-oriented", "frontfacing", "we", "employ", "semi-automatic", "procedure", "segment", "orient", "shape", "preprocessing", "stage", "still", "require", "manual", "effort", "advance", "upon", "current", "compatible", "shape", "segmentation", "orientation", "technique", "would", "broadly", "beneficial", "-lsb-", "Fu", "et", "al.", "2008", "Kalogerakis", "et", "al.", "2010", "Huang", "et", "al.", "2011", "Sidi", "et", "al.", "2011", "-rsb-", "we", "model", "also", "use", "simplify", "assumption", "geometric", "feature", "component", "normally", "distribute", "simplify", "learn", "procedure", "do", "capture", "more", "complex", "variability", "geometric", "feature", "further", "model", "only", "learn", "linear", "correlation", "between", "component", "feature", "addition", "component", "placement", "approach", "describe", "section", "5.2", "heuristic", "can", "fail", "produce", "visually", "please", "result", "specifically", "do", "optimize", "orientation", "component", "do", "prevent", "intersection", "between", "component", "show", "Figure", "11", "analysis", "function", "shape", "likewise", "interesting", "direction", "can", "enhance", "shape", "synthesis", "can", "lead", "learn", "model", "continuous", "shape", "variability", "increasingly", "complex", "real-world", "domain", "which", "can", "enable", "new", "capability", "shape", "reconstruction", "we", "grateful", "Aaron", "Hertzmann", "Sergey", "Levine", "Philipp", "Kr?henb?hl", "comment", "paper", "Tom", "Funkhouser", "helpful", "discussion", "research", "conduct", "conjunction", "Intel", "Science", "Technology", "Center", "Visual", "Computing", "support", "part", "kaust", "global", "Collaborative", "Research", "NSF", "grant", "ses-0835601", "ccf0641402", "okeloh", "M.", "M.", "EIDEL", "h.-p", "2010", "connection", "between", "partial", "symmetry", "inverse", "procedural", "modeling", "ACM", "transaction", "Graphics", "29", "ouchard", "G.", "rigg", "B.", "2005", "hierarchical", "part-based", "visual", "object", "categorization", "IEEE", "Conference", "Com", "haudhurus", "S.", "OLTUN", "V.", "2010", "data-driven", "suggestion", "creativity", "support", "3d", "modeling", "ACM", "transaction", "Graphics", "29", "haudhurus", "S.", "ALOGERAKIS", "E.", "UIBAS", "L.", "OLTUN", "V.", "2011", "probabilistic", "reasoning", "assembly-based", "3d", "modeling", "ACM", "transaction", "Graphics", "30", "heeseman", "P.", "TUTZ", "J.", "1996", "bayesian", "classification", "-lrb-", "autoclass", "-rrb-", "Theory", "result", "advance", "Knowledge", "Dis", "hennubhotlum", "C.", "EPSON", "A.", "2001", "S-PCA", "extract", "multi-scale", "structure", "from", "datum", "International", "Confer", "idler", "S.", "eonardi", "a.", "2007", "towards", "scalable", "representation", "object", "category", "Learning", "hierarchy", "part", "a.", "2008", "m.", "P.", "P.", "S.", "D.", "UANG", "Q.", "OLTUN", "V.", "UIBAS", "L.", "2011", "Joint", "shape", "segmentation", "linear", "programming", "ACM", "transaction", "Graphics", "30", "ALOGERAKIS", "E.", "ERTZMANN", "a.", "ingh", "K.", "2010", "Learning", "3d", "mesh", "segmentation", "labeling", "ACM", "transaction", "Graphics", "29", "OLLER", "D.", "riedman", "N.", "2009", "Probabilistic", "Graphical", "model", "principle", "technique", "MIT", "Press", "RAEVOY", "V.", "ULIUS", "D.", "heffer", "a.", "2007", "Model", "composition", "from", "interchangeable", "component", "Pacific", "Graphics", "IEEE", "Computer", "Society", "ee", "J.", "unkhouser", "t.", "2008", "sketch-based", "search", "composition", "3d", "model", "Eurographics", "Workshop", "errell", "P.", "anocha", "D.", "2011", "Model", "synthesis", "general", "procedural", "modeling", "algorithm", "IEEE", "transaction", "visualization", "computer", "graphic", "17", "errell", "P.", "2007", "example-based", "model", "synthesis", "Symposium", "Interactive", "3D", "Graphics", "ACM", "mmer", "B.", "UHMANN", "J.", "2010", "learn", "compositional", "nature", "visual", "object", "category", "recognition", "vsjanikov", "m.", "W.", "UIBAS", "L.", "itra", "N.", "J.", "2011", "exploration", "continuous", "variability", "collection", "3d", "shape", "ACM", "transaction", "Graphics", "30", "anzato", "M.", "A.", "usskind", "J.", "NIH", "V.", "inton", "G.", "2011", "deep", "generative", "model", "application", "recognition", "IEEE", "Conference", "Computer", "Vision", "Pattern", "OUX", "N.", "L.", "EESS", "N.", "HOTTON", "J.", "INN", "J.", "2011", "learn", "generative", "model", "image", "factor", "appearance", "shape", "neural", "computation", "23", "harf", "a.", "lumenkrant", "M.", "hamir", "a.", "ohen", "D.", "2006", "SnapPaste", "interactive", "technique", "easy", "mesh", "composition", "visual", "computer", "22", "idi", "O.", "VAN", "AICK", "O.", "LEIMAN", "Y.", "HANG", "H.", "ohen", "D.", "2011", "unsupervised", "co-segmentation", "set", "shape", "via", "descriptor-space", "spectral", "clustering", "ACM", "transaction", "Graphics", "30", "tava", "O.", "ENE", "B.", "ech", "R.", "LIAGA", "D.", "RISTOF", "P.", "2010", "inverse", "procedural", "modeling", "automatic", "generation", "l-system", "Computer", "Graphics", "Forum", "29", "odorovic", "S.", "HUJA", "N.", "2008", "unsupervised", "category", "modeling", "recognition", "segmentation", "image", "IEEE", "transaction", "Pattern", "Analysis", "Machine", "Intelligence", "30", "12", "Z.", "HEN", "X.", "uille", "a.", "L.", "hu", "s.-c", "2005", "image", "parsing", "unifying", "segmentation", "detection", "recognition", "International", "Journal", "Computer", "Vision", "63", "ESSEL", "R.", "UMEL", "i.", "LEIN", "R.", "2009", "3d", "shape", "benchmark", "retrieval", "automatic", "classification", "architectural", "datum", "eurographic", "2009", "Workshop", "3D", "Object", "Re", "K.", "HENG", "H.", "HANG", "H.", "OHEN", "D.", "IU", "L.", "iong", "Y.", "2011", "photo-inspired", "model-driven", "3d", "object", "modeling", "ACM", "transaction", "Graphics", "30", "hu", "L.", "L.", "C.", "UANG", "H.", "HEN", "Y.", "uille", "a.", "L.", "2008", "unsupervised", "structure", "learning", "hierarchical", "recursive", "composition", "suspicious", "coincidence", "competitive", "exclusion", "european", "conference", "computer", "Vision", "first", "mesh", "orient", "so", "upward", "direction", "front-facing", "direction", "sparse-pca", "-lsb-", "chennubhotla", "Jepson", "2001", "-rsb-", "surface", "sample", "specify", "component", "use", "extract", "principal", "axis", "each", "mesh", "sparsepca", "tend", "choose", "axis", "align", "latent", "xy", "frame", "which", "appropriate", "since", "mesh", "usually", "already", "orient", "some", "permutation", "latent", "axis", "specify", "principal", "axis", "align", "example", "upward", "direction", "chair", "determine", "SPCA", "axis", "correspond", "smallest", "variance", "point", "seat", "which", "center", "mass", "back", "have", "positive", "y-axis", "value", "process", "fail", "mesh", "orient", "manually", "each", "shape", "component", "from", "each", "source", "mesh", "repository", "we", "extract", "high-dimensional", "feature", "vector", "contain", "-rrb-", "3d", "scale", "vector", "orient", "bound", "box", "component", "-rrb-", "histogram", "16", "uniform", "bin", "principal", "curvature", "-lrb-", "curvature", "estimate", "multiple", "scale", "over", "neighborhood", "point", "sample", "increase", "radius", "10", "relative", "median", "geodesic", "distance", "between", "all", "pair", "point", "sample", "surface", "-rrb-", "-rrb-", "histogram", "16", "uniform", "bin", "shape", "diameter", "over", "surface", "its", "logarithmized", "version", "w.r.t.", "normalize", "parameter", "-rrb-", "follow", "entry", "derive", "from", "singular", "value", "-lcb-", "-rcb-", "covariance", "matrix", "sample", "position", "surface", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-rrb-", "lightfield", "descriptor", "value", "compute", "-lsb-", "Chen", "et", "al.", "2003", "-rsb-", "-lrb-", "since", "mesh", "orient", "consistently", "descriptor", "can", "compare", "without", "search", "over", "align", "transform", "-rrb-", "we", "perform", "pca", "matrix", "lightfield", "feature", "per", "component", "also", "matrix", "contain", "descriptor", "-lrb-", "b-d", "-rrb-", "reduce", "overall", "dimensionality", "feature", "final", "feature", "vector", "contain", "3d", "scale", "vector", "project", "low-dimensional", "feature", "finally", "each", "component", "we", "detect", "slot", "connect", "they", "other", "component", "-lrb-", "figure", "-lrb-", "-rrb-", "-rrb-", "component", "obtain", "cut", "topologically", "manifold", "mesh", "along", "edge", "loop", "slot", "simply", "edge", "loop", "all", "other", "component", "we", "mark", "vertex", "close", "component", "different", "category", "slot", "vertex", "use", "threshold", "equal", "1/64", "radius", "bound", "sphere", "mesh", "vertex", "find", "threshold", "double", "until", "least", "ten", "slot", "vertex", "find", "we", "also", "automatically", "extract", "ground", "contact", "each", "component", "exist", "contact", "extract", "find", "vertex", "whose", "distance", "ground", "plane", "below", "threshold", "use", "detect", "slot", "vertex" ],
  "content" : "We demonstrate two applications of the presented model. First, it can be used to amplify an existing shape database. Second, the model enables interactive shape synthesis interfaces that allow rapid creation of plausible shapes subject to high-level constraints. The pioneering Modeling by Example system by Funkhouser et al. [2004] used a database of segmented shapes to enable interactive assembly of new shapes from retrieved components. None of these techniques allow automatic synthesis of plausible new shapes with novel structure from a complex domain described only by a set of examples. While their probabilistic model can be used to assemble complete novel shapes, the plausibility of the synthesized shapes is severely limited. However, our model operates not on image pixels or patches, but on geometric and semantic features of three-dimensional shape components. Our probabilistic model is designed to represent the componentbased structure of shapes in complex domains such as furniture, aircraft, vehicles, etc. Our key observation is that the structural variability in such domains is often characterized by the presence of multiple underlying types of shapes and their components. For example, the expected set of components present in a chair?as well as their geometry?differs markedly between office chairs, dining chairs, and cantilever chairs. This observation allows us to design a compact hierarchical model that can be effectively trained on small datasets. Our model incorporates latent variables that parameterize the types of shapes in the domain as well as the styles of individual components. The model is trained on a set of compatibly segmented shapes. In our implementation, we use the compatible segmentation and labeling technique of Kalogerakis et al. [2010], assisted by manual segmentation and labeling. Random variables. Our model is illustrated in Figure 2 . It is a hierarchical mixture of distributions over attributes of shape components, with a single latent variable R at the root. This variable can be interpreted as the overall type of the shape. These include N l , the number of components from category l, C l , a vector of continuous geometric features of components from category l, and D l , a vector of discrete geometric features of components from category l. In our implementation, the continuous features include curvature histograms, shape diameter histograms, scale parameters, spin images, PCA-based descriptors, and lightfield descriptors. Specifically, these features specify the number of components from each category l ? that are adjacent to components from category l. Illustrative example. Figure 3 shows a small dataset of compatibly segmented tables and a probabilistic model learned for this dataset. Our model learned that there the two dominant styles: onelegged tables and four-legged tables. For each style, the model represents the conditional distribution over the number of components from each category: specifically, the number of tabletops (N top ) and the number of legs (N leg ). In this example, the model learned that there are two dominant tabletop styles: rectangular tabletops and roughly circular tabletops. The variables C top and C leg represent continuous geometric features for the respective component categories, while D top and D leg represent discrete geometric features. For one-legged tables, the conditional probability distribution associated with C leg indicates that the horizontal extent of the base of the leg is positively correlated with the horizontal extent of the tabletop. The model represents a joint probability distribution p(X) over all random variables X = {R, S, N, C, D}. This distribution is factorized as a product of conditional probability distributions (CPDs) as follows: where ?(N l ), ?(C l ), ?(D l ) are the sets of observed random variables that are linked to N l , C l and D l by lateral edges. Parametrization of CPDs for discrete variables. The CPDs for the discrete random variables T = {S l , N l , D l } of the model can be represented as conditional probability tables (CPTs). The values Q = {q t|u } comprise the parameters of the CPT. For the random variable R, which has no parents, we simply store the probability table P (R = r) = q r . When a discrete random variable has a set of multiple parents U = {U 1 , U 2 , . . . , U m }, we use sigmoid functions instead of a CPT to parametrize its CPD. Sigmoid functions reduce the complexity of the model and improve generalization, since the number of parameters in a sigmoid CPD increases linearly with the number and domain size of the parent random variables, while the number of parameters of CPTs increases exponentially. The sigmoid CPD is expressed as follows: where u = {u 1 , u 2 , . . . , u m } is the assignment to the parent variables, W = {w t,0 , w t,? } t?T are the parameters of the sigmoids, and I j (u j ) = {I(U j = u j )} is a vector-valued binary indicator function for each of the parent variables U j . Parametrization of CPDs for continuous variables. The CPD for each continuous random variable C is expressed as a conditional linear multivariate Gaussian. Let U = {U 1 , U 2 , . . . , U m } be the discrete and Z = {z 1 , z 2 , . . . , z n } the continuous parents of C. The conditional linear Gaussian for C is defined as where ? = {? u,? } and ? = {? u } are the parameters of the conditional Gaussian for each u in the value space U of U, and v is the vector of assignments to the continuous parents Z. Specifically, the parameters ? u,0 and ? u are the conditional mean and the covariance matrix, respectively, while the remaining parameters ? are regression coefficients. If C has no continuous parents, the CPD becomes We now describe the offline procedure for learning the structure and parameters of the probabilistic model. The input is a set of K compatibly segmented shapes. For each component, we compute its geometric attributes as described in Appendix A. Our training data is thus a set of feature vectors O = {O 1 , O 2 , . . . , O K }, where O k = {N k , D k , C k }. Assuming a uniform prior P (G) over possible structures, maximizing P (G | O) reduces to maximizing the marginal likelihood P (O | G). Our choice of priors is discussed in the supplementary material. In the above expression, the marginal likelihood involves summing over all possible assignments to the latent variables R and S, thus the number of integrals is exponentially large. P (O | G) ? P (O ? | G) ? P (O | G, ?  ? G ) . (1) P (O ? | G, ?  ? G )\n        Here ?  ? G are the parameters estimated for a given G, and O ? is a fictitious dataset that comprises the training data O and approximate statistics for the values of the latent variables. The search proceeds as follows: we start with a domain size of 1 for R, corresponding to a single shape style. Then, for each component style S l in each category l, we evaluate the score with a domain size of 2. This corresponds to a single component style, since the value 0 for S l denotes the absence of components from this category. We then gradually increase the domain size of S l , evaluating the score at each step. If the score decreases, the previous value (a local maximum) is retained as the domain size for S l and the search moves to the next component category. After the search iterates over all variables in S, we increase the domain size of R and repeat the procedure. The search terminates when the score reaches a local maximum that does not improve over 10 subsequent iterations; the domain size for R is set to the value that yielded the highest score, and the domain sizes for all variables in S are set to the corresponding locally maximal values. We retain the graph structure that yields the highest score, along with the corresponding parameters for all the CPDs in the model, computed as described below. Parameter estimation. For a given structure G, we perform maximum a posteriori (MAP) estimation of the parameters. Thus, MAP estimates are found with the expectation-maximization (EM) algorithm. The details of the EM algorithm are discussed in the supplementary material, along with the computation of the three terms in (1). All computations involving probabilities are performed in log-space to avoid numerical errors. A model trained on a set of shapes as described in Section 4 can be used to synthesize new shapes. The synthesis proceeds in two stages. In the first stage, we enumerate high-probability instantiations of the model. Each instantiation specifies a set of components. In the second stage, we optimize the placement of these components to produce a cohesive shape. Instantiations of the model, corresponding to sets of components, can be found through forward sampling. However, this random sampling process is biased towards higher-probability assignments to the random variables. Forward sampling is thus unsuitable for efficiently enumerating all instantiations that have non-negligible probability. Instead, we use a simple deterministic procedure. First, we topologically sort the nodes in the model. Note that the style variables R and S always appear before other variables, but the complete ordering depends on the learned graph structure. Next, we create a tree whose nodes correspond to partial assignments to the random variables. The tree is initialized with an empty root node. The children of the root are all possible assignments to R. The tree continues to expand by creating nodes for the next partial assignment based on the values of the next random variable in the sorted list. When the algorithm reaches the continuous variables C l , the partial assignments could in principle take any value in R dim(C l ) , which would make the search infeasible. However, only specific values of these variables correspond to geometric features of components extracted from the training set. Therefore, we expand the partial assignments only to those values of C l that correspond to existing components from category l. Branches that contain assignments that have extremely low probability density (less than 10 ?12 in our implementation) are pruned from the tree. To assist this placement, certain regions on each component are marked as ?slots? that specify where this component can be attached to other components. Each slot stores the category label of components it can be attached to. It also stores simple automatically extracted symmetry relationships that allow correct relative placement of symmetric groups of bilistic by the least-squares model. Optimizing The components optimization component are that placement. drawn aligns from all the (a) pairs source Three of adjacent shapes source shapes shown components on from the at the left. their chair Initially, corresponding database. the legs ?Slots? and slots. the back are highlighted are placed relative in red. (b) to the A set seat of according components to for transformations a new chair synthesized stored in the by seat?s the probaslots. (c) The final synthesized chair, with components placed and scaled adjacent components. In the example shown in Figure 4 , the chair seat has two slots for front legs and two slots for back legs. The symmetry information stored in the seat slots specifies that the leg placed in the front right slot of the seat is a symmetric counterpart of the leg placed in the front left slot, reflected by one of the symmetry planes of the seat. Note that these relationships are a property of the seat and not of the legs, thus different legs in a new chair can be placed consistently around the same seat. This gives us a deterministic procedure for placing each component vis-a-vis its adjacent components by matching slots and applying the stored symmetry transforms. This initial placement is further refined by an optimization step that aligns all pairs of adjacent components at their points of contact. The optimization minimizes a squared error term over the slots, which penalizes discrepancies of position and relative size between each pair of adjacent slots, expressed as a function of the translation and scaling parameters of the corresponding components. To ensure that components are not drastically distorted in scale, the optimization penalizes deviation from the original component scales, weighting the error in each parameter by a learned variance in scale. Finally, the error term also penalizes deviations from symmetry and ground contact. (Ground contact points are extracted as described in Appendix A.) We used the same objective term weights for all domains in our evaluation. A linear least-squares solver, with nonnegativity constraints for the scaling parameters, is used to minimize the error. To enhance the visual appearance of synthesized shapes, we glue adjacent components of organic shapes by matching adjacent edge loops, shifting local neighborhoods with a smooth falloff, and applying a final Laplacian smoothing filter. vehicles chairs ships creatures # of training shapes 100 22 88 42 69 # of categories 14 7 11 30 11 # of components 881 122 504 639 593 # of synth. shapes 1267 253 870 199 563 We describe two applications of the presented model. The first is amplification of an input shape database and the second is constrained shape synthesis based on high-level specifications provided interactively by a user. Shape database amplification. The first application is a direct result of applying the learning and inference procedures described in the preceding sections. Given an input dataset of compatibly segmented and labeled shapes, we train the model as described in Section 4. We then synthesize all instantiations of the model that have non-negligible probability and optimize the resulting shapes, as described in Section 5. We identify and reject instantiations that are very similar to shapes in the input dataset or to previous instantiations. Note that this pruning is optional, since these instantiations still correspond to plausible shapes in our experiments; we simply seek to avoid visually redundant shapes generated by shuffling very similar components around. We also reject synthesized shapes for which the component placement optimization fails. Constrained shape synthesis. Our model can also be used to synthesize shapes subject to interactively specified constraints. The interface allows combining multiple types of constraints and is demonstrated in the accompanying video. To synthesize shapes subject to the provided constraints, we perform the deterministic search procedure described in Section 5.1 with the modification that partial assignments to constrained random variables assume values only from the range corresponding to the specified constraints. We evaluated the presented model on five shape datasets obtained from publicly available 3D model libraries (Digimation Model Bank, Dosch 3D, and the furniture database of Wessel et al. [2009]). The datasets were compatibly segmented and labeled using the technique of Kalogerakis et al. [2010], assisted by manual segmentation and labeling. Table 1 gives the number of shapes in each dataset, the number of component categories, the number of individual components extracted from each dataset, and the number of new shapes synthesized for each dataset by our model. These synthesized shapes are shown alongside the training shapes in Figures 1, 14, 15, 16, and 17, as well as in the accompanying video. Figure 5 shows a histogram of the number of components used per synthesized shape and a histogram of the number of source shapes that contributed components per synthesized shape. Generalization performance. A key question in the evaluation of a probabilistic model is how well it generalizes from the training data. A successful generative model will be able to not only reproduce instances from the training data, but synthesize genuinely novel plausible instances from the domain exemplified by the dataset. A standard technique for evaluating generalization performance is holdout validation, where the dataset is randomly split into a training set and a test set. The test set is withheld and only the training set is used for training the model. The trained model is then evaluated on the test set, by computing the probability assigned by the model to instances in the test set. Higher probability on the test set corresponds to better generalization performance. Components from multiple source shapes (right) are combined by the probabilistic model to yield plausible new shapes (left, blue). Utilized components are highlighted in color in the source shapes. repeat the procedure with three random 80-20 training-test splits of the dataset, and take the geometric mean of the resulting probabilities. We compare the presented model to weaker models in which some of the components of the presented model are disabled. The results are shown in Figure 6 . Each bar in the figure corresponds to the negative logarithm of the probability assigned to the test data by our model or a weaker variant; a lower value corresponds to better generalization performance. We have also evaluated the performance of the model with impoverished datasets. To this end, we gradually changed the split ratios from 80-20 (train on 80% of the data, test on the remaining 20%) to 20-80 (train on 20% of the data, test on the remaining 80%). The results are plotted in Figure 7 . Generalization performance degraded when the dataset made available for training became less representative of the overall domain. The rapid degradation for construction vehicles is due to the small size of the dataset: 20% of the data in this case corresponds to having only four examples. Comparison to prior work. The probabilistic model developed by Chaudhuri et al. [2011] can also be used to synthesize complete novel shapes, although it was not designed for this purpose and in our experiments generally produced shapes of low plausibility ( Figure 9 ). For quantitative evaluation against this prior model, we could not use holdout validation, since the model of Chaudhuri et al. has a different parameterization from ours and the logprobabilities of their model and ours are not directly comparable. Instead, we conducted an informal perceptual evaluation with 107 student volunteers recruited through a university mailing list. Each volunteer performed 30 pairwise comparisons in a Web-based survey. Each comparison was between images of two shapes from the same randomly chosen domain. The shapes were randomly sampled from three sets: original training shapes, shapes synthesized by our model and optimized by the procedure described in Section 5.2, and shapes synthesized by the model of Chaudhuri et al. and optimized by the same procedure. Each comparison involved images of shapes from two of these three sets. The images were sampled from the complete set of 321 images of training shapes, the complete set of 3152 images of shapes synthesized by our model, and 672 images of shapes synthesized by the model of Chaudhuri et al. The participants were asked to choose which of the two presented objects was more plausible, or indicate lack of preference. A total of 3210 pairwise comparisons were performed. The results are visualized in Figure 10 . Shapes produced by our model were seen as more plausible than shapes produced by the prior model, with strong statistical significance. Content of learned latent variables. Our model is distinguished by its use of latent variables to compactly parameterize the underlying causes of structural variability in complex domains. We visualize the styles learned by two of the variables for the set of chairs in Figures 12 and 13. Figure 12 shows high-probability shapes sampled by fixing the root variable in the learned model to each of its possible values. 107 volunteers performed pairwise comparisons to evaluate the plausibility of shapes produced by our model against original training shapes and the shapes produced by the prior model of Chaudhuri et al. Results marked with a ? are strongly statistically significant (p < 10 ?7 ), according to a two-tailed single sample t-test. Lateral edges. Lateral edges capture strong correlations between features of different component categories. The construction vehicle shown in Figure 9(c) was synthesized by a model without lateral edges and has a bumper instead of a front scoop or another appropriate front tool. Likewise, for the chairs dataset, a learned lateral edge connects geometric features of the front legs with geometric features of the back legs. The chair in Figure 9(c) was synthesized by a model without lateral edges and has incompatible front and back legs. Overall, the number of lateral edges learned by the full model correlates with the number of component categories and the complexity of the domain. There are 9 learned edges for vehicles, 24 for creatures, 35 for chairs, 36 for planes, and 89 for ships. Computational complexity and running times. The score evaluation (including parameter estimation) has complexity O(LK), where L is the number of component categories and K is the number of input shapes. The total complexity of learning is O(L 3 K), taking into account the greedy search for the domain sizes of the hidden variables and the lateral edges. Our implementation is not parallelized, and was executed on a single core of an Intel i7-740 CPU. Learning took about 0.5 hours for construction vehicles, 3 hours for creatures, 8 hours for chairs, 20 hours for planes, and 70 hours for ships. For shape synthesis, enumerating all possible instantiations of a learned model takes less than an hour in all cases, and final assembly of each shape takes a few seconds. We presented a probabilistic model of component-based shape structure that can be used to synthesize new shapes from a domain demonstrated by a set of example shapes. Our processing pipeline assumes that the training shapes are compatibly segmented. Furthermore, the extraction of geometric features used for training assumes that the shapes are upright-oriented and frontfacing. We employed semi-automatic procedures to segment and orient shapes, but the preprocessing stage still required manual effort. Advances upon current compatible shape segmentation and orientation techniques would be broadly beneficial [Fu et al. 2008; Kalogerakis et al. 2010; Huang et al. 2011; Sidi et al. 2011]. Our model also uses the simplifying assumption that the geometric features of components are normally distributed. This simplifies the learning procedure, but does not capture more complex variability of geometric features. Further, the model only learns linear correlations between component features. In addition, the component placement approach described in Section 5.2 is heuristic and can fail to produce visually pleasing results. Specifically, it does not  optimize the orientation of components and does not prevent intersections between components, as shown in Figure 11 . Analysis of the function of shapes is likewise an interesting direction that can enhance shape synthesis. This can lead to learned models of continuous shape variability in increasingly complex real-world domains, which can enable new capabilities for shape reconstruction. We are grateful to Aaron Hertzmann, Sergey Levine, and Philipp Kr?henb?hl for their comments on this paper, and to Tom Funkhouser for helpful discussions. This research was conducted in conjunction with the Intel Science and Technology Center for Visual Computing, and was supported in part by KAUST Global Collaborative Research and by NSF grants SES-0835601 and CCF0641402. B OKELOH , M., W AND , M., AND S EIDEL , H.-P. 2010. A connection between partial symmetry and inverse procedural modeling. ACM Transactions on Graphics 29, 4. B OUCHARD , G., AND T RIGGS , B. 2005. Hierarchical part-based visual object categorization. IEEE Conference on Com- C HAUDHURI , S., AND K OLTUN , V. 2010. Data-driven suggestions for creativity support in 3D modeling. ACM Transactions on Graphics 29, 6. C HAUDHURI , S., K ALOGERAKIS , E., G UIBAS , L., AND K OLTUN , V. 2011. Probabilistic reasoning for assembly-based 3D modeling. ACM Transactions on Graphics 30, 4. C HEESEMAN , P., AND S TUTZ , J. 1996. Bayesian classification (autoclass): Theory and results. Advances in Knowledge Dis- C HENNUBHOTLA , C., AND J EPSON , A. 2001. S-PCA: Extracting multi-scale structure from data. International Confer- F IDLER , S., AND L EONARDIS , A. 2007. Towards scalable representations of object categories: Learning a hierarchy of parts. , A. 2008. M., S , P., M , P., , S., D , D. H UANG , Q., K OLTUN , V., AND G UIBAS , L. 2011. Joint shape segmentation with linear programming. ACM Transactions on Graphics 30, 6. K ALOGERAKIS , E., H ERTZMANN , A., AND S INGH , K. 2010. Learning 3D mesh segmentation and labeling. ACM Transactions on Graphics 29, 4. K OLLER , D., AND F RIEDMAN , N. 2009. Probabilistic Graphical Models: Principles and Techniques. The MIT Press. K RAEVOY , V., J ULIUS , D., AND S HEFFER , A. 2007. Model composition from interchangeable components. Pacific Graphics, IEEE Computer Society. L EE , J., AND F UNKHOUSER , T. 2008. Sketch-based search and composition of 3D models. Eurographics Workshop on M ERRELL , P., AND M ANOCHA , D. 2011. Model synthesis: A general procedural modeling algorithm. IEEE Transactions on Visualization and Computer Graphics 17, 6. M ERRELL , P. 2007. Example-based model synthesis. Symposium on Interactive 3D Graphics, ACM. O MMER , B., AND B UHMANN , J. 2010. Learning the compositional nature of visual object categories for recognition. O VSJANIKOV , M., L I , W., G UIBAS , L., AND M ITRA , N. J. 2011. Exploration of continuous variability in collections of 3D shapes. ACM Transactions on Graphics 30, 4. R ANZATO , M. A., S USSKIND , J., M NIH , V., AND H INTON , G. 2011. On deep generative models with applications to recognition. IEEE Conference on Computer Vision and Pattern R OUX , N. L., H EESS , N., S HOTTON , J., AND W INN , J. 2011. Learning a generative model of images by factoring appearance and shape. Neural Computation, 23. S HARF , A., B LUMENKRANTS , M., S HAMIR , A., AND C OHEN O R , D. 2006. SnapPaste: an interactive technique for easy mesh composition. Visual Computer 22, 9. S IDI , O., VAN K AICK , O., K LEIMAN , Y., Z HANG , H., AND C OHEN -O R , D. 2011. Unsupervised co-segmentation of a set of shapes via descriptor-space spectral clustering. ACM Transactions on Graphics 30, 6. S TAVA , O., B ENE S , B., M ECH , R., A LIAGA , D., AND K RISTOF , P. 2010. Inverse procedural modeling by automatic generation of L-systems. Computer Graphics Forum 29, 2. T ODOROVIC , S., AND A HUJA , N. 2008. Unsupervised category modeling, recognition, and segmentation in images. IEEE Transactions on Pattern Analysis and Machine Intelligence 30, 12. T U , Z., C HEN , X., Y UILLE , A. L., AND Z HU , S.-C. 2005. Image parsing: Unifying segmentation, detection, and recognition. International Journal of Computer Vision 63, 2. W ESSEL , R., B L UMEL  ? , I., AND K LEIN , R. 2009. A 3d shape benchmark for retrieval and automatic classification of architectural data. In Eurographics 2009 Workshop on 3D Object Re- X U , K., Z HENG , H., Z HANG , H., C OHEN -O R , D., L IU , L., AND X IONG , Y. 2011. Photo-inspired model-driven 3D object modeling. ACM Transactions on Graphics 30, 4. Z HU , L. L., L IN , C., H UANG , H., C HEN , Y., AND Y UILLE , A. L. 2008. Unsupervised structure learning: Hierarchical recursive composition, suspicious coincidence and competitive exclusion. European Conference on Computer Vision. First, the meshes are oriented so that +Z is the upward direction and +Y is the front-facing direction. Sparse-PCA [Chennubhotla and Jepson 2001] on surface samples of a specified component is used to extract principal axes of each mesh. SparsePCA tends to choose axes that align with the latent XY Z frame, which is appropriate since the meshes are usually already oriented to some permutation of the latent axes. Specified principal axes are aligned to +Z and +Y . For example, the upward direction of chairs is determined by the SPCA axis that corresponds to the smallest variance in the points of the seats and for which the center of mass of backs has positive y-axis value. If this process fails, the meshes are oriented manually. Then, for each shape component c from each source mesh m in the repository, we extract a high-dimensional feature vector containing: a) the 3D scale vector of the oriented bounding box of the component; b) histograms of 4, 8 and 16 uniform bins for principal curvatures ? 1 and ? 2 (the curvatures are estimated at multiple scales over neighborhoods of point samples of increasing radii: 1%, 2%, 5% and 10% relative to the median geodesic distance between all pairs of point samples on the surface of m); c) histograms of 4, 8 and 16 uniform bins of the shape diameter over the surface of c, and of its logarithmized versions w.r.t. normalizing parameters 1, 2, 4 and 8; d) the following entries, derived from the singular values {s 1 , s 2 , s 3 } of the covariance matrix of sample positions on the surface of c: s 1 / i s i , s 2 / i s i , s 3 / i s i , (s 1 +s 2 )/ i s i , (s 1 +s 3 )/ i s i , (s 2 +s 3 )/ i s i , s 1 /s 2 , s 1 /s 3 , s 2 /s 3 , s 1 /s 2 + s 1 /s 3 , s 1 /s 2 + s 2 /s 3 , s 1 /s 3 + s 2 /s 3 ; e) lightfield descriptor values computed as in [Chen et al. 2003] (since the meshes are oriented consistently, these descriptors can be compared without searching over aligning transforms). We perform PCA on the matrix of lightfield features per component, and also on the matrix containing the descriptors (b-d) to reduce the overall dimensionality of the features. The final feature vector C l contains the 3D scale vector and the projected low-dimensional features. Finally, for each component we detect slots that connect them to other components ( Figure 4(a) ). For components obtained by cutting topologically manifold meshes along edge loops, the slots are simply these edge loops. For all other components, we mark vertices close to a component of a different category as slot vertices, using a threshold equal to 1/64 of the radius of the bounding sphere of the mesh. If no such vertices are found, the threshold is doubled until at least ten slot vertices are found. We also automatically extract ground contacts for each component, if these exist. These contacts are extracted by finding the vertices whose distance to the ground plane is below the threshold used to detect slot vertices.",
  "resources" : [ ]
}