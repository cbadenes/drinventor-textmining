{
  "uri" : "sig2010-a33-ho_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2010/a33-ho_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Spatial Relationship Preserving Character Motion Adaptation",
    "published" : "2010",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Edmond S. L.-Ho",
      "name" : "Edmond S. L.",
      "surname" : "Ho"
    }, {
      "uri" : "http://drinventor/Taku-Komura",
      "name" : "Taku",
      "surname" : "Komura"
    }, {
      "uri" : "http://drinventor/Chiew-Lan-Tai",
      "name" : "Chiew-Lan",
      "surname" : "Tai"
    } ]
  },
  "bagOfWords" : [ "close", "interaction", "necessarily", "any", "contact", "between", "different", "body", "part", "single", "multiple", "character", "environment", "common", "computer", "animation", "3d", "computer", "game", "yoga", "wrestling", "dancing", "move", "through", "constrain", "environment", "some", "example", "motion", "spatial", "relationship", "between", "different", "body", "part", "character", "important", "capture", "semantics", "scene", "when", "animator", "synthesize", "edit", "movement", "special", "care", "need", "preserve", "spatial", "relationship", "example", "arch", "back", "avoid", "punch", "hand", "extend", "around", "each", "other", "two", "body", "move", "synchronously", "close", "proximity", "get", "small", "car", "bend", "down", "however", "traditionally", "spatial", "relationship", "exist", "only", "animator?s", "mind", "digitally", "embed", "datum", "although", "human", "use", "spatial", "relationship", "recognize", "semantics", "interaction", "usage", "have", "be", "consider", "much", "character", "animation", "exist", "scene", "representation", "have", "fundamental", "limitation", "handle", "close", "interaction", "currently", "motion", "typically", "describe", "term", "joint", "angle", "kinematic", "constraint", "contact", "representation", "automatically", "compute", "valid", "motion", "require", "randomize", "exploration", "significant", "computation", "collision", "detection", "animator", "also", "need", "shoulder", "burden", "specify", "all", "kinematic", "constraint", "advance", "from", "animator?s", "perspective", "impractical", "conductive", "manual", "editing", "competitive", "automatic", "solution", "require", "effective", "representation", "allow", "extraction", "spatial", "relationship", "from", "exist", "motion", "datum", "synthesis", "new", "animation", "preserve", "relationship", "representation", "only", "allow", "quantitative", "evaluation", "way", "different", "body", "part", "interact", "also", "facilitate", "qualitative", "characterization", "scene", "semantics", "paper", "we", "propose", "simple", "representation", "which", "we", "call", "interaction", "mesh", "represent", "spatial", "relationship", "between", "nearby", "body", "part", "interaction", "mesh", "volumetric", "mesh", "define", "joint", "character", "vertex", "objects/environment", "which", "character", "interact", "when", "editing", "retargeting", "movement", "motion", "automatically", "adapt", "deform", "interaction", "mesh", "all", "frame", "efficient", "laplacian", "deformation", "technique", "-lsb-", "Alexa", "2003", "Zhou", "et", "al.", "2005", "-rsb-", "high-level", "semantics", "interaction", "maintain", "through", "preserve", "local", "detail", "interaction", "mesh", "interaction", "mesh", "representation", "general", "provide", "unified", "treatment", "interact", "body", "part", "single", "multiple", "character", "well", "object", "environment", "result", "applicable", "many", "type", "scenario", "when", "single", "character?s", "action", "involve", "close", "interaction", "between", "different", "body", "part", "-lrb-", "dancing", "-rrb-", "multi-character", "interaction", "-lrb-", "wrestling", "fight", "game", "-rrb-", "additionally", "motion", "may", "either", "involve", "much", "tangling", "contact", "-lrb-", "e.g.", "judo", "fig.", "-rrb-", "little", "contact", "-lrb-", "e.g.", "lambada", "dance", "-rrb-", "additionally", "can", "apply", "either", "per-frame", "space-time", "domain", "accord", "complexity", "problem", "available", "computing", "resource", "Motion", "adaptation", "interaction", "mesh", "fully", "automatic", "when", "animator", "change", "size", "morphology", "character", "edit", "part", "motion", "system", "automatically", "deform", "interaction", "mesh", "all", "frame", "use", "spacetime", "optimization", "create", "new", "motion", "sequence", "preserve", "original", "context", "scene", "constraint", "need", "specify", "animator", "since", "all", "encode", "interaction", "mesh", "desire", "user", "may", "add", "extra", "constraint", "anchor", "body", "foot", "approach", "efficient", "allow", "real-time", "control", "character", "virtual", "environment", "specifically", "computational", "cost", "increase", "only", "linearly", "number", "frame", "complexity", "articulate", "body", "structure", "interaction", "mesh", "useful", "synthesize", "motion", "film", "computer", "game", "digital", "mannequin", "system", "we", "demonstrate", "its", "usefulness", "character", "animation", "retargeting", "capture", "human", "motion", "character", "very", "different", "proportion", "volume", "monkey", "also", "editing", "motion", "multiple", "character", "while", "preserve", "original", "context", "scene", "contribution", "we", "introduce", "new", "representation", "call", "interaction", "mesh", "encode", "spatial", "relationship", "between", "closely", "interact", "body", "part", "articulate", "character", "object", "environment", "we", "present", "automatic", "method", "use", "interaction", "mesh", "editing", "retargeting", "motion", "close", "interaction", "synthesize", "motion", "preserve", "spatial", "relationship", "thus", "scene", "semantics", "while", "reduce", "number", "inappropriate", "interpenetration", "most", "exist", "motion", "synthesis", "method", "use", "kinematic", "constraint", "positional", "constraint", "enforce", "spatial", "relationship", "between", "character", "environment", "few", "more", "recent", "work", "character", "animation", "consider", "implicit", "spatial", "relationship", "constraint-based", "motion", "synthesis", "since", "kinematic", "constraint", "can", "usually", "represent", "single", "equation", "can", "easily", "embed", "optimization", "problem", "motion", "synthesis", "approach", "have", "be", "adopt", "physically-based", "animation", "-lsb-", "Popovi", "Witkin", "1999", "Komura", "et", "al.", "2000", "Liu", "Popovi", "??", "2002", "Fang", "Pollard", "2003", "-rsb-", "motion", "editing", "-lsb-", "Gleicher", "1997", "Callennec", "boulic", "2004", "Komura", "et", "al.", "2004", "Liu", "et", "al.", "2006", "Shum", "et", "al.", "2009", "-rsb-", "motion", "retargeting", "-lsb-", "gleicher", "1998", "Lee", "Shin", "1999", "Choi", "Ko", "2000", "-rsb-", "one", "early", "work", "gleicher", "-lsb-", "1998", "-rsb-", "handle", "close", "interaction", "multiple", "character", "he", "retarget", "close", "dancing", "motion", "two", "character", "body", "different", "size", "while", "keep", "hand", "connect", "use", "positional", "constraint", "other", "method", "avoid", "penetration", "interact", "body", "part", "use", "inequality", "constraint", "-lsb-", "Liu", "et", "al.", "2006", "-rsb-", "combination", "collision", "detection", "equality", "constraint", "-lsb-", "Xu", "et", "al.", "2007", "Shi", "et", "al.", "2007", "-rsb-", "method", "produce", "excellent", "result", "interaction", "contact", "however", "applicable", "maintain", "spatial", "relationship", "less", "explicit", "because", "represent", "they", "single", "equation", "difficult", "example", "Lambada", "dance", "dancer", "twist", "body", "around", "each", "other", "without", "necessarily", "any", "body", "contact", "handle", "motion", "where", "interaction", "condition", "largely", "implicit", "difficult", "since", "context", "scene", "must", "preserve", "while", "avoid", "penetration", "collision", "without", "good", "representation", "implicit", "spatial", "relationship", "motion", "synthesis", "require", "complex", "global", "path", "planner", "involve", "significant", "collision", "detection", "effort", "randomize", "exploration", "-lsb-", "LaValle", "Kuffner", "2001", "Yamane", "et", "al.", "2004", "Shapiro", "et", "al.", "2007", "-rsb-", "which", "difficult", "large", "number", "degree", "freedom", "character", "animation", "spatial", "relationship", "have", "be", "few", "recent", "work", "which", "take", "account", "implicit", "spatial", "relationship", "multiple", "character", "when", "synthesize", "new", "animation", "Kwon", "et", "al.", "-lsb-", "2008", "-rsb-", "handle", "spatial", "relationship", "between", "character", "group", "motion", "encode", "neighborhood", "formation", "individual", "trajectory", "laplacian", "coordinate", "when", "editing", "trajectory", "relative", "spatial", "arrangement", "character", "preserve", "apply", "laplacian", "mesh", "editing", "technique", "-lsb-", "Alexa", "2003", "Sorkine", "et", "al.", "2004", "-rsb-", "we", "method", "similar", "we", "also", "employ", "laplacian", "mesh", "editing", "technique", "we", "address", "very", "different", "problem", "individual", "character", "case", "2d", "particle", "close", "interaction", "contrast", "we", "method", "aim", "preserve", "spatial", "relationship", "between", "body", "3d", "articulate", "character", "which", "require", "consider", "connection", "joint", "rigidity", "body", "component", "penetration", "between", "they", "Ho", "Komura", "-lsb-", "2009b", "-rsb-", "use", "Gauss", "Linking", "Integral", "detect", "tangled", "limb", "encode", "they", "use", "rational", "tangle", "motion", "retrieval", "later", "propose", "new", "representation", "call", "topology", "coordinate", "represent", "tangled", "body", "part", "-lsb-", "Ho", "Komura", "2009a", "-rsb-", "apply", "synthesize", "character", "motion", "close", "contact", "method", "adequate", "handle", "motion", "involve", "tangle", "between", "1d", "manifold", "strand", "skeleton", "however", "extension", "motion", "involve", "character", "shape", "seem", "difficult", "since", "relationship", "between", "rigid", "body", "surface", "need", "encode", "further", "method", "can", "handle", "close", "interaction", "without", "any", "tangle", "propose", "method", "consider", "relationship", "among", "rigid", "body", "part", "more", "general", "since", "can", "handle", "motion", "close", "interaction", "with/without", "tangle", "recent", "work", "Zhou", "et", "al.", "-lsb-", "2010", "-rsb-", "deformation", "transfer", "represent", "spatial", "relationship", "between", "multiple", "component", "object", "euclidean", "distance", "encode", "they", "use", "minimum", "span", "tree", "since", "spatial", "relationship", "assume", "fix", "-lrb-", "same", "rest", "pose", "-rrb-", "during", "deformation", "method", "applicable", "motion", "time-varying", "spatial", "relationship" ],
  "content" : "Close interactions, not necessarily with any contacts, between different body parts of single or multiple characters or with the environment are common in computer animation and 3D computer games. Yoga, wrestling, dancing and moving through a constrained environment are some examples. In such motions, the spatial relationships between different body parts of characters are important in capturing the semantics of the scene. When an animator synthesizes or edits such movements, special care is needed to preserve these spatial relationships, for example, ?arching back to avoid a punch?, ?hands extending around each other?, ?two bodies moving synchronously in close proximity? or ?getting into a small car by bending down?. However, traditionally, such spatial relationships exist only in the animator?s mind and are not digitally embedded into the data. Although humans use spatial relationships to recognize semantics of interactions, their usage has not been considered much in character animation. Existing scene representations have a fundamental limitation in handling such close interactions. Currently, a motion is typically described in terms of joint angles and kinematic constraints such as contacts. With this representation, automatically computing a valid motion requires randomized exploration and significant computation for collision detection. The animator also needs to shoulder the burden of specifying all the kinematic constraints in advance. From the animator?s perspective, this is impractical and not conductive to manual editing. Competitive automatic solutions require an effective representation that allows the extraction of spatial relationships from existing motion data and synthesis of new animations that preserve these relationships. Such a representation will not only allow quantitative evaluation of the way different body parts are interacting, but also facilitate qualitative characterization of scene semantics. In this paper, we propose a simple representation which we call the interaction mesh to represent the spatial relationships between nearby body parts. The interaction mesh is a volumetric mesh defined by the joints of the characters and the vertices of the objects/environment with which the characters are interacting. When editing or retargeting the movements, the motions are automatically adapted by deforming the interaction meshes at all frames with efficient Laplacian deformation techniques [Alexa 2003; Zhou et al. 2005]. The high-level semantics of the interactions are maintained through preserving the local details of the interaction meshes. The interaction mesh representation is general. It provides a unified treatment for interacting body parts of single or multiple characters as well as objects in the environment. As a result, it is applicable to many types of scenarios, such as when single character?s actions involve close interactions between different body parts (dancing) or multi-character interactions (wrestling, fighting games). Additionally, the motions may either involve much tangling and contacts (e.g. judo, Fig. 1 ) or little contact (e.g. Lambada dance). Additionally, it can be applied either per-frame or in the space-time domain according to the complexity of the problem and the available computing resources. Motion adaptation with the interaction mesh is fully automatic. When the animator changes the size or morphology of the characters or edits parts of the motion, the system automatically deforms the interaction meshes at all the frames using a spacetime optimization and creates a new motion sequence that preserves the original context of the scene. No constraints need to be specified by the animator since they are all encoded in the interaction meshes. If desired, the user may add extra constraints such as anchoring the bodies at the feet. The approach is efficient, allowing real-time control of characters in virtual environments. Specifically, the computational cost increases only linearly in the number of frames and the complexity of the articulated body structures. The interaction mesh is useful for synthesizing motions for films, computer games and digital mannequin systems. We demonstrate its usefulness in character animation by retargeting captured human motions to characters of very different proportions and volumes, such as a monkey and also by editing the motions of multiple characters while preserving the original context of the scene. Contributions We introduce a new representation called the interaction mesh for encoding the spatial relationships between closely interacting body parts of articulated characters and objects in environment. We then present an automatic method that uses the interaction mesh for editing or retargeting motions with close interactions. The synthesized motions preserve the spatial relationships, and thus the scene semantics, while reducing the number of inappropriate interpenetrations. Most existing motion synthesis methods use kinematic constraints such as positional constraints to enforce a spatial relationship between characters and the environment. A few more recent works on character animation consider implicit spatial relationships. Constraint-based motion synthesis Since kinematic constraints can usually be represented by single equations, they can be easily embedded into optimization problems for motion synthesis. Such an approach has been adopted for physically-based animation [Popovi? and Witkin 1999; Komura et al. 2000; Liu and Popovi?? 2002; Fang and Pollard 2003], motion editing [Gleicher 1997; Callennec and Boulic 2004; Komura et al. 2004; Liu et al. 2006; Shum et al. 2009] and motion retargeting [Gleicher 1998; Lee and Shin 1999; Choi and Ko 2000]. One of the early works by Gleicher [1998] handles close interactions of multiple characters. He retargets close dancing motions of two characters to bodies of different sizes while keeping their hands connected using positional constraints. Other methods avoid penetrations of interacting body parts by using inequality constraints [Liu et al. 2006] or a combination of collision detections and equality constraints [Xu et al. 2007; Shi et al. 2007]. These methods produce excellent results for interactions with contacts, however, they are not applicable for maintaining spatial relationships that are less explicit, because representing them as single equations is difficult. For example, in Lambada dances, the dancers twist their bodies around each other without necessarily any body contact. Handling such motions where the interaction conditions are largely implicit is difficult since the context of the scene must be preserved while avoiding penetrations and collisions. Without a good representation of such implicit spatial relationships, the motion synthesis requires complex global path planners involving significant collision detection effort and randomized exploration [LaValle and Kuffner 2001; Yamane et al. 2004; Shapiro et al. 2007], which is difficult for large numbers of degrees of freedom. Character animation by spatial relationships There have been a few recent works which take into account the implicit spatial relationships of multiple characters when synthesizing new animations. Kwon et al. [2008] handle the spatial relationships between characters in group motions by encoding the neighborhood formations and individual trajectories as Laplacian coordinates. When editing the trajectories, the relative spatial arrangements of characters are preserved by applying Laplacian mesh editing techniques [Alexa 2003; Sorkine et al. 2004]. Our method is similar in that we also employ Laplacian mesh editing technique, but we are addressing a very different problem. The individual characters in their case are 2D particles with no close interactions. In contrast, our method aims to preserve the spatial relationships between the bodies of 3D articulated characters, which requires considering the connections at the joints, rigidity of the body components and penetrations between them. Ho and Komura [2009b] use Gauss Linking Integral to detect tangled limbs and encode them using rational tangles for motion retrieval. They later proposed a new representation called topology coordinates for representing tangled body parts [Ho and Komura 2009a] and applied it to synthesize character motions in close contact. These methods are adequate for handling motions involving tangles between 1D manifolds such as strands or skeletons. However, extension to motions involving character shapes seems difficult since relationships between rigid bodies or surfaces need to be encoded. Further, these methods cannot handle close interactions without any tangles. The proposed method considers the relationships among rigid body parts and is more general since it can handle motions of close interactions with/without tangles. A recent work by Zhou et al. [2010] for deformation transfer represents the spatial relationships between multiple components of an object by Euclidean distance and encode them using a minimum spanning tree. Since the spatial relationships are assumed to be fixed (same as rest pose) during deformation, the method is not applicable to motions with time-varying spatial relationships.",
  "resources" : [ ]
}