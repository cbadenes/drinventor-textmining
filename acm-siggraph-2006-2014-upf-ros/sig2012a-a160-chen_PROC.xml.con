{
  "uri" : "sig2012a-a160-chen_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2012a/a160-chen_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Depth-Presorted Triangle Lists",
    "published" : "2012",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Ge-Chen",
      "name" : "Ge",
      "surname" : "Chen"
    }, {
      "uri" : "http://drinventor/Pedro V.-Sander",
      "name" : "Pedro V.",
      "surname" : "Sander"
    }, {
      "uri" : "http://drinventor/Diego-Nehab",
      "name" : "Diego",
      "surname" : "Nehab"
    }, {
      "uri" : "http://drinventor/Lei-Yang",
      "name" : "Lei",
      "surname" : "Yang"
    }, {
      "uri" : "http://drinventor/Liang-Hu",
      "name" : "Liang",
      "surname" : "Hu"
    } ]
  },
  "bagOfWords" : [ "section", "we", "discuss", "performance", "memory", "consumption", "we", "approach", "all", "experiment", "be", "conduct", "Intel", "xeon", "2.27", "GHz", "E5520", "CPU", "12gb", "RAM", "AMD", "Radeon", "HD", "6970", "GPU", "we", "use", "model", "resolution", "range", "from", "1,000", "100,000", "triangle", "which", "we", "believe", "representative", "resolution", "depth", "complexity", "most", "static", "model", "find", "game", "all", "rendering", "use", "alpha", "blend", "proper", "semitransparency", "when", "render", "back-to-front", "figure", "runtime", "performance", "result", "figure", "average", "over", "256", "viewpoint", "around", "model", "report", "ratio", "relative", "baseline", "standard", "rendering", "measure", "directly", "clock", "tick", "baseline", "render", "all", "input", "triangle", "order", "optimize", "vertex-cache", "locality", "-lrb-", "completely", "disregard", "depth-sorting", "-rrb-", "example", "render", "depth-sorted", "model", "we", "method", "twice", "expensive", "baseline", "rendering", "we", "report", "performance", "ratio", "two", "segment", "partitioning", "figure", "show", "effect", "increase", "number", "viewpoint", "partition", "average", "number", "triangle", "per", "segment", "-lrb-", "i.e", "actually", "process", "draw-call", "run-time", "-rrb-", "well", "total", "memory", "consumption", "average", "draw", "call", "size", "report", "ratio", "number", "triangle", "input", "triangle", "list", "total", "memory", "ratio", "report", "ratio", "total", "memory", "use", "standard", "triangle", "list", "duplicated", "triangle", "calculation", "assume", "each", "vertex", "contain", "position", "normal", "texture", "coordinate", "note", "although", "increase", "number", "partition", "increase", "memory", "consumption", "reduce", "average", "segment", "size", "important", "note", "total", "memory", "increase", "only", "happen", "transparent", "part", "model", "have", "any", "transparency", "effect", "all", "furthermore", "vast", "majority", "memory", "modern", "game", "consume", "texture", "geometry", "lagging", "far", "behind", "we", "find", "use", "viewpoint", "partition", "provide", "reasonable", "trade-off", "model", "we", "test", "amount", "memory", "use", "significantly", "higher", "than", "partition", "marked", "decrease", "average", "segment", "size", "translate", "performance", "gain", "render", "time", "remainder", "experiment", "section", "we", "use", "viewpoint", "partition", "preprocess", "Figure", "show", "preprocessing", "time", "we", "method", "depend", "model", "number", "triangle", "can", "take", "anywhere", "between", "few", "minute", "several", "hour", "complete", "computation", "different", "segment", "parallelize", "use", "multiple", "CPU", "core", "while", "preprocessing", "algorithm", "can", "slow", "large", "input", "important", "point", "out", "only", "need", "execute", "once", "each", "static", "model", "further", "optimization", "could", "improve", "preprocessing", "time", "we", "instead", "concentrate", "we", "effort", "optimize", "better", "run-time", "result", "which", "ultimate", "goal", "render", "approach", "figure", "compare", "performance", "three", "version", "we", "run-time", "selection", "procedure", "each", "use", "different", "stage", "pipeline", "geometry", "shader", "option", "significantly", "slower", "due", "fact", "add", "new", "shade", "stage", "render", "pipeline", "therefore", "we", "only", "see", "option", "be", "viable", "when", "rendering", "effect", "already", "require", "geometry", "shader", "which", "case", "would", "require", "simply", "add", "plane", "test", "exist", "shader", "vertex", "shader", "fragment", "shader", "version", "significantly", "faster", "very", "low-resolution", "model", "rendering", "fill-bound", "make", "fragment", "shader", "option", "more", "costly", "mediumand", "high-resolution", "model", "however", "vertex", "processing", "overhead", "vertex", "shader", "approach", "dominate", "thus", "most", "practical", "model", "size", "fragment", "shader", "option", "most", "efficient", "we", "algorithm", "be", "only", "slower", "than", "baseline", "overall", "performance", "we", "compare", "overall", "performance", "we", "fragment", "shader", "algorithm", "selection", "state-of-theart", "real-time", "depth-sorting", "algorithm", "per-pixel", "dynamic", "link", "list", "-lrb-", "ll", "-rrb-", "-lsb-", "Yang", "et", "al.", "2010", "-rsb-", "stochastic", "transparency", "-lrb-", "st", "-rrb-", "-lsb-", "Enderton", "et", "al.", "2010", "-rsb-", "dual", "depth", "peeling", "-lrb-", "ddp", "-rrb-", "-lsb-", "Bavoil", "Myers", "2008", "-rsb-", "st", "approximate", "algorithm", "while", "ddp", "ll", "produce", "exact", "result", "-lrb-", "ddp", "use", "occlusion", "query", "ensure", "further", "pass", "require", "ll", "use", "sophisticated", "sorting", "operation", "available", "legacy", "hardware", "-rrb-", "test", "be", "run", "each", "we", "model", "640", "480", "-lrb-", "figure", "-rrb-", "1280", "720", "-lrb-", "figure", "-rrb-", "screen", "resolution", "demonstrate", "different", "trade-off", "involve", "we", "algorithm", "significantly", "faster", "than", "alternative", "particularly", "high", "screen", "resolution", "conversely", "advantage", "we", "method", "even", "higher", "smaller", "model", "because", "relative", "overhead", "increase", "pixel", "count", "negligible", "we", "method", "contrast", "effect", "increase", "input", "triangle", "count", "nevertheless", "even", "low", "screen", "resolution", "larger", "model", "we", "method", "significantly", "faster", "than", "alternative", "we", "method", "become", "slower", "than", "alternative", "would", "require", "combination", "enormous", "amount", "geometry", "either", "small", "screen", "coverage", "-lrb-", "pixel", "base", "approach", "-rrb-", "very", "small", "maximum", "depth-complexity", "-lrb-", "depth-peeling", "approach", "-rrb-", "since", "gpus", "heavily", "optimize", "batch", "processing", "few", "large", "index", "buffer", "we", "simpler", "singlepass", "method", "faster", "practical", "scenario", "even", "up", "several", "million", "transparent", "triangle", "complex", "scene", "we", "test", "we", "approach", "complex", "room", "scene", "-lrb-", "figure", "10", "-rrb-", "consist", "physical", "simulation", "multiple", "semi-transparent", "dragon", "interact", "collide", "one", "another", "we", "use", "screen", "resolution", "1280", "720", "4x-msaa", "refer", "accompany", "video", "entire", "animation", "sequence", "intermodel", "depth-sorting", "perform", "CPU", "use", "model", "convex", "bound", "volume", "which", "also", "use", "collision", "detection", "trivial", "fast", "small", "number", "object", "since", "convex", "bound", "volume", "allow", "inter-penetrate", "sorting", "result", "guarantee", "correct", "standard", "rendering", "-lrb-", "figure", "10a", "-rrb-", "do", "render", "triangle", "each", "model", "depth", "sort", "order", "therefore", "yield", "incorrect", "transparency", "effect", "example", "rear", "left", "foot", "dragon", "show", "closeup", "appear", "very", "prominently", "even", "though", "behind", "body", "expect", "we", "method", "-lrb-", "figure", "10b", "-rrb-", "ll", "st", "ddp", "generate", "correct", "result", "we", "measure", "render", "time", "entire", "scene", "vary", "number", "dragon", "-lrb-", "figure", "10c", "-rrb-", "result", "scene", "geometric", "complexity", "40,000", "2,000,000", "triangle", "-lrb-", "50", "dragon", "-rrb-", "clearly", "performance", "inversely", "proportional", "number", "dragon", "scene", "we", "method", "significantly", "faster", "compare", "other", "approach", "furthermore", "we", "method", "ddp", "produce", "exact", "result", "which", "case", "st", "ll", "msaa", "Game", "scene", "show", "we", "method", "also", "apply", "more", "typical", "game", "scene", "-lrb-", "figure", "11", "-rrb-", "we", "create", "another", "experiment", "include", "animation", "sequence", "which", "character", "move", "around", "game", "scene", "multiple", "solid", "object", "semi-transparent", "model", "refer", "accompany", "video", "entire", "animation", "sequence", "get", "sense", "performance", "implication", "we", "approach", "scenario", "we", "vary", "resolution", "we", "semi-transparent", "model", "order", "present", "we", "performance", "result", "function", "percentage", "scene", "primitive", "semi-transparent", "so", "instance", "approximately", "15", "game?s", "primitive", "semitransparent", "slowdown", "have", "triangle", "sort", "order", "just", "about", "1.1", "other", "hand", "more", "extreme", "scenario", "where", "semi-transparent", "object", "dominate", "have", "50", "primitive", "count", "slowdown", "more", "significant", "1.5", "we", "present", "new", "algorithm", "efficient", "exact", "depth-sorted", "rendering", "static", "triangle", "model", "we", "method", "produce", "depthpresorted", "triangle", "list", "which", "each", "triangle", "annotated", "test", "plane", "list", "can", "render", "depth-sorted", "order", "use", "single", "draw", "call", "give", "viewpoint", "simple", "run-time", "culling", "procedure", "execute", "GPU", "rasterize", "subsequence", "triangle", "produce", "depth-sorted", "rendering", "model", "relative", "viewpoint", "we", "show", "approach", "significantly", "faster", "than", "alternative", "method", "main", "limitation", "we", "method", "-lrb-", "-rrb-", "standard", "rendering", "-lrb-", "-rrb-", "we", "result", "-lrb-", "-rrb-", "rendering", "we", "approach", "only", "suitable", "static", "model", "viewpoint", "outside", "bound", "polyhedron", "however", "we", "feel", "exist", "wide", "range", "application", "which", "limitation", "do", "matter", "finally", "we", "believe", "novel", "selection", "base", "scheme", "use", "single", "draw", "call", "significant", "departure", "from", "exist", "method", "most", "which", "require", "either", "sort", "multipass", "rendering", "we", "believe", "direction", "worth", "further", "investigation", "particularly", "way", "handle", "deformable", "model", "would", "interesting", "consider", "generate", "set", "order", "conjunction", "allow", "limited", "range", "deformation", "run-time", "alternatively", "we", "finegrain", "triangle-level", "technique", "can", "combine", "coarse-level", "dynamic", "sort", "enable", "animated", "character", "rigid", "part" ],
  "content" : "In this section we discuss the performance and memory consumption of our approach. All experiments were conducted on an Intel R Xeon R 2.27GHz E5520 CPU with 12GB of RAM and an AMD Radeon HD 6970 GPU. We used models with resolutions ranging from 1,000 to 100,000 triangles, which we believe are representative of the resolution and depth complexity of most static models found in games. All renderings used alpha blending for proper semitransparency when rendering back-to-front as in figure 1 . The runtime performance results in figures 7, 8, and 9 are averaged over 256 viewpoints around the model and reported as ratios relative to a baseline standard rendering, measured directly in clock ticks. The baseline renders all input triangles in a order optimized for vertex-cache locality (completely disregarding depth-sorting). For example, if rendering a depth-sorted model with our method is twice as expensive as the baseline rendering, we report the performance ratio of two. Segment partitioning Figure 5 shows the effect of increasing the number of viewpoint partitions on the average number of triangles per segment (i.e, that are actually processed by the draw-call at run-time), as well as on the total memory consumption. The average draw call size is reported as a ratio to the number of triangles in the input triangle list. The total memory ratio is reported as a ratio to the total memory used by a standard triangle list with no duplicated triangles. The calculation assumes that each vertex contains a position, normal, and texture coordinates. Note that although increasing the number of partitions increases memory consumption, it reduces the average segment size. It is important to note that the total memory increase only happens for the transparent parts of models that have any transparency effect at all. Furthermore, the vast majority of memory in modern games is consumed by textures, with geometry lagging far behind. We found that using 6 viewpoint partitions provides a reasonable trade-off for the models we tested. The amount of memory used is not significantly higher than that of 4 partitions, but there is a marked decrease in average segment size. This translates to performance gains at rendering time. For the remainder of the experiments in this section we used 6 viewpoint partitions. Preprocessing Figure 6 shows the preprocessing time of our method. Depending on model and number of triangles, it can take anywhere between a few minutes to several hours to complete. The computation of different segments was parallelized using multiple CPU cores. While the preprocessing algorithm can be slow on large input, it is important to point out that it only needs to be executed once for each static model. Further optimizations could improve the preprocessing time, but we instead concentrated our efforts on optimizing for better run-time results, which is the ultimate goal. Rendering approaches Figure 7 compares performance of the three versions of our run-time selection procedure, each using a different stage of the pipeline. The geometry shader option is significantly slower due to the fact that it adds a new shading stage to the rendering pipeline. Therefore, we only see this option being viable when the rendering effect already requires a geometry shader, in which case it would require simply adding the plane test to an existing shader. The vertex shader and fragment shader versions are significantly faster. For very low-resolution models, the rendering is fill-bound, making the fragment shader option more costly. For mediumand high-resolution models, however, the vertex processing overhead of the vertex shader approach dominates. Thus, for most practical model sizes, the fragment shader option is the most efficient, with our algorithm being only 2?3? slower than baseline. Overall performance We compared the overall performance of our fragment shader algorithm with a selection of state-of-theart real-time depth-sorting algorithms: per-pixel dynamic linked lists (LL) [Yang et al. 2010], stochastic transparency (ST) [Enderton et al. 2010], and dual depth peeling (DDP) [Bavoil and Myers 2008]. ST is an approximate algorithm, while DDP and LL produce exact results. (DDP uses occlusion queries to ensure that no further passes are required and LL uses a sophisticated sorting operation that is not available in legacy hardware.) Tests were run for each of our models at 640?480 ( figure 8 ) and 1280?720 ( figure 9 ) screen resolutions to demonstrate the different trade-offs involved. Our algorithm is significantly faster than the alternatives, particularly at high screen resolutions. Conversely, the advantage of our method is even higher for smaller models. This is because the relative overhead of increasing pixel count is negligible in our method, in contrast to the effect of increasing input triangle count. Nevertheless, even at low screen resolutions and with larger models, our method is significantly faster than the alternatives. For our method to become slower than the alternatives, it would require the combination of an enormous amount of geometry with either small screen coverage (for pixel based approaches) or very small maximum depth-complexity (for depth-peeling approaches). Since GPUs are heavily optimized for batch processing with few large index buffers, our simpler, singlepass method is faster for practical scenarios of even up to several million of transparent triangles. Complex scene We tested our approach on a complex Room scene ( figure 10 ) consisting of a physical simulation with multiple semi-transparent dragons interacting and colliding with one another. We used a screen resolution of 1280?720 and 4X-MSAA. Refer to the accompanying video for the entire animation sequence. Intermodel depth-sorting was performed in the CPU using the models? convex bounding volumes, which are also used for collision detection. This is trivial and fast for a small number of objects. Since the convex bounding volumes are not allowed to inter-penetrate, the sorting results are guaranteed to be correct. Standard rendering ( figure 10a ) does not render the triangles of each model in depth sorted order and therefore yields an incorrect transparency effect. For example, the rear left foot of the dragon shown in the closeup appears very prominently even though it is behind the body. As expected, our method ( figure 10b ), LL, ST, and DDP generate correct results. We measured rendering time of the entire scene for a varying number of dragons ( figure 10c ), resulting in a scene geometric complexity of 40,000 to 2,000,000 triangles (1 to 50 dragons). Clearly, the performance is inversely proportional to the number of dragons in the scene and our method is significantly faster compared to other approaches. Furthermore, our method and DDP produce exact results, which is not the case for ST and LL with MSAA. Game scene To show that our method also applies to a more typical Game scene ( figure 11 ), we created another experiment including an animation sequence in which a character moves around a game scene with multiple solid objects and a semi-transparent model. Refer to the accompanying video for the entire animation sequence. To get a sense of the performance implications of our approach on these scenarios, we varied the resolution of our semi-transparent model in order to present our performance results as a function of the percentage of scene primitives that are semi-transparent. So, for instance, if approximately 15% of the game?s primitives are semitransparent, the slowdown for having the triangles in sorted order is just about 1.1?. On the other hand, in a more extreme scenario where the semi-transparent objects start to dominate by having 50% of the primitive count, the slowdown is a more significant 1.5?. We presented a new algorithm for efficient, exact, depth-sorted rendering of static triangle models. Our method produces a depthpresorted triangle list in which each triangle is annotated by test planes. These lists can be rendered in depth-sorted order using a single draw call. Given a viewpoint, a simple run-time culling procedure executed by the GPU rasterizes a subsequence of the triangles that produce a depth-sorted rendering of the model relative to that viewpoint. We show that this approach is significantly faster than the alternative methods. The main limitations of our method is (a) Standard rendering\n        (b) Our result (a) Renderings with our approach that it is only suitable for static models, and for viewpoints outside of a bounding polyhedron. However, we feel that there exists a wide range of applications for which these limitations do not matter. Finally, we believe that this novel selection based scheme using a single draw call is a significant departure from existing methods, most of which require either sorting or multipass rendering. We believe that this direction is worth further investigation, particularly on ways to handle deformable models. It would be interesting to consider generating a set of orders that, in conjunction, allow for a limited range of deformation at run-time. Alternatively, our finegrained triangle-level technique can be combined with coarse-level dynamic sorting to enable animated characters with rigid parts.",
  "resources" : [ ]
}