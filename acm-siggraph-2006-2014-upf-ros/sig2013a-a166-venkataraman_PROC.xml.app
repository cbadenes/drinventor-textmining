{
  "uri" : "sig2013a-a166-venkataraman_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2013a/a166-venkataraman_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "PiCam: An Ultra-Thin High Performance Monolithic Camera Array",
    "published" : "2013",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Kartik-Venkataraman",
      "name" : "Kartik",
      "surname" : "Venkataraman"
    }, {
      "uri" : "http://drinventor/Dan-Lelescu",
      "name" : "Dan",
      "surname" : "Lelescu"
    }, {
      "uri" : "http://drinventor/Jacques-Duparr?",
      "name" : "Jacques",
      "surname" : "Duparr?"
    }, {
      "uri" : "http://drinventor/Andrew-McMahon",
      "name" : "Andrew",
      "surname" : "McMahon"
    }, {
      "uri" : "http://drinventor/Gabriel-Molina",
      "name" : "Gabriel",
      "surname" : "Molina"
    }, {
      "uri" : "http://drinventor/Priyam-Chatterjee",
      "name" : "Priyam",
      "surname" : "Chatterjee"
    }, {
      "uri" : "http://drinventor/Robert-Mullis",
      "name" : "Robert",
      "surname" : "Mullis"
    }, {
      "uri" : "http://drinventor/Shree-Nayar",
      "name" : "Shree",
      "surname" : "Nayar"
    } ]
  },
  "bagOfWords" : [ "we", "present", "PiCam", "-lrb-", "Pelican", "Imaging", "Camera-Array", "-rrb-", "ultra-thin", "high", "performance", "monolithic", "camera", "array", "capture", "light", "field", "synthesize", "high", "resolution", "image", "along", "range", "image", "-lrb-", "scene", "depth", "-rrb-", "through", "integrate", "parallax", "detection", "superresolution", "camera", "passive", "support", "both", "still", "video", "low", "light", "capable", "small", "enough", "include", "next", "generation", "mobile", "device", "include", "smartphone", "prior", "work", "-lsb-", "Rander", "et", "al.", "1997", "Yang", "et", "al.", "2002", "Zhang", "Chen", "2004", "Tanida", "et", "al.", "2001", "Tanida", "et", "al.", "2003", "Duparr", "et", "al.", "2004", "-rsb-", "camera", "array", "have", "explore", "multiple", "facet", "light", "field", "capture", "from", "viewpoint", "synthesis", "synthetic", "refocus", "compute", "range", "image", "high", "speed", "video", "micro-optical", "aspect", "system", "miniaturization", "however", "none", "have", "address", "modification", "need", "achieve", "strict", "form", "factor", "image", "quality", "require", "make", "array", "camera", "practical", "mobile", "device", "we", "approach", "we", "customize", "many", "aspect", "camera", "array", "include", "lens", "pixel", "sensor", "software", "algorithm", "achieve", "imaging", "performance", "form", "factor", "comparable", "exist", "mobile", "phone", "camera", "registration", "uncertainty", "from", "parallax", "detection", "process", "integrate", "Maximum-a-Posteriori", "formulation", "synthesize", "estimate", "high", "resolution", "image", "scene", "depth", "we", "conclude", "some", "example", "we", "array", "capability", "postcapture", "-lrb-", "still", "-rrb-", "refocus", "video", "refocus", "view", "synthesis", "demonstrate", "motion", "parallax", "3d", "range", "image", "briefly", "address", "future", "work", "keyword", "plenoptic", "acquisition", "computational", "camera", "light", "field", "array", "camera", "parallax", "detection", "superresolution", "depth", "map", "fundamental", "problem", "design", "camera", "mobile", "device", "smartphone", "tablet", "industrial", "design", "constraint", "have", "meet", "any", "give", "xy", "sensor", "format", "corresponding", "optical", "format", "which", "through", "standard", "optical", "design", "constraint", "define", "lower", "limit", "camera", "module", "z-height", "automatically", "key", "industrial", "design", "constraint", "we", "describe", "approach", "solve", "form", "factor", "problem", "replace", "single", "aperture", "camera", "number", "smaller", "aperture", "-lrb-", "lens", "array", "-rrb-", "largely", "overlap", "field", "view", "smaller", "optical", "format", "-lrb-", "aperture", "-rrb-", "focal", "length", "therefore", "camera", "module", "z-height", "correspondingly", "reduce", "sensor", "array", "together", "lens", "array", "package", "form", "integrate", "camera", "array", "thin", "form", "factor", "Venkataraman", "K.", "Lelescu", "D.", "Duparr", "??", "J.", "McMahon", "a.", "Molina", "G.", "Chatterjee", "P.", "Mullis", "R.", "Nayar", "S.", "2013", "PiCam", "ultra-thin", "high", "Performance", "Monolithic", "Camera", "Array", "ACM", "Trans", "32", "Article", "166", "-lrb-", "November", "2013", "-rrb-", "13", "page", "dous", "10.1145", "2508363.2508390", "http://doi.acm.org/10.1145/2508363.2508390", "however", "we", "approach", "unique", "we", "first", "envision", "array", "camera", "single", "monolithic", "sensor", "substrate", "corresponding", "integrated", "lens", "array", "target", "equivalent", "multiple-megapixel", "camera", "here", "each", "sensor", "capable", "be", "independently", "control", "respect", "gain", "exposure", "trigger", "time", "addition", "relatively", "narrow", "spectral", "sensitivity", "each", "camera", "-lrb-", "example", "blue", "400nm", "500nm", "green", "470nm", "600nm", "red", "570nm", "700nm", "-rrb-", "relax", "optical", "design", "constraint", "imaging", "software", "pipeline", "synthesize", "high", "resolution", "color", "image", "take", "integrated", "approach", "parallax", "detection/correction", "superresolution", "introduce", "new", "element", "image", "restoration", "process", "while", "adapt", "imaging", "condition", "independent", "control", "each", "camera", "array", "provide", "new", "flexibility", "deliver", "versatile", "solution", "combination", "depth", "could", "enable", "suite", "application", "result", "from", "select", "set", "application", "refocus", "point", "cloud", "generation", "present", "section", "very", "first", "vision", "array", "camera", "Lippmann", "-lsb-", "1908", "-rsb-", "where", "he", "combine", "lenticular", "array", "photographic", "film", "order", "capture", "reproduce", "stereoscopic", "imaging", "more", "recent", "effort", "array", "camera", "result", "from", "need", "perform", "still", "video", "view", "synthesis", "-lsb-", "levoy", "Hanrahan", "1996", "Taylor", "1996", "-rsb-", "Levoy", "et", "al.", "provide", "system", "rotate", "camera", "gantry", "which", "allow", "one", "capture", "single", "static", "scene", "from", "multiple", "perspective", "while", "both", "early", "system", "be", "primarily", "use", "synthesize", "novel", "view", "capture", "scene", "neither", "explore", "synthesis", "image", "be", "any", "way", "enhance", "resolution", "from", "original", "image", "result", "artifact", "during", "view", "synthesis", "none", "approach", "however", "lend", "themselves", "easily", "small", "form", "factor", "design", "ng", "introduce", "lenslet", "array", "focal", "plane", "main", "lens", "position", "sensor", "focal", "plane", "lenslet", "array", "each", "lenslet", "capture", "sub-aperture", "main", "lens", "provide", "depth", "field", "correspondingly", "larger", "than", "produce", "full", "aperture", "lens", "refocusing", "achieve", "summation", "shift", "version", "sub-aperture", "image", "albeit", "considerable", "cost", "overall", "image", "resolution", "allow", "one", "capture", "non-overlapping", "content", "interleave", "pixel", "under", "lenslet", "first", "array", "camera", "develop", "goal", "reduce", "track", "length", "electronic", "imaging", "system", "tomboarchitecture", "-lsb-", "Tanida", "et", "al.", "2001", "Tanida", "et", "al.", "2003", "-rsb-", "here", "single", "aperture", "camera", "divide", "several", "smaller", "more", "less", "identical", "optical", "channel", "optically", "isolate", "from", "one", "another", "however", "neither", "approach", "consider", "integrated", "approach", "parallax", "detection/correction", "superresolution", "choose", "instead", "recover", "resolution", "fix", "depth", "from", "camera", "single", "pixel", "apply", "per", "lens", "many", "small", "lens", "be", "fabricate", "use", "lithographic", "means", "each", "lens", "have", "different", "viewing", "direction", "however", "system", "very", "scalable", "require", "non-economically", "large", "footprint", "order", "achieve", "resolution", "order", "several", "megapixel", "thus", "smaller", "lens", "can", "more", "easily", "approach", "diffraction", "limit", "smaller", "number", "optical", "element", "each", "camera", "picam", "array", "optically", "isolate", "sensitive", "just", "one", "color", "light", "red", "green", "blue", "occlusion", "visibility", "problem", "manifest", "itself", "picam", "when", "capture", "foreground", "object", "against", "background", "object", "satisfy", "spectral", "uniformity", "criterion", "video", "use", "case", "we", "observe", "when", "spectral", "band", "each", "channel", "have", "correct", "substantially", "reduce", "color", "blur", "also", "correspondingly", "reduce", "therefore", "optical", "format", "-lrb-", "f-number", "-rrb-", "take", "together", "psf", "determine", "total", "space-bandwidth", "product", "diffraction", "limited", "optics", "other", "word", "total", "information", "content", "optical", "image", "sensor", "architecture", "picam", "array", "have", "many", "aspect", "need", "consider", "ensure", "optimal", "system", "performance", "term", "overall", "resolution", "optimality", "die", "area", "power", "consumption", "datum", "readout", "flexibility", "camera", "control", "although", "image", "sensor", "we", "use", "much", "like", "typical", "cmo", "image", "sensor", "from", "device", "physics", "circuit", "design", "perspective", "architecture", "device", "carefully", "choose", "maximize", "feature-set", "performance", "camera", "array", "challenge", "array", "camera", "result", "from", "requirement", "superresolution", "should", "able", "recover", "higher", "resolution", "final", "output", "image", "than", "intrinsic", "resolution", "input", "component", "image", "image", "sensor", "pixel", "pitch", "determine", "spatial", "sampling", "rate", "corresponding", "Nyquist", "frequency", "-lrb-", "-rrb-", "simply", "one", "half", "reciprocal", "center-to-center", "pixel", "spacing", "difference", "between", "aliase", "pattern", "different", "camera", "image", "primarily", "due", "array?s", "sampling", "diversity", "result", "from", "different", "viewing", "direction", "which", "either", "intentionally", "introduce", "result", "from", "-lrb-", "positional", "-rrb-", "manufacturing", "tolerance", "main", "task", "microlen", "gather", "all", "light", "incident", "its", "surface", "focus", "light", "onto", "photodiode", "bottom", "most", "layer", "moreover", "show", "Figure", "-lrb-", "-rrb-", "we", "shape", "microlen", "narrower", "result", "reduction", "pixel", "blur", "since", "microlen", "now", "average", "light", "over", "relatively", "smaller", "area", "drastic", "reduction", "one", "main", "reason", "why", "care", "must", "take", "optimize", "pixel", "mtf", "we", "case", "work", "out", "factor", "1140", "2.4", "large", "synthetic", "aperture", "array", "provide", "we", "multiple", "aperture", "therefore", "multiple", "point", "view", "generate", "hr", "image", "one", "could", "generate", "view", "from", "any", "one", "multiple", "viewpoint", "from", "any", "point", "between", "each", "pixel", "-lrb-", "-rrb-", "reference", "camera", "best", "depth", "must", "detect", "depth", "correspond", "lowest", "matching", "cost", "select", "depth", "pixel", "-lrb-", "-rrb-", "additionally", "weighting", "term", "can", "use", "modulate", "influence", "red", "blue", "matching", "score", "relative", "influence", "green", "camera", "clarity", "presentation", "we", "restrict", "we", "discussion", "estimate", "single", "color", "channel", "-lrb-", "specifically", "green", "channel", "-rrb-", "goal", "estimate", "from", "lower-resolution", "observation", "-lcb-", "-rcb-", "-lrb-", "where", "index", "camera", "-rrb-", "give", "knowledge", "we", "imaging", "system", "decimation", "matrix", "reflect", "sampling", "although", "pixel", "blur", "spatially", "invariant", "lens", "blur", "so", "practice", "more", "recently", "bayesian", "approach", "take", "account", "imaging", "system", "characteristic", "have", "be", "apply", "successfully", "superresolve", "light", "field", "image", "Bishop", "Favaro", "-lsb-", "2012", "-rsb-", "may", "include", "spatial", "interpolation", "neighbor", "grid", "position", "-lrb-", "stack", "end", "up", "empty", "-rrb-", "would", "appear", "imply", "order", "warping", "blur", "prior", "decimation", "need", "form", "gradient", "inconsequential", "invert", "blur", "warp", "operation", "case", "map", "image", "correctly", "non-reference", "camera", "viewpoint", "gradient", "would", "consequently", "inaccurate", "specifically", "corresponding", "entry", "-lrb-", "-rrb-", "shift", "matrix", "apply", "-lcb-", "-rcb-", "pixel", "position", "all", "even", "some", "camera", "directly", "link", "stack", "-lcb-", "-rcb-", "follow", "warp", "we", "blur", "decimate", "each", "hr", "warped", "image", "obtain", "estimate", "correspond", "each", "camera", "case", "we", "can", "relate", "LR", "image", "simple", "registration", "model", "commonly", "do", "literature", "-lsb-", "Irani", "Peleg", "1991", "Vandewalle", "et", "al.", "2007", "-rsb-", "approach", "describe", "until", "now", "computationally", "expensive", "-lrb-", "require", "visit", "every", "LR", "camera", "every", "hr", "grid", "position", "-rrb-", "although", "spatial", "localization", "motivate", "from", "we", "need", "obtain", "accurate", "likelihood", "gradient", "estimate", "even", "local", "sparsely", "fuse", "hr", "grid", "we", "could", "certainly", "exploit", "spatial", "stack-neighborhood", "reduce", "uncertainty", "likelihood", "gradient", "estimation", "all", "hr", "grid", "location", "contribute", "now", "filter", "gradient", "position", "-lcb-", "-rcb-", "locallyadaptive", "prior", "we", "introduce", "instead", "have", "form", "however", "although", "do", "paper", "we", "can", "also", "incorporate", "diagonal", "weight", "matrix", "weigh", "norm", "equation", "function", "snr", "thus", "would", "cause", "higher", "relative", "weight", "datum", "fidelity", "term", "high", "snr", "pixel", "while", "low", "snr", "image", "prior", "would", "more", "significant", "until", "now", "we", "have", "restrict", "we", "discussion", "estimate", "single", "color", "channel", "namely", "green", "channel", "key", "challenge", "create", "robust", "imaging", "system", "estimation", "accurate", "depth", "parallax", "stage", "result", "resolution", "depth", "map", "all", "scene", "be", "capture", "same", "time", "picam", "iphone5", "under", "same", "illumination", "condition", "last", "row", "Figure", "14", "show", "example", "image", "be", "refocus", "first", "foreground", "focus", "background", "focus", "author", "wish", "thank", "people", "whose", "hard", "work", "have", "make", "computational", "camera", "array", "possible", "include", "engineering", "team", "lead", "Purnam", "Sheth", "finally", "we", "would", "like", "acknowledge", "support", "encouragement", "Chris", "Pickett" ],
  "content" : "We present PiCam (Pelican Imaging Camera-Array), an ultra-thin high performance monolithic camera array, that captures light fields and synthesizes high resolution images along with a range image (scene depth) through integrated parallax detection and superresolution. The camera is passive, supporting both stills and video, low light capable, and small enough to be included in the next generation of mobile devices including smartphones. Prior works [Rander et al. 1997; Yang et al. 2002; Zhang and Chen 2004; Tanida et al. 2001; Tanida et al. 2003; Duparr? et al. 2004] in camera arrays have explored multiple facets of light field capture from viewpoint synthesis, synthetic refocus, computing range images, high speed video, and micro-optical aspects of system miniaturization. However, none of these have addressed the modifications needed to achieve the strict form factor and image quality required to make array cameras practical for mobile devices. In our approach, we customize many aspects of the camera array including lenses, pixels, sensors, and software algorithms to achieve imaging performance and form factor comparable to existing mobile phone cameras. The registration uncertainty from the parallax detection process is integrated into a Maximum-a-Posteriori formulation that synthesizes an estimate of the high resolution image and scene depth. We conclude with some examples of our array capabilities such as postcapture (still) refocus, video refocus, view synthesis to demonstrate motion parallax, 3D range images, and briefly address future work. Keywords: plenoptic acquisition, computational camera, light field, array camera, parallax detection, superresolution, depth map A fundamental problem in designing cameras for mobile devices such as smartphones and tablets is the industrial design constraints that have to be met. For any given XY sensor format there is a corresponding optical format which, through standard optical design constraints, defines the lower limit of the camera module z-height automatically. This is a key industrial design constraint. We describe an approach to solve the form factor problem by replacing a single aperture in the camera with a number of smaller apertures (lens array) with largely overlapping fields of view. With the smaller optical format (aperture), the focal length and therefore the camera module z-height, are correspondingly reduced. The sensor array together with the lens array are packaged to form an integrated camera array with a thin form factor. Venkataraman, K., Lelescu, D., Duparr??e, J., McMahon, A., Molina, G., Chatterjee, P., Mullis, R., Nayar, S. 2013. PiCam: An Ultra-Thin High Performance Monolithic Camera Array. ACM Trans. 32, 6, Article 166 (November 2013), 13 pages. DOI = 10.1145/2508363.2508390 http://doi.acm.org/10.1145/2508363.2508390. However, our approach is unique in that we are the first to envision an array camera on a single monolithic sensor substrate with a corresponding integrated lens array, that targets the equivalent of multiple-megapixel cameras. Here, each sensor is capable of being independently controlled with respect to gain, exposure, and trigger times. In addition, the relatively narrow spectral sensitivity of each camera (for example: blue=400nm to 500nm, green=470nm to 600nm, or red=570nm to 700nm) relaxes optical design constraints. The imaging software pipeline synthesizes a high resolution color image by taking an integrated approach to parallax detection/correction and superresolution and introducing new elements in the image restoration process, while adapting to imaging conditions. The independent control of each camera in the array provides new flexibility and delivers a versatile solution that in combination with depth could enable a suite of applications. Results from a selected set of these applications, such as refocus, and point cloud generation are presented in Section 5. The very first vision of an array camera was by Lippmann [1908] where he combined a lenticular array with photographic film in order to capture and reproduce stereoscopic imaging. The more recent efforts in array cameras resulted from a need to perform still and video view  synthesis [Levoy and Hanrahan 1996; Taylor 1996]. Levoy et al. provided a system with rotating camera gantry, which allowed one to capture a single static scene from multiple perspectives. While both of these early systems were primarily used to synthesize novel views of the captured scene, neither explored the synthesis of images that were in any way enhanced in resolution from the original images. This resulted in artifacts during view synthesis. None of these approaches, however, lend themselves easily to small form factor designs. Ng introduced a lenslet array at the focal plane of the main lens and positioned the sensor at the focal plane of the lenslet array. Each lenslet captures a sub-aperture of the main lens and provides a depth of field that is correspondingly larger than that produced by the full aperture of the lens. Refocusing is achieved by a summation of the shifted versions of the sub-aperture images albeit at a considerable cost to overall image resolution. This allows one to capture non-overlapping content interleaved in the pixels under the lenslets. The first array camera that was developed with the goal to reduce the track length of an electronic imaging system was the TOMBOarchitecture [Tanida et al. 2001; Tanida et al. 2003]. Here, the single aperture in the camera was divided into several smaller and more or less identical optical channels optically isolated from one another. However, neither of these approaches considered an integrated approach to parallax detection/correction and superresolution, choosing instead to recover the resolution at a fixed depth from the camera. A single pixel was applied per lens and many small lenses were fabricated using lithographic means, with each lens having a different viewing direction. However, the system was not very scalable as it required a non-economically large footprint in order to achieve resolutions of the order of several megapixels. Thus, smaller lenses can more easily approach the diffraction limit with a smaller number of optical elements. Each camera in the PiCam array is optically isolated and sensitive to just one color of light: red, green, or blue. The ?occlusion? or ?visibility? problem manifests itself in PiCam when capturing a foreground object against a background object. This satisfies the spectral uniformity criteria in the 3 ? 3 video use case. We observe that when the spectral band of each channel that has to be corrected is substantially reduced, the color blur is  also correspondingly reduced. Therefore, the optical format (or F-number) taken together with the PSF determines the total space-bandwidth product of the diffraction limited optics or, in other words, the total information content in the optical image. The sensor architecture for the PiCam array has many aspects that need to be considered for ensuring optimal system performance in terms of overall resolution, optimality in die area, power consumption and data readout, and flexibility in camera control. Although the image sensor we use is much like a typical CMOS image sensor from a device physics and circuit design perspective, the architecture of the device was carefully chosen to maximize the feature-set and performance of the camera array. The challenge for array cameras results from the requirement that superresolution should be able to recover a higher resolution final output image than the intrinsic resolution in the input component images. For an image sensor, the pixel pitch determines the spatial sampling rate, and the corresponding Nyquist frequency (N y) is simply one half of the reciprocal of the center-to-center pixel spacing. The differences between the aliasing patterns in the different camera images are primarily due to the array?s sampling diversity resulting from the different viewing directions, which are either intentionally introduced or result from (positional) manufacturing tolerances. The main task of the microlens is to gather all the light incident on its surface and focus that light onto the photodiode in the bottom most layer. Moreover, as shown in Figure 5(b) , we shaped the microlens to be narrower, resulting in a reduction of the pixel blur, since the microlens is now averaging light over a relatively smaller area. This drastic reduction is one of the main reasons why care must be taken to optimize the pixel MTF. In our case, this works out to a factor of 1140 = 2.4. The large synthetic aperture of the array provides us with multiple apertures and, therefore, multiple points of view. In generating an HR image, one could generate the view from any one of the multiple viewpoints or from any point in between. For each pixel (i, j) in the reference camera, the best depth must be detected. The depth corresponding to the lowest matching cost is selected as the depth of the pixel (i, j). Additionally, ? R and ? B are weighting terms that can be used to modulate the influence of the red or blue matching scores relative to the influence of the green cameras. For clarity of presentation, we will restrict our discussion to estimating a single color channel (specifically, green channel). The goal is to estimate x from the lower-resolution observations {y p } (where p indexes the cameras), given knowledge of our imaging system. The decimation matrix D reflects the sampling 1 Although the pixel blur is spatially invariant, the lens blur is not so in practice. More recently, such Bayesian approaches taking into account the imaging system characteristics have been applied successfully to superresolve light field images by Bishop and Favaro [2012]. This may include a spatial interpolation of neighboring grid positions (if a stack ends up empty). This would appear to imply that the order of warping and blurring prior to the decimation needed to form gradients is inconsequential. Inverting the blurring and warping operations in such cases will not map the images correctly to the non-reference camera viewpoints, and the gradients would consequently be inaccurate. Specifically, the corresponding entries W p (.) of the shift matrices are applied to the {s, t} pixel position, for all p, even if some of the cameras are not directly linked in the stack S at {s, t}. Following this warp, we blur and decimate each HR warped image to obtain an estimate of g p corresponding to each camera y p . In such cases, we cannot relate the LR images with simple registration models as commonly done in literature [Irani and Peleg 1991; Vandewalle et al. 2007]. The approach described until now is computationally expensive (requiring visiting of every LR camera, for every HR grid position). Although this spatial localization is motivated from our need to obtain accurate likelihood gradient estimates even for local sparsely fused HR grids, we could certainly exploit spatial stack-neighborhoods to reduce uncertainty in likelihood gradient estimation for all HR grid locations. These contribute now to a filtered gradient at position {s p , t p }: The locallyadaptive prior we introduce instead has the form However, although not done in this paper, we can also incorporate a diagonal weight matrix ? to weigh the norm in Equation 7, as a function of the SNR. Thus, ? would cause a higher relative weight for the data fidelity term for high SNR pixels, while for low SNR the image prior would be more significant. Until now, we have restricted our discussion to estimating a single color channel, namely the green channel. A key  challenge in creating a robust imaging system is the estimation of accurate depth by the parallax stage and the resulting resolution of the depth map. All of these scenes were captured at the same time by the PiCam and by the iPhone5 under the same illumination conditions. The last row of Figure 14 shows an example of an image being refocused, first with the foreground in focus and then with the background in focus. The authors wish to thank the people whose hard work has made this computational camera array possible, including the engineering team led by Purnam Sheth. Finally, we would like to acknowledge the support and encouragement of Chris Pickett.",
  "resources" : [ ]
}