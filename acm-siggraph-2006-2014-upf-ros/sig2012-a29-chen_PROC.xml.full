{
  "uri" : "sig2012-a29-chen_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2012/a29-chen_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Schelling Points on 3D Surface Meshes",
    "published" : null,
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ ]
  },
  "bagOfWords" : [ "c895ec2f7e1385ab993699506d39477b1707ed18b79bbd4aa3de06e233ff2fe3", "p2g", "10.1145", "2185520.2185525", "name", "identification", "possible", "Schelling", "Points", "3D", "surface", "mesh", "Xiaobai", "Chen", "Abulhair", "Saparov", "Bill", "Pang", "Thomas", "Funkhouser", "Princeton", "University", "paper", "investigate", "schell", "point", "3d", "mesh", "feature", "point", "select", "people", "pure", "coordination", "game", "due", "salience", "collect", "datum", "investigation", "we", "design", "online", "experiment", "ask", "people", "select", "point", "3d", "surface", "expect", "select", "other", "people", "we", "analyze", "property", "select", "point", "find", "-rrb-", "schelling", "point", "set", "usually", "highly", "symmetric", "-rrb-", "local", "curvature", "property", "-lrb-", "e.g.", "Gauss", "curvature", "-rrb-", "most", "helpful", "identify", "obvious", "schell", "point", "-lrb-", "tip", "protrusion", "-rrb-", "-rrb-", "global", "property", "-lrb-", "e.g.", "segment", "centeredness", "proximity", "symmetry", "axis", "etc.", "-rrb-", "require", "explain", "more", "subtle", "feature", "base", "observation", "we", "use", "regression", "analysis", "combine", "multiple", "property", "analytical", "model", "predict", "where", "Schelling", "point", "likely", "new", "mesh", "we", "find", "model", "benefit", "from", "variety", "surface", "property", "particularly", "when", "training", "datum", "come", "from", "example", "same", "object", "class", "keyword", "3d", "shape", "analysis", "feature", "detection", "shape", "matching", "Links", "dl", "pdf", "introduction", "detection", "salient", "feature", "point", "3d", "surface", "fundamental", "problem", "computer", "graphic", "many", "application", "shape", "analysis", "related", "field", "include", "object", "recognition", "-lsb-", "Johnson", "2000", "-rsb-", "shape", "matching", "-lsb-", "Zhang", "et", "al.", "2008", "-rsb-", "shape-based", "retrieval", "-lsb-", "funkhouser", "shilane", "2006", "-rsb-", "metamorphosis", "-lsb-", "Alexa", "2000", "-rsb-", "cross-parameterization", "-lsb-", "kraevoy", "Sheffer", "2004", "-rsb-", "texture", "mapping", "-lsb-", "Zhang", "et", "al.", "2005", "-rsb-", "deformation", "transfer", "-lsb-", "Sumner", "Popovic", "2004", "-rsb-", "shape", "approximation", "-lsb-", "Lee", "et", "al.", "2005", "-rsb-", "viewpoint", "selection", "-lsb-", "Lee", "et", "al.", "2005", "-rsb-", "symmetry", "detection", "-lsb-", "xu", "et", "al.", "2009", "-rsb-", "part-based", "segmentation", "-lsb-", "Katz", "et", "al.", "2005", "Zhou", "Huang", "2004", "-rsb-", "although", "many", "definition", "have", "be", "propose", "what", "constitute", "salient", "feature", "point", "computer", "graphic", "literature", "-lrb-", "e.g.", "maximum", "average", "geodesic", "distance", "maximum", "Gauss", "curvature", "maximum", "mean", "curvature", "difference", "increase", "scale", "etc.", "-rrb-", "none", "they", "capture", "social/psychological", "essence", "salience", "define", "Oxford", "English", "Dictionary", "quality", "fact", "be", "more", "prominent", "person?s", "awareness", "he", "memory", "past", "experience", "-lsb-", "Simpson", "1989", "-rsb-", "definition", "capture", "semantic", "essence", "stable", "feature", "point", "therefore", "one", "we", "believe", "useful", "application", "computer", "graphic", "ACM", "Reference", "Format", "Chen", "X.", "Saparov", "a.", "Pang", "B.", "Funkhouser", "T.", "2012", "Schelling", "Points", "3D", "surface", "mesh", "ACM", "Trans", "graph", "31", "Article", "29", "-lrb-", "July", "2012", "-rrb-", "12", "page", "dous", "10.1145", "2185520.2185525", "http://doi.acm.org/10.1145/2185520.2185525", "copyright", "Notice", "permission", "make", "digital", "hard", "copy", "part", "all", "work", "personal", "classroom", "use", "grant", "without", "fee", "provide", "copy", "make", "distribute", "profit", "direct", "commercial", "advantage", "copy", "show", "notice", "fus", "rst", "page", "initial", "screen", "display", "along", "full", "citation", "copyright", "component", "work", "own", "other", "than", "ACM", "must", "honor", "abstract", "credit", "permit", "copy", "otherwise", "republish", "post", "server", "redistribute", "list", "use", "any", "component", "work", "other", "work", "require", "prior", "specific", "permission", "and/or", "fee", "permission", "may", "request", "from", "Publications", "Dept.", "ACM", "Inc.", "Penn", "Plaza", "Suite", "701", "New", "York", "NY", "10121-0701", "fax", "+1", "212", "869-0481", "permissions@acm.org", "2012", "ACM", "0730-0301/2012", "08-art29", "15.00", "DOI", "10.1145", "2185520.2185525", "http://doi.acm.org/10.1145/2185520.2185525", "figure", "schelling", "point", "-lrb-", "red", "-rrb-", "position", "surface", "select", "consistently", "many", "people", "when", "try", "match", "each", "other", "without", "communication", "goal", "paper", "develop", "model", "salience", "3d", "surface", "mesh", "base", "social/psychological", "definition", "achieve", "goal", "we", "leverage", "concept", "focal", "point", "introduce", "Schelling", "he", "seminal", "paper", "pure", "coordination", "game", "-lsb-", "schell", "1960", "-rsb-", "game", "theory", "focal", "point", "-lrb-", "also", "call", "schelling", "point", "-rrb-", "solution", "people", "tend", "use", "absence", "communication", "because", "seem", "natural", "special", "relevant", "they", "-lsb-", "Parker", "2011", "-rsb-", "discover", "focal", "point", "schell", "perform", "user", "study", "which", "he", "ask", "people", "make", "selection", "expect", "match", "other", "people?s", "selection", "since", "people", "be", "allow", "communicate", "any", "way", "usually", "pick", "most", "conspicuous", "point", "often", "use", "semantic", "information", "provide", "input", "example", "ask", "select", "time", "place", "New", "York", "City", "meet", "someone", "without", "any", "prior", "communication", "people", "tend", "choose", "Grand", "Central", "Terminal", "noon", "choice", "clearly", "result", "prior", "semantic", "knowledge", "make", "choice", "more", "prominent", "person?s", "awareness", "he", "memory", "past", "experience", "-lrb-", "i.e.", "social/psychological", "salience", "-rrb-", "inspire", "schelling?s", "work", "we", "design", "user", "study", "ask", "people", "select", "point", "3d", "surface", "mesh", "expect", "select", "other", "people", "use", "acquire", "datum", "build", "model", "mesh", "saliency", "we", "primary", "research", "contribution", "analysis", "collect", "datum", "we", "find", "-rrb-", "schelling", "point", "set", "usually", "highly", "symmetric", "-rrb-", "local", "curvature", "property", "-lrb-", "e.g.", "absolute", "value", "minimum", "curvature", "-rrb-", "most", "helpful", "predict", "obvious", "schelling", "point", "feature", "-rrb-", "global", "property", "-lrb-", "e.g.", "symmetry", "segment", "centeredness", "-rrb-", "require", "explain", "other", "feature", "we", "secondary", "research", "contribution", "method", "use", "acquire", "analyze", "predict", "Schelling", "point", "3d", "mesh", "include", "-rrb-", "design", "user", "study", "-rrb-", "analysis", "consistency", "property", "schelling", "point", "-rrb-", "learn", "model", "predict", "distribution", "Schelling", "point", "-rrb-", "algorithm", "use", "learn", "model", "extract", "Schelling", "point", "new", "mesh", "ACM", "transaction", "Graphics", "Vol", "31", "no.", "Article", "29", "publication", "date", "July", "2012", "29:2", "X.", "Chen", "et", "al.", "related", "work", "detection", "matching", "salient", "feature", "point", "classical", "problem", "computer", "vision", "geometric", "modeling", "computer-aided", "design", "computer", "graphic", "several", "other", "field", "-lsb-", "van", "Kaick", "et", "al.", "2010", "-rsb-", "section", "we", "cover", "most", "related", "work", "focus", "method", "design", "saliency", "estimation", "point", "feature", "point", "detection", "have", "be", "lot", "recent", "work", "automatically", "extract", "feature", "point", "3d", "mesh", "example", "method", "include", "local", "maximum", "average", "geodesic", "distance", "-lrb-", "agd", "-rrb-", "other", "point", "surface", "-lsb-", "zhou", "Huang", "2004", "Zhang", "et", "al.", "2005", "Zhang", "et", "al.", "2008", "-rsb-", "local", "maximum", "difference", "Gaussians", "multiple", "scale", "-lsb-", "Castellani", "et", "al.", "2008", "-rsb-", "local", "maximum", "gaussian", "curvature", "-lsb-", "Lipman", "Funkhouser", "2009", "-rsb-", "property", "Heat", "Kernel", "Signature", "-lsb-", "Sun", "et", "al.", "2009", "-rsb-", "scale-space", "analysis", "mean", "curvature", "flow", "-lsb-", "Zaharescu", "et", "al.", "2009", "-rsb-", "other", "multiscale", "analysis", "-lsb-", "Li", "Guskov", "2005", "Li", "Guskov", "2007", "Novotni", "et", "al.", "2005", "Schlattmann", "et", "al.", "2008", "Sonthi", "et", "al.", "1997", "-rsb-", "point", "convex", "hull", "after", "md", "embedding", "-lsb-", "Katz", "et", "al.", "2005", "-rsb-", "leaf", "node", "curve", "skeleton", "extraction", "-lsb-", "Hisada", "et", "al.", "2002", "-rsb-", "point", "unlikely", "local", "shape", "descriptor", "-lsb-", "Chua", "Jarvis", "1996", "Johnson", "2000", "-rsb-", "point", "local", "shape", "descriptor", "distinctive", "object", "class", "-lsb-", "shilane", "Funkhouser", "2007", "-rsb-", "most", "method", "base", "differential", "property", "surface", "-lrb-", "e.g.", "-lsb-", "Castellani", "et", "al.", "2008", "-rsb-", "-rrb-", "while", "other", "base", "global", "property", "-lsb-", "Zhang", "et", "al.", "2008", "-rsb-", "and/or", "shape", "descriptor", "statistics", "-lrb-", "e.g.", "-lsb-", "Johnson", "2000", "-rsb-", "-rrb-", "previous", "work", "have", "analyze", "which", "feature", "point", "most", "stable", "under", "various", "model", "perturbation", "-lsb-", "bronstein", "et", "al.", "2010", "-rsb-", "none", "study", "how", "relate", "semantic", "salience", "Schelling", "sense", "Saliency", "Estimation", "related", "work", "method", "have", "be", "propose", "define", "continuous", "measure", "saliency", "across", "surface", "mesh", "processing", "application", "motivate", "perceptual", "criterion", "-lsb-", "Hoffman", "Singh", "1997", "-rsb-", "-lsb-", "Lee", "et", "al.", "2005", "-rsb-", "use", "centersurround", "filter", "curvature", "across", "multiple", "scale", "select", "salient", "region", "mesh", "simplification", "viewpoint", "selection", "-lsb-", "gal", "cohen-or", "2006", "-rsb-", "compute", "saliency", "region", "base", "its", "size", "relative", "whole", "object", "its", "curvature", "variance", "curvature", "number", "curvature", "change", "within", "region", "-lsb-", "shilane", "Funkhouser", "2007", "-rsb-", "define", "distinction", "surface", "region", "base", "its", "similarity", "object", "within", "same", "class", "difference", "object", "other", "class", "paper", "study", "how", "type", "saliency", "measure", "relate", "human-selected", "focal", "point", "provide", "new", "saliency", "measure", "learn", "from", "example", "Saliency", "evaluation", "comparison", "-lsb-", "Kim", "et", "al.", "2010", "-rsb-", "study", "how", "eye", "fixation", "relate", "mesh", "saliency", "-lsb-", "Lee", "et", "al.", "2005", "-rsb-", "other", "study", "have", "evaluate", "compare", "feature", "point", "detection", "algorithm", "image", "computer", "vision", "-lsb-", "Ko", "Nam", "2006", "Moreels", "Perona", "2007", "Privitera", "Stark", "2000", "Schmid", "et", "al.", "2000", "Stark", "Schiele", "2007", "Zuliani", "et", "al.", "2004", "-rsb-", "example", "-lsb-", "Schmid", "et", "al.", "2000", "-rsb-", "-lsb-", "Sebe", "Lew", "2003", "-rsb-", "compare", "interest", "point", "detector", "basis", "stability", "repeatability", "information", "content", "-lsb-", "Privitera", "Stark", "2000", "-rsb-", "compare", "region", "interest", "algorithm", "base", "how", "well", "match", "eye", "fixation", "measure", "eye", "tracker", "-lsb-", "Huang", "et", "al.", "2009", "-rsb-", "compare", "algorithm", "respect", "point", "collect", "game", "-lrb-", "photoshoot", "-rrb-", "ask", "people", "select", "point", "image", "expect", "match", "partner?s", "selection", "much", "like", "ESP", "game", "propose", "-lsb-", "Von", "Ahn", "Dabbish", "2008", "-rsb-", "work", "similar", "ours", "also", "ask", "people", "match", "point", "selection", "however", "methodology", "study", "can", "produce", "bias", "select", "point", "due", "training", "effect", "immediate", "feedback", "-lrb-", "pure", "coordination", "game", "-rrb-", "consider", "only", "2d", "point", "natural", "image", "do", "provide", "any", "analysis", "how", "image", "property", "correlate", "select", "point", "do", "suggest", "new", "property", "correlate", "select", "point", "-lrb-", "e.g.", "symmetry", "segmentation", "etc.", "-rrb-", "do", "provide", "predictor", "point", "learn", "from", "collect", "example", "Perceptual", "Psychology", "have", "be", "many", "study", "perceptual", "psychology", "understand", "how", "people", "assign", "importance", "region", "image", "most", "have", "be", "base", "visual", "attention", "-lsb-", "Koch", "Ullman", "1985", "Milanes", "et", "al.", "1994", "Tsotsos", "et", "al.", "1995", "Itti", "et", "al.", "1998", "Rosenholtz", "1999", "Santella", "DeCarlo", "2004", "-rsb-", "-rrb-", "example", "-lsb-", "Koch", "Ullman", "1985", "-rsb-", "propose", "model", "salient", "point", "would", "one", "different", "from", "surroundings", "other", "perceptual", "psychology", "study", "have", "study", "which", "point", "most", "important", "approximation", "contour", "example", "-lsb-", "Attneave", "1954", "-rsb-", "show", "80", "subject", "series", "16", "shape", "draw", "2d", "contour", "ask", "they", "select", "pattern", "10", "dot", "which", "would", "resemble", "shape", "closely", "possible", "he", "main", "finding", "most", "people", "select", "point", "where", "contour", "most", "different", "from", "straight", "line", "i.e.", "where", "curvature", "have", "large", "magnitude", "while", "study", "related", "ours", "we", "aim", "discover", "which", "point", "have", "semantic", "salience", "3d", "mesh", "study", "how", "people", "do", "have", "very", "recently", "be", "study", "computer", "graphic", "aim", "understand", "how", "people", "perform", "task", "interest", "computer", "graphic", "example", "-lsb-", "Cole", "et", "al.", "2008", "-rsb-", "study", "where", "artist", "draw", "line", "when", "make", "line", "drawing", "-lsb-", "Chen", "et", "al.", "2009", "-rsb-", "analyze", "how", "people", "decompose", "surface", "part", "both", "case", "machine", "learning", "algorithm", "be", "develop", "produce", "prediction", "new", "surface", "base", "training", "classifier", "example", "collect", "from", "human", "-lsb-", "Cole", "et", "al.", "2008", "Kalogerakis", "et", "al.", "2010", "-rsb-", "we", "study", "follow", "line", "research", "focus", "feature", "point", "detection", "novel", "only", "because", "consider", "new", "question", "where", "do", "people", "select", "feature", "point", "also", "because", "ask", "question", "different", "way", "where", "do", "other", "people", "select", "feature", "point", "??", "because", "include", "new", "algorithm", "analyze", "extract", "feature", "point", "base", "collect", "datum", "approach", "goal", "paper", "develop", "model", "semantic", "salience", "3d", "surface", "we", "general", "approach", "gather", "large", "collection", "feature", "point", "from", "people", "study", "what", "geometric", "property", "distinguish", "they", "from", "other", "although", "general", "idea", "may", "sound", "straight-forward", "surprisingly", "difficult", "design", "study", "collect", "useful", "datum", "salience", "we", "do", "want", "simply", "ask", "people", "please", "click", "important", "point", "because", "different", "people", "might", "have", "different", "idea", "what", "mean", "important", "-lrb-", "e.g.", "functional", "structural", "social", "visual", "etc.", "-rrb-", "would", "difficult", "ask", "question", "way", "reveal", "people?s", "intention", "without", "lead", "they", "answer", "during", "pilot", "study", "we", "try", "approach", "base", "-lsb-", "attneave", "1954", "-rsb-", "where", "we", "ask", "people", "select", "point", "3d", "surface", "from", "which", "another", "person", "could", "recognize", "object", "class", "just", "view", "those", "point", "approach", "resounding", "failure", "we", "find", "most", "people", "select", "point", "only", "2d", "silhouette", "curve", "surface", "see", "from", "single", "canonical", "view", "-lrb-", "e.g.", "outline", "fish", "see", "from", "side", "-rrb-", "which", "do", "seem", "match", "notion", "semantic", "salience", "useful", "3d", "application", "ultimately", "we", "arrive", "approach", "base", "schelling?s", "focal", "point", "we", "ask", "people", "select", "point", "think", "select", "other", "concept", "focal", "point", "introduce", "pure", "coordination", "game", "theory", "1960", "-lsb-", "schell", "1960", "-rsb-", "-lrb-", "page", "57", "-rrb-", "schell", "find", "people", "ask", "make", "selection", "match", "other", "people?s", "selection", "amongst", "seemingly", "equivalent", "distinct", "option", "-lrb-", "segregate", "Nash", "equilibrium", "-rrb-", "often", "make", "same", "choice", "without", "any", "communication", "feedback", "example", "people", "be", "ask", "choose", "head", "tail", "other", "information", "besides", "goal", "match", "many", "other", "people", "possible", "86", "choose", "head", "-lsb-", "schell", "1960", "-rsb-", "ask", "match", "other", "people?s", "selection", "map", "most", "people", "agree", "just", "few", "point", "-lrb-", "e.g.", "prominent", "intersection", "-rrb-", "conjecture", "commonly", "select", "focal", "point", "-lrb-", "later", "call", "Schelling", "point", "-rrb-", "arise", "from", "strategy", "outcome", "property", "prominence", "conspicuousness", "-lsb-", "schell", "1960", "-rsb-", "decade", "later", "Lewis", "use", "schelling?s", "idea", "introduce", "term", "salience", "which", "he", "define", "first", "property", "outcome", "stand", "out", "from", "rest", "its", "uniqueness", "some", "conspicuous", "respect", "second", "be", "unique", "some", "way", "everyone", "notice", "expect", "other", "notice", "-lsb-", "Lewis", "1969", "-rsb-", "-lrb-", "page", "35", "-rrb-", "he", "use", "formal", "game", "model", "characterize", "coordination", "strategy", "hypothesize", "people", "use", "common", "knowledge", "select", "amongst", "distinct", "Nash", "equilibrium", "common", "knowledge", "about", "feature", "point", "3d", "surface", "we", "aim", "capture", "leverage", "we", "work", "inspire", "idea", "schelling", "Lewis", "we", "have", "design", "method", "study", "semantic", "salience", "3d", "mesh", "specifically", "we", "first", "acquire", "large", "number", "Schelling", "point", "ask", "people", "select", "point", "3d", "surface", "mesh", "expect", "select", "other", "people", "-lrb-", "section", "-rrb-", "we", "analyze", "property", "collect", "point", "set", "ask", "question", "like", "how", "consistent", "schell", "point", "select", "different", "mesh", "within", "same", "object", "class", "??", "how", "location", "schelling", "point", "associate", "geometric", "property", "surface", "??", "-lrb-", "section", "-rrb-", "next", "we", "train", "regression", "model", "predict", "likelihood", "point", "surface", "schelling", "point", "base", "its", "surface", "property", "-lrb-", "section", "-rrb-", "finally", "we", "provide", "algorithm", "predict", "set", "Schelling", "point", "new", "mesh", "-lrb-", "section", "-rrb-", "ACM", "transaction", "Graphics", "Vol", "31", "no.", "Article", "29", "publication", "date", "July", "2012", "Schelling", "Points", "3D", "surface", "mesh", "29:3", "Study", "Design", "first", "most", "difficult", "issue", "face", "we", "investigation", "how", "design", "study", "acquire", "Schelling", "point", "from", "many", "people", "many", "type", "3d", "surface", "we", "would", "like", "collect", "enough", "datum", "analyze", "how", "Schelling", "point", "relate", "surface", "property", "across", "wide", "variety", "mesh", "train", "predictive", "model", "can", "use", "estimate", "Schelling", "point", "new", "3d", "mesh", "course", "difficult", "because", "require", "recruit", "supervise", "many", "-lrb-", "possibly", "hundred", "thousand", "-rrb-", "human", "subject", "user", "study", "address", "issue", "we", "perform", "we", "study", "on-line", "follow", "approach", "-lsb-", "Chen", "et", "al.", "2009", "-rsb-", "-lsb-", "Cole", "et", "al.", "2009", "-rsb-", "we", "recruit", "subject", "we", "study", "through", "Amazon?s", "mechanical", "Turk", "-lrb-", "AMT", "-rrb-", "-lsb-", "Amazon", "2009", "-rsb-", "on-line", "platform", "match", "people", "willing", "work", "pay", "task", "alternatively", "we", "could", "have", "design", "on-line", "game", "acquire", "input", "-lrb-", "-lsb-", "Huang", "et", "al.", "2009", "Von", "Ahn", "Dabbish", "2008", "-rsb-", "-rrb-", "approach", "would", "have", "require", "attract", "player", "population", "which", "beyond", "scope", "paper", "since", "task", "AMT", "typically", "short", "duration", "-lrb-", "minute", "two", "-rrb-", "inexpensive", "-lrb-", "around", "10", "cent", "-rrb-", "accessible", "on-line", "-lrb-", "web", "page", "-rrb-", "well-suited", "study", "like", "ours", "require", "lot", "people", "do", "simple", "menial", "task", "-lrb-", "e.g.", "click", "point", "surface", "-rrb-", "challenge", "any", "on-line", "study", "design", "protocol", "acquire", "useful", "information", "from", "diverse", "population", "subject", "unlike", "laboratory", "study", "where", "handful", "screen", "subject", "train", "monitor", "employ", "several", "hour", "we", "have", "access", "much", "larger", "number", "people", "less", "control", "over", "subject", "selection", "less", "trust", "every", "individual", "motivate", "do", "good", "job", "we", "challenge", "design", "study", "motivate", "people", "work", "responsibly", "incorporate", "unbiased", "mechanism", "discard", "datum", "from", "those", "don?t", "we", "design", "easy-to-learn", "task", "which", "subject", "provide", "better", "input", "get", "pay", "more", "those", "do", "do", "good", "job", "get", "pay", "nothing", "specifically", "we", "present", "each", "user", "3d", "mesh", "show", "interactive", "viewer", "crystal", "ball", "camera", "control", "simple", "method", "click", "point", "mouse", "-lrb-", "one", "key", "add", "point", "select", "position", "mesh", "another", "key", "remove", "previously", "add", "point", "-rrb-", "we", "provide", "follow", "instruction", "select", "point", "surface", "3d", "object", "likely", "select", "other", "people", "we", "ask", "many", "people", "do", "same", "task", "see", "how", "you", "selection", "match", "other", "we", "reward", "structure", "rank", "people", "accord", "score", "function", "provide", "positive", "credit", "each", "point", "also", "select", "least", "25", "other", "people", "negative", "credit", "other", "point", "zero", "credit", "less", "than", "ten", "point", "be", "select", "base", "ranking", "we", "pay", "top", "score", "30", "people", "next", "60", "x/2", "bottom", "10", "be", "pay", "incentive", "structure", "choose", "base", "result", "pilot", "study", "which", "suggest", "useful", "provide", "motivation", "people", "select", "more", "than", "just", "very", "obvious", "schell", "point", "-lrb-", "e.g.", "end", "limb", "animal", "-rrb-", "better", "acquire", "too", "many", "point", "from", "people", "than", "too", "few", "-lrb-", "surface", "have", "fewer", "schelling", "point", "extra", "point", "distribute", "somewhat", "randomly", "-rrb-", "datum", "filter", "even", "though", "we", "pay", "structure", "encourage", "people", "do", "good", "job", "we", "employ", "three", "filter", "discard", "point", "set", "we", "expect", "provide", "bad", "datum", "i.e.", "when", "user", "-rrb-", "click", "too", "few", "point", "-lrb-", "less", "than", "ten", "-rrb-", "-rrb-", "maintain", "approximately", "same", "camera", "viewpoint", "entire", "interactive", "session", "-lrb-", "cumulative", "camera", "rotation", "less", "than", "36", "degree", "-rrb-", "-rrb-", "click", "too", "hastily", "-lrb-", "average", "time", "per", "click", "less", "than", "one", "second", "-rrb-", "filter", "be", "choose", "basis", "pilot", "study", "which", "show", "empirically", "significant", "fraction", "people", "provide", "careful", "datum", "simple", "filter", "be", "effective", "conservatively", "discard", "careless", "datum", "while", "retain", "much", "good", "datum", "regard", "we", "design", "we", "filter", "favor", "false-negative", "-lrb-", "discard", "good", "datum", "-rrb-", "over", "false-positive", "-lrb-", "accept", "careless", "datum", "-rrb-", "since", "easy", "collect", "datum", "AMT", "mesh", "selection", "order", "cover", "wide", "variety", "object", "category", "leverage", "datum", "collect", "previous", "study", "we", "choose", "collect", "Schelling", "point", "3d", "mesh", "from", "Watertight", "Track", "2007", "SHREC", "shape-based", "Retrieval", "Contest", "datum", "set", "contain", "400", "mesh", "spread", "evenly", "among", "20", "object", "category", "-lrb-", "human", "cup", "glass", "airplane", "ant", "chair", "octopus", "table", "teddy", "hand", "plier", "fish", "bird", "spring", "armadillo", "buste", "mechanical", "part", "bearing", "vase", "four-legged", "animal", "-rrb-", "which", "we", "use", "all", "spring", "form", "interesting", "datum", "set", "we", "study", "because", "contain", "category", "different", "articulate", "pose", "-lrb-", "ant", "octopus", "bird", "teddy", "pliers", "glass", "-rrb-", "different", "local", "part", "-lrb-", "human", "hand", "four-leg", "animal", "-rrb-", "different", "global", "structure", "-lrb-", "fish", "table", "cup", "mechanical", "part", "bearing", "chair", "buste", "vase", "-rrb-", "also", "datum", "set", "highly", "tessellated", "-lrb-", "average", "10,223", "vertex", "per", "mesh", "-rrb-", "so", "we", "can", "limit", "select", "point", "vertex", "mesh", "finally", "since", "have", "be", "use", "previous", "study", "mesh", "matching", "-lsb-", "Giorgi", "et", "al.", "2007", "-rsb-", "segmentation", "-lsb-", "Chen", "et", "al.", "2009", "-rsb-", "provide", "opportunity", "investigate", "how", "Schelling", "point", "correspond", "other", "type", "datum", "Protocol", "Implementation", "reduce", "bias", "acquire", "datum", "we", "implement", "scheduling", "program", "record", "AMT", "identifier", "IP", "address", "every", "subject", "do", "we", "task", "program", "ensure", "single", "AMT", "identifier", "IP", "address", "can", "work", "same", "mesh", "twice", "mesh", "distribute", "randomize", "order", "datum", "provide", "approximately", "same", "number", "subject", "every", "mesh", "interactive", "Java", "Applet", "present", "user", "view", "mesh", "select", "point", "initialize", "random", "camera", "direction", "two", "virtual", "light", "all", "point", "object", "centroid", "from", "distance", "relative", "object", "bound", "box", "size", "user", "rotate", "mesh", "light", "move", "camera", "stay", "along", "equator", "90", "degree", "angle", "camera", "Applet", "record", "position", "time", "stamp", "camera", "parameter", "every", "point", "add", "delete", "from", "datum", "set", "send", "datum", "back", "we", "server", "feedback", "payment", "be", "make", "any", "subject", "until", "all", "datum", "collect", "avoid", "training", "effect", "datum", "Collection", "use", "protocol", "we", "use", "AMT", "acquire", "24,124", "point", "set", "from", "1,696", "unique", "AMT", "account", "raw", "datum", "9,965", "point", "set", "-lrb-", "44", "-rrb-", "from", "1,060", "unique", "AMT", "account", "pass", "all", "three", "datum", "filter", "16", "have", "too", "few", "point", "14", "be", "enter", "too", "little", "camera", "motion", "28", "be", "click", "too", "hastily", "9,965", "point", "set", "we", "final", "datum", "set", "contain", "201,304", "point", "total", "average", "approximately", "10,000", "point", "per", "object", "category", "500", "point", "per", "mesh", "20", "point", "per", "point", "set", "each", "380", "mesh", "represent", "datum", "from", "25", "people", "average", "every", "mesh", "have", "least", "23", "point", "set", "schell", "point", "extraction", "post-process", "we", "extract", "discrete", "set", "Schelling", "Points", "from", "collect", "datum", "i.e.", "one", "upon", "which", "many", "people", "agree", "course", "since", "datum", "discrete", "-lrb-", "vertex", "mesh", "-rrb-", "spatial", "noise", "point", "selection", "process", "some", "aggregation", "require", "identify", "commonly", "select", "point", "address", "issue", "we", "first", "construct", "function", "every", "mesh", "indicate", "number", "time", "every", "vertex", "select", "different", "people", "reduce", "spatial", "noise", "we", "blur", "function", "geodesically", "gaussian", "filter", "maximal", "value", "0.01", "where", "represent", "radius", "mesh", "-lrb-", "surf", "acearea", "-lrb-", "-rrb-", "-rrb-", "result", "smooth", "schell", "distribution", "function", "-lrb-", "-rrb-", "roughly", "estimate", "probability", "each", "vertex", "select", "person", "we", "study", "-lrb-", "show", "red", "figure", "-rrb-", "we", "extract", "discrete", "set", "Schelling", "point", "from", "local", "maximum", "-lrb-", "-rrb-", "build", "indicator", "function", "-lrb-", "-rrb-", "tell", "whether", "vertex", "schelling", "point", "-lrb-", "-lrb-", "-rrb-", "one", "Schelling", "point", "zero", "otherwise", "-rrb-", "form", "set", "we", "select", "every", "vertex", "-lrb-", "-rrb-", "greater", "than", "12.5", "spatial", "separation", "more", "than", "0.02", "from", "any", "other", "vertex", "higher", "-lrb-", "-rrb-", "choice", "include", "least", "vertex", "be", "select", "spatial", "error", "less", "than", "least", "25", "people", "we", "study", "-lrb-", "positive", "payment", "threshold", "we", "study", "-rrb-", "some", "example", "point", "set", "show", "blue", "figure", "ACM", "transaction", "Graphics", "Vol", "31", "no.", "Article", "29", "publication", "date", "July", "2012", "29:4", "X.", "Chen", "et", "al.", "figure", "schelling", "point", "saturation", "red", "depict", "estimate", "fraction", "people", "select", "mesh", "vertex", "we", "study", "Extracted", "Schelling", "point", "show", "blue", "analysis", "Schelling", "Points", "large", "datum", "set", "provide", "opportunity", "investigate", "number", "question", "potential", "interest", "computer", "graphic", "perceptual", "psychology", "include", "how", "consistently", "do", "people", "select", "point", "same", "mesh", "how", "symmetric", "select", "point", "set", "how", "select", "point", "distribute", "surface", "what", "geometric", "property", "3d", "surface", "prominent", "select", "point", "section", "take", "step", "towards", "address", "question", "how", "consistently", "do", "people", "select", "point", "same", "mesh", "first", "most", "basic", "question", "whether", "people", "select", "point", "consistently", "we", "study", "address", "question", "we", "compute", "geodesic", "distance", "between", "point", "select", "different", "people", "same", "mesh", "k-th", "point", "every", "point", "set", "select", "every", "mesh", "we", "compute", "geodesic", "distance", "-lrb-", "-rrb-", "from", "point", "closest", "point", "every", "other", "point", "set", "collect", "same", "mesh", "normalize", "scale", "divide", "square", "root", "surface", "area", "we", "analyze", "consistency", "point", "set", "plot", "cumulative", "distribution", "-lrb-", "-rrb-", "indicate", "fraction", "point", "set", "consistent", "each", "select", "point", "range", "distance", "threshold", "example", "Figure", "3a", "show", "cumulative", "distribution", "where", "horizontal", "axis", "represent", "normalize", "distance", "threshold", "-lrb-", "-lrb-", "-rrb-", "-rrb-", "vertical", "axis", "represent", "fraction", "point", "within", "threshold", "point", "set", "select", "different", "people", "same", "mesh", "thick", "black", "curve", "represent", "overall", "average", "all", "point", "collect", "datum", "set", "aggregated", "first", "over", "all", "point", "within", "same", "mesh", "over", "all", "mesh", "within", "same", "object", "class", "finally", "over", "all", "class", "datum", "set", "avoid", "over-weighting", "point", "set", "mesh", "large", "number", "point", "thin", "solid", "color", "curve", "depict", "average", "different", "subset", "point", "base", "order", "which", "user", "select", "point", "within", "his/her", "interactive", "session", "-lrb-", "e.g.", "red", "curve", "show", "distance", "from", "first", "point", "select", "each", "session", "purple", "curve", "show", "same", "second", "third", "point", "blue", "curve", "point", "4-7", "etc.", "curve", "tell", "more", "detailed", "story", "how", "consistency", "relate", "order", "point", "be", "select", "look", "curve", "Figure", "3a", "we", "can", "readily", "make", "two", "observation", "first", "different", "people", "tend", "pick", "point", "fairly", "consistently", "one", "another", "same", "mesh", "use", "normalize", "distance", "0.05", "-lrb-", "approximately", "inch", "human", "body", "-rrb-", "threshold", "classify", "whether", "point", "consistent", "point", "set", "we", "find", "48.5", "select", "point", "consistent", "other", "point", "set", "level", "consistency", "far", "greater", "than", "12.8", "would", "observe", "point", "be", "select", "randomly", "second", "we", "observe", "point", "select", "earlier", "interactive", "session", "tend", "more", "consistent", "than", "one", "select", "later", "-lrb-", "higher", "density", "near", "-lrb-", "-rrb-", "curve", "represent", "point", "select", "earlier", "-rrb-", "which", "suggest", "people", "choose", "most", "salient", "point", "first", "other", "later", "result", "combine", "visualization", "figure", "suggest", "people", "select", "point", "non-random", "consistent", "way", "we", "study", "how", "consistently", "do", "people", "select", "point", "different", "mesh", "same", "object", "category", "second", "question", "potential", "interest", "whether", "people", "select", "semantically", "equivalent", "schelling", "point", "different", "mesh", "within", "same", "object", "category", "example", "select", "particular", "point", "-lrb-", "e.g.", "knee", "-rrb-", "when", "object", "one", "pose", "-lrb-", "e.g.", "run", "dog", "-rrb-", "do", "also", "select", "point", "when", "same", "object", "different", "pose", "-lrb-", "e.g.", "sit", "dog", "-rrb-", "do", "select", "semantically", "equivalent", "point", "different", "object", "within", "same", "general", "category", "-lrb-", "e.g.", "all", "fourlegged", "animal", "-rrb-", "address", "question", "we", "produce", "semantic", "mapping", "between", "all", "pair", "twenty", "mesh", "within", "each", "twenty", "object", "category", "use", "those", "mapping", "compute", "cumulative", "distribution", "normalize", "distance", "between", "select", "point", "produce", "mapping", "expert", "user", "select", "set", "landmark", "point", "every", "mesh", "semantically", "consistent", "every", "other", "mesh", "same", "category", "example", "four", "leg", "animal", "category", "every", "mesh", "mark", "landmark", "point", "represent", "tip", "nose", "tip", "right", "ear", "middle", "back", "etc.", "landmark", "point", "provide", "coarse", "point", "correspondence", "from", "which", "dense", "one-way", "inter-surface", "mapping", "a?b", "establish", "from", "vertex", "vertex", "use", "simple", "procedure", "base", "similarity", "pairwise", "geodesic", "distance", "-lrb-", "follow", "strategy", "outline", "-lsb-", "Bronstein", "et", "al.", "2006", "-rsb-", "except", "maintain", "explicit", "correspondence", "between", "landmark", "point", "-rrb-", "use", "inter-surface", "mapping", "we", "can", "study", "consistency", "point", "select", "people", "different", "mesh", "within", "same", "object", "class", "specifically", "each", "point", "select", "person", "mesh", "we", "use", "inter-surface", "mapping", "transfer", "domain", "every", "other", "mesh", "same", "class", "form", "every", "point", "set", "collect", "mesh", "we", "compute", "-lrb-", "-rrb-", "normalize", "geodesic", "distance", "from", "point", "closest", "point", "add", "cumulative", "distribution", "use", "same", "procedure", "describe", "previous", "subsection", "result", "show", "figure", "3b", "interestingly", "we", "find", "consistency", "point", "select", "different", "people", "different", "mesh", "same", "class", "almost", "quite", "high", "consistency", "point", "select", "different", "people", "same", "mesh", "overall", "39.4", "point", "select", "one", "mesh", "consistent", "point", "set", "select", "different", "mesh", "same", "object", "class", "since", "local", "geometry", "mesh", "within", "same", "class", "sometimes", "very", "different", "result", "suggest", "criterion", "people", "use", "select", "point", "base", "only", "absolute", "geometric", "property", "-lrb-", "e.g.", "Gauss", "curvature", "-rrb-", "rather", "relative", "property", "-lrb-", "e.g.", "extrema", "Gauss", "curvature", "-rrb-", "semantic", "feature", "consistent", "across", "different", "instance", "within", "same", "class", "how", "symmetric", "select", "point", "set", "third", "question", "interest", "regard", "symmetry", "person", "select", "point", "symmetric", "object", "how", "often", "do", "also", "select", "its", "symmetric", "correspondence", "-lrb-", "-rrb-", "example", "person", "select", "right", "ear", "head", "how", "often", "do", "also", "select", "left", "ear", "investigate", "question", "we", "manually", "produce", "symmetry", "mapping", "from", "every", "mesh", "onto", "itself", "establish", "dense", "symmetric", "point", "correspondence", "each", "319", "mesh", "intrinsic", "reflective", "symmetry", "do", "click", "symmetric", "pair", "landmark", "point", "-lrb-", "e.g.", "right", "eye", "leave", "eye", "leave", "elbow", "right", "elbow", "etc.", "-rrb-", "interpolate", "those", "pair", "form", "dense", "correspondence", "over", "entire", "surface", "use", "algorithm", "base", "-lsb-", "Bronstein", "et", "al.", "2006", "-rsb-", "give", "symmetric", "mapping", "we", "analyze", "consistency", "every", "point", "set", "its", "symmetric", "correspondence", "use", "method", "describe", "previous", "subsection", "i.e.", "we", "build", "cumulative", "distribution", "normalize", "geodesic", "distance", "from", "every", "point", "closest", "point", "same", "point", "set", "after", "symmetric", "mapping", "have", "be", "apply", "-lrb-", "Figure", "3c", "-rrb-", "we", "result", "reveal", "point", "set", "select", "people", "highly", "symmetric", "76.0", "point", "consistent", "symmetric", "mapping", "more", "specifically", "compare", "histogram", "Figure", "we", "find", "point", "set", "select", "people", "far", "more", "consistent", "symmetric", "mapping", "than", "point", "set", "select", "different", "people", "we", "conclude", "symmetry", "important", "cue", "select", "salient", "point", "we", "study", "how", "select", "point", "distribute", "surface", "fourth", "question", "interest", "characterize", "spatial", "distribution", "point", "select", "people", "address", "question", "we", "show", "histogram", "distance", "from", "each", "point", "other", "point", "same", "set", "mesh", "different", "object", "class", "Figure", "plot", "show", "separate", "curve", "each", "19", "object", "class", "-lrb-", "dot", "line", "-rrb-", "along", "overall", "average", "-lrb-", "thick", "red", "line", "-rrb-", "three", "interesting", "observation", "can", "make", "from", "histogram", "first", "people", "tend", "spread", "point", "fairly", "evenly", "mesh", "i.e.", "few", "point", "either", "very", "close", "very", "far", "from", "other", "point", "second", "spacing", "different", "object", "class", "different", "example", "point", "bust", "-lrb-", "statue", "head", "-rrb-", "tend", "closer", "one", "another", "-lrb-", "dot", "light", "blue", "curve", "left", "-rrb-", "while", "point", "octopus", "more", "widely", "space", "-lrb-", "light", "blue", "curve", "right", "-rrb-", "Third", "spacing", "point", "appear", "dictate", "more", "size", "mesh", "show", "person", "than", "physical", "size", "object", "real", "world", "example", "spacing", "point", "pair", "eyeglass", "same", "human", "body", "also", "same", "airplane", "similarly", "spacing", "point", "human", "hand", "different", "show", "alone", "part", "entire", "body", "from", "observation", "we", "hypothesize", "people", "think", "virtual", "object", "scale", "show", "select", "largest", "feature", "available", "screen", "regardless", "size", "real", "world", "what", "geometric", "property", "distinguish", "schell", "point", "finally", "interesting", "ask", "whether", "possible", "characterize", "common", "geometric", "property", "schelling", "point", "example", "schell", "point", "commonly", "extrema", "Gauss", "curvature", "can", "Schelling", "point", "predict", "analysis", "average", "geodesic", "distance", "other", "geometric", "property", "commonly", "use", "feature", "extraction", "computer", "graphic", "other", "geometric", "property", "mesh", "associate", "shell", "point", "have", "be", "use", "point", "feature", "extraction", "before", "investigate", "question", "we", "compute", "number", "geometric", "property", "every", "vertex", "every", "mesh", "datum", "set", "analyze", "how", "property", "explain", "placement", "schelling", "point", "base", "information", "theory", "statistics", "set", "property", "consider", "include", "curvature", "Gauss", "mean", "minimum", "maximum", "curvature", "compute", "-lsb-", "Rusinkiewicz", "2004", "-rsb-", "mesh", "Saliency", "mesh", "saliency", "-lrb-", "scale", "0.1", "0.3", "0.5", "0.7", "-rrb-", "compute", "code", "provide", "-lsb-", "Lee", "et", "al.", "2005", "-rsb-", "geodesic", "Distance", "average", "-lrb-", "agd", "-rrb-", "median", "-lrb-", "mgd", "-rrb-", "standard", "deviation", "-lrb-", "sdgd", "-rrb-", "tenth", "percentile", "-lrb-", "10gd", "-rrb-", "ninetieth", "percentile", "-lrb-", "90gd", "-rrb-", "maximum", "geodesic", "distance", "-lrb-", "ggd", "-rrb-", "from", "all", "other", "vertex", "estimate", "dijkstra?s", "algorithm", "shape", "Diameter", "function", "-lrb-", "sdf", "-rrb-", "median", "length", "ray", "trace", "from", "through", "interior", "describe", "-lsb-", "Shapira", "et", "al.", "2008", "-rsb-", "use", "implementation", "provide", "-lsb-", "Kalogerakis", "et", "al.", "2010", "-rsb-", "Heat", "Kernel", "Signature", "amount", "heat", "diffuse", "from", "itself", "within", "time", "five", "equally", "space", "time", "duration", "range", "from", "very", "small", "-lrb-", "hks1", "-rrb-", "very", "large", "-lrb-", "hks101", "-rrb-", "compute", "implementation", "provide", "-lsb-", "Sun", "et", "al.", "2009", "-rsb-", "up", "coordinate", "-lrb-", "zposition", "-rrb-", "normal", "direction", "-lrb-", "znormal", "-rrb-", "assume", "prescribe", "standard", "modeling", "language", "symmetry", "intrinsic", "reflective", "intrinsic", "symmetry", "Axis", "function", "propose", "-lsb-", "Xu", "et", "al.", "2009", "-rsb-", "per", "we", "implementation", "segment", "centeredness", "centeredness", "point", "within", "its", "part", "compute", "first", "decompose", "mesh", "segment", "automatically", "algorithm", "-lsb-", "Shapira", "et", "al.", "2008", "-rsb-", "compute", "distance", "from", "closest", "segmentation", "boundary", "divide", "maximal", "distance", "closest", "segmentation", "boundary", "all", "vertex", "segment", "contain", "most", "property", "have", "be", "use", "before", "characterize", "saliency", "and/or", "generate", "point", "set", "mesh", "however", "we", "consider", "two", "new", "one", "specifically", "motivate", "visual", "inspection", "schelling", "point", "set", "collect", "we", "study", "symmetry", "segment", "centeredness", "we", "observe", "people", "often", "select", "point", "symmetry", "axis", "center", "large", "convex", "part", "absence", "other", "more", "distinguishing", "feature", "nearby", "-lrb-", "e.g.", "center", "lens", "glass", "belly", "button", "teddy", "bear", "figure", "thus", "we", "expect", "extrema", "function", "-lrb-", "e.g.", "segment", "centeredness", "-rrb-", "correlate", "location", "select", "point", "hypothesis", "corroborate", "histogram", "show", "Figure", "which", "plot", "frequency", "select", "point", "versus", "segment", "centeredness", "-lrb-", "automatic", "sdf", "segmentation", "use", "throughout", "paper", "manual", "segmentation", "provide", "Benchmark", "3D", "Mesh", "segmentation", "-lsb-", "Chen", "et", "al.", "2009", "-rsb-", "which", "include", "only", "comparison", "sake", "-rrb-", "we", "find", "select", "point", "appear", "most", "often", "center", "extract", "part", "i.e.", "rightmost", "bin", "histogram", "contain", "25", "distribution", "we", "also", "consider", "function", "derive", "from", "basic", "geometric", "property", "specifically", "we", "include", "difference", "between", "minimum", "maximum", "curvature", "-lrb-", "curvdiff", "-rrb-", "which", "smallest", "center", "local", "rotational", "symmetry", "we", "include", "absolute", "value", "Gauss", "mean", "minimum", "maximum", "curvature", "which", "largest", "critical", "point", "peaks/divots", "peaks/divots", "ridges/valleys", "respectively", "we", "also", "include", "blur", "four", "level", "-lrb-", "0.01", "0.02", "0.04", "0.08", "-rrb-", "all", "property", "except", "HKS", "CurvRing", "geodesic", "Distance", "which", "already", "very", "smooth", "finally", "every", "property", "function", "property", "-lrb-", "-rrb-", "we", "include", "percentile", "transformation", "-lrb-", "-rrb-", "encode", "percentage", "vertex", "have", "smaller", "value", "within", "same", "mesh", "analyze", "how", "Schelling", "point", "associate", "property", "we", "calculate", "information", "theory", "statistics", "coverage", "plot", "estimate", "how", "well", "property", "distribution", "explain", "schelling", "distribution", "result", "representative", "set", "property", "function", "they", "show", "Table", "Figure", "Information", "Gain", "middle", "two", "column", "Table", "show", "information", "Gain", "-lrb-", "-rrb-", "function", "several", "property", "p.", "-lrb-", "-rrb-", "difference", "between", "entropy", "schelling", "point", "indicator", "function", "-lrb-", "-rrb-", "its", "average", "entropy", "condition", "discretized", "value", "property", "higher", "value", "information", "gain", "indicate", "stronger", "predictor", "schelling", "point", "location", "independent", "other", "property", "from", "result", "we", "see", "curvature", "strongest", "single", "cue", "feature", "point", "selection", "many", "Schelling", "point", "tip", "protrusion", "-lrb-", "finger", "toe", "-rrb-", "which", "have", "large", "positive", "minimum", "curvature", "few", "conspicuous", "saddle", "point", "-lrb-", "e.g.", "between", "finger", "-rrb-", "which", "have", "highly", "negative", "Gauss", "curvature", "other", "property", "commonly", "use", "feature", "point", "detection", "-lrb-", "e.g.", "Saliency", "HKS", "agd", "-rrb-", "also", "provide", "fairly", "good", "predictor", "Random", "Forest", "Importance", "rightmost", "two", "column", "Table", "show", "importance", "compute", "Random", "forest", "-lsb-", "Breiman", "2001", "-rsb-", "which", "estimate", "importance", "feature", "combination", "other", "build", "large", "number", "decision", "tree", "train", "different", "set", "property", "measure", "difference", "between", "prediction", "error", "without", "each", "property", "suggest", "indeed", "minimum", "curvature", "Gauss", "curvature", "most", "useful", "property", "predict", "Schelling", "point", "also", "suggest", "add", "value", "AGD", "HKS", "mean", "curvature", "other", "common", "property", "limit", "since", "redundant", "minimum", "Gauss", "curvature", "other", "hand", "importance", "global", "property", "symmetry", "sdf", "segment", "centeredness", "relatively", "high", "-lrb-", "84", "54", "33", "respectively", "-rrb-", "which", "suggest", "provide", "cue", "independent", "other", "property", "we", "note", "percentile", "-lrb-", "column", "-rrb-", "appear", "more", "useful", "predict", "Schelling", "point", "than", "raw", "geometric", "property", "value", "e.g.", "vertex", "have", "curvature", "higher", "than", "other", "same", "surface", "more", "likely", "schell", "point", "than", "one", "within", "any", "specific", "range", "value", "Coverage", "plot", "Figure", "show", "stack", "plot", "represent", "fraction", "Schelling", "point", "explain", "extrema", "different", "mesh", "property", "produce", "result", "we", "extract", "largest", "local", "maximum", "each", "property", "-lrb-", "14", "match", "average", "size", "point", "set", "collect", "we", "study", "-rrb-", "maximum", "spread", "least", "geodesic", "distance", "0.02", "use", "algorithm", "describe", "section", "each", "schelling", "point", "we", "consider", "surface", "property", "order", "from", "bottom", "top", "mark", "property", "vote", "first", "have", "one", "its", "largest", "local", "maximum", "within", "0.05", "after", "all", "vote", "cast", "-lrb-", "one", "each", "schelling", "point", "each", "mesh", "-rrb-", "we", "average", "vote", "per", "mesh", "average", "fraction", "per", "class", "-lrb-", "show", "first", "19", "bar", "Figure", "-rrb-", "finally", "average", "those", "fraction", "get", "result", "entire", "datum", "set", "-lrb-", "show", "bar", "label", "overall", "far", "right", "-rrb-", "result", "suggest", "extrema", "minimum", "curvature", "explain", "56.7", "Schelling", "point", "-lrb-", "bottom", "blue", "region", "rightmost", "bar", "-rrb-", "remain", "schelling", "point", "6.7", "explain", "Gauss", "curvature", "-lrb-", "red", "-rrb-", "9.1", "one", "still", "remain", "explain", "symmetry", "-lrb-", "irsa", "-rrb-", "so", "please", "note", "variation", "result", "different", "object", "class", "curvature", "measure", "almost", "completely", "sufficient", "explain", "Schelling", "point", "airplane", "example", "symmetry", "segment", "centeredness", "more", "helpful", "property", "explain", "Schelling", "point", "teddy", "bear", "interestingly", "approximately", "11", "Schelling", "point", "describe", "strongest", "local", "maximum", "any", "property", "consider", "examine", "those", "point", "visually", "we", "find", "tend", "reside", "either", "semantic", "feature", "off-center", "smooth", "surface", "-lrb-", "e.g.", "eye", "teddy", "bear", "-rrb-", "and/or", "geometric", "feature", "do", "appear", "among", "strongest", "maximum", "-lrb-", "e.g.", "knee", "elbow", "when", "appendage", "bent", "-rrb-", "perhaps", "other", "geometric", "property", "could", "discover", "explain", "remain", "point", "future", "work", "ACM", "transaction", "Graphics", "Vol", "31", "no.", "Article", "29", "publication", "date", "July", "2012", "Schelling", "Points", "3D", "surface", "mesh", "29:5", "-lrb-", "-rrb-", "consistency", "point", "select", "-lrb-", "-rrb-", "consistency", "point", "select", "different", "people", "same", "mesh", "people", "mesh", "same", "object", "class", "figure", "consistency", "point", "collect", "we", "study", "plot", "show", "cumulative", "distribution", "normalize", "distance", "from", "each", "point", "closest", "point", "another", "point", "set", "different", "color", "curve", "depict", "average", "different", "subset", "point", "thick", "black", "curve", "represent", "overall", "average", "all", "point", "thin", "colored", "one", "separate", "point", "base", "order", "which", "be", "select", "during", "interactive", "session", "consistency", "first", "point", "select", "show", "top", "red", "curve", "point", "2-3", "show", "purple", "point", "4-7", "blue", "etc.", "note", "average", "normalize", "edge", "length", "mesh", "0.013", "normalize", "distance", "threshold", "use", "call", "point", "consistent", "we", "analysis", "0.05", "-rrb-", "consistency", "point", "select", "same", "person", "symmetric", "side", "mesh", "ACM", "transaction", "Graphics", "Vol", "31", "no.", "Article", "29", "publication", "date", "July", "2012", "29:6", "X.", "Chen", "et", "al.", "Figure", "histogram", "spacing", "between", "point", "collect", "different", "mesh", "category", "distance", "list", "fraction", "square", "root", "mesh", "area", "Red", "line", "show", "average", "Figure", "schelling", "point", "most", "often", "center", "segment", "-lrb-", "far", "right", "plot", "-rrb-", "ACM", "transaction", "Graphics", "Vol", "31", "no.", "Article", "29", "publication", "date", "July", "2012", "Schelling", "Points", "3D", "surface", "mesh", "29:7", "property", "best", "Filter", "Info", "Gain", "Importance", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-lrb-", "-rrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-lrb-", "-rrb-", "-rrb-", "MinCurv", "-lrb-", "-lrb-", "-rrb-", "-rrb-", "195", "203", "216", "801", "GaussCurv", "201", "211", "59", "267", "symmetry", "-lrb-", "-rrb-", "12", "25", "18", "84", "sdf", "17", "26", "31", "54", "segcenter", "-lrb-", "-rrb-", "24", "43", "15", "33", "hk", "-lrb-", "101", "-rrb-", "104", "141", "15", "31", "saliency", "-lrb-", "0.3", "-rrb-", "48", "85", "26", "30", "maxcurv", "-lrb-", "-rrb-", "53", "99", "19", "30", "zposition", "20", "51", "29", "27", "znormal", "11", "14", "24", "25", "meancurv", "-lrb-", "-rrb-", "43", "98", "11", "23", "CurvDiff", "29", "46", "22", "21", "agd", "25", "85", "18", "18", "property", "best", "Filter", "Info", "Gain", "Importance", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-lrb-", "-rrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-lrb-", "-rrb-", "-rrb-", "MinCurv", "-lrb-", "-lrb-", "-rrb-", "-rrb-", "195203216801", "GaussCurv", "201", "211", "59", "267", "symmetry", "-lrb-", "-rrb-", "12", "25", "18", "84", "sdf", "17", "26", "31", "54", "segcenter", "-lrb-", "-rrb-", "24", "43", "15", "33", "hk", "-lrb-", "101", "-rrb-", "104", "141", "15", "31", "saliency", "-lrb-", "0.3", "-rrb-", "48", "85", "26", "30", "maxcurv", "-lrb-", "-rrb-", "53", "99", "19", "30", "zposition", "20", "51", "29", "27", "znormal", "11", "14", "24", "25", "meancurv", "-lrb-", "-rrb-", "43", "98", "11", "23", "CurvDiff", "29", "46", "22", "21", "agd", "25", "85", "18", "18", "Table", "Information", "gain", "-lrb-", "x1000", "-rrb-", "random", "forest", "importance", "mesh", "property", "-lrb-", "row", "-rrb-", "predict", "schelling", "point", "distribution", "represent", "property", "value", "best", "filter", "find", "-lrb-", "-rrb-", "gaussian", "blur", "-lrb-", "-rrb-", "its", "percentile", "within", "mesh", "-lrb-", "-rrb-", "information", "gain", "-lrb-", "-rrb-", "estimate", "importance", "analysis", "Random", "forest", "Figure", "Stackplot", "show", "fraction", "schell", "point", "first", "explain", "extrema", "each", "property", "consider", "order", "show", "bottom", "top", "prediction", "Schelling", "Distributions", "section", "we", "investigate", "whether", "possible", "predict", "mesh", "saliency", "use", "datum", "collect", "we", "study", "mesh", "never", "see", "before", "we", "aim", "provide", "method", "estimate", "probability", "person", "would", "have", "select", "each", "vertex", "mesh", "be", "include", "we", "study", "i.e.", "predict", "schelling", "point", "distribution", "-lrb-", "-rrb-", "transfer", "simple", "method", "approach", "problem", "would", "transfer", "Schelling", "point", "from", "other", "similar", "mesh", "which", "AMT", "datum", "have", "be", "collect", "give", "new", "mesh", "we", "could", "select", "set", "similar", "mesh", "from", "collect", "schelling", "point", "datum", "set", "compute", "map", "-lrb-", "-rrb-", "from", "each", "vertex", "corresponding", "vertex", "-lrb-", "-rrb-", "each", "similar", "mesh", "predict", "transfer", "schelling", "point", "distribution", "-lrb-", "-rrb-", "vertex", "aggregate", "schelling", "point", "map", "from", "other", "mesh", "-lrb-", "-rrb-", "1/k", "-lrb-", "-lrb-", "-rrb-", "-rrb-", "method", "very", "simple", "however", "work", "well", "only", "when", "accurate", "map", "can", "compute", "when", "two", "mesh", "have", "same", "number", "Schelling", "point", "same", "exact", "arrangement", "neither", "which", "often", "case", "regression", "second", "method", "build", "regression", "model", "base", "geometric", "property", "surface", "give", "training", "set", "mesh", "collect", "Schelling", "point", "we", "compute", "geometric", "property", "list", "section", "-lrb-", "Gauss", "curvature", "etc.", "-rrb-", "every", "vertex", "every", "mesh", "training", "set", "learn", "model", "relate", "those", "property", "schelling", "point", "indicator", "function", "-lrb-", "-rrb-", "model", "simple", "implement", "since", "consider", "each", "vertex", "mesh", "independently", "can", "apply", "arbitrary", "new", "surface", "we", "implementation", "build", "regression", "model", "base", "m5p", "regression", "tree", "provide", "Weka", "-lsb-", "Witten", "Frank", "2005", "-rsb-", "-rrb-", "model", "build", "decision", "tree", "take", "training", "set", "vertex", "label", "property", "describe", "previous", "section", "along", "observe", "value", "schelling", "point", "distribution", "vertex", "analyze", "datum", "build", "binary", "tree", "split", "feature", "space", "distinct", "region", "fit", "linear", "regression", "model", "-lrb-", "-rrb-", "each", "region", "independently", "choose", "we", "study", "because", "can", "fit", "non-linear", "relationship", "between", "input", "output", "variable", "-lrb-", "piecewise", "linear", "-rrb-", "provide", "explanation", "how", "model", "operate", "-lrb-", "decision", "tree", "-rrb-", "which", "much", "easier", "decipher", "than", "most", "other", "regression", "model", "example", "figure", "show", "top", "node", "m5p", "regression", "tree", "learn", "we", "system", "when", "train", "sample", "datum", "teddy", "bear", "examine", "tree", "interesting", "note", "top", "few", "level", "split", "take", "account", "different", "property", "minimum", "curvature", "symmetry", "segmentation", "centerness", "shape", "diameter", "saliency", "etc.", "also", "different", "derive", "property", "utilize", "percentile", "more", "often", "choose", "split", "decision", "tree", "value", "derivative", "more", "often", "choose", "linear", "equation", "leaf", "node", "overall", "tree", "suggest", "several", "type", "property", "can", "combine", "make", "better", "prediction", "than", "any", "one", "alone", "course", "nothing", "we", "study", "dependent", "particular", "choice", "regression", "model", "we", "believe", "several", "other", "alternative", "could", "have", "be", "use", "just", "effectively", "result", "evaluate", "compare", "how", "effectively", "transfer", "regression", "method", "work", "we", "perform", "series", "leave-one-out", "experiment", "where", "we", "utilize", "Schelling", "point", "collect", "from", "people", "all", "one", "mesh", "predict", "schelling", "point", "distribution", "one", "hold", "out", "we", "evaluate", "quality", "prediction", "comparison", "schelling", "point", "datum", "collect", "mesh", "evaluation", "perform", "compute", "information", "gain", "between", "predict", "actual", "point", "set", "distribution", "Table", "first", "test", "we", "use", "vertex-to-vertex", "map", "transfer", "Schelling", "point", "hold", "out", "mesh", "from", "other", "mesh", "same", "object", "class", "map", "be", "construct", "two", "different", "method", "-rrb-", "manually", "interpolate", "human-selected", "landmark", "corre", "ACM", "transaction", "Graphics", "Vol", "31", "no.", "Article", "29", "publication", "date", "July", "2012", "29:8", "X.", "Chen", "et", "al.", "Figure", "top", "node", "m5p", "regression", "tree", "learn", "from", "schell", "point", "teddy", "bear", "spondence", "-lrb-", "truemap", "-rrb-", "-rrb-", "automatically", "use", "Blended", "Intrinsic", "Maps", "-lsb-", "Kim", "et", "al.", "2011", "-rsb-", "-lrb-", "blendedmap", "-rrb-", "both", "case", "we", "consider", "case", "where", "point", "transfer", "from", "just", "most", "similar", "mesh", "compute", "geodesic", "d2", "shap", "descriptor", "-lrb-", "closest", "-rrb-", "where", "transfer", "aggregate", "from", "all", "mesh", "same", "object", "class", "-lrb-", "inclass", "-rrb-", "result", "test", "average", "over", "all", "380", "mesh", "show", "top", "four", "row", "Table", "suggest", "transfer", "point", "do", "work", "well", "general", "many", "class", "object", "-lrb-", "e.g.", "fish", "vase", "chair", "airplane", "bird", "etc.", "-rrb-", "different", "mesh", "have", "different", "arrangement", "part", "account", "failure", "even", "TrueMap", "other", "class", "-lrb-", "e.g.", "ant", "hand", "etc.", "-rrb-", "compute", "semantically", "correct", "map", "between", "mesh", "difficult", "account", "worse", "performance", "blendedmap", "second", "test", "we", "use", "regression", "tree", "learn", "from", "schell", "point", "subset", "mesh", "predict", "-lrb-", "-rrb-", "other", "we", "execute", "two", "experiment", "differ", "how", "training", "set", "be", "choose", "first", "experiment", "-lrb-", "inclass", "-rrb-", "regression", "tree", "be", "build", "leave-one-out", "style", "use", "training", "datum", "from", "mesh", "same", "class", "i.e.", "model", "train", "19", "out", "20", "mesh", "each", "object", "class", "test", "20th", "-lrb-", "-lsb-", "Kalogerakis", "et", "al.", "2010", "-rsb-", "-rrb-", "second", "experiment", "-lrb-", "outclass", "-rrb-", "regression", "tree", "each", "mesh", "train", "only", "use", "datum", "from", "mesh", "other", "object", "class", "result", "study", "show", "Table", "suggest", "regression", "significantly", "outperform", "transfer", "algorithm", "datum", "set", "even", "when", "training", "perform", "only", "example", "from", "different", "object", "class", "also", "show", "regression", "model", "combine", "many", "surface", "property", "outperform", "any", "single", "property", "i.e.", "highest", "information", "gain", "achieve", "any", "single", "property", "-lrb-", "gausscurvature", "-rrb-", "0.211", "-lrb-", "second", "row", "Table", "-rrb-", "comparison", "0.257", "-lrb-", "outclass", "-rrb-", "0.341", "-lrb-", "inclass", "-rrb-", "achieve", "regression", "visualization", "schelling", "point", "distribution", "predict", "regression", "model", "train", "InClass", "show", "Figure", "mesh", "color", "scheme", "same", "Figure", "facilitate", "direct", "visual", "comparison", "from", "image", "-lrb-", "other", "provide", "supplemental", "material", "-rrb-", "we", "see", "learn", "model", "precise", "actual", "Schelling", "distribution", "however", "predict", "tip", "protrusion", "well", "-lrb-", "corner", "airplane", "-rrb-", "well", "some", "subtle", "feature", "-lrb-", "e.g.", "center", "eyeglass", "eye", "bust", "belly", "button", "teddy", "bear", "etc.", "-rrb-", "difficult", "recognize", "threshold", "any", "single", "surface", "property", "TrueMaps", "consider", "only", "didactic", "purpose", "since", "enter", "manually", "could", "use", "automatic", "prediction", "system", "ACM", "transaction", "Graphics", "Vol", "31", "no.", "Article", "29", "publication", "date", "July", "2012", "Schelling", "Points", "3D", "surface", "mesh", "29:9", "prediction", "source", "best", "Filter", "Info", "Method", "-lrb-", "-rrb-", "datum", "-lrb-", "-rrb-", "gain", "PredictMap", "Closest", "-lrb-", "blur", "-lrb-", "-rrb-", "-rrb-", "70", "InClass", "-lrb-", "blur", "-lrb-", "-rrb-", "-rrb-", "105", "TrueMap", "Closest", "-lrb-", "blur", "-lrb-", "-rrb-", "-rrb-", "160", "InClass", "-lrb-", "blur", "-lrb-", "-rrb-", "-rrb-", "236", "regression", "OutClass", "Blur", "-lrb-", "-rrb-", "257", "InClass", "Blur", "-lrb-", "-rrb-", "341", "prediction", "source", "best", "Filter", "Info", "Method", "-lrb-", "-rrb-", "datum", "-lrb-", "-rrb-", "gain", "PredictMap", "Closest", "-lrb-", "blur", "-lrb-", "-rrb-", "-rrb-", "70", "InClass", "-lrb-", "blur", "-lrb-", "-rrb-", "-rrb-", "105", "TrueMap", "Closest", "-lrb-", "blur", "-lrb-", "-rrb-", "-rrb-", "160", "InClass", "-lrb-", "blur", "-lrb-", "-rrb-", "-rrb-", "236", "regression", "OutClass", "Blur", "-lrb-", "-rrb-", "257", "InClass", "Blur", "-lrb-", "-rrb-", "341", "Table", "Information", "gain", "-lrb-", "x1000", "-rrb-", "schelling", "point", "prediction", "Figure", "visualization", "schelling", "point", "distribution", "predict", "we", "algorithm", "after", "training", "property", "different", "mesh", "same", "object", "class", "-lrb-", "inclass", "-rrb-", "prediction", "Schelling", "Points", "many", "application", "important", "only", "estimate", "mesh", "saliency", "also", "extract", "discrete", "set", "salient", "feature", "point", "example", "surface", "matching", "algorithm", "often", "detect", "set", "feature", "search", "correspondence", "between", "they", "successful", "algorithm", "require", "set", "feature", "point", "have", "many", "property", "schelling", "point", "stability", "spacing", "symmetry", "etc.", "many", "algorithm", "possible", "address", "problem", "include", "one", "perform", "combinatorial", "optimization", "over", "possible", "candidate", "set", "choose", "one", "maximize", "some", "objective", "function", "however", "purpose", "study", "we", "choose", "simple", "greedy", "algorithm", "have", "be", "use", "several", "other", "saliency", "experiment", "-lrb-", "e.g.", "-lsb-", "Shilane", "Funkhouser", "2007", "-rsb-", "-rrb-", "algorithm", "aim", "select", "set", "vertex", "-lcb-", "-rcb-", "maximize", "sum", "-lrb-", "-rrb-", "select", "vertex", "subject", "constraint", "two", "vertex", "-lcb-", "-rcb-", "too", "close", "one", "another", "do", "so", "sort", "vertex", "from", "highest", "-lrb-", "-rrb-", "lowest", "repeatedly", "select", "next", "vertex", "remain", "whose", "position", "closer", "than", "normalize", "geodesic", "distance", "threshold", "any", "previously", "select", "vertex", "-lrb-", "0.05", "-rrb-", "process", "avoid", "select", "many", "point", "near", "one", "another", "mesh", "provide", "easy", "way", "reduce", "point", "set", "size", "increase", "distance", "threshold", "terminate", "greedy", "search", "after", "give", "number", "have", "be", "select", "result", "investigate", "how", "effectively", "algorithm", "can", "predict", "Schelling", "point", "we", "perform", "analysis", "similarity", "automatically", "generate", "point", "set", "one", "collect", "from", "people", "analysis", "we", "extract", "14", "point", "each", "mesh", "-lrb-", "even", "number", "closest", "median", "point", "set", "collect", "from", "people", "-rrb-", "follow", "general", "methodology", "describe", "section", "5a", "we", "measure", "distance", "from", "point", "we", "automatically", "extract", "point", "set", "schellling", "point", "same", "mesh", "plot", "cumulative", "distribution", "respect", "increase", "normalize", "distance", "threshold", "comparison", "sake", "we", "consider", "point", "set", "extract", "same", "algorithm", "from", "maximum", "every", "surface", "property", "consider", "section", "we", "consider", "point", "set", "transfer", "from", "schell", "point", "other", "mesh", "within", "same", "class", "use", "mapping", "algorithm", "describe", "section", "Figure", "show", "result", "Figure", "3a", "horizontal", "axis", "contain", "increase", "distance", "threshold", "vertical", "axis", "show", "consistency", "use", "cumulative", "distribution", "point", "pair", "whose", "normalize", "geodesic", "distance", "less", "than", "red", "curve", "top", "represent", "consistency", "between", "Schelling", "point", "collect", "from", "people", "point", "set", "extract", "automatically", "from", "distribution", "predict", "regression", "use", "InClass", "training", "lower", "curve", "represent", "best", "point", "set", "generate", "other", "method", "result", "suggest", "point", "select", "we", "algorithm", "from", "distribution", "learn", "regression", "use", "InClass", "training", "closer", "Schelling", "point", "collect", "we", "study", "than", "those", "predict", "other", "method", "we", "also", "find", "slightly", "more", "consistent", "Schelling", "point", "than", "average", "point", "set", "collect", "from", "people", "suggest", "regression", "point", "extraction", "algorithm", "predict", "schelling", "point", "set", "effectively", "relate", "surface", "property", "schelling", "point", "location", "Figure", "consistency", "between", "Schelling", "point", "point", "set", "extract", "different", "algorithm", "validation", "Controlled", "user", "study", "final", "test", "we", "investigate", "impact", "collect", "datum", "via", "Amazaon", "mechanical", "Turk", "-lrb-", "AMT", "-rrb-", "main", "conclusion", "we", "study", "although", "AMT", "become", "common", "platform", "perceptual", "experiment", "computer", "graphic", "-lrb-", "e.g.", "-lsb-", "Cole", "et", "al.", "2009", "-rsb-", "-rrb-", "several", "study", "validate", "AMT", "study", "laboratory", "-lrb-", "e.g.", "-lsb-", "Heer", "Bostock", "2010", "-rsb-", "-rrb-", "valuable", "ask", "whether", "datum", "we", "gather", "from", "AMT", "representative", "which", "would", "collect", "from", "controlled", "group", "participant", "laboratory", "environment", "course", "practical", "duplicate", "AMT", "experiment", "exactly", "laboratory", "since", "would", "take", "hundred", "-lrb-", "possibly", "thousand", "-rrb-", "hour", "collect", "equivalent", "amount", "datum", "stead", "we", "run", "small", "study", "which", "we", "recruit", "30", "volunteer", "through", "email", "inquiry", "acquaintence", "student", "unfamiliar", "we", "project", "volunteer", "20", "be", "male", "10", "be", "female", "span", "range", "age", "be", "20", "year", "old", "16", "-lrb-", "2130", "-rrb-", "-lrb-", "31-40", "-rrb-", "-lrb-", "41-50", "-rrb-", "-lrb-", "51-60", "-rrb-", "-lrb-", "60", "-rrb-", "all", "except", "four", "self-evaluate", "have", "least", "plenty", "experience", "computer", "only", "report", "have", "plenty", "experience", "graphic", "every", "participant", "perform", "study", "Windows", "computer", "3-button", "mouse", "we", "ask", "each", "participant", "select", "point", "19", "mesh", "-lrb-", "one", "select", "randomly", "from", "each", "object", "category", "-rrb-", "exact", "same", "instruction", "user", "interface", "provide", "AMT", "-lrb-", "substitute", "incentive", "gain", "point", "selection", "consistent", "other", "rather", "than", "higher", "monetary", "payment", "-rrb-", "after", "completion", "partipant", "complete", "exit", "survey", "which", "25", "respond", "yes", "mostly", "question", "ask", "whether", "complete", "task", "satisfaction", "we", "reject", "datum", "from", "other", "user", "leave", "474", "point", "set", "from", "25", "participant", "those", "354", "-lrb-", "74.7", "-rrb-", "pass", "all", "three", "datum", "filter", "66", "-lrb-", "13.9", "-rrb-", "have", "too", "few", "point", "23", "-lrb-", "4.9", "-rrb-", "be", "enter", "too", "little", "camera", "motion", "31", "-lrb-", "6.5", "-rrb-", "be", "click", "too", "hastily", "significantly", "lower", "rejection", "rate", "than", "datum", "collect", "AMT", "analyze", "point", "set", "pass", "all", "filter", "we", "find", "closely", "match", "characteristic", "datum", "collect", "AMT", "particular", "distribution", "distance", "indicate", "consistency", "point", "select", "different", "people", "same", "mesh", "-lrb-", "figure", "10a", "-rrb-", "reflective", "symmetry", "point", "select", "same", "user", "same", "mesh", "almost", "identical", "those", "collect", "AMT", "same", "set", "mesh", "-lrb-", "figure", "10b", "-rrb-", "course", "enough", "datum", "study", "consistency", "across", "different", "mesh", "same", "class", "study", "variation", "within", "specific", "subset", "object", "however", "all", "statistics", "compute", "small", "controlled", "datum", "set", "closely", "match", "those", "larger", "AMT", "datum", "set", "ACM", "transaction", "Graphics", "Vol", "31", "no.", "Article", "29", "publication", "date", "July", "2012", "29:10", "X.", "Chen", "et", "al.", "Figure", "10", "comparison", "consistency", "symmetry", "point", "set", "collect", "small", "controlled", "study", "-lrb-", "left", "-rrb-", "versus", "one", "collect", "from", "people", "Amazon", "mechanical", "Turk", "-lrb-", "right", "-rrb-", "-lrb-", "-rrb-", "top", "row", "show", "consistency", "point", "select", "different", "people", "same", "mesh", "-lrb-", "like", "Figure", "3a", "-rrb-", "-lrb-", "-rrb-", "bottom", "row", "show", "consistency", "point", "select", "same", "person", "symmetric", "side", "mesh", "-lrb-", "like", "Figure", "3c", "-rrb-", "Figure", "11", "predict", "schelling", "distribution", "-lrb-", "left", "-rrb-", "can", "use", "preserve", "salient", "detail", "during", "mesh", "simplfication", "conclusion", "paper", "we", "have", "describe", "study", "Schelling", "point", "3d", "mesh", "i.e.", "point", "people", "expect", "select", "other", "people", "on-line", "experiment", "we", "gather", "9,965", "point", "set", "contain", "total", "201,304", "point", "during", "both", "qualitative", "quantitative", "analysis", "we", "find", "point", "appear", "mainly", "semantically", "stable", "position", "3d", "mesh", "e.g.", "extrema", "curvature", "axis", "symmetry", "center", "segment", "etc.", "we", "also", "find", "select", "fairly", "consistently", "different", "people", "same", "mesh", "slightly", "less", "so", "different", "mesh", "same", "object", "class", "however", "select", "very", "consistently", "symmetric", "part", "within", "same", "mesh", "we", "have", "use", "datum", "train", "algorithm", "predict", "distribution", "schelling", "point", "new", "mesh", "use", "algorithm", "feature", "point", "detection", "saliency", "measure", "produce", "we", "method", "could", "use", "variety", "application", "computer", "graphic", "-lrb-", "e.g.", "-lsb-", "Alexa", "2000", "Funkhouser", "Shilane", "2006", "Johnson", "2000", "Katz", "et", "al.", "2005", "Lee", "et", "al.", "2005", "Zhang", "et", "al.", "2005", "-rsb-", "-rrb-", "example", "Figure", "11", "show", "how", "predict", "schelling", "distribution", "can", "guide", "mesh", "simplification", "algorithm", "preserve", "feature", "higher", "expect", "semantic", "salience", "-lrb-", "-lsb-", "Lee", "et", "al.", "2005", "-rsb-", "-rrb-", "case", "quadric", "error", "use", "qslim", "-lsb-", "Garland", "Heckbert", "1997", "-rsb-", "be", "scale", "learn", "regression", "from", "InClass", "example", "note", "how", "detail", "better", "preserve", "salient", "area", "we", "study", "just", "first", "step", "thus", "have", "several", "limitation", "suggest", "topic", "future", "work", "first", "consider", "only", "watertight", "mesh", "relatively", "smooth", "feature", "therefore", "some", "finding", "regard", "local", "geometric", "feature", "may", "generalize", "polygon-soup", "model", "commonly", "find", "computer", "graphic", "repository", "second", "consider", "only", "point", "feature", "study", "line", "region", "feature", "would", "also", "valuable", "Third", "study", "geometric", "surface", "property", "collect", "datum", "future", "work", "could", "study", "other", "aspect", "datum", "include", "time-dependent", "strategy", "people", "use", "select", "feature", "point", "finally", "focus", "only", "application", "computer", "graphic", "-lrb-", "mesh", "saliency", "feature", "point", "detection", "-rrb-", "future", "work", "might", "consider", "question", "perceptual", "psychology", "ACM", "transaction", "Graphics", "Vol", "31", "no.", "Article", "29", "publication", "date", "July", "2012", "Schelling", "Points", "3D", "surface", "mesh", "29:11", "acknowledgment", "we", "thank", "Doug", "DeCarlo", "introduce", "we", "work", "Thomas", "Schelling", "Maneesh", "Singh", "useful", "discussion", "during", "early", "phase", "project", "we", "also", "thank", "Daniela", "Giorgi", "AIM@SHAPE", "access", "SHREC", "2007", "Watertight", "model", "Evangelos", "Kalogerakis", "use", "shape", "feature", "extraction", "code", "finally", "we", "thank", "nsf", "-lrb-", "ccf-0937139", "cns-0831374", "-rrb-", "Intel", "-lrb-", "ISTC-VC", "-rrb-", "Adobe", "Google", "partial", "funding", "project", "reference", "lexa", "M.", "2000", "merge", "polyhedral", "shape", "scatter", "feature", "visual", "computer", "16", "26", "37", "MAZON", "2009", "mechanical", "turk", "http://www.mturk.com", "ttneave", "F.", "1954", "some", "informational", "aspect", "visual", "perception", "psychological", "review", "61", "REIMAN", "L.", "2001", "Random", "forest", "machine", "Learning", "45", "32", "ronstein", "a.", "ronstein", "m.", "IMMEL", "R.", "2006", "Generalized", "multidimensional", "scaling", "framework", "isometryinvariant", "partial", "surface", "matching", "Proceedings", "National", "Academy", "Science", "1168", "1172", "ronstein", "a.", "ronstein", "M.", "USTOS", "B.", "ASTELLANI", "U.", "RISANI", "M.", "ALCIDIENO", "B.", "UIBAS", "L.", "OKKINOS", "I.", "URINO", "V.", "VSJANIKOV", "M.", "atane", "G.", "ipiran", "i.", "pagnuolo", "m.", "UN", "J.", "2010", "SHREC", "2011", "robust", "feature", "detection", "description", "benchmark", "Eurographics", "Workshop", "3D", "Object", "Retrieval", "astellanus", "U.", "RISTANI", "M.", "ANTONI", "S.", "URINO", "V.", "2008", "sparse", "point", "match", "combine", "3d", "mesh", "saliency", "statistical", "descriptor", "Computer", "Graphics", "Forum", "27", "643", "652", "hen", "X.", "OLOVINSKIY", "a.", "unkhouser", "t.", "2009", "benchmark", "3d", "mesh", "segmentation", "ACM", "transaction", "graphic", "-lrb-", "Proc", "SIGGRAPH", "-rrb-", "28", "-lrb-", "Aug.", "-rrb-", "hua", "C.", "ARVIS", "R.", "1996", "point", "signature", "new", "representation", "3d", "object", "recognition", "International", "Journal", "Computer", "Vision", "25", "63", "85", "ole", "F.", "OLOVINSKIY", "a.", "impaecher", "a.", "arro", "H.", "S.", "inkelstein", "a.", "unkhouser", "T.", "usinkiewicz", "S.", "2008", "where", "do", "people", "draw", "line", "ACM", "transaction", "graphic", "-lrb-", "Proc", "SIGGRAPH", "-rrb-", "27", "-lrb-", "Aug.", "-rrb-", "ole", "F.", "anik", "K.", "ARLO", "D.", "inkelstein", "a.", "unkhouser", "T.", "anish", "ingh", "S.", "R.", "2009", "how", "well", "do", "line", "drawing", "depict", "shape", "ACM", "transaction", "graphic", "-lrb-", "Proc", "SIGGRAPH", "-rrb-", "28", "-lrb-", "Aug.", "-rrb-", "unkhouser", "T.", "HILANE", "P.", "2006", "partial", "matching", "3d", "shape", "priority-driven", "search", "Symposium", "Geometry", "Processing", "AL", "R.", "ohen", "D.", "2006", "salient", "geometric", "feature", "partial", "shape", "matching", "similarity", "ACM", "Transaction", "Graphics", "-lrb-", "January", "-rrb-", "arland", "m.", "eckbert", "P.", "S.", "1997", "surface", "simplification", "use", "quadric", "error", "metric", "Proceedings", "SIGGRAPH", "1997", "Computer", "Graphics", "Proceedings", "annual", "Conference", "Series", "209", "216", "iorgus", "D.", "IASOTTI", "S.", "araboschus", "L.", "2007", "SHREC", "shape", "REtrieval", "Contest", "Watertight", "model", "track", "http://watertight.ge.imati.cnr.it/", "eer", "J.", "OSTOCK", "M.", "2010", "crowdsource", "graphical", "perception", "use", "mechanical", "Turk", "assess", "visualization", "design", "ACM", "Human", "factor", "Computing", "Systems", "-lrb-", "CHI", "-rrb-", "203", "212", "isada", "m.", "elyaev", "a.", "UNII", "T.", "2002", "skeletonbased", "approach", "detection", "perceptually", "salient", "feature", "polygonal", "surface", "Computer", "Graphics", "Forum", "21", "689", "700", "OFFMAN", "D.", "D.", "INGH", "M.", "1997", "salience", "visual", "part", "vol", "63", "uang", "T.", "HENG", "K.", "HUANG", "Y.", "2009", "collaborative", "benchmark", "region", "interest", "detection", "algorithm", "296", "303", "tti", "L.", "OCH", "C.", "EIBUR", "E.", "1998", "model", "saliencybased", "visual", "attention", "rapid", "scene", "analysis", "IEEE", "transaction", "Pattern", "Analysis", "Machine", "Intelligence", "20", "11", "1254", "1259", "ohnson", "a.", "2000", "surface", "landmark", "selection", "matching", "natural", "terrain", "IEEE", "Conference", "Computer", "Vision", "Pattern", "recognition", "-lrb-", "cvpr", "-rrb-", "vol", "413", "420", "use", "saliency", "choose", "spin", "image", "ALOGERAKIS", "E.", "ERTZMANN", "a.", "ingh", "K.", "2010", "Learning", "3d", "mesh", "segmentation", "labeling", "ACM", "transaction", "graphic", "-lrb-", "proc", "SIGGRAPH", "-rrb-", "29", "ATZ", "S.", "EIFMAN", "G.", "al", "a.", "2005", "mesh", "segmentation", "use", "feature", "point", "core", "extraction", "visual", "computer", "-lrb-", "September", "-rrb-", "IM", "Y.", "ARSHNEY", "a.", "ADN", "ranc", "ois", "uimbretus", "re", "D.", "J.", "2010", "mesh", "saliency", "human", "eye", "fixation", "ACM", "transaction", "Applied", "Perception", "-lrb-", "February", "-rrb-", "IM", "V.", "IPMAN", "Y.", "unkhouser", "t.", "2011", "blended", "intrinsic", "map", "ACM", "transaction", "graphic", "-lrb-", "SIGGRAPH", "2011", "-rrb-", "-lrb-", "jul", "-rrb-", "B.", "be", "J.", "2006", "object-of-interest", "image", "segmentation", "base", "human", "attention", "semantic", "region", "clustering", "Opt", "Soc", "be", "opt", "image", "Sci", "Vis", "23", "10", "-lrb-", "October", "-rrb-", "2462", "2470", "OCH", "C.", "LLMAN", "S.", "1985", "shift", "selective", "visual", "attention", "towards", "underlie", "neural", "circuitry", "human", "Neurobiology", "219", "227", "RAEVOY", "V.", "heffer", "a.", "2004", "cross-parameterization", "compatible", "remeshing", "3d", "model", "ACM", "transaction", "graphic", "-lrb-", "Proc", "SIGGRAPH", "-rrb-", "23", "861", "869", "ee", "C.", "H.", "ARSHNEY", "a.", "ACOBS", "D.", "W.", "2005", "mesh", "saliency", "ACM", "transaction", "graphic", "-lrb-", "SIGGRAPH", "2005", "-rrb-", "-lrb-", "aug", "-rrb-", "ewi", "D.", "1969", "Convention", "Philosophical", "Study", "Harvard", "University", "Press", "X.", "USKOV", "I.", "2005", "multi-scale", "feature", "approximate", "alignment", "point-based", "surface", "Symposium", "Geometry", "Processing", "X.", "USKOV", "I.", "2007", "3d", "object", "recognition", "from", "range", "image", "use", "pyramid", "matching", "Workshop", "3D", "Representation", "recognition", "-lrb-", "3drr", "-rrb-", "ipman", "Y.", "unkhouser", "t.", "2009", "Mobius", "voting", "surface", "correspondence", "ACM", "transaction", "graphic", "-lrb-", "SIGGRAPH", "2009", "-rrb-", "-lrb-", "August", "-rrb-", "ilane", "R.", "ECHSLER", "H.", "il", "S.", "OST", "J.", "UN", "T.", "1994", "integration", "bottom-up", "top-down", "cue", "visual", "attention", "use", "non-linear", "relaxation", "IEEE", "Computer", "Vision", "Pattern", "recognition", "781", "785", "oreel", "P.", "erona", "P.", "2007", "evaluation", "feature", "detector", "descriptor", "base", "3d", "object", "ijcv", "73", "-lrb-", "July", "-rrb-", "263", "284", "ovotnus", "M.", "EGENER", "P.", "LEIN", "R.", "2005", "correspondence", "generation", "matching", "3d", "shape", "subpart", "Tech", "Rep.", "CG-2005-2", "Universit?t", "Bonn", "June", "arker", "P.", "2011", "Webster?s", "On-line", "Dictionary", "Rosetta", "Edition", "http://www.websters-online-dictionary.org", "rivitera", "C.", "TARK", "L.", "2000", "algorithm", "define", "visual", "regions-of-interest", "comparison", "eye", "fixation", "PAMI", "22", "-lrb-", "September", "-rrb-", "970", "982", "osenholtz", "R.", "1999", "simple", "saliency", "model", "predict", "num", "ber", "motion", "popout", "phenomenon", "Vision", "Research", "39", "19", "3157", "3163", "usinkiewicz", "S.", "2004", "estimate", "curvature", "derivative", "triangle", "mesh", "Symposium", "3D", "Data", "Processing", "visualization", "Transmission", "antellum", "a.", "arlo", "D.", "2004", "robust", "clustering", "eye", "movement", "recording", "quantification", "visual", "interest", "Eye", "Tracking", "Research", "application", "-lrb-", "etra", "-rrb-", "27", "34", "CHELLING", "T.", "1960", "Strategy", "Conflict", "Harvard", "University", "Press", "chlattmann", "M.", "EGENER", "P.", "LEIN", "R.", "2008", "Scale", "space", "base", "feature", "point", "detection", "surface", "Journal", "WSCG", "16", "-lrb-", "February", "-rrb-", "chmid", "C.", "OHR", "R.", "AUCKHAGE", "C.", "2000", "evaluation", "interest", "point", "detector", "ijcv", "37", "-lrb-", "June", "-rrb-", "151", "172", "ebe", "N.", "EW", "M.", "2003", "compare", "salient", "point", "detector", "pattern", "recognition", "letter", "24", "1-3", "-lrb-", "January", "-rrb-", "89", "96", "hapira", "L.", "hamir", "a.", "ohen", "D.", "2008", "consistent", "mesh", "partitioning", "skeletonisation", "use", "shape", "diameter", "function", "Vis", "Comput", "24", "249", "259", "hilane", "P.", "unkhouser", "t.", "2007", "distinctive", "region", "3d", "surface", "ACM", "transaction", "Graphics", "26", "-lrb-", "June", "-rrb-", "impson", "J.", "1989", "Oxford", "English", "Dictionary", "Second", "Edition", "Oxford", "University", "Press", "http://dictionary.oed.com", "onthus", "R.", "UNJUR", "G.", "ADH", "R.", "1997", "shape", "feature", "determination", "use", "curvature", "region", "representation", "Proc", "solid", "modeling", "ACM", "tark", "m.", "chiele", "B.", "2007", "how", "good", "local", "feature", "class", "geometric", "object", "umner", "R.", "opovic", "J.", "2004", "deformation", "transfer", "triangle", "mesh", "ACM", "transaction", "graphic", "-lrb-", "Proc", "SIGGRAPH", "-rrb-", "23", "399", "405", "UN", "J.", "VSJANIKOV", "M.", "UIBAS", "L.", "2009", "concise", "provably", "informative", "Multi-Scale", "Signature", "base", "Heat", "Diffusion", "Computer", "Graphics", "Forum", "vol", "28", "Wiley", "Online", "Library", "1383", "1392", "sotso", "J.", "ULHANE", "S.", "AI", "W.", "AI", "Y.", "AVIS", "N.", "UFLO", "F.", "1995", "model", "visual-attention", "via", "selective", "tuning", "artificial", "Intelligence", "78", "1-2", "507", "545", "VAN", "AICK", "O.", "HANG", "H.", "AMARNEH", "G.", "ohen", "D.", "2010", "survey", "shape", "correspondence", "Proc", "Eurographics", "State-of-the-art", "Report", "hn", "L.", "ABBISH", "L.", "2008", "Designing", "game", "purpose", "Communications", "ACM", "51", "58", "67", "ITTEN", "I.", "H.", "rank", "E.", "2005", "datum", "mining", "Practical", "machine", "learning", "tool", "technique", "2nd", "edition", "K.", "HANG", "H.", "agliasacchus", "a.", "iu", "L.", "G.", "ENG", "M.", "iong", "Y.", "2009", "partial", "intrinsic", "reflectional", "symmetry", "3d", "shape", "ACM", "transaction", "graphic", "-lrb-", "Proceedings", "SIGGRAPH", "Asia", "2009", "-rrb-", "28", "appear", "aharescu", "a.", "oyer", "E.", "ARANASI", "K.", "oraud", "R.", "2009", "surface", "feature", "detection", "description", "application", "mesh", "matching", "cvpr", "hang", "E.", "ISCHAIKOW", "K.", "urk", "G.", "2005", "featurebased", "surface", "parameterization", "texture", "mapping", "ACM", "transaction", "Graphics", "24", "hang", "H.", "heffer", "a.", "ohen", "D.", "HOU", "Q.", "VAN", "AICK", "O.", "agliasacchus", "a.", "2008", "deformationdriven", "shape", "correspondence", "Comput", "graph", "Forum", "27", "1431", "1439", "HOU", "Y.", "uang", "Z.", "2004", "decompose", "polygon", "mesh", "means", "critical", "point", "MMM", "187", "195", "ulianus", "M.", "ENNEY", "C.", "anjunath", "B.", "2004", "mathematical", "comparison", "point", "detector", "Computer", "Vision", "Pattern", "recognition", "Workshop", "172", "ACM", "transaction", "Graphics", "Vol", "31", "no.", "Article", "29", "publication", "date", "July", "2012", "29:12", "X.", "Chen", "et", "al.", "ACM", "transaction", "Graphics", "Vol", "31", "no.", "Article", "29", "publication", "date", "July", "2012" ],
  "content" : "\n  \n    c895ec2f7e1385ab993699506d39477b1707ed18b79bbd4aa3de06e233ff2fe3\n    p2g\n    10.1145/2185520.2185525\n    Name identification was not possible. \n  \n  \n    \n      \n        Schelling Points on 3D Surface Meshes\n      \n      Xiaobai Chen, Abulhair Saparov, Bill Pang, and Thomas Funkhouser Princeton University\n      This paper investigates ?Schelling points? on 3D meshes, feature points selected by people in a pure coordination game due to their salience. To collect data for this investigation, we designed an online experiment that asked people to select points on 3D surfaces that they expect will be selected by other people. We then analyzed properties of the selected points, finding that: 1) Schelling point sets are usually highly symmetric, and 2) local curvature properties (e.g., Gauss curvature) are most helpful for identifying obvious Schelling points (tips of protrusions), but 3) global properties (e.g., segment centeredness, proximity to a symmetry axis, etc.) are required to explain more subtle features. Based on these observations, we use regression analysis to combine multiple properties into an analytical model that predicts where Schelling points are likely to be on new meshes. We find that this model benefits from a variety of surface properties, particularly when training data comes from examples in the same object class. Keywords: 3D shape analysis, feature detection, shape matching\n      Links:\n      \n        \n      \n      DL PDF\n      \n        \n      \n    \n    \n      \n        1 Introduction\n      \n      Detection of ?salient? feature points on 3D surfaces is a fundamental problem in computer graphics with many applications in shape analysis and related fields, including object recognition [Johnson 2000], shape matching [Zhang et al. 2008], shape-based retrieval [Funkhouser and Shilane 2006], metamorphosis [Alexa 2000], cross-parameterization [Kraevoy and Sheffer 2004], texture mapping [Zhang et al. 2005], deformation transfer [Sumner and Popovic 2004], shape approximation [Lee et al. 2005], viewpoint selection [Lee et al. 2005], symmetry detection [Xu et al. 2009], and part-based segmentation [Katz et al. 2005; Zhou and Huang 2004]. Although many definitions have been proposed for what constitutes ?salient? feature points in the computer graphics literature (e.g., maxima of average geodesic distance, maxima of Gauss curvature, maxima of mean curvature differences at increasing scales, etc.), none of them captures the social/psychological essence of salience as defined in the Oxford English Dictionary: ?the quality or fact of being more prominent in a person?s awareness or in his memory of past experience? [Simpson 1989]. It is this definition that captures the semantic essence of a stable feature point, and therefore one that we believe is useful for applications in computer graphics.\n      ACM Reference Format Chen, X., Saparov, A., Pang, B., Funkhouser, T. 2012. Schelling Points on 3D Surface Meshes. ACM Trans. Graph. 31 4, Article 29 (July 2012), 12 pages. DOI = 10.1145/2185520.2185525 http://doi.acm.org/10.1145/2185520.2185525. Copyright Notice Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or direct commercial advantage and that copies show this notice on the fi rst page or initial screen of a display along with the full citation. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers, to redistribute to lists, or to use any component of this work in other works requires prior specific permission and/or a fee. Permissions may be requested from Publications Dept., ACM, Inc., 2 Penn Plaza, Suite 701, New York, NY 10121-0701, fax +1\n      \n        212\n        869-0481, or permissions@acm.org.\n      \n      ? 2012 ACM 0730-0301/2012/08-ART29 $15.00 DOI 10.1145/2185520.2185525 http://doi.acm.org/10.1145/2185520.2185525\n      \n        \n        Figure 1: Schelling points (red). Positions on a surface selected consistently by many people when trying to match each other without communication.\n      \n      The goal of this paper is to develop a model of salience on 3D surface meshes based on this social/psychological definition. To achieve this goal, we leverage the concept of focal points as introduced by Schelling in his seminal paper on pure coordination games [Schelling 1960]. In game theory, ?a focal point (also called a Schelling point) is a solution that people will tend to use in the absence of communication, because it seems natural, special or relevant to them? [Parker 2011]. To discover focal points, Schelling performed user studies in which he asked people to make selections that they expect will match other people?s selections. Since the people were not allowed to communicate in any way, they usually picked the most conspicuous point, often using semantic information not provided in the input. For example, if asked to select a time and place in New York City to meet someone without any prior communication, people tended to choose Grand Central Terminal at noon. This choice is clearly the result of prior semantic knowledge that makes that choice more prominent in a person?s awareness or in his memory of past experience (i.e., social/psychological salience).  Inspired by Schelling?s work, we designed a user study that asks people to select points on 3D surface meshes that they expect will be selected by other people and used the acquired data to build a model of mesh saliency. Our primary research contribution is the analysis of the collected data. We find that: 1) Schelling point sets are usually highly symmetric, and 2) local curvature properties (e.g., absolute value of minimum curvature) are most helpful for predicting obvious Schelling point features, but 3) global properties (e.g., symmetry and segment centeredness) are required to explain other features. Our secondary research contributions are the methods used for acquiring, analyzing, and predicting Schelling points on 3D meshes. They include: 1) the design of a user study, 2) the analysis of consistency and properties of Schelling points, 3) a learned model for predicting the distribution of Schelling points, and 4) an algorithm that uses the learned model to extract Schelling points on new meshes.\n      ACM Transactions on Graphics, Vol. 31, No. 4, Article 29, Publication Date: July 2012\n      29:2\n      ?\n      X. Chen et al.\n      \n        2 Related Work\n        Detection and matching of salient feature points are classical problems in computer vision, geometric modeling, computer-aided design, computer graphics, and several other fields [van Kaick et al. 2010]. In this section, we cover the most related work, focusing on methods designed for saliency estimation at a point. Feature Point Detection: There has been lots of recent work on automatically extracting feature points on 3D meshes. Example methods include local maxima of average geodesic distance (AGD) to other points on the surface [Zhou and Huang 2004; Zhang et al. 2005; Zhang et al. 2008], local maxima of differences of Gaussians at multiple scales [Castellani et al. 2008], local maxima of Gaussian curvature [Lipman and Funkhouser 2009], properties of the Heat Kernel Signature [Sun et al. 2009], scale-space analysis of mean curvature flow [Zaharescu et al. 2009], other multiscale analysis [Li and Guskov 2005; Li and Guskov 2007; Novotni et al. 2005; Schlattmann et al. 2008; Sonthi et al. 1997], points on the convex hull after MDS embedding [Katz et al. 2005], leaf nodes of a curve skeleton extraction [Hisada et al. 2002], points with unlikely local shape descriptors [Chua and Jarvis 1996; Johnson 2000], and points with local shape descriptors distinctive of an object class [Shilane and Funkhouser 2007]. Most methods are based on differential properties of the surface (e.g., [Castellani et al. 2008]), while others are based on global properties [Zhang et al. 2008] and/or shape descriptor statistics (e.g., [Johnson 2000]). Previous work has analyzed which of these feature points is most stable under various models of perturbation [Bronstein et al. 2010], but none as studied how they relate to semantic salience in the Schelling sense. Saliency Estimation: In related work, methods have been proposed to define continuous measures of ?saliency? across a surface for mesh processing applications. Motivated by perceptual criteria [Hoffman and Singh 1997], [Lee et al. 2005] used a centersurround filter of curvature across multiple scales to select salient regions for mesh simplification and viewpoint selection. [Gal and Cohen-Or 2006] computed the saliency of a region based on its size relative to the whole object, its curvature, the variance of curvature, and the number of curvature changes within the region. [Shilane and Funkhouser 2007] defined the ?distinction? of a surface region based on its similarity to objects within the same class and difference to objects in other classes. This paper studies how these types of saliency measure relate to human-selected focal points and provides a new saliency measure learned from examples. Saliency Evaluation and Comparison: [Kim et al. 2010] studied how eye fixations relate to mesh saliency [Lee et al. 2005], and other studies have evaluated and compared feature point detection algorithms for images in computer vision [Ko and Nam 2006; Moreels and Perona 2007; Privitera and Stark 2000; Schmid et al. 2000; Stark and Schiele 2007; Zuliani et al. 2004]. For example, [Schmid et al. 2000] and [Sebe and Lew 2003] compare interest point detectors on the basis of stability, repeatability, and information content. [Privitera and Stark 2000] compare region of interest algorithms based on how well they match eye fixations measured with an eye tracker. [Huang et al. 2009] compare algorithms with respect to points collected in a game (Photoshoot) that asks people to select points on images that they expect will match a partner?s selection, much like the ESP game proposed by [Von Ahn and Dabbish 2008]. This work is similar to ours in that it also asks people to match point selections. However, the methodology of that study can produce bias in selected points due to training effects of immediate feedback (it is not a pure coordination game), it considers only 2D points in natural images, it does not provide any analysis of how image properties correlate with selected points, it does not suggest new properties correlated with the selected points (e.g., symmetry,  segmentations, etc.), and it does not provide a predictor of points learned from the collected examples. Perceptual Psychology: There have been many studies in perceptual psychology to understand how people assign importance to regions of images. Most have been based on visual attention [Koch and Ullman 1985; Milanes et al. 1994; Tsotsos et al. 1995; Itti et al. 1998; Rosenholtz 1999; Santella and DeCarlo 2004]). For example, [Koch and Ullman 1985] proposed a model that salient points would be ones that are different from their surroundings. Other perceptual psychology studies have studied which points are most important for approximation of a contour. For example, [Attneave 1954] showed 80 subjects a series of 16 shapes drawn as 2D contours and then asked them to select ?a pattern of 10 dots which would resemble the shape as closely as possible.? His main finding was that most people select points where the ?contour is most different from a straight line? ? i.e., where the curvature has large magnitude. While these studies are related to ours, we aim to discover which points have semantic salience in 3D meshes. Studying how people do X: There have very recently been studies in computer graphics aimed at understanding how people perform tasks of interest in computer graphics. For example, [Cole et al. 2008] studied where artists draw lines when make line drawings, and [Chen et al. 2009] analyzed how people decompose surfaces into parts. In both cases, machine learning algorithms were then developed to produce predictions for new surfaces based on training a classifier on examples collected from humans [Cole et al. 2008; Kalogerakis et al. 2010]. Our study follows this line of research, focusing on feature point detection. It is novel not only because it considers a new question: ?where do people select feature points?,? but also because it asks the question in a different way: ?where do other people select feature points?? and because it includes new algorithms for analyzing and extracting feature points based on the collected data.\n      \n      \n        3 Approach\n        The goal of this paper is to develop a model of semantic salience for 3D surfaces. Our general approach is to gather a large collection of feature points from people and then to study what geometric properties distinguish them from others. Although this general idea may sound straight-forward, it is surprisingly difficult to design a study to collect useful data on salience. We did not want to simply ask people to ?please click on important points? because different people might have different ideas of what it means to be important (e.g., functional, structural, social, visual, etc.), and it would be difficult to ask the question in a way that reveals people?s intentions without leading them to an answer. During a pilot study, we tried an approach based on [Attneave 1954], where we asked people to select points on a 3D surface from which another person could recognize the object class by just viewing those points. This approach was a resounding failure. We found that most people selected points only on a 2D silhouette curve of the surface as seen from a single canonical view (e.g., the outline of a fish as seen from the side), which does not seem to match a notion of semantic salience that is useful for 3D applications. Ultimately, we arrived at an approach based on Schelling?s focal points: we ask people to select points they think will be selected by others. The concept of focal points was introduced in pure coordination game theory in the 1960?s [Schelling 1960] (page 57) ? Schelling found that people asked to make selections that match other people?s selections amongst seemingly equivalent distinct options (segregated Nash equilibria) often make the same choices without any communication or feedback. For example, if people  were asked to choose ?heads? or ?tails? with no other information besides the goal of matching as many other people as possible, 86% chose heads [Schelling 1960]. If asked to match other people?s selection on a map, most people agreed on just a few points (e.g., prominent intersections). It was conjectured that the commonly selected focal points (later called Schelling points) arise from a strategy or outcome with properties of ?prominence or conspicuousness? [Schelling 1960]. A decade later, Lewis used Schelling?s ideas to introduce the term ?salience,? which he defined, first, as the property of an outcome of ?standing out from the rest by its uniqueness in some conspicuous respect? and, second, as ?being unique in some way everyone will notice, expect the others to notice? [Lewis 1969] (page 35). He used formal game models to characterize coordination strategies, hypothesizing that people use ?common knowledge? to select amongst distinct Nash equilibria. It is this ?common knowledge? about feature points on 3D surfaces that we aim to capture and leverage in our work. Inspired by the ideas of Schelling and Lewis, we have designed a method to study semantic salience on 3D meshes. Specifically, we first acquire a large number of Schelling points by asking people to select points on 3D surface meshes that they expect will be selected by other people (Section 4). We then analyze properties of the collected point sets, asking questions like: ?how consistent are Schelling points selected on different meshes within the same object class?? and ?how are the locations of Schelling points associated with geometric properties of the surface?? (Section 5). Next, we train a regression model that predicts the likelihood that a point on a surface is a Schelling point based on its surface properties (Section 6). Finally, we provide an algorithm to predict a set of Schelling points for new meshes (Section 7).\n        ACM Transactions on Graphics, Vol. 31, No. 4, Article 29, Publication Date: July 2012\n        Schelling Points on 3D Surface Meshes\n        ?\n        29:3\n      \n      \n        4 Study Design\n        The first and most difficult issue faced in our investigation is how to design a study to acquire Schelling points from many people for many types of 3D surfaces. We would like to collect enough data to analyze how Schelling points relate to surface properties across a wide variety of meshes and to train a predictive model that can be used to estimate Schelling points for new 3D meshes. Of course, this is difficult because it requires recruiting and supervising many (possibly hundreds or thousands of) human subjects in a user study. To address this issue, we performed our study on-line. Following the approach of [Chen et al. 2009] and [Cole et al. 2009], we recruited subjects for our study through Amazon?s Mechanical Turk (AMT) [Amazon 2009], an on-line platform that matches people willing to work with paying tasks. Alternatively, we could have designed an on-line game to acquire input (as in [Huang et al. 2009; Von Ahn and Dabbish 2008]), but that approach would have required attracting a player population, which is beyond the scope of this paper. Since tasks on the AMT are typically short in duration (a minute or two), inexpensive (around 10 cents), and accessible on-line (in a web page), it is well-suited for studies like ours that require lots of people to do simple, menial tasks (e.g., clicking points on a surface). The challenge with any on-line study is to design a protocol that acquires useful information from a diverse population of subjects. Unlike a laboratory study, where a handful of screened subjects are trained, monitored, and employed for several hours, we have access to a much larger number of people, but less control over subject selection and less trust that every individual is motivated to do a good job. As such, our challenge is to design a study that motivates people to work responsibly and incorporates unbiased mechanisms to discard data from those that don?t.  We designed an easy-to-learn task in which subjects that provide ?better? input get paid more, and those that do not do a ?good? job get paid nothing. Specifically, we presented each user with a 3D mesh shown in an interactive viewer with a crystal ball camera control and a simple method for clicking on points with the mouse (one key for adding a point at the selected position on the mesh and another key for removing a previously added point). Then, we provided the following instructions: ? select points on the surface of a 3D object likely to be selected by other people. We will ask many people to do the same task and see how your selection matches others.? Our reward structure ranked people according to a scoring function that provides positive credit for each point also selected by at least 25% of other people, negative credit for other points, and zero credit if less than ten points were selected. Based on the ranking, we paid the top scoring 30% of people X, the next 60% X/2, and the bottom 10% were not paid. This incentive structure was chosen based on the results of a pilot study, which suggested that it is useful to provide motivation for people to select more than just the very obvious Schelling points (e.g., the ends of limbs on animals) and that it is better to acquire too many points from people than too few (if a surface has fewer Schelling points, then ?extra? points will be distributed somewhat randomly). Data Filtering: Even though our pay structure encourages people to do a good job, we employ three filters to discard point sets we expect to provide bad data: i.e., when the user: 1) clicks too few points (less than ten), 2) maintains approximately the same camera viewpoint for the entire interactive session (the cumulative camera rotation is less than 36 degrees), and 3) clicks too hastily (the average time per click is less than one second). These filters were chosen on the basis of a pilot study, which showed empirically that a significant fraction of people provided careful data and that these simple filters were effective at conservatively discarding the careless data while retaining much of the good data. In this regard, we designed our filters to favor false-negatives (discarding good data) over false-positives (accepting careless data), since it is easy to collect data on the AMT. Mesh Selection: In order to cover a wide variety of object categories, and to leverage data collected in previous studies, we chose to collect Schelling points for the 3D meshes from the Watertight Track of the 2007 SHREC Shape-based Retrieval Contest. This data set contains 400 meshes spread evenly among 20 object categories (human, cup, glasses, airplane, ant, chair, octopus, table, teddy, hand, plier, fish, bird, spring, armadillo, buste, mechanical part, bearing, vase, and four-legged animal), of which we use all but the ?spring.? It forms an interesting data set for our study because it contains categories with different articulated poses (ant, octopus, bird, teddy, pliers, glasses), different local parts (human, hand, four-leg animals), and different global structures (fish, table, cup, mechanical part, bearing, chair, buste, and vase). Also, the data set is highly tessellated (an average of 10,223 vertices per mesh), and so we can limit selected points to vertices of the mesh. Finally, since it has been used for previous studies of mesh matching [Giorgi et al. 2007] and segmentation [Chen et al. 2009], it provides an opportunity to investigate how Schelling points correspond with other types of data. Protocol Implementation: To reduce bias in the acquired data, we implemented a scheduling program that records the AMT identifier and IP address of every subject doing our task. That program ensures that no single AMT identifier or IP address can work on the same mesh twice, that meshes are distributed in randomized order, and that data is provided by approximately the same number of subjects for every mesh. The interactive Java Applet presented to the user for viewing meshes and selecting points is initialized with a random camera direction and two virtual lights, all that point at the object centroid from a distance relative to the object bounding box size. As the user rotates the meshes, the lights move with the camera, staying along the equator at 90 degree angles to the camera. The Applet records the position, time stamp, and camera parameters for every point added or deleted from the data set, and sends the data back to our server. No feedback or payments were made to any subject until all data was collected to avoid training effects. Data Collection: Using this protocol, we used the AMT to acquire 24,124 point sets from 1,696 unique AMT accounts. Of this raw data, 9,965 point sets (44%) from 1,060 unique AMT accounts passed all three data filters ? 16% had too few points, 14% were entered with too little camera motion, and 28% were clicked too hastily. The 9,965 point sets in our final data set contain 201,304 points in total, an average of approximately 10,000 points per object category, 500 points per mesh, and 20 points per point set. Each of the 380 meshes was represented by data from 25 people, on average, and every mesh had at least 23 point sets. Schelling Point Extraction: As a post-process, we extract a discrete set of Schelling Points from the collected data ? i.e., the ones upon which many people agreed. Of course, since the data is discrete (on vertices of a mesh), and there is spatial noise ? in the point selection process, some aggregation is required to identify commonly selected points. To address this issue, we first construct a function on every mesh M that indicates the number of times every vertex V was selected by different people. Then, to reduce spatial noise, we blur that function geodesically with a Gaussian filter with maximal value 1 and ? = 0.01R, where R represents the radius of the mesh (R = p Surf aceArea(M )). The result is a smooth Schelling distribution function, S D (V ), roughly estimating the probability that each vertex V will be selected by a person in our study (shown in red in Figures 1 and 2). Then, we extract a discrete set of Schelling points, S, from local maxima of S D (V ) and build an indicator function, S P (V ), that tells whether vertex V is a Schelling point (S P (V ) is one at Schelling points and zero otherwise). To form this set, we select every vertex V with S D (V ) greater than 12.5% and spatial separation by more than 0.02R from any other vertex V k with higher S D (V k ). These choices include at least the vertices that were selected with spatial error less than ? by at least 25% of the people in our study (the positive payment threshold in our study). Some examples point sets are shown in blue in Figure 2 .\n        ACM Transactions on Graphics, Vol. 31, No. 4, Article 29, Publication Date: July 2012\n        29:4\n        ?\n        X. Chen et al.\n        \n          \n          Figure 2: Schelling points. The saturation of red depicts the estimated fraction of people selecting a mesh vertex in our study. Extracted Schelling points are shown in blue.\n        \n      \n      \n        5 Analysis of Schelling Points\n        This large data set provides an opportunity to investigate a number of questions of potential interest in computer graphics and perceptual psychology, including ?How consistently do people select points on the same mesh?,? ?How symmetric are the selected point sets?,? ?How are the selected points distributed on the surface?,? and ?What geometric properties of a 3D surface are prominent at selected points?.? This section takes steps towards addressing these questions.  A. How consistently do people select points on the same mesh? The first and most basic question is whether people select points consistently in our study. To address this question, we compute the geodesic distances between points selected by different people on the same mesh. For the k-th point P i,k M in every point set P i M selected on every mesh M , we compute the geodesic distance d M (P i,k M , P j M ) from that point to the closest point in every other point set P j M collected on the same mesh, normalizing for scale by dividing by square root of the surface area. We then analyze the consistency of the point sets by plotting cumulative distributions of d M (P i,k M , P j M ) indicating the fraction of point sets that are consistent with each selected point for a range of distance thresholds. For example, Figure 3a shows cumulative distributions where the horizontal axis represents normalized distance thresholds (d M (P i,k M , P j M )) and the vertical axis represents the fraction of points within that threshold of point sets selected by different people on the same mesh. The thick black curve represents the overall average of all points in the collected data set, aggregated first over all points within the same mesh, then over all meshes within the same object class, and finally over all classes in the data set to avoid over-weighting point sets or meshes with large numbers of points. The thin solid colored curves depict averages for different subsets of the points based on the order in which a user selected a point within his/her interactive session (e.g., the red curve shows distances from the first point selected in each session, the purple curve shows the same for the second and third point, the blue curve for points 4-7, etc. These curves tell a more detailed story of how consistency relates to the order that points were selected. Looking at the curves in Figure 3a , we can readily make two observations. First, different people tend to pick points fairly consistently with one another on the same mesh. Using a normalized distance of 0.05R (approximately 3 inches on a human body) as a threshold to classify whether a point P i,k M is ?consistent? with a point set P j M , we find that 48.5% of the selected points are ?consistent? with other point sets. This level of consistency is far greater than 12.8% that would be observed if points were selected randomly. Second, we observe that points selected earlier in an interactive session tend to be more consistent than ones selected later (there are higher densities near d M (p i , P j ) = 0 in the curves representing points selected earlier), which suggests that people choose the most ?salient? points first, and others later. These results, combined with the visualizations in Figure 2 , suggest that people selected points in a non-random, consistent way in our study. B. How consistently do people select points on different meshes of the same object category? A second question of potential interest is whether people select semantically equivalent Schelling points on different meshes within the same object category. For example, if they select a particular point (e.g., the knee) when the object is in one pose (e.g., a running dog), do they also select that point when the same object is in a different pose (e.g., a sitting dog)? And, do they select a semantically equivalent point on a different object within the same general category (e.g., all fourlegged animals)? To address these questions, we produced a semantic mapping between all pairs of the twenty meshes within each of the twenty object categories and used those mappings to compute cumulative distributions of normalized distances between selected points. To produce the mappings, an expert user selected a set of landmark points for every mesh that is semantically consistent with every other mesh in the same category. For example, in the four legged animal category, every mesh was marked with landmark points representing the ?tip of the nose,? ?tip of right ear,? ?middle of the back,? etc. These landmark points provided a coarse point correspondence from which a dense one-way inter-surface mapping A?B was established from vertices of A to vertices of B using a simple procedure based on similarities of pairwise geodesic distances (following the strategy outlined in [Bronstein et al. 2006], except maintaining the explicit correspondences between landmark points). Using these inter-surface mappings, we can study the consistency of points selected by people on different meshes within the same object class. Specifically, for each point P i,k M selected by a person on mesh M , we use the inter-surface mapping M ?M to transfer it to the domain of every other mesh M in the same class to form P i,k M ?M . Then, for every point set P j M collected on mesh M , we compute d M (P i,k M ?M , P j M ), the normalized geodesic distance from the point P i,k M ?M to the closest point in P j M , and add it to the cumulative distributions using the same procedure as described in the previous subsection. The results are shown in Figures 3b. Interestingly, we find that the consistency of points selected by different people on different meshes in the same class is almost, but not quite, as high as the consistency of points selected by different people on the same mesh. Overall, 39.4% of the points selected on one mesh are ?consistent? with point sets selected on different meshes of the same object class. Since the local geometry of meshes within the same class are sometimes very different, this result suggests that the criteria people used for selecting points is not based only on absolute geometric properties (e.g., Gauss curvature), but rather on relative properties (e.g., extrema of Gauss curvature) or on semantic features that are consistent across different instances within the same class. C. How symmetric are the selected point sets? A third question of interest regards symmetry: if a person selects a point on a symmetric object, how often do they also select the its symmetric correspondence(s)? For example, if a person selects the right ear on a head, how often do they also select the left ear? To investigate this question, we manually produced a symmetry mapping from every mesh onto itself to establish dense symmetric point correspondences for each of the 319 meshes with intrinsic reflective symmetry. This was done by clicking on symmetric pairs of landmark points (e.g., right eye to left eye, left elbow to right elbow, etc.) and then interpolating those pairs to form a dense correspondence over the entire surface using an algorithm based on [Bronstein et al. 2006]. Given the symmetric mapping, we analyze the consistency of every point set with its symmetric correspondence using the methods described in the previous subsections ? i.e., we build cumulative distributions of the normalized geodesic distance from every point to the closest point in the same point set after the symmetric mapping has been applied ( Figure 3c ). Our results reveal that point sets selected by people are highly symmetric ? 76.0% of the points are ?consistent? with the symmetric mapping. More specifically, comparing to the histograms in Figure 3 , we find that point sets selected by people are far more consistent with their symmetric mapping than they are with point sets selected by different people. As such, we conclude that symmetry is an important cue for selecting ?salient? points in our study. D. How are the selected points distributed on a surface? A fourth question of interest is to characterize the spatial distribution of points selected by people. To address this question, we show the histogram of distances from each point to other points in the same set for meshes of different object class in Figure 4 . The plot shows a separate curve for each of the 19 object classes (dotted lines), along with the overall average (thick red line). Three interesting observations can be made from these histograms. First, people tend to spread points fairly evenly on a mesh ? i.e., there are few points that are either very close to or very far from other points. Second, the spacing for different object classes is different. For example, points on busts (statue heads) tend to be closer to one another (dotted light blue curve on left), while points on octopi are more widely spaced (light blue curve on right). Third, the spacing of points appears to be dictated more by the size of the mesh shown to the person than the physical size of the object in the real world. For example, the spacing of points on a pair of eyeglasses is the same as for a human body, and also the same as for an airplane. Similarly, the spacing of points on a human hand is different if shown alone or as part of an entire body. From these observations, we hypothesize that people think of the virtual objects at the scale they are shown and select the largest features available on the screen regardless of their size in the real world. F. What geometric properties distinguish Schelling points? Finally, it is interesting to ask whether it is possible to characterize common geometric properties of Schelling points. For example, are Schelling points commonly at extrema of Gauss curvature? Can Schelling points be predicted by analysis of average geodesic distance or other geometric properties commonly used for feature extraction in computer graphics? And, are there other geometric properties of meshes that are associated with Shelling points, but have not been used for point feature extraction before? To investigate these questions, we compute a number of geometric properties for every vertex V of every mesh M in the data set, and then analyze how these properties explain the placement of Schelling points based on information theory statistics. The set of properties considered includes: ? Curvatures: the Gauss, mean, minimum, and maximum curvatures at V , as computed in [Rusinkiewicz 2004]. ? Mesh Saliency: the mesh saliency at V (at scales 0.1, 0.3, 0.5, and 0.7), as computed with code provided by [Lee et al. 2005]. ? Geodesic Distance: the average (AGD), median (MGD), standard deviation (SDGD), tenth percentile (10GD), ninetieth percentile (90GD), and maximum of geodesic distance (GGD) from V to all other vertices in M , as estimated by Dijkstra?s algorithm. ? Shape Diameter Function (SDF): the median length of rays traced from V through the interior of M as described in [Shapira et al. 2008] using the implementation provided by [Kalogerakis et al. 2010]. ? Heat Kernel Signature: the amount of heat diffused from V to itself within time t, for five equally spaced time durations ranging from very small (HKS1) to very large (HKS101), as computed with the implementation provided by [Sun et al. 2009]. ? Up: the Z coordinate (ZPosition) and normal direction (ZNormal), assuming it is prescribed by standards in the modeling language. ? Symmetry: the Intrinsic Reflective Intrinsic Symmetry Axis function proposed by [Xu et al. 2009], per our implementation. ? Segment Centeredness: the centeredness of the point within its part, as computed by first decomposing the mesh into segments automatically with the algorithm in [Shapira et al. 2008] and then computing the distance from V to the closest segmentation boundary divided by the maximal distance to the closest segmentation boundary for all vertices in the segment containing V . Most of these properties have been used before for characterizing saliency and/or generating point sets on meshes. However, we consider two new ones that are specifically motivated by visual inspection of Schelling point sets collected in our study: symmetry and segment centeredness. We observe that people often select points on symmetry axes and centers of large convex parts in the absence of other more distinguishing features nearby (e.g., the center of the lens of the glasses and the belly button of the teddy bear in Figure 2 . Thus, we expect that extrema of these functions (e.g., segment centeredness = 1) will be correlated with locations of selected points. This hypothesis is corroborated by the histogram shown in Figure 5 , which plots frequencies of selected points versus segment centeredness (for automatic SDF segmentations, as used throughout this paper: and for manual segmentations provided by the Benchmark of 3D Mesh Segmentation [Chen et al. 2009], which are included only for comparison sake). We find that selected points appear most often at the center of extract parts ? i.e., the rightmost bin of the histogram contains 25% of the distribution. We also consider functions derived from these basic geometric properties. Specifically, we include the difference between minimum and maximum curvature (CurvDiff), which is smallest at centers of local rotational symmetry. We include the absolute value of Gauss, mean, minimum, and maximum curvatures, which are largest at critical points, peaks/divots, peaks/divots, and ridges/valleys, respectively. We also include blurs at four levels (? = 0.01R, ? = 0.02R, ? = 0.04R, and ? = 0.08R) for all properties except HKS, CurvRing, and Geodesic Distance, which are already very smooth. Finally, for every property, p, and function of that property, f (p), we include a percentile transformation, %(p), that encodes the percentage of vertices that have a smaller value within the same mesh. To analyze how Schelling points are associated with these properties, we calculate information theory statistics and coverage plots to estimate how well property distributions explain the Schelling distribution. Results for a representative set of properties and functions on them are shown in Table 1 and Figure 6 . Information Gain: The middle two columns of Table 1 show the Information Gain, G(f ), for functions f of several properties p. G(f ) is the difference between entropy of the Schelling point indicator function, S P (V ) and its average entropy conditioned on discretized values of the property f ? higher values of Information Gain indicate a stronger predictor of the Schelling point locations independent of other properties. From these results, we see that curvature is the strongest single cue for feature point selection ? many of the Schelling points are at the tips of protrusions (fingers and toes), which have large positive minimum curvature, and a few are at conspicuous saddle points (e.g., between fingers), which have highly negative Gauss curvature. Other properties commonly used for feature point detection (e.g., Saliency, HKS, and AGD) also provide fairly good predictors. Random Forest Importance: The rightmost two columns of Table 1 show the importance of f as computed by the Random Forests of [Breiman 2001], which estimate the importance of a feature in combinations with others by building a large number of decision trees trained with different sets of properties and measuring the differences between prediction errors with and without each property. It suggests that indeed minimum curvature and Gauss curvature are most useful properties for predicting Schelling points. It also suggests that the added value of AGD, HKS, mean curvature, and other common properties is limited, since they are redundant with minimum and Gauss curvatures. On the other hand, the importance of global properties, such as symmetry, SDF, and segment centeredness, is relatively high (84, 54, and 33, respectively), which suggests they provide cues that are independent of other properties. We note that percentiles (columns 4 and 6) appear more useful for predicting Schelling points than raw geometric property values: e.g., vertices having curvature higher than others on the same surface are more likely to be Schelling points than ones within any specific range of values. Coverage plots: Figure 6 shows stack plots representing the fraction of Schelling points in S ?explained? by extrema of different mesh properties. To produce this result, we extracted the K largest local maxima of each property (K = 14, matching the average size of a point set collected in our study), with maxima spread by at least geodesic distance 0.02R, using the algorithm described in Section 7. Then, for each Schelling point, s i ? S, we considered the surface properties in the order from bottom to top, marking the property with a vote if it is the first to have one of its K largest local maxima within 0.05R of s i . After all votes are cast (one for each Schelling point on each mesh), we average the votes per mesh, and then average the fractions per class (shown in the first 19 bars in Figure 6 ), and finally average those fractions to get a result for the entire data set (shown in the bar labeled ?Overall? on the far right). These results suggest that extrema of minimum curvature ?explain? 56.7% of the Schelling points (bottom blue region on the rightmost bar). Of the remaining Schelling points, 6.7% are explained by Gauss curvature (red); and 9.1% of the ones still remaining are explained by symmetry (IRSA); and so on. Please note that there is variation in the results for different object classes: curvature measures are almost completely sufficient for explaining Schelling points on airplanes, for example; but symmetry and segment centeredness are more helpful properties for explaining Schelling points on teddy bears. Interestingly, approximately 11% of Schelling points are not described by the strongest K local maxima of any property considered. Examining those points visually, we find that they tend to reside either at semantic features off-center on smooth surfaces (e.g., the eyes on the teddy bears) and/or at geometric features that did not appear among the strongest maxima (e.g., a knee or elbow when the appendage is not bent). Perhaps other geometric properties could be discovered to explain these remaining points in future work.\n        ACM Transactions on Graphics, Vol. 31, No. 4, Article 29, Publication Date: July 2012\n        Schelling Points on 3D Surface Meshes\n        ?\n        29:5\n        \n          \n        \n        (a) Consistency of points selected by (b) Consistency of points selected by different people on the same mesh people on meshes of the same object class\n        \n          Figure 3: Consistency of points collected in our study. The plots show cumulative distributions of normalized distance from each point to the closest point in another point set. Different colored curves depict averages for different subsets points. The thick black curve represents the overall average of all points. The thin colored ones separate points based on the order in which they were selected during an interactive session: the consistency of the first point selected is shown in the top red curve, points 2-3 are shown in purple, points 4-7 in blue, etc. Note that the average normalized edge length for these meshes is 0.013, and the normalized distance threshold used to call a point ?consistent? in our analysis is 0.05.\n        \n        c) Consistency of points selected by the same person on symmetric sides of a mesh\n        ACM Transactions on Graphics, Vol. 31, No. 4, Article 29, Publication Date: July 2012\n        29:6\n        ?\n        X. Chen et al.\n        \n          \n          Figure 4: Histogram of spacings between points collected for different mesh categories. Distances are listed as fractions the square root of the mesh area. Red line shows average.\n        \n        \n          \n          Figure 5: Schelling points are most often at centers of segments (far right of plot).\n        \n        ACM Transactions on Graphics, Vol. 31, No. 4, Article 29, Publication Date: July 2012\n        Schelling Points on 3D Surface Meshes\n        ?\n        29:7\n        \n          \n            \n              \n                \n                   Property\n                   Best Filter\n                   Info Gain\n                   Importance\n                \n                \n                   (p)\n                   (f)\n                   G(f) G(%(f))\n                   I(f) I(%(f))\n                \n              \n              \n                \n                   MinCurv\n                   |(B(p, 1))|\n                   195 203\n                   216 801\n                \n                \n                   GaussCurv\n                   |p|\n                   201 211\n                   59 267\n                \n                \n                   Symmetry\n                   B(p, 4)\n                   12 25\n                   18 84\n                \n                \n                   SDF\n                   p\n                   17 26\n                   31 54\n                \n                \n                   SegCenter\n                   B(p, 3)\n                   24 43\n                   15 33\n                \n                \n                   HKS(101)\n                   p\n                   104 141\n                   15 31\n                \n                \n                   Saliency(0.3)\n                   p\n                   48 85\n                   26 30\n                \n                \n                   MaxCurv\n                   B(|p|, 4)\n                   53 99\n                   19 30\n                \n                \n                   ZPosition\n                   p\n                   20 51\n                   29 27\n                \n                \n                   ZNormal\n                   p\n                   11 14\n                   24 25\n                \n                \n                   MeanCurv\n                   B(p, 4)\n                   43 98\n                   11 23\n                \n                \n                   CurvDiff\n                   p\n                   29 46\n                   22 21\n                \n                \n                   AGD\n                   p\n                   25 85\n                   18 18\n                \n              \n            \n          \n          Property Best Filter Info Gain Importance (p) (f) G(f) G(%(f)) I(f) I(%(f)) MinCurv |(B(p, 1))| 195 203 216 801 GaussCurv |p| 201 211 59 267 Symmetry B(p, 4) 12 25 18 84 SDF p 17 26 31 54 SegCenter B(p, 3) 24 43 15 33 HKS(101) p 104 141 15 31 Saliency(0.3) p 48 85 26 30 MaxCurv B(|p|, 4) 53 99 19 30 ZPosition p 20 51 29 27 ZNormal p 11 14 24 25 MeanCurv B(p, 4) 43 98 11 23 CurvDiff p 29 46 22 21 AGD p 25 85 18 18\n          Table 1: Information gain (x1000) and random forest importance of mesh properties (rows) for predicting the Schelling point distribution. p represents the property value, f is the best filter found for p, B(?, ?) is Gaussian blur, %(f ) is its percentile within a mesh, G(?) is information gain, and I(?) is an estimate of importance by analysis of Random Forests.\n        \n        \n          \n          Figure 6: Stackplot showing fractions of Schelling points first ?explained? by extrema of each property considered in the order shown bottom to top.\n        \n      \n      \n        6 Prediction of Schelling Distributions\n        In this section, we investigate whether it is possible to predict mesh saliency using the data collected in our study. That is, for a mesh M never seen before, we aim to provide a method that estimates the probability that a person would have selected each vertex V of the mesh if it were included in our study ? i.e., the predicted Schelling point distribution, S ? D (V ).  Transfer: A simple method to approach this problem would be to transfer the Schelling points from other similar meshes for which AMT data has been collected. That is, given a new mesh M , we could select a set of K similar meshes M i from the collected Schelling point data set, compute a map m i (M ? M i ) from each vertex V j of M to the corresponding vertex m i (V j ) in each similar mesh M i , and then predict the transferred Schelling point distribution S ? T (V ) for vertices of M by aggregating the Schelling points mapped from other meshes: S ? T (V ) = 1/K P K i S P (m i (V )). This method is very simple. However, it will work well only when an accurate map can be computed, and when two meshes have the same number of Schelling points in the same exact arrangement, neither of which is often the case. Regression: A second method is to build a regression model based on geometric properties of a surface. Given a ?training? set of meshes M i with collected Schelling points, we compute the geometric properties listed in Section 5 (Gauss curvature, etc.) for every vertex of every mesh M i in a training set and then learn a model that relates those properties to the Schelling point indicator function S P (V ). This model is simple to implement, since it considers each vertex of the mesh independently, and it can be applied to arbitrary new surfaces. Our implementation for building the regression model is based on M5P regression trees as provided by Weka [Witten and Frank 2005]). This model builds a decision tree that takes in a training set of vertices labeled with the properties described in the previous section along with the observed value of the Schelling point distribution at that vertex. It analyzes this data and builds a binary tree that splits feature space into distinct regions and then fits a linear regression model for S(V ? ) for each region independently. It was chosen for our study because it can fit non-linear relationships between input and output variables (piecewise linear), and it provides an explanation for how the model operates (the decision tree), which is much easier to decipher than most other regression models. As an example, Figure 7 shows the top nodes of a M5P regression tree learned by our system when trained on the sampled data for teddy bears. Examining the tree, it is interesting to note that the top few levels of splits take into account different properties: minimum curvature, symmetry, segmentation centerness, shape diameter, saliency, etc. Also, different derived properties are utilized, with percentiles more often chosen for splits in the decision tree, and values or derivatives more often chosen for linear equations in the leaf nodes. Overall, this tree suggests that several types of properties can be combined to make better predictions than any one alone. Of course, nothing in our study is dependent on this particular choice of regression model, and we believe that several other alternatives could have been used just as effectively. Results: To evaluate and compare how effectively the transfer and regression methods work, we performed a series of leave-one-out experiments where we utilized the Schelling points collected from people on all but one mesh to predict the Schelling point distribution on the one held out, and then we evaluated the quality of the prediction by comparison to the Schelling point data collected for that mesh. Evaluation was performed by computing the Information Gain between the predicted and actual point set distributions, as in Table 1 . For the first tests, we used vertex-to-vertex maps to transfer Schelling points to the held out mesh M from other meshes in the same object class. Maps were constructed with two different methods: 1) manually by interpolating human-selected landmark corre-\n        ACM Transactions on Graphics, Vol. 31, No. 4, Article 29, Publication Date: July 2012\n        29:8\n        ?\n        X. Chen et al.\n        \n        \n          Figure 7:\n        \n        Top nodes of an M5P regression tree learned from Schelling points on teddy bears.\n        spondences (TrueMap), 1 and 2) automatically using Blended Intrinsic Maps [Kim et al. 2011] (BlendedMap). In both cases, we considered cases where points are transferred from just the most similar mesh as computed with a geodesic D2 shap descriptor (Closest), and where they are transferred and aggregated from all meshes in the same object class (InClass). Results of these tests, averaged over all 380 meshes, are shown in the top four rows of Table 2 . They suggest that transferring points does not work well, in general, For many classes of objects (e.g., fish, vase, chair, airplane, bird, etc.), different meshes have different arrangements of parts, accounting for the failures of even TrueMap. For other classes (e.g., ant, hand, etc.), computing semantically correct maps between meshes is difficult, accounting for the worse performance of BlendedMaps. For the second tests, we used regression trees learned from Schelling points on a subset of meshes to predict S ? D (V ) for others. We executed two experiments that differ in how the training sets were chosen. In the first experiment (InClass), regression trees were built in leave-one-out style using training data from meshes of the same class ? i.e., the model was trained on 19 out of the 20 meshes in each object class and then tested on the 20th (as in [Kalogerakis et al. 2010]). In the second experiment (OutClass), the regression tree for each mesh was trained only using data from meshes of other object classes. Results of this study are shown in Table 2 . They suggest that regression significantly outperforms transfer algorithms on this data set, even when training is performed only on examples from different object classes. They also show that the regression model combining many surface properties outperforms any single property ? i.e., the highest Information Gain achieved for any single property (GaussCurvature) is 0.211 (second row of Table 1 ), in comparison to 0.257 (OutClass) and 0.341 (InClass) achieved with regression. Visualizations of Schelling point distributions predicted with a regression model trained InClass are shown in Figure 8 . The meshes and color scheme are the same as in Figure 1 to facilitate direct visual comparison. From these images (and others provided in supplemental materials), we see that these learned models are not as precise as the actual Schelling distributions. However, they predict tips of protrusions well (corners in the airplane) as well as some subtle features (e.g., centers of eyeglasses, eyes of the bust, belly button of the teddy bear, etc.) that are difficult to recognize with a threshold on any single surface property.\n        1\n      \n      \n        TrueMaps are considered only for didactic purposes. Since they are entered manually, they could not be used in an automatic prediction system.\n        ACM Transactions on Graphics, Vol. 31, No. 4, Article 29, Publication Date: July 2012\n        Schelling Points on 3D Surface Meshes\n        ?\n        29:9\n        \n          \n            \n              \n                \n                   Prediction\n                   Source\n                   Best Filter\n                   Info\n                \n              \n              \n                \n                   Method (p)\n                   Data\n                   (f)\n                   Gain\n                \n                \n                   PredictMap\n                   Closest\n                   %(Blur(p, 2))\n                   70\n                \n                \n                  \n                   InClass\n                   %(Blur(p, 2))\n                   105\n                \n                \n                   TrueMap\n                   Closest\n                   %(Blur(p, 2))\n                   160\n                \n                \n                  \n                   InClass\n                   %(Blur(p, 2))\n                   236\n                \n                \n                   Regression\n                   OutClass\n                   Blur(p, 1)\n                   257\n                \n                \n                  \n                   InClass\n                   Blur(p, 1)\n                   341\n                \n              \n            \n          \n          Prediction Source Best Filter Info Method (p) Data (f) Gain PredictMap Closest %(Blur(p, 2)) 70 InClass %(Blur(p, 2)) 105 TrueMap Closest %(Blur(p, 2)) 160 InClass %(Blur(p, 2)) 236 Regression OutClass Blur(p, 1) 257 InClass Blur(p, 1) 341\n          Table 2: Information gain (x1000) of Schelling point predictions.\n        \n        \n          \n          Figure 8: Visualizations of Schelling point distributions predicted by our algorithm after training on properties of different meshes in the same object class (InClass).\n        \n      \n      \n        7 Prediction of Schelling Points\n        For many applications, it is important to not only estimate mesh saliency, but also to extract a discrete set of salient feature points. For example, surface matching algorithms often start by detecting a set of features and then searching for correspondences between them. To be successful, these algorithms require a set of feature points that have many of the properties of Schelling points: stability, spacing, symmetry, etc. Many algorithms are possible to address this problem, including ones that perform a combinatorial optimization over possible candidate sets, choosing the one that maximizes some objective function. However, for the purposes of this study, we choose a simple greedy algorithm that has been used in several other saliency experiments (e.g., [Shilane and Funkhouser 2007]). The algorithm aims to select a set of vertices {V i } that maximizes the sum of S(V ? i ) at selected vertices, subject to the constraint that no two vertices in {V i } are too close to one another. It does so by sorting vertices from highest S(V ? ) to lowest and then repeatedly selecting the next vertex remaining whose position is not closer than a normalized geodesic distance threshold, D, to any previously selected vertex (D = 0.05). This process avoids selecting many points near one another on the mesh and provides an easy way to reduce the point set size by increasing the distance threshold D or terminating the greedy search after a given number has been selected. Results: To investigate how effectively an algorithm can predict Schelling points, we perform an analysis of the similarities of the automatically generated point sets to the ones collected from people. For this analysis, we extract k = 14 points for each mesh (the even number closest to the median of point sets collected from  people) and then follow the general methodology described in Section 5A. That is, we measure the distance from points in our automatically extracted point sets to the Schellling points S P on the same mesh and plot the cumulative distribution with respect to increasing normalized distance thresholds. For comparison sake, we consider point sets extracted with the same algorithm from maxima of every surface property considered in Section 5, and we consider point sets transferred from Schelling points on other meshes within the same class using the mapping algorithms described in Section 6. Figure 9 shows the results. As in Figure 3a , the horizontal axis contains increasing distance thresholds, D, and the vertical axis shows consistency using the cumulative distribution of point pairs whose normalized geodesic distance is less than D. The red curve on top represents the consistency between Schelling points S P collected from people with point sets extracted automatically from the distribution predicted with regression using InClass training. The lower curves represent the best point sets generated with other methods. These results suggest that the points selected by our algorithm from the distribution learned with regression using InClass training are closer to the Schelling points collected in our study than those predicted with other methods. We also find that they are slightly more consistent with the Schelling points than the average point set collected from people, suggesting that the regression and point extraction algorithms for predicting Schelling point sets are effectively relating surface properties to Schelling point locations.\n        \n          \n          Figure 9: Consistency between Schelling points and point sets extracted with different algorithms.\n        \n      \n      \n        8 Validation with Controlled User Study\n        As a final test, we investigated the impact of collecting data via the Amazaon Mechanical Turk (AMT) on the main conclusions of our study. Although the AMT is becoming a common platform for perceptual experiments in computer graphics (e.g., [Cole et al. 2009]) and there are several studies validating AMT studies in the laboratory (e.g., [Heer and Bostock 2010]), it is valuable to ask whether the data we gathered from the AMT is representative of that which would be collected from a controlled group of participants in a laboratory environment. Of course, it is not practical to duplicate the AMT experiment exactly in the laboratory, since it would take hundreds (or possibly thousands) of hours to collect an equivalent amount of data. In stead, we ran a small study in which we recruited 30 volunteers through email inquiries to acquaintences and students unfamiliar with our project. Of these volunteers, 20 were male and 10 were female. They span a range of ages: 6 were ? 20 years old, 16 (2130), 2 (31-40), 2 (41-50), 3 (51-60), and 1 (>60). All except four self-evaluate as having at least ?plenty? of experience with computers, but only 9 report having ?plenty? of experience with graphics. Every participant performed the study on a Windows computer with a 3-button mouse. We asked each of the participants to select points on 19 meshes (one selected randomly from each object category) with the exact same instructions and user interface provided on the AMT (substituting the incentive to gain ?points? for selections consistent with others? rather than higher monetary payment). After completion, partipants completed an exit survey, in which 25 responded ?yes? or ?mostly? to a question asking whether they completed the task to their satisfaction. We rejected data from the other users, leaving 474 point sets from 25 participants. Of those, 354 (74.7%) passed all three data filters ? 66 (13.9%) had too few points, 23 (4.9%) were entered with too little camera motion, and 31 (6.5%) were clicked too hastily. This is a significantly lower rejection rate than for the data collected on the AMT. Analyzing the point sets passing all filters, we find that they closely matches the characteristics of data collected on the AMT. In particular, the distribution of distances indicating the consistency of points selected by different people on the same mesh ( Figure 10a ) and the reflective symmetry of points selected by the same user on the same mesh are almost identical to those collected on the AMT for the same set of meshes ( Figure 10b ). Of course, there is not enough data to study consistency across different meshes in the same class, or to study variations within specific subsets of objects. However, all statistics computed for this small, controlled data set closely match those of the larger AMT data set.\n        ACM Transactions on Graphics, Vol. 31, No. 4, Article 29, Publication Date: July 2012\n        29:10\n        ?\n        X. Chen et al.\n        \n          \n          Figure 10: Comparison of consistency and symmetry of point sets collected in a small, controlled study (left) versus ones collected from people on the Amazon Mechanical Turk (right). (a) The top row shows the consistency of points selected by different people on the same mesh (like Figure 3a ). (b) The bottom row shows the consistency of points selected by the same person on symmetric sides of a mesh (like Figure 3c ).\n        \n        \n          \n          Figure 11: The predicted Schelling distribution S ? D (left) can be used to preserve salient detail during mesh simplfication.\n        \n      \n      \n        9 Conclusion\n        In this paper, we have described a study of Schelling points on 3D meshes ? i.e., points that people expect to be selected by other people. With an on-line experiment, we gathered 9,965 points sets containing a total of 201,304 points. During both qualitative and quantitative analysis, we find that these points appear mainly at ?semantically stable? positions on a 3D mesh ? e.g., extrema of curvature, on axes of symmetry, centers of segments, etc. We also find that they are selected fairly consistently by different people on the same mesh, and slightly less so on different meshes of the same object class. However, they are selected very consistently on symmetric parts within the same mesh. We have used this data to train an algorithm for predicting the distribution of Schelling point on new meshes and used it in algorithms for feature point detection.  The saliency measures produced with our methods could be used in a variety of applications in computer graphics (e.g., [Alexa 2000; Funkhouser and Shilane 2006; Johnson 2000; Katz et al. 2005; Lee et al. 2005; Zhang et al. 2005]). For example, Figure 11 shows how a predicted Schelling distribution can guide a mesh simplification algorithm to preserve features with higher expected semantic salience (as in [Lee et al. 2005]). In this case, quadric errors used by QSlim [Garland and Heckbert 1997] were scaled by S ? D 2 learned with regression from InClass examples. Note how detail is better preserved in salient areas. Our study is just a first step and thus has several limitations that suggest topics for future work. First, it considers only watertight meshes with relatively smooth features, and therefore some of the findings regarding local geometric features may not generalize to polygon-soup models commonly found in computer graphics repositories. Second, it considers only point features: studying line and region features would also be valuable. Third, it studies geometric surface properties of the collected data: future work could study other aspects of the data, including the time-dependent strategy people used to select feature points. Finally, it focuses only on applications in computer graphics (mesh saliency and feature point detection): future work might consider questions in perceptual psychology.\n        ACM Transactions on Graphics, Vol. 31, No. 4, Article 29, Publication Date: July 2012\n        Schelling Points on 3D Surface Meshes\n        ?\n        29:11\n      \n      \n        Acknowledgments\n        We thank Doug DeCarlo for introducing us to the work of Thomas Schelling and Maneesh Singh for useful discussions during the early phases of the project. We also thank Daniela Giorgi and AIM@SHAPE for access to the SHREC 2007 Watertight Models and Evangelos Kalogerakis for use of shape feature extraction code. Finally, we thank NSF (CCF-0937139, CNS-0831374), Intel (ISTC-VC), Adobe, and Google for partial funding of this project.\n      \n      \n        References\n        \n          A LEXA , M. 2000. Merging polyhedral shapes with scattered features. Visual Computer 16, 26?37.\n          A MAZON , 2009. Mechanical turk. http://www.mturk.com .\n          A TTNEAVE , F. 1954. Some informational aspects of visual perception. Psychological Review 61, 3.\n          B REIMAN , L. 2001. Random forests. Machine Learning 45, 1, 5?32.\n          B RONSTEIN , A., B RONSTEIN , M., AND K IMMEL , R. 2006. Generalized multidimensional scaling: A framework for isometryinvariant partial surface matching. Proceedings of the National Academy of Science, 1168?1172.\n          B RONSTEIN , A., B RONSTEIN , M., B USTOS , B., C ASTELLANI , U., C RISANI , M., F ALCIDIENO , B., G UIBAS , L., K OKKINOS , I., M URINO , V., O VSJANIKOV , M., P ATANE , G., S IPIRAN , I., S PAGNUOLO , M., AND S UN , J. 2010. SHREC 2011: robust feature detection and description benchmark. In Eurographics Workshop on 3D Object Retrieval.\n          C ASTELLANI , U., C RISTANI , M., F ANTONI , S., AND M URINO , V. 2008. Sparse points matching by combining 3d mesh saliency with statistical descriptors. Computer Graphics Forum 27, 2, 643?652.\n          C HEN , X., G OLOVINSKIY , A., AND F UNKHOUSER , T. 2009. A benchmark for 3D mesh segmentation. ACM Transactions on Graphics (Proc. SIGGRAPH) 28, 3 (Aug.).\n          C HUA , C., AND J ARVIS , R. 1996. Point signatures: A new representation for 3D object recognition. International Journal of Computer Vision 25, 1, 63?85.\n          C OLE , F., G OLOVINSKIY , A., L IMPAECHER , A., B ARROS , H. S., F INKELSTEIN , A., F UNKHOUSER , T., AND R USINKIEWICZ , S. 2008. Where do people draw lines? ACM Transactions on Graphics (Proc. SIGGRAPH) 27, 3 (Aug.).\n          C OLE , F., S ANIK , K., D E C ARLO , D., F INKELSTEIN , A., F UNKHOUSER , T., AND AN D M ANISH S INGH , S. R. 2009. How well do line drawings depict shape? ACM Transactions on Graphics (Proc. SIGGRAPH) 28, 3 (Aug.).\n          F UNKHOUSER , T., AND S HILANE , P. 2006. Partial matching of 3d shapes with priority-driven search. In Symposium on Geometry Processing.\n          G AL , R., AND C OHEN -O R , D. 2006. Salient geometric features for partial shape matching and similarity. ACM Transaction on Graphics (January).\n          G ARLAND , M., AND H ECKBERT , P. S. 1997. Surface simplification using quadric error metrics. In Proceedings of SIGGRAPH 1997, Computer Graphics Proceedings, Annual Conference Series, 209?216.\n          G IORGI , D., B IASOTTI , S., AND P ARABOSCHI , L., 2007. SHREC:SHape REtrieval Contest: Watertight models track, http://watertight.ge.imati.cnr.it/.\n          H EER , J., AND B OSTOCK , M. 2010. Crowdsourcing graphical perception: Using Mechanical Turk to assess visualization design. In ACM Human Factors in Computing Systems (CHI), 203?212.\n          H ISADA , M., B ELYAEV , A., AND K UNII , T. 2002. A skeletonbased approach for detection of perceptually salient features on polygonal surfaces. Computer Graphics Forum 21, 4, 689?700.\n          H OFFMAN , D. D., AND S INGH , M. 1997. Salience of visual parts. vol. 63.\n          H UANG , T., C HENG , K., AND C HUANG , Y. 2009. A collaborative benchmark for region of interest detection algorithms. 296?303.\n          I TTI , L., K OCH , C., AND N EIBUR , E. 1998. A model of saliencybased visual attention for rapid scene analysis. IEEE Transactions on Pattern Analysis and Machine Intelligence 20, 11, 1254?1259.\n          J OHNSON , A. 2000. Surface landmark selection and matching in natural terrain. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), vol. 2, 413?420. Using saliency in choosing spin images.\n          K ALOGERAKIS , E., H ERTZMANN , A., AND S INGH , K. 2010. Learning 3d mesh segmentation and labeling. ACM Transactions on Graphics (proc. SIGGRAPH) 29, 3.\n          K ATZ , S., L EIFMAN , G., AND T AL , A. 2005. Mesh segmentation using feature point and core extraction. Visual Computer (September).\n          K IM , Y., V ARSHNEY , A., AND ADN F RANC  ? OIS G UIMBRETI ? RE , D. J. 2010. Mesh saliency and human eye fixations. ACM Transactions on Applied Perception 7, 2 (February).\n          K IM , V., L IPMAN , Y., AND F UNKHOUSER , T. 2011. Blended intrinsic maps. ACM Transactions on Graphics (SIGGRAPH 2011) (jul).\n          K O , B., AND N AM , J. 2006. Object-of-interest image segmentation based on human attention and semantic region clustering. J Opt Soc Am A Opt Image Sci Vis 23, 10 (October), 2462?2470.\n          K OCH , C., AND U LLMAN , S. 1985. Shifts in selective visual attention: towards the underlying neural circuitry. Human Neurobiology 4, 219?227.\n          K RAEVOY , V., AND S HEFFER , A. 2004. Cross-parameterization and compatible remeshing of 3d models. ACM Transactions on Graphics (Proc SIGGRAPH) 23, 3, 861?869.\n          L EE , C. H., V ARSHNEY , A., AND J ACOBS , D. W. 2005. Mesh saliency. ACM Transactions on Graphics (SIGGRAPH 2005) (aug).\n          L EWIS , D. 1969. Convention: A Philosophical Study. Harvard University Press.\n          L I , X., AND G USKOV , I. 2005. Multi-scale features for approximate alignment of point-based surfaces. In Symposium on Geometry Processing.\n          L I , X., AND G USKOV , I. 2007. 3d object recognition from range images using pyramid matching. In Workshop on 3D Representation for Recognition (3dRR).\n          L IPMAN , Y., AND F UNKHOUSER , T. 2009. Mobius voting for surface correspondence. ACM Transactions on Graphics (SIGGRAPH 2009) (August).\n          M ILANES , R., W ECHSLER , H., G IL , S., B OST , J., AND P UN , T. 1994. Integration of bottom-up and top-down cues for visual attention using non-linear relaxation. IEEE Computer Vision and Pattern Recognition, 781?785.\n          M OREELS , P., AND P ERONA , P. 2007. Evaluation of features detectors and descriptors based on 3d objects. IJCV 73, 3 (July), 263?284.\n          N OVOTNI , M., D EGENER , P., AND K LEIN , R. 2005. Correspondence generation and matching of 3d shape subparts. Tech. Rep. CG-2005-2, Universit?t Bonn, June.\n          P ARKER , P. 2011. Webster?s On-line Dictionary: The Rosetta Edition. http://www.websters-online-dictionary.org .\n          P RIVITERA , C., AND S TARK , L. 2000. Algorithms for defining visual regions-of-interest: Comparison with eye fixations. PAMI 22, 9 (September), 970?982.\n          R OSENHOLTZ , R. 1999. A simple saliency model predicts a num ber of motion popout phenomena. Vision Research 39, 19, 3157? 3163.\n          R USINKIEWICZ , S. 2004. Estimating curvatures and their derivatives on triangle meshes. In Symposium on 3D Data Processing, Visualization, and Transmission.\n          S ANTELLA , A., AND D E C ARLO , D. 2004. Robust clustering of eye movement recordings for quantification of visual interest. In Eye Tracking Research and Applications (ETRA), 27?34.\n          S CHELLING , T. 1960. The Strategy of Conflict. Harvard University Press.\n          S CHLATTMANN , M., D EGENER , P., AND K LEIN , R. 2008. Scale space based feature point detection on surfaces. Journal of WSCG 16 (February).\n          S CHMID , C., M OHR , R., AND B AUCKHAGE , C. 2000. Evaluation of interest point detectors. IJCV 37, 2 (June), 151?172.\n          S EBE , N., AND L EW , M. 2003. Comparing salient point detectors. Pattern Recognition Letters 24, 1-3 (January), 89?96.\n          S HAPIRA , L., S HAMIR , A., AND C OHEN -O R , D. 2008. Consistent mesh partitioning and skeletonisation using the shape diameter function. Vis. Comput. 24, 4, 249?259.\n          S HILANE , P., AND F UNKHOUSER , T. 2007. Distinctive regions of 3d surfaces. ACM Transactions on Graphics 26, 2 (June).\n          S IMPSON , J. 1989. Oxford English Dictionary, Second Edition. Oxford University Press. http://dictionary.oed.com .\n          S ONTHI , R., K UNJUR , G., AND G ADH , R. 1997. Shape feature determination using the curvature region representation. In Proc. Solid Modeling, ACM.\n          S TARK , M., AND S CHIELE , B. 2007. How good are local features for classes of geometric objects. 1?8.\n          S UMNER , R., AND P OPOVIC , J. 2004. Deformation transfer for triangle meshes. ACM Transactions on Graphics (Proc SIGGRAPH) 23, 3, 399?405.\n          S UN , J., O VSJANIKOV , M., AND G UIBAS , L. 2009. A Concise and Provably Informative Multi-Scale Signature Based on Heat Diffusion. In Computer Graphics Forum, vol. 28, Wiley Online Library, 1383?1392.\n          T SOTSOS , J., C ULHANE , S., W AI , W., L AI , Y., D AVIS , N., AND N UFLO , F. 1995. Modeling visual-attention via selective tuning. Artificial Intelligence 78, 1-2, 507?545.\n          VAN K AICK , O., Z HANG , H., H AMARNEH , G., AND C OHEN O R , D. 2010. A survey on shape correspondence. In Proc. of Eurographics State-of-the-art Report.\n          V ON A HN , L., AND D ABBISH , L. 2008. Designing games with a purpose. Communications of the ACM 51, 8, 58?67.\n          W ITTEN , I. H., AND F RANK , E. 2005. Data mining: Practical machine learning tools and techniques, 2nd edition.\n          X U , K., Z HANG , H., T AGLIASACCHI , A., L IU , L., L I , G., M ENG , M., AND X IONG , Y. 2009. Partial intrinsic reflectional symmetry of 3d shapes. ACM Transactions on Graphics, (Proceedings SIGGRAPH Asia 2009) 28, 5, to appear.\n          Z AHARESCU , A., B OYER , E., V ARANASI , K., AND H ORAUD , R. 2009. Surface feature detection and description with applications to mesh matching. In CVPR.\n          Z HANG , E., M ISCHAIKOW , K., AND T URK , G. 2005. Featurebased surface parameterization and texture mapping. ACM Transactions on Graphics 24, 1.\n          Z HANG , H., S HEFFER , A., C OHEN -O R , D., Z HOU , Q., VAN K AICK , O., AND T AGLIASACCHI , A. 2008. Deformationdriven shape correspondence. Comput. Graph. Forum 27, 5, 1431?1439.\n          Z HOU , Y., AND H UANG , Z. 2004. Decomposing polygon meshes by means of critical points. In MMM, 187?195.\n          Z ULIANI , M., K ENNEY , C., AND M ANJUNATH , B. 2004. A mathematical comparison of point detectors. In Computer Vision and Pattern Recognition Workshop, 172.\n        \n        ACM Transactions on Graphics, Vol. 31, No. 4, Article 29, Publication Date: July 2012\n        29:12\n        ?\n        X. Chen et al.\n        ACM Transactions on Graphics, Vol. 31, No. 4, Article 29, Publication Date: July 2012\n      \n    \n  ",
  "resources" : [ ]
}