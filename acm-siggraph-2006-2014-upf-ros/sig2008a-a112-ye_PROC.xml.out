{
  "uri" : "sig2008a-a112-ye_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2008a/a112-ye_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Animating Responsive Characters with Dynamic Constraints in Near-Unactuated Coordinates",
    "published" : "2008",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Yuting-Ye",
      "name" : "Yuting",
      "surname" : "Ye"
    }, {
      "uri" : "http://drinventor/C. Karen-Liu",
      "name" : "C. Karen",
      "surname" : "Liu"
    } ]
  },
  "bagOfWords" : [ "we", "demonstrate", "simplicity", "robustness", "we", "technique", "show", "variety", "example", "generate", "same", "set", "parameter", "consequently", "most", "application", "only", "focus", "perturbation", "have", "large", "impact", "character", "since", "virtually", "impossible", "predefine", "all", "possible", "perturbation", "animated", "response", "although", "we", "focus", "small-scale", "perturbation", "mainly", "affect", "upper", "body", "motion", "we", "technique", "can", "integrate", "seamlessly", "any", "technique", "produce", "balanced", "lower", "body", "motion", "presence", "large", "perturbation", "we", "able", "identify", "those", "compliant", "dof", "we", "can", "apply", "hybrid", "method", "only", "consider", "dynamics", "compliant", "dof", "kinematically", "control", "rest", "character", "we", "method", "provide", "more", "principled", "way", "identify", "less", "actuated", "coordinate", "-lrb-", "correspond", "eigenvalue", "close", "zero", "-rrb-", "specific", "each", "input", "motion", "sequence", "we", "denote", "those", "dof", "near-unactuated", "coordinate", "because", "near-unactuated", "coordinate", "use", "very", "little", "internal", "torque", "input", "motion", "enforce", "dynamic", "equation", "zero", "internal", "actuation", "do", "visually", "modify", "input", "motion", "when", "external", "perturbation", "when", "character", "perturb", "however", "near-unactuated", "coordinate", "compliantly", "react", "external", "force", "while", "actuate", "coordinate", "attempt", "maintain", "input", "joint", "position", "we", "modify", "lower", "body", "motion", "simple", "kinematic", "method", "base", "perturbation", "force", "enforce", "dynamic", "constraint", "near-unactuated", "coordinate", "lead", "two", "main", "advantage", "generalize", "coordinate", "we", "parameterization", "align", "mechanical", "joint", "space", "rather", "align", "more", "meaningful", "actuation", "space", "derive", "from", "input", "motion", "practice", "we", "technique", "can", "adapt", "transparently", "any", "kinematically", "control", "framework", "without", "aid", "forward", "simulator", "additional", "motion", "datum", "we", "demonstrate", "simplicity", "robustness", "we", "approach", "show", "wide", "range", "input", "motion", "arbitrary", "perturbation", "we", "result", "show", "realistic", "recovery", "motion", "emerge", "consequence", "interaction", "kinematic", "dynamic", "control", "we", "believe", "behavior", "due", "fact", "objective", "function", "must", "pull", "joint", "back", "original", "trajectory", "without", "use", "any", "internal", "torque", "near-unactuated", "coordinate", "synthesize", "responsive", "character", "animation", "important", "research", "topic", "broad", "range", "application", "da", "Silva", "et", "al.", "-lsb-", "2008", "-rsb-", "introduce", "systematic", "method", "derive", "balance", "controller", "tailor", "input", "motion", "reduce", "effort", "parameter", "tuning", "we", "method", "also", "produce", "responsive", "motion", "preserve", "style", "input", "motion", "kinematically", "control", "character", "animation", "more", "preferable", "many", "online", "application", "because", "easier", "implement", "provide", "precise", "user", "controllability", "we", "method", "also", "take", "hybrid", "approach", "synthesis", "responsive", "motion", "however", "instead", "divide", "kinematic", "dynamic", "control", "time", "domain", "we", "divide", "they", "spatially", "transform", "space", "span", "set", "basis", "represent", "joint", "actuation", "original", "motion", "many", "technique", "have", "successfully", "demonstrate", "pre-recorded", "datum", "can", "adapt", "new", "situation", "response", "online", "user", "control", "-lsb-", "treuille", "et", "al.", "2007", "McCann", "Pollard", "2007", "Cooper", "et", "al.", "2007", "Shin", "oh", "2006", "-rsb-", "few", "method", "extend", "data-driven", "approach", "synthesize", "responsive", "motion", "balance", "recovery", "against", "external", "force", "-lsb-", "Arikan", "et", "al.", "2005", "Yin", "et", "al.", "2005", "-rsb-", "we", "method", "synthesize", "responsive", "motion", "via", "dynamic", "constraint", "instead", "motion", "blending", "thereby", "completely", "remove", "dependency", "motion", "database", "moreover", "we", "allow", "direct", "kinematic", "control", "additional", "objective", "biomechanic", "researcher", "have", "apply", "dimension", "reduction", "technique", "muscle", "activation", "datum", "measure", "from", "behavioral", "experiment", "-lsb-", "Tresch", "et", "al.", "2006", "Ting", "2007", "Alexandrov", "et", "al.", "2005", "-rsb-", "we", "method", "inspire", "ting?s", "work", "we", "formulate", "dynamic", "equation", "space", "muscle", "synergy", "rather", "than", "space", "joint", "configuration", "however", "we", "do", "use", "PCA", "tool", "dimension", "reduction", "we", "only", "apply", "pca", "identify", "principle", "component", "correspond", "lower", "eigenvalue", "because", "principle", "component", "represent", "dimension", "motion", "where", "active", "body", "control", "do", "play", "important", "role", "we", "entire", "algorithm", "can", "describe", "three", "simple", "step", "give", "input", "motion", "sequence", "apply", "inverse", "dynamics", "method", "obtain", "internal", "joint", "torque", "upper", "body", "apply", "pca", "obtain", "set", "eigenvector", "E.", "define", "set", "near-unactuated", "coordinate", "subset", "smallest", "corresponding", "eigenvalue", "formulate", "constrain", "optimization", "each", "frame", "solve", "pose", "satisfy", "equation", "motion", "while", "maintain", "original", "motion", "we", "represent", "character?s", "skeleton", "transformation", "hierarchy", "18", "body", "node", "24", "dof", "upper", "body", "12", "dof", "lower", "body", "global", "translation", "orientation", "represent", "six", "dof", "root", "hierarchy", "preprocessing", "step", "we", "perform", "inverse", "dynamics", "method", "pca", "input", "motion", "identify", "near-unactuated", "coordinate", "one", "cycle", "from", "input", "motion", "manually", "select", "preprocessing", "compute", "joint", "torque", "input", "motion", "we", "express", "la", "where", "lagrangian", "dynamic", "system", "internal", "torque", "th", "column", "jacobian", "matrix", "which", "project", "external", "force", "onto", "absence", "external", "force", "apply", "upper", "body", "we", "use", "equation", "-lrb-", "-rrb-", "solve", "internal", "joint", "torque", "upper", "body", "each", "frame", "form", "joint", "torque", "basis", "-lsb-", "-rsb-", "24", "where", "number", "frame", "select", "input", "motion", "cycle", "perform", "pca", "yield", "eigenvector", "-lsb-", "24", "-rsb-", "rank", "from", "largest", "corresponding", "eigenvalue", "smallest", "we", "divide", "two", "set", "-lsb-", "-rsb-", "contain", "first", "24", "eigenvector", "contain", "rest", "eigenvector", "smallest", "corresponding", "eigenvalue", "we", "define", "set", "near-unactuated", "coordinate", "we", "implementation", "set", "10", "all", "example", "except", "Tai", "Chi", "motion", "we", "discretize", "time", "domain", "interval", "1/60s", "input", "motion", "each", "time", "step", "we", "solve", "upper", "body", "joint", "angle", "next", "interval", "formulate", "constrain", "optimization", "we", "use", "dynamic", "constraint", "ensure", "nearunactuated", "coordinate", "have", "zero", "internal", "actuation", "all", "time", "where", "internal", "joint", "torque", "upper", "body", "compute", "via", "equation", "-lrb-", "-rrb-", "express", "function", "f.", "backward", "difference", "use", "compute", "joint", "velocity", "-lrb-", "-rrb-", "Joint", "acceleration", "compute", "central", "differencing", "-lrb-", "+1", "2q", "-rrb-", "perturbation", "-lrb-", "-rrb-", "original", "motion", "close", "satisfy", "we", "use", "spring-like", "objective", "track", "input", "motion", "-lrb-", "-rrb-", "damp", "objective", "model", "dissipation", "dynamic", "system", "when", "human", "perturb", "unexpectedly", "typically", "delay", "between", "perturbation", "muscle", "activation", "due", "latency", "sensory", "feedback", "-lsb-", "Miall", "et", "al.", "1985", "Georgopoulos", "et", "al.", "1981", "-rsb-", "delay", "arm", "movement", "due", "visual", "sensory", "feedback", "usually", "range", "from", "150-250", "ms.", "we", "incorporate", "delay", "minimize", "torque", "change", "200", "m", "after", "perturbation", "highly", "actuated", "coordinate", "E.", "summary", "we", "formulate", "follow", "optimization", "each", "time", "step", "solve", "upper", "body", "motion", "argmin", "subject", "+1", "-lrb-", "-rrb-", "where", "operator", "denote", "element-wise", "multiplication", "two", "vector", "all", "we", "experiment", "we", "set", "every", "element", "200", "three", "element", "correspond", "spine", "ball", "joint", "dof", "30", "rest", "element", "10", "all", "element", "set", "30", "time", "perturbation", "smoothly", "decrease", "zero", "200", "ms.", "value", "do", "depend", "input", "motion", "skeletal", "model", "although", "we", "method", "focus", "upper", "body", "response", "we", "formulate", "simple", "computation", "root", "lower", "body", "motion", "when", "character", "perturb", "since", "we", "method", "do", "model", "ground", "contact", "friction", "force", "impact", "perturbation", "root", "can", "simply", "model", "impulse", "proportional", "external", "force", "root", "movement", "cause", "footskating", "penetration", "ground", "we", "apply", "simple", "inverse", "kinematic", "method", "lower", "body", "fix", "foot", "contact", "we", "apply", "we", "method", "variety", "cyclic", "motion", "different", "style", "perform", "different", "subject", "one", "complete", "cycle", "each", "motion", "sufficient", "compute", "near-unacutated", "coordinate", "upper", "body", "simulation", "run", "20", "frame", "per", "second", "single", "core", "2.8", "GHz", "Intel", "Core", "duo", "processor", "we", "use", "snopt", "-lsb-", "Gill", "et", "al.", "1996", "-rsb-", "solve", "optimization", "problem", "each", "time", "step", "we", "result", "reveal", "dynamic", "constraint", "near-unactuated", "coordinate", "produce", "compliant", "response", "unexpected", "perturbation", "coordinate", "recovery", "motion", "customize", "input", "motion", "all", "example", "be", "generate", "use", "identical", "set", "weight", "describe", "section", "experiment", "show", "wide", "range", "weight", "produce", "similar", "result", "please", "see", "supplemental", "video", "all", "example", "describe", "below", "eigenvector", "analysis", "demonstrate", "importance", "joint", "actuation", "space", "we", "conduct", "several", "experiment", "normal", "walk", "different", "choice", "coordinate", "which", "dynamic", "constraint", "enforce", "we", "first", "simulated", "same", "input", "motion", "different", "value", "number", "dynamic", "constraint", "nearunactuated", "coordinate", "character", "appear", "more", "responsive", "number", "dynamic", "constraint", "increase", "however", "character", "able", "completely", "recover", "from", "perturbation", "when", "more", "than", "12", "dynamic", "constraint", "when", "number", "dynamic", "constraint", "increase", "16", "character", "simply", "fail", "track", "input", "motion", "second", "experiment", "simulated", "motion", "dynamic", "constraint", "coordinate", "correspond", "higher", "eigenvalue", "result", "show", "character", "able", "maintain", "original", "motion", "without", "actuation", "those", "coordinate", "perturbation", "we", "first", "experiment", "apply", "same", "external", "force", "different", "body", "part", "1.7", "80kg", "male", "character", "during", "different", "phase", "normal", "walking", "sequence", "result", "show", "same", "push", "incur", "larger", "response", "during", "single", "support", "than", "double", "support", "moreover", "character", "exhibit", "more", "stability", "when", "push", "apply", "same", "side", "support", "leg", "when", "push", "arm", "character", "react", "more", "compliantly", "than", "when", "push", "head", "shoulder", "-lrb-", "figure", "-rrb-", "second", "experiment", "test", "effect", "different", "external", "force", "direction", "character", "have", "harder", "time", "recover", "from", "backward", "push", "than", "forward", "one", "indicate", "he", "torso", "actuation", "asymmetric", "along", "sagittal", "direction", "addition", "produce", "highly", "coordinate", "reaction", "we", "method", "also", "preserve", "individual", "style", "we", "demonstrate", "large-scale", "arm", "movement", "female", "character", "-lrb-", "1.5", "40kg", "-rrb-", "preserve", "she", "reactive", "motion", "we", "scale", "magnitude", "external", "force", "proportionally", "female", "subject?s", "weight", "we", "method", "also", "allow", "user", "interact", "character", "perturb", "root", "movement", "illustrate", "we", "simulated", "reaction", "character", "step", "fast", "move", "platform", "root", "accelerate", "abruptly", "character?s", "upper", "body", "react", "passively", "gradually", "recover", "original", "motion", "pattern", "style", "coordinate", "actuation", "space", "encode", "muscle", "usage", "coordination", "specific", "input", "motion", "consequently", "each", "motion", "sequence", "react", "unexpected", "perturbation", "unique", "style", "we", "apply", "same", "set", "external", "force", "normal", "walk", "backward", "walk", "sneaky", "walk", "perform", "same", "male", "character", "-lrb-", "figure", "-rrb-", "comparison", "other", "motion", "normal", "walk", "exhibit", "higher", "coordination", "among", "upper", "body", "counteract", "disturbance", "use", "torso", "both", "arm", "simultaneously", "backward", "walk", "motion", "exhibit", "higher", "stability", "against", "forward", "push", "response", "compliantly", "backward", "push", "sneaky", "walk", "character", "maintain", "more", "stable", "posture", "center", "mass", "position", "lower", "than", "other", "motion", "result", "show", "same", "amount", "force", "induce", "smaller", "response", "sneaky", "walk", "compare", "actuation", "among", "style", "individual", "we", "extract", "near", "unactuated", "coordinate", "one", "individual", "perform", "normal", "walk", "apply", "they", "simulate", "another", "individual?s", "normal", "walk", "under", "perturbation", "result", "show", "plausible", "reactive", "motion", "can", "generate", "only", "when", "two", "individual", "have", "similar", "weight", "height", "we", "also", "conduct", "similar", "experiment", "different", "action", "style", "actuation", "sneaky", "walk", "reproduce", "normal", "walk", "faithfully", "without", "disturbance", "generate", "unrealistic", "response", "when", "perturb", "additional", "objective", "we", "formulation", "allow", "animator", "include", "additional", "objective", "enforce", "kinematic", "property", "input", "motion", "example", "we", "capture", "walking", "sequence", "subject", "hold", "cup", "he", "right", "hand", "during", "motion", "synthesis", "additional", "objective", "add", "keep", "cup", "upright", "orientation", "asymmetrical", "muscle", "usage", "left", "right", "arm", "result", "many", "interesting", "behavior", "when", "character", "push", "right", "arm", "he", "maintain", "orientation", "cup", "rotate", "he", "torso", "compensate", "movement", "he", "right", "arm", "contrast", "when", "left", "arm", "push", "same", "force", "he", "stiffen", "he", "torso", "reduce", "its", "movement", "impact", "right", "arm", "similarly", "we", "add", "objective", "repel", "character", "from", "obstacle", "environment", "character", "fail", "completely", "avoid", "obstacle", "external", "force", "apply", "site", "collision", "non-locomotion", "we", "method", "also", "work", "other", "periodic", "motion", "Tai", "Chi", "form", "although", "Tai", "Chi", "motion", "require", "higher", "overall", "internal", "torque", "than", "other", "locomotion", "sequence", "-lrb-", "-rrb-", "highly", "actuated", "coordinate", "mostly", "lie", "frontal", "plane", "moreover", "torque", "usage", "arm", "Tai", "Chi", "motion", "highly", "correlate", "result", "character", "react", "perturbation", "sagittal", "plane", "both", "arm", "move", "fluidly", "we", "have", "present", "technique", "synthesize", "generic", "class", "dynamic", "response", "small-scale", "perturbation", "enforce", "dynamic", "constraint", "actuation", "space", "virtual", "character", "respond", "arbitrary", "unexpected", "perturbation", "specific", "style", "encode", "input", "motion", "we", "have", "demonstrate", "simplicity", "robustness", "we", "technique", "show", "variety", "example", "generate", "same", "set", "parameter", "we", "method", "can", "readily", "augmented", "any", "kinematic", "technique", "character", "animation", "motion", "graph", "motion", "blending", "without", "modification", "exist", "implementation", "nor", "additional", "datum", "main", "assumption", "we", "approach", "only", "small", "set", "coordinate", "muscle", "group", "activate", "perform", "rhythmic", "motion", "biomechanic", "researcher", "have", "also", "hypothesize", "postural", "response", "under", "perturbation", "can", "activate", "few", "muscle", "synergy", "-lsb-", "Torres-Oviedo", "Ting", "2007", "-rsb-", "we", "result", "suggest", "same", "muscle", "synergy", "use", "input", "motion", "can", "also", "produce", "reasonable", "recovery", "motion", "from", "small", "perturbation", "thereby", "lend", "support", "hypothesis", "muscle", "synergy", "building", "block", "construct", "motor", "output", "pattern", "however", "we", "method", "robust", "against", "steady", "perturbation", "clear", "whether", "human", "body", "switch", "different", "muscle", "synergy", "when", "present", "sustained", "disturbance", "we", "anticipate", "technique", "can", "apply", "whole", "body", "motion", "we", "can", "accurately", "measure", "ground", "contact", "force", "we", "approach", "use", "inverse", "dynamics", "method", "principle", "component", "analysis", "both", "which", "know", "sensitive", "input", "noise", "fortunately", "we", "method", "do", "directly", "apply", "computed", "torque", "simulate", "motion", "only", "use", "they", "derive", "eigenbasis", "input", "activity", "we", "test", "robustness", "we", "method", "against", "datum", "noise", "randomly", "select", "different", "cycle", "from", "input", "motion", "result", "show", "sporadic", "noise", "motion", "have", "negligible", "effect", "long", "input", "motion", "contain", "sufficient", "clean", "datum", "author", "would", "like", "thank", "Satoru", "Ishigaki", "Wei", "Liu", "Shuang", "Hao", "help", "collect", "motion", "datum", "work", "support", "NSF", "grant", "ccf-cise", "0742303" ],
  "content" : "We demonstrate the simplicity and robustness of our technique by showing a variety of examples generated with the same set of parameters. Consequently, most applications only focus on perturbations that have a large impact on the character since it is virtually impossible to predefine all possible perturbations and animated responses. Although we focus on small-scale perturbations that mainly affect the upper body motion, our technique can be integrated seamlessly with any technique that produces balanced lower body motion in the presence of large perturbations. If we are able to identify those compliant DOFs, we can apply a hybrid method that only considers dynamics in the compliant DOFs and kinematically controls the rest of the character. Our method provides a more principled way to identify the less actuated coordinates (corresponding to eigenvalues close to zero) specific to each input motion sequence. We denote those DOFs as near-unactuated coordinates. Because the near-unactuated coordinates use very little internal torques in the input motion, enforcing the dynamic equations with zero internal actuation does not visually modify the input motion when there is no external perturbation. When the character is perturbed, however, the near-unactuated coordinates will compliantly react to the external force while the actuated coordinates will attempt to maintain the input joint positions. We modify the lower body motion with a simple kinematic method based on the perturbation force. Enforcing dynamic constraints in the near-unactuated coordinates leads to two main advantages. The generalized coordinates in our parameterization are not aligned with the mechanical joint space, but rather aligned with a more meaningful actuation space derived from the input motion. In practice, our technique can be adapted transparently to any kinematically controlled framework without the aid of a forward simulator or additional motion data. We demonstrate the simplicity and robustness of our approach by showing a wide range of input motions with arbitrary perturbations. Our results show that realistic recovery motion emerges as a consequence of the interaction of the kinematic and the dynamic control. We believe this behavior is due to the fact that the objective function must pull the joints back to the original trajectories without using any internal torques in the near-unactuated coordinates. Synthesizing responsive character animation is an important research topic with a broad range of applications. da Silva et al. [2008] introduced a systematic method to derive a balance controller tailored to the input motion, reducing the effort on parameter tuning. Our method also produces responsive motion that preserves the ?style? of the input motion. Kinematically controlled character animation is more preferable in many online applications because it is easier to implement and provides precise user controllability. Our method also takes a hybrid approach to synthesis of responsive motions. However, instead of dividing the kinematic and dynamic control in the time domain, we divide them spatially in a transformed space, spanned by a set of basis representing the joint actuation in the original motion. Many techniques have successfully demonstrated that pre-recorded data can be adapted to new situations in response to online user control [Treuille et al. 2007; McCann and Pollard 2007; Cooper et al. 2007; Shin and Oh 2006]. A few methods extended data-driven approaches to synthesizing responsive motions, such as balance recovery against external forces [Arikan et al. 2005; Yin et al. 2005]. Our method synthesizes responsive motions via dynamic constraints instead of motion blending, thereby completely removing the dependency on a motion database. Moreover, we allow for direct kinematics control with additional objectives. Biomechanics researchers have applied dimension reduction techniques to the muscle activation data measured from behavioral experiments [Tresch et al. 2006; Ting 2007; Alexandrov et al. 2005]. Our method is inspired by Ting?s work in that we formulate the dynamic equations in the space of muscle synergies, rather than the space of joint configurations. However, we do not use PCA as a tool for dimension reduction. We only apply PCA for identifying the principle components corresponding to lower eigenvalues because these principle components represent the dimensions of the motion where active body control does not play an important role. Our entire algorithm can be described in three simple steps. Given an input motion sequence M, apply the inverse dynamics method to obtain the internal joint torques U on the upper body. Apply PCA on U to obtain a set of eigenvectors E. Define a set of near-unactuated coordinates E ? as a subset of E with k smallest corresponding eigenvalues. Formulate a constrained optimization at each frame to solve for a pose that satisfies the equations of motion in E, ? while maintaining the original motion M. We represent the character?s skeleton as a transformation hierarchy of 18 body nodes with 24 DOFs on the upper body, q u , and 12 DOFs on the lower body, q l . The global translation and orientation are represented by six DOFs, q r , at the root of the hierarchy. In the preprocessing step, we perform the inverse dynamics method and PCA on the input motion to identify the near-unactuated coordinates. One cycle from the input motion is manually selected for preprocessing. To compute the joint torques of the input motion, we express La- where L is the Lagrangian of the dynamic system, u j is the internal torque in q j , and J j is the j th column of Jacobian matrix J which projects the external force f onto q j . In the absence of external forces applied on the upper body, we use Equation (1) to solve for the internal joint torques u n on the upper body at each frame n, forming a joint torque basis U = [u 1 , u 2 , ? ? ? , u N ] ? R 24?N , where N is the number of frames in the selected input motion cycle. Performing PCA on U yields eigenvectors E = [e 1 , e 2 , ? ? ? , e 24 ], ranked from the largest corresponding eigenvalue to the smallest. We divide E into two sets, E = [ E ? E]: ? E ? contains the first 24 ? k eigenvectors and E ? contains the rest of the eigenvectors with k smallest corresponding eigenvalues. We then define E ? as the set of near-unactuated coordinates. In our implementation, k is set to 10 for all the examples except for the Tai Chi motion. We discretize time domain into intervals of 1/60s as in the input motion. At each time step, we solve for upper body joint angles q u of the next interval n + 1 by formulating a constrained optimization. We use dynamic constraints C D to ensure that the nearunactuated coordinates have zero internal actuation at all times. where the internal joint torques on the upper body u, computed via Equation (1), are expressed as a function of q, q,  ? q  ? and f. Backward differencing is used to compute the joint velocity: q  ? n ? ?t 1 (q n ? q n?1 ). Joint acceleration is computed by central differencing as: q  ? n ? ?t 1 2 (q n+1 ? 2q n + q n?1 ). If there is no perturbation (f = 0), the original motion is close to satisfying C D . We use a spring-like objective to track the input motion M = (m 1 , m 2 ? ? ? , m N ) and a damping objective to model the dissipation in the dynamic system: When human is perturbed unexpectedly, there is typically a delay between the perturbation and muscle activation due to the latency in sensory feedback [Miall et al. 1985; Georgopoulos et al. 1981]. The delay on arm movement due to the visual sensory feedback usually ranges from 150-250 ms. We incorporate this delay by minimizing the torque change for 200 ms after the perturbation in the highly actuated coordinates E. ? In summary, we formulate the following optimization at each time step to solve for upper body motion: argmin w 1 ? G p + w 2 ? G v + w 3 ? G u subject to C D = 0 q n+1 u (6) where operator ? denotes the element-wise multiplication of two vectors. In all our experiments, we set every element of w 1 to 200,  the three elements of w 2 corresponding to the spine ball joint DOFs to 30, and the rest of the elements in w 2 to 10. All the elements in w 3 are set to 30 1 at the time of the perturbation and then smoothly decreased to zero in 200 ms. The values do not depend on the input motion or the skeletal model. Although our method focuses on the upper body response, we formulate a simple computation for the root and lower body motion when the character is perturbed. Since our method does not model the ground contact and friction forces, the impact of the perturbation on the root can simply be modeled as an impulse, proportional to the external force f: If the root movement causes footskating or penetration of the ground, we apply a simple inverse kinematics method on the lower body to fix the foot contacts. We applied our method to a variety of cyclic motions with different styles performed by different subjects. One complete cycle of each motion is sufficient to compute the near-unacutated coordinates for the upper body. The simulation runs at 20 frames per second on a single core of a 2.8 GHz Intel Core 2 Duo processor. We use SNOPT [Gill et al. 1996] to solve the optimization problem at each time step. Our results reveal that dynamic constraints in the near-unactuated coordinates produce compliant responses to unexpected perturbations and coordinated recovery motions customized to the input motion. All the examples were generated using an identical set of weights described in Section 4. Experiments show that a wide range of weights produce similar results. Please see the supplemental video for all the examples described below. Eigenvector analysis To demonstrate the importance of the joint actuation space, we conducted several experiments of a normal walk with different choices of coordinates in which dynamic constraints are enforced. We first simulated the same input motion with different values of k, the number of dynamic constraints in the nearunactuated coordinates. The character appears more responsive as the number of dynamic constraints increases. However, the character is not able to completely recover from a perturbation when there are more than 12 dynamic constraints. When the number of dynamic constraints increases to 16, the character simply fails to track the input motion. The second experiment simulated the motion with dynamic constraints in the coordinates corresponding to higher eigenvalues. The result shows that the character is not able to maintain the original motion without actuations in those coordinates. Perturbation Our first experiment applied the same external force on different body parts of a 1.7m, 80kg male character during different phases of a normal walking sequence. The results show that the same push incurs a larger response during the single support than the double support. Moreover, the character exhibits more stability when the push is applied on the same side of the supporting leg. When pushed on the arms, the character reacts more compliantly than when pushed on the head or shoulder ( Figure 2 ). The second experiment tested the effect of different external force directions. The character has a harder time recovering from a backward push than a forward one, indicating that his torso actuation is asymmetric along the sagittal direction. In addition to producing highly coordinated reactions, our method also preserves individual styles. We demonstrated that the large-scale arm movement of a female character (1.5m, 40kg) is preserved in her reactive motions. We scaled the magnitude of the external forces proportionally to the female subject?s weight. Our method also allows the user to interact with the character by perturbing the root movement. To illustrate this, we simulated the reaction of the character stepping on a fast moving platform. As the root accelerates abruptly, the character?s upper body reacts passively and gradually recovers to the original motion pattern. Style The coordinates in the actuation space encode muscle usage and coordination specific to the input motion. Consequently, each motion sequence reacts to the unexpected perturbations with a unique style. We applied the same set of external forces to normal walk, backward walk, and sneaky walk performed by the same male character ( Figure 3 ). In comparison to other motions, the normal walk exhibits higher coordination among the upper body as it counteracts the disturbance using the torso and both arms simultaneously. The backward walking motion exhibits higher stability against a forward push but responses compliantly to a backward push. In the sneaky walk, the character maintains a more stable posture with the center of mass position lower than other motions. The results show that the same amount of force induces smaller responses on a sneaky walk. To compare the actuation among styles of individuals, we extracted the near unactuated coordinates of one individual performing a normal walk, and applied them to simulate another individual?s normal walk under perturbations. The results show that plausible reactive motions can be generated only when the two individuals have similar weight and height. We also conducted similar experiments for different action styles. The actuation of a sneaky walk reproduces a normal walk faithfully without disturbances, but generates unrealistic response when perturbed. Additional objectives Our formulation allows the animator to include additional objectives to enforce kinematic properties of the input motion. For example, we captured a walking sequence with the subject holding a cup in his right hand. During motion synthesis, an additional objective was added to keep the cup in an upright orientation. The asymmetrical muscle usage in the left and the right arms results in many interesting behaviors. When the character is pushed on the right arm, he maintains the orientation of the cup by rotating his torso to compensate for the movement of his right arm. In contrast, when the left arm is pushed by the same force, he stiffens his torso to reduce its movement and the impact on the right arm. Similarly, we added an objective that repels the character from the obstacles in the environment. If the character fails to completely avoid the obstacles, an external force is applied at the site of collision. Non-locomotion Our method also works on other periodic motions such as Tai Chi forms. Although the Tai Chi motion requires higher overall internal torques than other locomotion sequences (k = 5), the highly actuated coordinates mostly lie on the frontal plane. Moreover, the torque usage of arms in the Tai Chi motion are highly correlated. As a result, the character reacts to perturbations on the sagittal plane with both arms moving fluidly. We have presented a technique that synthesizes a generic class of dynamic responses to small-scale perturbations. By enforcing the dynamic constraints in the actuation space, the virtual character responds to arbitrary unexpected perturbations in a specific style encoded in the input motion. We have demonstrated the simplicity and robustness of our technique by showing a variety of examples generated with the same set of parameters. Our method can be readily augmented to any kinematic technique for character animation, such as motion graphs or motion blending, without modification to the existing implementation nor additional data. The main assumption of our approach is that only a small set of coordinated muscle groups are activated for performing rhythmic motion. Biomechanics researchers have also hypothesized that postural responses under perturbations can be activated by a few muscle synergies [Torres-Oviedo and Ting 2007]. Our results suggest that the same muscle synergies used for the input motion can also produce reasonable recovery motion from a small perturbation, thereby lending support to the hypothesis of muscle synergies as building blocks for constructing motor output patterns. However, our method is not as robust against steady perturbations. It is not clear whether the human body will switch to different muscle synergies when presented with sustained disturbances. We anticipate that the technique can be applied to the whole body motion if we can accurately measure the ground contact forces. Our approach uses inverse dynamics methods and principle component analysis, both of which are known to be sensitive to input noise. Fortunately, our method does not directly apply the computed torques to simulate motion but only uses them to derive the  eigenbasis of the input activity. We tested the robustness of our method against data noise by randomly selecting different cycles from the input motion. The results show that sporadic noise in the motion has negligible effect as long as the input motion contains sufficient clean data. The authors would like to thank Satoru Ishigaki, Wei Liu and Shuang Hao for their help in collecting motion data. This work is supported by NSF grant CCF-CISE 0742303.",
  "resources" : [ ]
}