{
  "uri" : "sig2010a-a144-hachisuka_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2010a/a144-hachisuka_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "A Progressive Error Estimation Framework for Photon Density Estimation",
    "published" : "2010",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Toshiya-Hachisuka",
      "name" : "Toshiya",
      "surname" : "Hachisuka"
    }, {
      "uri" : "http://drinventor/Wojciech-Jarosz",
      "name" : "Wojciech",
      "surname" : "Jarosz"
    }, {
      "uri" : "http://drinventor/Henrik Wann-Jensen",
      "name" : "Henrik Wann",
      "surname" : "Jensen"
    } ]
  },
  "bagOfWords" : [ "we", "have", "implement", "we", "error", "estimation", "top", "implementation", "progressive", "photon", "mapping", "algorithm", "all", "result", "be", "compute", "2.4", "GHz", "Intel", "Core", "q6600", "use", "one", "core", "all", "example", "we", "use", "parameter", "0.8", "progressive", "photon", "mapping", "algorithm", "Figure", "analytic", "investigation", "we", "error", "estimation", "we", "use", "cubic", "ramp", "scene", "describe", "figure", "640000", "sample", "initial", "radius", "1.5", "user-specified", "confidence", "0.95", "graph", "-lrb-", "-rrb-", "show", "estimate", "error", "fact", "above", "actual", "error", "almost", "all", "location", "specify", "we", "further", "investigate", "influence", "bias", "estimation", "noise", "bind", "estimation", "plot", "each", "component", "separately", "graph", "-lrb-", "-rrb-", "note", "we", "framework", "do", "estimate", "bound", "bias", "bias", "itself", "graph", "show", "bias", "estimation", "capture", "error", "due", "bias", "around", "slope", "function", "whereas", "noise", "bind", "estimation", "capture", "error", "due", "sampling", "noise", "around", "flat", "region", "function", "we", "test", "we", "framework", "three", "example", "scene", "reference", "rendering", "show", "Figure", "each", "iteration", "use", "15k", "emit", "photon", "confidence", "specify", "90", "first", "scene", "Cornell", "box", "glass", "sphere", "metal", "sphere", "here", "noise", "dominate", "error", "because", "scene", "compose", "mostly", "large", "flat", "region", "fairly", "uniform", "illumination", "second", "scene", "consist", "three", "flashlight", "model", "we", "model", "filament", "lens", "reflector", "flashlight", "order", "simulate", "realistic", "lighting", "pattern", "scene", "expect", "have", "larger", "bias", "due", "sharp", "caustic", "from", "flashlight", "third", "scene", "room", "lighting", "fixture", "each", "lighting", "fixture", "consist", "filament", "glass", "casing", "reflector", "which", "replicate", "light", "transport", "real-world", "lighting", "fixture", "scene", "contain", "both", "sharp", "illumination", "feature", "due", "caustic", "well", "flat", "continuous", "illumination", "which", "realistic", "mixture", "bias", "noise", "error", "note", "both", "flashlight", "scene", "room", "scene", "have", "light", "path", "which", "difficult", "unbiased", "render", "method", "handle", "-lrb-", "sd", "path", "from", "very", "small", "light", "source", "-lsb-", "hachisuka", "et", "al.", "2008", "-rsb-", "-rrb-", "Figure", "show", "behavior", "actual", "error", "estimate", "error", "test", "scene", "we", "pick", "three", "point", "investigate", "actual", "error", "estimate", "error", "show", "leftmost", "column", "figure", "one", "might", "notice", "we", "estimate", "error", "do", "bind", "actual", "error", "some", "point", "point", "room", "scene", "indeed", "expect", "behavior", "because", "we", "error", "estimation", "motivate", "stochastic", "error", "bound", "stochastic", "error", "bound", "definition", "bind", "actual", "error", "some", "probability", "so", "even", "we", "error", "estimate", "perfect", "some", "point", "where", "actual", "error", "higher", "than", "estimation", "expect", "practice", "since", "bias", "estimation", "approximation", "may", "also", "cause", "extra", "overestimation", "underestimation", "actual", "error", "addition", "what", "expect", "from", "exact", "stochastic", "error", "bound", "what", "important", "practice", "whether", "estimate", "error", "respect", "user-specified", "confidence", "order", "check", "we", "compute", "actual", "confidence", "test", "scene", "figure", "ideal", "behavior", "actual", "confidence", "stay", "user-specified", "confidence", "all", "time", "we", "calculate", "actual", "confidence", "percentage", "all", "error", "estimate", "above", "true", "error", "obtain", "use", "reference", "image", "we", "test", "50", "90", "user-specified", "confidence", "although", "calcuated", "confidence", "exactly", "same", "specify", "confidence", "deviation", "from", "user-specified", "confidence", "within", "across", "many", "iteration", "both", "50", "90", "difference", "scene", "yellow", "blue", "image", "figure", "visualize", "whether", "estimate", "error", "above", "error", "per", "pixel", "-lrb-", "yellow", "bound", "blue", "bound", "-rrb-", "note", "also", "error", "estimation", "itself", "become", "more", "reliable", "we", "add", "more", "sample", "because", "magnitude", "error", "estimate", "decrease", "Figure", "show", "ratio", "estimate", "bias", "estimate", "noise", "bind", "use", "15m", "photon", "estimate", "error", "capture", "noise", "flat", "region", "well", "bias", "due", "sharp", "feature", "practical", "scene", "biasto-noise", "ratio", "image", "demonstrate", "importance", "each", "component", "we", "overall", "error", "estimate", "result", "image", "show", "bias", "estimation", "dominate", "error", "estimation", "around", "sharp", "feature", "-lrb-", "show", "red", "-rrb-", "noise", "bind", "estimation", "dominate", "error", "estimation", "within", "flat", "region", "-lrb-", "show", "green", "-rrb-", "predict", "sufficient", "total", "number", "photon", "obtain", "desire", "quality", "particular", "scene", "difficult", "unfortunately", "currently", "set", "tedious", "trial-and-error", "user", "example", "application", "we", "error", "estimation", "we", "propose", "automatic", "way", "stop", "render", "process", "without", "specify", "total", "number", "photon", "total", "render", "time", "instead", "we", "stop", "render", "process", "when", "average", "estimated", "error", "over", "image", "below", "user", "specify", "threshold", "we", "believe", "provide", "more", "meaningful", "termination", "criterion", "which", "allow", "user", "focus", "quality", "result", "image", "abstract", "parameter", "involve", "render", "algorithm", "each", "iteration", "we", "simply", "compute", "average", "estimated", "error", "over", "all", "measurement", "point", "where", "number", "measurement", "point", "render", "process", "stop", "when", "ave", "thr", "give", "error", "threshold", "thr", "note", "we", "could", "even", "use", "we", "error", "estimation", "individually", "terminate", "computation", "each", "measurement", "point", "since", "error", "estimate", "per", "measurement", "point", "here", "we", "use", "average", "error", "proof", "concept", "show", "we", "error", "estimation", "useful", "practical", "application", "since", "we", "interested", "average", "error", "per-pixel", "error", "we", "choose", "rather", "lower", "50", "confidence", "application", "order", "get", "tighter", "error", "estimation", "Figure", "-lrb-", "-rrb-", "show", "sequence", "color-code", "image", "actual", "error", "different", "user-specified", "threshold", "we", "plot", "graph", "actual", "average", "relative", "error", "average", "estimate", "error", "Figure", "-lrb-", "-rrb-", "although", "we", "use", "50", "confidence", "terminate", "render", "process", "we", "also", "show", "result", "estimate", "average", "error", "use", "90", "confidence", "reference", "average", "we", "error", "estimate", "use", "50", "confidence", "successfully", "predict", "without", "any", "user", "input", "other", "than", "threshold", "different", "scene", "need", "different", "number", "iteration", "obtain", "sufficient", "quality", "Table", "show", "number", "iteration", "use", "achieve", "specify", "threshold", "note", "even", "though", "flashlight", "scene", "have", "more", "triangle", "than", "Cornell", "box", "scene", "number", "iteration", "achieve", "same", "threshold", "less", "than", "Cornell", "box", "actual", "average", "relative", "error", "achieve", "thr", "0.0625", "0.0465", "0.0448", "0.0437", "Cornell", "box", "scene", "flashlight", "scene", "room", "scene", "respectively", "although", "statement", "different", "scene", "need", "different", "number", "sample", "sound", "trivial", "we", "do", "know", "how", "many", "sample", "need", "unless", "we", "actually", "render", "image", "we", "believe", "even", "simple", "application", "shed", "light", "theoretical", "analysis", "convergence", "behavior", "progressive", "density", "estimation", "which", "still", "unknown", "since", "we", "error", "estimation", "framework", "do", "need", "additional", "photon", "trace", "range", "query", "runtime", "overhead", "due", "error", "estimation", "very", "small", "we", "implementation", "each", "pass", "include", "error", "estimation", "take", "681m", "1291m", "720m", "average", "Cornell", "box", "scene", "flashlight", "scene", "room", "scene", "respectively", "overhead", "due", "error", "estimation", "2.2", "m", "5.9", "m", "3.3", "m", "which", "all", "less", "than", "render", "time", "without", "error", "estimation", "predict", "sufficient", "total", "number", "photon", "obtain", "desire", "quality", "particular", "scene", "difficult", "unfortunately", "currently", "set", "tedious", "trial-and-error", "user", "example", "application", "we", "error", "estimation", "we", "propose", "automatic", "way", "stop", "render", "process", "without", "specify", "total", "number", "photon", "total", "render", "time", "instead", "we", "stop", "render", "process", "when", "average", "estimated", "error", "over", "image", "below", "user", "specify", "threshold", "we", "believe", "provide", "more", "meaningful", "termination", "criterion", "which", "allow", "user", "focus", "quality", "result", "image", "abstract", "parameter", "involve", "render", "algorithm", "each", "iteration", "we", "simply", "compute", "average", "estimated", "error", "over", "all", "measurement", "point", "where", "number", "measurement", "point", "render", "process", "stop", "when", "ave", "thr", "give", "error", "threshold", "thr", "note", "we", "could", "even", "use", "we", "error", "estimation", "individually", "terminate", "computation", "each", "measurement", "point", "since", "error", "estimate", "per", "measurement", "point", "here", "we", "use", "average", "error", "proof", "concept", "show", "we", "error", "estimation", "useful", "practical", "application", "since", "we", "interested", "average", "error", "per-pixel", "error", "we", "choose", "rather", "lower", "50", "confidence", "application", "order", "get", "tighter", "error", "estimation", "Figure", "-lrb-", "-rrb-", "show", "sequence", "color-code", "image", "actual", "error", "different", "user-specified", "threshold", "we", "plot", "graph", "actual", "average", "relative", "error", "average", "estimate", "error", "Figure", "-lrb-", "-rrb-", "although", "we", "use", "50", "confidence", "terminate", "render", "process", "we", "also", "show", "result", "estimate", "average", "error", "use", "90", "confidence", "reference", "average", "we", "error", "estimate", "use", "50", "confidence", "successfully", "predict", "without", "any", "user", "input", "other", "than", "threshold", "different", "scene", "need", "different", "number", "iteration", "obtain", "sufficient", "quality", "Table", "show", "number", "iteration", "use", "achieve", "specify", "threshold", "note", "even", "though", "flashlight", "scene", "have", "more", "triangle", "than", "Cornell", "box", "scene", "number", "iteration", "achieve", "same", "threshold", "less", "than", "Cornell", "box", "actual", "average", "relative", "error", "achieve", "thr", "0.0625", "0.0465", "0.0448", "0.0437", "Cornell", "box", "scene", "flashlight", "scene", "room", "scene", "respectively", "although", "statement", "different", "scene", "need", "different", "number", "sample", "sound", "trivial", "we", "do", "know", "how", "many", "sample", "need", "unless", "we", "actually", "render", "image", "we", "believe", "even", "simple", "application", "shed", "light", "theoretical", "analysis", "convergence", "behavior", "progressive", "density", "estimation", "which", "still", "unknown", "since", "we", "error", "estimation", "framework", "do", "need", "additional", "photon", "trace", "range", "query", "runtime", "overhead", "due", "error", "estimation", "very", "small", "we", "implementation", "each", "pass", "include", "error", "estimation", "take", "681m", "1291m", "720m", "average", "Cornell", "box", "scene", "flashlight", "scene", "room", "scene", "respectively", "overhead", "due", "error", "estimation", "2.2", "m", "5.9", "m", "3.3", "m", "which", "all", "less", "than", "render", "time", "without", "error", "estimation", "we", "have", "present", "error", "estimation", "framework", "progressive", "photon", "mapping", "which", "robust", "wide", "range", "light", "path", "base", "derivation", "stochastic", "error", "bound", "we", "characterize", "error", "use", "estimate", "bias", "estimate", "noise", "bind", "we", "estimate", "bias", "use", "derivative", "radiance", "purpose", "we", "have", "extend", "progressive", "radiance", "estimate", "work", "arbitrary", "smooth", "kernel", "use", "kernel-based", "approach", "we", "can", "compute", "derivative", "radiance", "use", "derivative", "kernel", "we", "have", "show", "bias", "estimate", "can", "use", "construct", "variance", "estimator", "progressive", "radiance", "estimate", "estimate", "error", "capture", "error", "due", "both", "bias", "noise", "under", "complex", "illumination", "give", "user-defined", "confidence", "we", "have", "demonstrate", "we", "error", "estimate", "can", "use", "automatically", "stop", "render", "process", "we", "believe", "we", "work", "first", "step", "towards", "answer", "important", "question", "how", "many", "photon", "need", "render", "scene", "several", "possible", "area", "future", "work", "we", "would", "like", "explore", "give", "error", "estimate", "we", "can", "try", "accelerate", "progressive", "photon", "mapping", "use", "adaptive", "sampling", "trace", "photon", "part", "scene", "where", "error", "large", "would", "interesting", "enhance", "error", "estimate", "perceptual", "metric", "Ramasubramanian", "et", "al.", "-lsb-", "1999", "-rsb-", "we", "would", "also", "like", "investigate", "error", "estimate", "can", "extend", "include", "stochastic", "progressive", "photon", "mapping", "-lsb-", "hachisuka", "Jensen", "2009", "-rsb-", "which", "would", "need", "estimation", "average", "bias", "over", "unknown", "region" ],
  "content" : "We have implemented our error estimation on top of an implementation of the progressive photon mapping algorithm. All results were computed on a 2.4GHz Intel Core 2 Q6600 using one core. In all examples, we used the parameter ? = 0.8 in the progressive photon mapping algorithm. Figure 5 is an analytic investigation of our error estimation. We used the cubic ramp scene described in Figure 2 with 640000 samples and an initial radius of 1.5. The user-specified confidence is 1 ? ? = 0.95. The graph (b) shows that the estimated error is in fact above the actual error in almost all locations as specified. We further investigated the influence of bias estimation and noise bound estimation by plotting each of these components separately in the graph (c). Note that our framework does not estimate bounds of bias, but bias itself. This graph shows that the bias estimation captures error due to bias around the slope of the function, whereas the noise bound estimation captures error due to sampling noise around the flat region of the function. We tested our framework on three example scenes. The reference renderings are shown in Figure 8 . Each iteration uses 15k emitted photons and the confidence was specified at 90%. The first scene is a Cornell box with a glass sphere and a metal sphere. Here noise dominates the error because the scene is composed of mostly large flat regions of fairly uniform illumination. The second scene consists of three flashlights models. We modeled the filament, lens and reflector of the flashlight in order to simulate a realistic lighting pattern. This scene is expected to have larger bias due to sharp caustics from the flashlights. The third scene is a room with lighting fixtures. Each lighting fixture consists of a filament, a glass casing, and reflectors which replicates light transport of real-world lighting fixtures. This scene contains both sharp illumination features due to caustics as well as flat and continuous illumination, which is a realistic mixture of bias and noise in error. Note that both the flashlights scene and the room scene have light paths which are difficult for unbiased rendering methods to handle (such as an SDS path from a very small light source [Hachisuka et al. 2008]). Figure 8 shows behavior of the actual error and the estimated error for the test scenes. We picked three points to investigate the actual error and the estimated error as shown in the leftmost column of Figure 8 . One might notice that our estimated error does not bound actual error at some points, such as the point A in the room scene. This is indeed the expected behavior because our error estimation is motivated by stochastic error bounds. Stochastic error bounds, by definition, bound the actual error with some probability, so even if our error estimate is perfect, some points where the actual error is higher than the estimation are to be expected. In practice, since bias estimation is an approximation, it may also cause extra overestimation or underestimation of the actual error in addition to what is expected from exact stochastic error bounds. What is important in practice is whether the estimated error respect the user-specified confidence. In order to check this, we computed the actual confidence on the test scenes in Figure 7 . The ideal behavior is that the actual confidence stays at the user-specified confidence all the time. We calculate the actual confidence as the percentage of all error estimates that are above the true errors obtained using the reference image. We tested 50% and 90% as the user-specified confidence. Although the calcuated confidence is not exactly the same as the specified confidence, the deviation from the user-specified confidence is within 5% across many iterations for both 50% and 90% in difference scenes. The yellow and blue images in Figure 1 visualize whether estimated error is above error per pixel (yellow: bounded, blue: not bounded). Note also that error estimation itself becomes more reliable as we add more samples because the magnitude of the error estimate decreases. Figure 6 shows the ratio of estimated bias to estimated noise bound using 15M photons. The estimated error captures noise in flat regions as well as bias due to sharp features in practical scenes. The biasto-noise ratio images demonstrate the importance of each of these components to our overall error estimate. The resulting images show bias estimation dominates the error estimation around sharp features (shown as red) and the noise bound estimation dominates the error estimation within flat regions (shown as green). Predicting a sufficient total number of photons to obtain a desired quality for a particular scene is difficult. Unfortunately, this is currently set by tedious trial-and-error by the user. As an example application of our error estimation, we propose an automatic way to stop the rendering process without specifying the total number of photons or the total render time. Instead, we stop the rendering process when the average estimated error over the image is below a user specified threshold. We believe that this provides a more meaningful termination criterion, which allows the user to focus on the quality of the resulting image and not abstract parameters involved in the rendering algorithm. At each iteration, we simply compute the average estimated error over all the measurement points: where N m is the number of measurement points. The rendering process stops when E ave ? E thr for a given error threshold E thr . Note that we could even use our error estimation to individually terminate the computation of each measurement point since the error is estimated per measurement point. Here, we use average error as a proof of concept that shows our error estimation is useful for a practical application. Since we are interested in the average error, not per-pixel error, we choose rather lower 50% confidence in this application in order to get tighter error estimation. Figure 9(a) shows a sequence of color-coded images of actual error with different user-specified thresholds. We plot the graphs of actual average relative error and the average of estimated error in Figure 9(b) . Although we used 50% confidence to terminate the rendering process, we also show the resulting estimated average error using 90% confidence for reference. The average of our error estimate using 50% confidence successfully predicts, without any user input other than the threshold, that different scenes need a different number of iterations to obtain sufficient quality. Table 2 shows the number of iterations used for achieving the specified threshold. Note that, even though the flashlight scene has more triangles than the Cornell box scene, the number of iterations to achieve the same threshold is less than that of the Cornell box. The actual average relative errors achieved with E thr = 0.0625 are 0.0465, 0.0448, 0.0437 for the Cornell box scene, the flashlight scene, and the room scene respectively. Although the statement that different scenes need different number of samples sound trivial, we do not know how many samples are needed unless we actually render an image. We believe that even this simple application will shed light on theoretical analysis of the convergence behavior of progressive density estimation, which is still unknown. Since our error estimation framework does not need additional photon tracing or range query, runtime overhead due to the error estimation is very small. In our implementation, each pass including the error estimation took 681ms, 1291ms, and 720ms on average for the Cornell box scene, the flashlight scene, and the room scene respectively, and the overhead due to the error estimation are 2.2ms, 5.9ms, and 3.3ms which are all less than 1% of the rendering time without error estimation. Predicting a sufficient total number of photons to obtain a desired quality for a particular scene is difficult. Unfortunately, this is currently set by tedious trial-and-error by the user. As an example application of our error estimation, we propose an automatic way to stop the rendering process without specifying the total number of photons or the total render time. Instead, we stop the rendering process when the average estimated error over the image is below a user specified threshold. We believe that this provides a more meaningful termination criterion, which allows the user to focus on the quality of the resulting image and not abstract parameters involved in the rendering algorithm. At each iteration, we simply compute the average estimated error over all the measurement points: where N m is the number of measurement points. The rendering process stops when E ave ? E thr for a given error threshold E thr . Note that we could even use our error estimation to individually terminate the computation of each measurement point since the error is estimated per measurement point. Here, we use average error as a proof of concept that shows our error estimation is useful for a practical application. Since we are interested in the average error, not per-pixel error, we choose rather lower 50% confidence in this application in order to get tighter error estimation. Figure 9(a) shows a sequence of color-coded images of actual error with different user-specified thresholds. We plot the graphs of actual average relative error and the average of estimated error in Figure 9(b) . Although we used 50% confidence to terminate the rendering process, we also show the resulting estimated average error using 90% confidence for reference. The average of our error estimate using 50% confidence successfully predicts, without any user input other than the threshold, that different scenes need a different number of iterations to obtain sufficient quality. Table 2 shows the number of iterations used for achieving the specified threshold. Note that, even though the flashlight scene has more triangles than the Cornell box scene, the number of iterations to achieve the same threshold is less than that of the Cornell box. The actual average relative errors achieved with E thr = 0.0625 are 0.0465, 0.0448, 0.0437 for the Cornell box scene, the flashlight scene, and the room scene respectively. Although the statement that different scenes need different number of samples sound trivial, we do not know how many samples are needed unless we actually render an image. We believe that even this simple application will shed light on theoretical analysis of the convergence behavior of progressive density estimation, which is still unknown. Since our error estimation framework does not need additional photon tracing or range query, runtime overhead due to the error estimation is very small. In our implementation, each pass including the error estimation took 681ms, 1291ms, and 720ms on average for the Cornell box scene, the flashlight scene, and the room scene respectively, and the overhead due to the error estimation are 2.2ms, 5.9ms, and 3.3ms which are all less than 1% of the rendering time without error estimation. We have presented an error estimation framework for progressive photon mapping, which is robust to a wide range of light paths. Based on the derivations of stochastic error bounds, we characterized error using estimated bias and an estimated noise bound. We estimate bias using derivatives of radiance, and for this purpose we have extended the progressive radiance estimate to work with arbitrary smooth kernels. Using a kernel-based approach we can compute the derivatives of radiance by using the derivatives of the kernel. We have shown that this bias estimate can be used to construct a variance estimator for the progressive radiance estimate. The estimated error captures error due to both bias and noise under complex illumination given user-defined confidence. We have demonstrated that our error estimate can be used to automatically stop the rendering process. We believe that our work is the first step towards answering the important question: ?How many photons are needed to render this scene? There are several possible areas of future work that we would like to explore. Given an error estimate, we can try to accelerate progressive photon mapping using adaptive sampling by tracing photons into the parts of the scene where the error is large. It would be interesting to enhance the error estimate with a perceptual metric such as Ramasubramanian et al. [1999]. We would also like to investigate if the error estimate can be extended to include stochastic progressive photon mapping [Hachisuka and Jensen 2009], which would need estimation of average bias over an unknown region.",
  "resources" : [ ]
}