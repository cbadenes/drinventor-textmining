{
  "uri" : "sig2013a-a157-li_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2013a/a157-li_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Analyzing Growing Plants from 4D Point Cloud Data",
    "published" : "2013",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Yangyan-Li",
      "name" : "Yangyan",
      "surname" : "Li"
    }, {
      "uri" : "http://drinventor/Xiaochen-Fan",
      "name" : "Xiaochen",
      "surname" : "Fan"
    }, {
      "uri" : "http://drinventor/Niloy J.-Mitra",
      "name" : "Niloy J.",
      "surname" : "Mitra"
    }, {
      "uri" : "http://drinventor/Daniel A.-Chamovitz",
      "name" : "Daniel A.",
      "surname" : "Chamovitz"
    }, {
      "uri" : "http://drinventor/Daniel-Cohen-Or",
      "name" : "Daniel",
      "surname" : "Cohen-Or"
    }, {
      "uri" : "http://drinventor/Baoquan-Chen",
      "name" : "Baoquan",
      "surname" : "Chen"
    } ]
  },
  "bagOfWords" : [ "study", "growth", "development", "plant", "central", "importance", "botany", "current", "quantitative", "either", "limit", "tedious", "sparse", "manual", "measurement", "coarse", "image-based", "2d", "measurement", "availability", "cheap", "portable", "3d", "acquisition", "device", "have", "potential", "automate", "process", "easily", "provide", "scientist", "volume", "accurate", "datum", "scale", "much", "beyond", "realm", "exist", "method", "we", "introduce", "framework", "study", "plant", "growth", "particularly", "focus", "accurate", "localization", "tracking", "topological", "event", "like", "bud", "bifurcation", "achieve", "novel", "forward-backward", "analysis", "wherein", "we", "track", "robustly", "detect", "plant", "component", "back", "time", "ensure", "correct", "spatio-temporal", "event", "detection", "use", "locally", "adapt", "threshold", "we", "evaluate", "we", "approach", "several", "group", "time", "lapse", "scan", "often", "range", "from", "day", "week", "diverse", "set", "plant", "species", "use", "result", "animate", "static", "virtual", "plant", "directly", "attach", "they", "physical", "simulator", "keyword", "growth", "analysis", "4d", "point", "cloud", "event", "detection", "study", "growth", "process", "organic", "life", "form", "have", "long", "history", "science", "traditionally", "study", "rely", "manual", "recording", "growth", "stage", "image-based", "measurement", "take", "sparse", "interval", "workflow", "tedious", "prone", "measurement", "bias", "difficult", "scale", "large-scale", "observation", "both", "space", "time", "advance", "affordable", "3d", "acquisition", "device", "provide", "new", "opportunity", "plant", "growth", "fundamentally", "different", "from", "animal", "growth", "study", "development", "involve", "detect", "specific", "growth", "event", "-lrb-", "e.g.", "bud", "leaf", "see", "figure", "-rrb-", "quantify", "event", "track", "subsequent", "evolution", "over", "time", "beyond", "difficulty", "arise", "from", "motion", "key", "challenge", "track", "continuous", "shape", "change", "geometry", "topology", "albeit", "very", "slow", "rate", "due", "growth", "possibly", "due", "decay", "different", "from", "typical", "motion", "capture", "setup", "study", "human", "movement", "all", "method", "however", "assume", "underlie", "object", "incompressible", "i.e.", "object", "can", "deform", "grow", "-lrb-", "decay", "-rrb-", "we", "propose", "interleaved", "spatial", "temporal", "analysis", "4d", "where", "challenge", "accurately", "locate", "bud", "bifurcation", "event", "beyond", "implication", "study", "underlie", "growth", "law", "plant", "recover", "growth", "parameter", "immediately", "useful", "animate", "plant", "growth", "simulate", "which", "otherwise", "very", "tedious", "work", "artist", "-lrb-", "section", "-rrb-", "organ", "information", "well", "property", "associate", "each", "organ", "can", "feed", "plant", "simulator", "produce", "simulation", "accurately", "mimic", "observe", "motion", "reality", "3d", "4d", "reconstruction", "when", "addition", "camera", "motion", "object", "move", "deform", "time", "information", "become", "critical", "hence", "4d", "reconstruction", "time", "be", "fourth", "dimension", "use", "accurate", "capture", "human", "motion", "facial", "expression", "while", "ensure", "spatio-temporal", "coherence", "across", "frame", "case", "shape", "deformation", "can", "directly", "recover", "without", "need", "any", "prior", "template", "prior", "-lsb-", "Mitra", "et", "al.", "2007", "Liao", "et", "al.", "2009", "Wand", "et", "al.", "2009", "Popa", "et", "al.", "2010", "Tevs", "et", "al.", "2012", "Akhter", "et", "al.", "2012", "-rsb-", "addition", "deform", "plant", "also", "grow", "-lrb-", "both", "discrete", "continuous", "-rrb-", "over", "time", "thus", "violate", "key", "assumption", "all", "above", "method", "while", "possible", "create", "very", "realistic", "look", "plant", "use", "l-system", "we", "interested", "capture", "both", "form", "dynamics", "real", "plant", "growth", "analyze", "datum", "can", "turn", "use", "re-create", "high", "quality", "geometry", "animate", "procedural", "plant", "accurately", "realistically", "which", "very", "tedious", "achieve", "manually", "although", "we", "target", "similar", "goal", "we", "capture", "live", "plant", "directly", "track", "growth", "without", "assume", "access", "underlie", "growth", "template", "bifurcation", "rule", "while", "very", "challenging", "often", "ambiguous", "automatically", "segment", "plant", "individual", "organ", "from", "isolate", "plant", "model", "we", "demonstrate", "segmentation", "can", "robustly", "extract", "from", "raw", "4d", "point", "cloud", "make", "resultant", "model", "directly", "useable", "simulation", "framework", "thus", "provide", "complementary", "way", "generate", "simulation-ready", "model", "Brendel", "et", "al.", "-lsb-", "2011", "-rsb-", "Gaur", "et", "al.", "-lsb-", "2011", "-rsb-", "convert", "training", "video", "spatio-temporal", "preserving", "representation", "allow", "detection", "localization", "relevant", "activity", "match", "they", "training", "datum", "Pirsiavash", "et", "al.", "-lsb-", "2012", "-rsb-", "present", "first-person", "view", "camera", "involve", "long-scale", "temporal", "structure", "complex", "object", "interaction", "well", "analysis", "detect", "activity", "datum", "set", "Shotton", "et", "al.", "-lsb-", "2011", "-rsb-", "recognize", "human", "pose", "instance", "per-pixel", "classification", "problem", "towards", "real-time", "solution", "instead", "supervised", "approach", "we", "directly", "detect", "bud", "event", "analyze", "morphology", "inspect", "plant", "without", "access", "any", "training", "set", "we", "acquisition", "system", "show", "Figure", "consist", "standard", "structured", "light", "scanner", "camera-projector", "pair", "-lsb-", "song", "Chung", "2008", "song", "et", "al.", "2013", "-rsb-", "turntable", "which", "place", "plant", "we", "have", "array", "four", "system", "each", "which", "can", "independently", "capture", "record", "growth", "plant", "full", "cycle", "scan", "consist", "12", "single-view", "scan", "we", "factor", "out", "known", "movement", "turntable", "bring", "scan", "consistent", "coordinate", "system", "refine", "initial", "alignment", "use", "multiview", "icp", "refinement", "size", "resultant", "point", "cloud", "directly", "depend", "coverage", "plant", "image", "space", "typically", "range", "between", "10-500k", "sum", "up", "3-150m", "point", "per", "day", "-lrb-", "exclude", "point", "from", "flower", "pot", "-rrb-", "while", "we", "use", "known", "technology", "core", "step", "main", "challenge", "practical", "how", "do", "we", "build", "very", "robust", "acquisition", "setup", "can", "scan", "over", "long", "duration", "-lrb-", "span", "few", "week", "-rrb-", "without", "significant", "drift", "alignment", "issue", "start", "from", "input", "4d", "point", "cloud", "datum", "record", "development", "plant", "we", "main", "goal", "track", "growth", "plant", "other", "word", "we", "would", "like", "associate", "each", "organ", "unique", "label", "detect", "spatio-temporal", "event", "organ?s", "birth", "death", "-lrb-", "i.e.", "bud", "bifurcation", "decay", "-rrb-", "two", "key", "challenge", "-lrb-", "-rrb-", "event", "when", "first", "occur", "too", "subtle", "accurately", "locate", "only", "later", "after", "few", "frame", "can", "robustly", "detect", "-lrb-", "ii", "-rrb-", "look", "too", "far", "future", "also", "misleading", "event", "can", "meanwhile", "disappear", "-lrb-", "e.g.", "decay", "leaf", "-rrb-", "organ", "can", "become", "occluded", "other", "one", "we", "propose", "mixed", "approach", "step", "forward", "through", "frame", "detect", "strong", "evidence", "event", "occur", "past", "step", "backwards", "correctly", "locate", "origin", "spatio-temporal", "event", "-lrb-", "see", "Figure", "-rrb-", "instead", "simultaneously", "solve", "organ", "category", "organ", "index", "we", "take", "two-stage", "approach", "we", "want", "each", "point", "map", "most", "likely", "organ", "type", "while", "neighbor", "point", "should", "map", "same", "organ", "type", "spatial", "coherence", "address", "issue", "we", "employ", "temporal", "coherence", "i.e.", "use", "segmentation", "result", "adjacent", "frame", "resolve", "ambiguity", "current", "frame", "plant", "mature", "its", "structure", "grow", "dense", "lead", "significant", "occlusion", "direct", "physical", "interaction", "among", "its", "various", "organ", "support", "underlie", "assumption", "temporary", "coherence", "during", "course", "plant?s", "growth", "we", "do", "make", "use", "any", "species-specific", "prior", "which", "could", "improve", "both", "accuracy", "-lrb-", "e.g.", "detect", "semi-folded", "leaf", "knowledge", "unfold", "process", "inherent", "leaf", "development", "certain", "species", "-rrb-", "efficiency", "-lrb-", "e.g.", "detect", "evidence", "new", "event", "early", "-rrb-", "detection", "event", "we", "observe", "case", "two", "organ", "can", "correctly", "segmented", "feature", "only", "challenge", "mainly", "lie", "departure", "from", "incompressibility", "assumption", "exist", "shape", "dynamics", "algorithm", "here", "new", "growth", "shape", "component", "growth", "new", "structure", "constantly", "happen", "addition", "complexity", "cause", "change", "point", "cloud", "density", "occlusion", "among", "structure" ],
  "content" : "Studying growth and development of plants is of central importance in botany. Current quantitative are either limited to tedious and sparse manual measurements, or coarse image-based 2D measurements. Availability of cheap and portable 3D acquisition devices has the potential to automate this process and easily provide scientists with volumes of accurate data, at a scale much beyond the realms of existing methods. We introduce a framework to study plant growth, particularly focusing on accurate localization and tracking topological events like budding and bifurcation. This is achieved by a novel forward-backward analysis, wherein we track robustly detected plant components back in time to ensure correct spatio-temporal event detection using a locally adapting threshold. We evaluate our approach on several groups of time lapse scans, often ranging from days to weeks, on a diverse set of plant species and use the results to animate static virtual plants or directly attach them to physical simulators. Keywords: growth analysis, 4D point cloud, event detection Studying growth processes in organic life forms has a long history in science. Traditionally, such studies rely on manual recordings of growth stages, or image-based measurements taken at sparse intervals. Such workflows are tedious, prone to measurement bias, and difficult to scale to large-scale observations, both in space and time. Advances in affordable 3D acquisition devices provide new opportunities. Plant growth is fundamentally different from animal growth. Studying such developments involves detecting specific growth events (e.g., budding of a leaf, see Figure 2 ), quantifying these events, and tracking their subsequent evolution over time. Beyond difficulties arising from motion, the key challenge is to track the continuous shape changes in geometry and topology, albeit at a very slow rate, due to growth, and possibly due to decay. This is different from typical motion capture setups studying human movements. All these methods, however, assume the underlying object to be incompressible, i.e., objects can deform but not grow (or decay). We propose an interleaved spatial and temporal analysis in 4D, where the challenge is to accurately locate budding and bifurcation events. Beyond implications in studying the underlying growth laws of plants, the recovered growth parameters are immediately useful for animating plant growth and simulating, which are otherwise very tedious work for artists (Section 7). The organ information as well as the properties associated with each organ can be fed into plant simulators to produce simulations that accurately mimic observed motions in reality. 3D and 4D reconstruction. When, in addition to camera motion, objects move or deform, time information becomes critical. Hence, 4D reconstruction with time being the fourth dimension is used for accurate capture of human motion or facial expressions while ensuring spatio-temporal coherence across frames. In such cases, shapes and deformations can be directly recovered without the need for any prior template priors [Mitra et al. 2007; Liao et al. 2009; Wand et al. 2009; Popa et al. 2010; Tevs et al. 2012; Akhter et al. 2012]. In addition to deforming, plants also grow (both discrete and continuous) over time and thus violates a key assumption in all the above methods. While it is possible to create very realistic looking plants using L-systems, we are interested in capturing both form and dynamics of real plant growth. The analyzed data can be in turn used to re-create high quality geometry or ?animate? procedural plants accurately and realistically, which is very tedious to achieve manually. Although we target a similar goal, we capture live plants and directly track their growth without assuming access to an underlying growth template or bifurcation rules. While it is very challenging and often ambiguous to automatically segment plants into individual organs from isolated plant models, we demonstrate that such segmentation can be robustly extracted from a raw 4D point cloud, making the resultant models directly useable by their simulation framework, and thus providing a complementary way to generate simulation-ready models. Brendel et al. [2011] and Gaur et al. [2011] convert training videos into spatio-temporal preserving representations, to allow the detection and localization of relevant activities by matching them to the training data. Pirsiavash et al. [2012] presented a first-person view camera involving long-scale temporal structure and complex object interactions as well as analysis on detecting activities in the data set. Shotton et al. [2011] recognize human pose as an instance of per-pixel classification problem towards a real-time solution. Instead of a supervised approach, we directly detect budding events by analyzing the morphology of the inspected plant, without access to any training set. Our acquisition system, shown in Figure 4 , consists of a standard structured light scanner with a camera-projector pair [Song and Chung 2008; Song et al. 2013] and a turntable on which to place the plant. We have an array of four such systems, each of which can independently capture and record the growth of a plant. A full cycle scan consists of 12 such single-view scans. We factor out the known movements of the turntable to bring the scans to a consistent coordinate system and refine this initial alignment using a multiview ICP refinement. The size of the resultant point cloud directly depends on the coverage of the plant in image space, typically ranging between 10-500K, summing up to 3-150M points per day (excluding points from the flower pots). While we use known technology in the core steps, the main challenge was practical ? how do we build a very robust acquisition setup that can scan over long durations (spanning a few weeks) without significant drift or alignment issues? Starting from input 4D point cloud data that records development of a plant, our main goal is to track growth of the plant. In other words, we would like to associate each organ with a unique label, and detect the spatio-temporal event of the organ?s birth or death (i.e., budding, bifurcation, or decay). There are two key challenges: (i) events, when they first occur, are too subtle to accurately locate, and only later, after a few frames, can they be robustly detected; and (ii) looking too far into the future is also misleading as events can meanwhile disappear (e.g., decay of a leaf), or the organs can become occluded by other ones. We propose a mixed approach: step forward through frames, detecting strong evidence that an event occurred in the past, and then step backwards to correctly locate the origin of the spatio-temporal event (see Figure 3 ). Instead of simultaneously solving for organ category and organ indices, we take a two-stage approach. We want each point to be mapped to the most likely organ type, while neighboring points should be mapped to the same organ type for spatial coherence. To address this issue, we employ temporal coherence, i.e., using the segmentation results of the adjacent frames to resolve ambiguity in the current frame. As a plant matures, its structures grow dense, leading to significant occlusions and direct physical interactions among its various organs. This supports the underlying assumption of temporary coherence during the course of the plant?s growth. We did not make use of any species-specific priors, which could improve both the accuracy (e.g., detecting a semi-folded leaf with the knowledge of the unfolding process inherent to the leaf development of certain species) and efficiency (e.g., detecting evidence of a new event early on) for the detection of an event. We observed that there are cases that two organs cannot be correctly segmented by features only. The challenges mainly lie in the departure from the incompressibility assumption in existing shape dynamics algorithms; here, new growth of shape components, or growth of new structures, constantly happens, in addition to the complexity caused by the changing point cloud density and occlusions among structures.",
  "resources" : [ ]
}