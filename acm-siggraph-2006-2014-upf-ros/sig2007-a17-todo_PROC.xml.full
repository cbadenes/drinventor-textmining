{
  "uri" : "sig2007-a17-todo_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2007/a17-todo_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Locally Controllable Stylized Shading",
    "published" : "2007",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Hideki-Todo",
      "name" : "Hideki",
      "surname" : "Todo"
    }, {
      "uri" : "http://drinventor/Ken-ichi Anjyo",
      "name" : "Ken",
      "surname" : "ichi Anjyo"
    }, {
      "uri" : "http://drinventor/William V. Baxter-III",
      "name" : "William V. Baxter",
      "surname" : "III"
    }, {
      "uri" : "http://drinventor/Takeo-Igarashi",
      "name" : "Takeo",
      "surname" : "Igarashi"
    } ]
  },
  "bagOfWords" : [ "4ba84e2facbb30ac8212135c4f5e62922cce4541808327ce94076ef152dc80b9", "osc", "10.1145", "1239451.1239468", "name", "identification", "possible", "locally", "controllable", "stylized", "shade", "Hideki", "Todo", "Ken-ichi", "Anjyo", "University", "Tokyo", "OLM", "Digital", "Inc.", "Figure", "comparison", "conventional", "toon", "shading", "-lrb-", "leftmost", "image", "-rrb-", "we", "result", "-lrb-", "remain", "image", "-rrb-", "edit", "be", "make", "three", "key", "frame", "indicate", "-lrb-", "leave", "-rrb-", "add", "shaded", "area", "below", "leave", "eye", "expressive", "impact", "-lrb-", "middle", "-rrb-", "delete", "dark", "area", "around", "right", "eye", "-lrb-", "right", "-rrb-", "add", "shaded", "area", "below", "nose", "emphasize", "three-dimensionality", "local", "edit", "integrate", "seamlessly", "global", "lighting", "animate", "smoothly", "require", "modification", "external", "lighting", "setup", "recent", "progress", "non-photorealistic", "rendering", "-lrb-", "npr", "-rrb-", "have", "lead", "many", "stylized", "shading", "technique", "efficiently", "convey", "visual", "information", "about", "object", "depict", "another", "crucial", "goal", "NPR", "give", "artist", "simple", "direct", "way", "express", "abstract", "idea", "bear", "imagination", "particular", "ability", "add", "intentional", "often", "unrealistic", "shading", "effect", "indispensable", "many", "application", "we", "propose", "set", "simple", "stylized", "shading", "algorithm", "allow", "user", "freely", "add", "localized", "light", "shade", "model", "manner", "consistent", "seamlessly", "integrate", "conventional", "lighting", "technique", "algorithm", "provide", "intuitive", "direct", "manipulation", "method", "base", "paint-brush", "metaphor", "control", "edit", "light", "shade", "locally", "desire", "we", "prototype", "system", "demonstrate", "how", "we", "method", "can", "enhance", "both", "quality", "range", "applicability", "conventional", "stylized", "shading", "offline", "animation", "interactive", "application", "cr", "category", "i.", "3.3", "-lsb-", "Computer", "Graphics", "-rsb-", "picture/image", "generation?display", "algorithm", "i.", "3.6", "-lsb-", "Computer", "Graphics", "-rsb-", "methodology", "techniques?interaction", "technique", "i.", "3.7", "-lsb-", "Computer", "Graphics", "-rsb-", "animation", "keyword", "non-photorealistic", "rendering", "stylized", "shading", "direct", "manipulation", "e-mail", "td-rg7@ui.is.s.u-tokyo.ac.jp", "e-mail", "anjyo@olm.co.jp", "e-mail", "baxter@olm.co.jp", "e-mail", "takeo@acm.org", "ACM", "Reference", "Format", "Todo", "H.", "Anjyo", "K.", "Baxter", "W.", "Igarashi", "T.", "2007", "locally", "Controllable", "Stylized", "shade", "ACM", "Trans", "graph", "26", "Article", "17", "-lrb-", "July", "2007", "-rrb-", "page", "dous", "10.1145", "1239451.1239468", "http://doi.acm.org/10.1145/12394", "51.1239468", "copyright", "Notice", "permission", "make", "digital", "hard", "copy", "part", "all", "work", "personal", "classroom", "use", "grant", "without", "fee", "provide", "copy", "make", "distribute", "profit", "direct", "commercial", "advantage", "copy", "show", "notice", "first", "page", "initial", "screen", "display", "along", "full", "citation", "copyright", "component", "work", "own", "other", "than", "ACM", "must", "honor", "abstract", "credit", "permit", "copy", "otherwise", "republish", "post", "server", "redistribute", "list", "use", "any", "component", "work", "other", "work", "require", "prior", "specific", "permission", "and/or", "fee", "permission", "may", "request", "from", "Publications", "Dept.", "ACM", "Inc.", "Penn", "Plaza", "Suite", "701", "New", "York", "NY", "10121-0701", "fax", "+1", "-lrb-212-rrb- 869-0481", "permissions@acm.org", "2007", "ACM", "0730-0301/2007", "03-art17", "5.00", "DOI", "10.1145", "1239451.1239468", "http://doi.acm.org/10.1145/1239451.1239468", "William", "Baxter", "Takeo", "Igarashi", "OLM", "Digital", "Inc.", "University", "Tokyo", "introduction", "we", "consider", "problem", "how", "provide", "user", "intuitive", "fine-grained", "control", "over", "stylized", "light", "shade", "3d", "object", "over", "past", "decade", "variety", "non-photorealistic", "rendering", "technique", "have", "be", "develop", "facilitate", "visual", "interpretation", "3d", "object", "most", "technique", "design", "elucidate", "particular", "attribute", "inherent", "object", "example", "Gooch", "Gooch", "-lsb-", "2001", "-rsb-", "develop", "lighting", "model", "change", "hue", "convey", "surface", "orientation", "edge", "location", "highlight", "3d", "technical", "illustration", "multi-scale", "shading", "method", "-lsb-", "Rusinkiewicz", "et", "al.", "2006", "-rsb-", "make", "detailed", "3d", "shape", "depiction", "all", "frequency", "possible", "other", "hand", "application", "field", "digital", "animation", "video", "game", "significant", "demand", "locally", "controllable", "stylized", "light", "shade", "which", "can", "achieve", "result", "directable", "intentional", "often", "fictive", "yet", "ultimately", "more", "attractive", "example", "canonical", "cartoon", "shader", "use", "routinely", "3d", "animation", "often", "create", "undesirable", "shaded", "area", "can", "arise", "from", "complexity", "underlie", "geometry", "complexity", "lighting", "just", "result", "basic", "physics", "illumination", "left", "image", "Figure", "show", "example", "where", "dark", "area", "partly", "cover", "right", "eye", "character", "director", "would", "like", "have", "ability", "have", "feature", "remove", "while", "retain", "other", "dark", "area", "other", "case", "might", "like", "request", "shaded", "area", "add", "below", "left", "eye", "show", "second", "image", "from", "leave", "Figure", "order", "emphasize", "character?s", "fierceness", "however", "satisfy", "diverse", "artistic", "requirement", "simultaneously", "would", "very", "hard", "almost", "impossible", "use", "only", "exist", "conventional", "lighting", "control", "and/or", "finetune", "parameter", "use", "change", "geometry", "model", "animate", "texture", "light", "map", "might", "helpful", "achieve", "time-consuming", "impractical", "production", "schedule", "despite", "crucial", "importance", "fine-grained", "artistic", "control", "stylized", "light", "shade", "very", "little", "research", "exist", "how", "provide", "control", "suitable", "interactive", "technique", "support", "we", "goal", "develop", "director-friendly", "methodology", "stylistic", "depiction", "light", "shade", "explain", "we", "approach", "more", "concisely", "we", "restrict", "discussion", "now", "make", "3d", "cartoon", "animation", "case", "due", "nature", "stylistic", "depiction", "technique", "use", "need", "physically", "realistic", "however", "must", "possess", "certain", "sense", "plausibility", "while", "meet", "directorial", "demand", "emphasis", "expressiveness", "over", "physical-realism", "imply", "we", "must", "rely", "animator?s", "creativity?more", "than", "automatic", "physically-based", "algorithms?to", "get", "desire", "animation", "therefore", "stylized", "shade", "approach", "should", "provide", "simple", "intuitive", "user", "interface", "so", "animator", "can", "easily", "interactively", "translate", "he", "she", "creative", "vision", "reality", "keyframebased", "technique", "appropriate", "since", "allow", "fine-tuning", "stylistic", "animation", "traditional", "convenient", "familiar", "way", "animator", "additionally", "real-time", "preview", "animation", "also", "indispensable", "basic", "requirement", "make", "stylized", "animation", "have", "lead", "we", "consider", "na?ve", "key-framing", "first", "approach", "towards", "new", "methodology", "overall", "process", "approach", "we", "propose", "begin", "make", "initial", "3d", "scene", "which", "include", "lighting", "animation", "setting", "use", "conventional", "3d", "software", "tool", "each", "keyframe", "user", "design", "and/or", "modify", "shaded", "area", "surface", "use", "paint-brush", "interface", "process", "perform", "interactive", "rate", "prescribe", "boundary", "constraint", "obtain", "area", "thereafter", "new", "surface", "brightness", "distribution", "automatically", "generate", "consider", "boundary", "constraint", "new", "surface", "brightness", "distribution", "keyframe", "automatically", "transmit", "all", "frame", "linear", "interpolation", "we", "thus", "obtain", "real-time", "preview", "stylistic", "animation", "central", "idea", "we", "approach", "effect", "desire", "change", "light", "shade", "boundary", "modify", "lambertian", "l?n", "lighting", "term", "directly", "add", "scalar", "offset", "function", "avoid", "need", "manipulate", "light", "vector", "normal", "can", "efficiently", "implement", "use", "scalar-valued", "radial", "basis", "function", "-lrb-", "-lsb-", "Wahba", "1990", "-rsb-", "-rrb-", "right", "image", "Figure", "from", "animation", "create", "use", "we", "technique", "while", "leftmost", "show", "scene", "before", "modification", "rest", "paper", "organize", "follow", "after", "briefly", "survey", "related", "work", "section", "we", "describe", "main", "idea", "underlie", "algorithm", "section", "section", "we", "describe", "some", "implementation", "detail", "we", "prototype", "system", "section", "demonstrate", "animation", "example", "discuss", "we", "result", "we", "conclude", "some", "limitation", "future", "work", "section", "ACM", "transaction", "Graphics", "Vol", "26", "no.", "Article", "17", "publication", "date", "July", "2007", "17-2", "Todo", "et", "al.", "related", "work", "number", "npr", "technique", "those", "-lsb-", "Gooch", "Gooch", "2001", "-rsb-", "have", "be", "develop", "emulate", "various", "stylistic", "appearance", "stylized", "rendering", "3d", "object", "Lake", "et", "al.", "-lsb-", "2000", "-rsb-", "propose", "several", "fundamental", "real-time", "rendering", "technique", "include", "traditional", "cartoon", "shader", "Lit-Sphere", "method", "Sloan", "et", "al.", "-lsb-", "2001", "-rsb-", "can", "describe", "view-independent", "tone", "detail", "use", "paint", "spherical", "environment", "map", "wysiwyg", "system", "Kalnins", "et", "al.", "-lsb-", "2002", "-rsb-", "allow", "direct", "drawing", "stroke", "onto", "3d", "object", "while", "learn", "stroke", "example", "multi-scale", "shading", "technique", "Rusinkiewicz", "et", "al.", "-lsb-", "2006", "-rsb-", "can", "also", "control", "appearance", "shape", "detail", "tuning", "parameter", "lighting", "model", "Barla", "et", "al.", "-lsb-", "2006", "-rsb-", "propose", "extension", "traditional", "cartoon", "shader", "which", "can", "control", "view-dependent", "tone", "detail", "include", "effect", "aerial", "perspective", "depth", "field", "cartoon", "highlight", "shader", "-lsb-", "Anjyo", "et", "al.", "2006", "-rsb-", "allow", "user", "directly", "click-and-drag", "highlight", "surface", "design", "animate", "they", "previous", "work", "user-specified", "indirect", "lighting", "design", "photo", "modify", "-lrb-", "l?n", "-rrb-", "original", "-lrb-", "l?n", "-rrb-", "-lrb-", "-rrb-", "figure", "modify", "shaded", "area", "paint", "brush", "terface", "result", "new", "area", "can", "represent", "functionally", "introduce", "offset", "function", "modify", "standard", "lighting", "term", "bottom", "graph", "show", "1-d", "intensity", "distribution", "along", "green", "line", "realistic", "scene", "render", "some", "extent", "related", "we", "approach", "well", "design", "issue", "photorealistic", "lighting", "find", "light", "placement", "result", "user-specified", "highlight", "shadow", "scene", "-lrb-", "see", "-lsb-", "Lee", "et", "al.", "2006", "-rsb-", "more", "detailed", "discussion", "-rrb-", "exist", "several", "good", "approach", "-lrb-", "-lsb-", "Schoeneman", "et", "al.", "1993", "Kawai", "et", "al.", "1993", "Pellacini", "et", "al.", "2002", "-rsb-", "instance", "-rrb-", "geometry-dependent", "lighting", "method", "-lsb-", "Lee", "et", "al.", "2006", "-rsb-", "may", "also", "useful", "indirect", "light", "design", "tool", "visualize", "scientific", "datum", "Okabe", "et", "al.", "-lsb-", "2006", "-rsb-", "Akers", "et", "al.", "-lsb-", "2003", "-rsb-", "take", "other", "approach", "modify", "lighting", "provide", "intuitive", "painting", "method", "modify", "illumination", "3d", "model", "we", "approach", "inspire", "all", "above", "method", "however", "ours", "unique", "allow", "user", "add", "light", "shade", "paint", "they", "directly", "onto", "3d", "object", "without", "elaborate", "lighting", "control", "make", "stylistic", "animation", "key-framing", "addition", "we", "demonstrate", "continuous", "tone", "detail", "can", "also", "paint", "animated", "extension", "we", "approach", "algorithm", "3.1", "overall", "process", "we", "begin", "restrict", "ourselves", "3d", "cartoon", "animation", "where", "each", "shaded", "area", "assign", "uniform", "color", "thresholded", "lambertian", "shading", "-lrb-", "-lsb-", "Lake", "et", "al.", "2000", "-rsb-", "-rrb-", "start", "from", "3d", "scene", "create", "use", "conventional", "lighting", "key-framing", "technique", "we", "consider", "how", "locally", "add", "light", "shade", "onto", "surface", "particular", "we", "describe", "how", "use", "paint-brush", "metaphor", "design", "shaded", "area", "keyframe", "painting", "process", "give", "keyframe", "involve", "interactively", "add", "light", "shade", "detail", "sculpt", "shape", "shade", "boundary", "editing", "straightforward", "we", "technique", "while", "would", "very", "time-consuming", "difficult", "manage", "use", "conventional", "lighting", "we", "implementation", "capable", "deal", "deform", "geometry", "multiple", "directional", "and/or", "point", "light", "source", "however", "without", "loss", "generality", "we", "explain", "we", "idea", "below", "context", "single", "light", "source", "extension", "deformation", "multiple", "light", "source", "straightforward", "give", "threshold", "thresholded", "lambertian", "shader", "create", "two", "-lrb-", "possibly", "disconnect", "-rrb-", "region", "which", "we", "call", "light", "dark", "area", "more", "precisely", "use", "set", "notation", "we", "define", "light", "area", "surface", "give", "threshold", "ACM", "transaction", "Graphics", "Vol", "26", "no.", "Article", "17", "publication", "date", "July", "2007", "locally", "Controllable", "Stylized", "shade", "17-3", "-lcb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-rcb-", "where", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "unit", "vector", "represent", "light", "direction", "surface", "normal", "point", "respectively", "boundary", "between", "light", "dark", "area", "obtain", "replace", "inequality", "-lrb-", "-rrb-", "equality", "-lrb-", "-rrb-", "above", "we", "refer", "dot", "product", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "intensity", "distribution", "give", "definition", "let", "we", "consider", "how", "enlarge", "portion", "light", "area", "example", "character?s", "face", "figure", "where", "light", "area", "flesh", "color", "let", "area", "boundary", "-lrb-", "draw", "red", "figure", "-rrb-", "area", "paint", "we", "brush-type", "interface", "-lrb-", "see", "next", "section", "specifics", "-rrb-", "area", "area", "user", "wish", "add", "original", "area", "core", "idea", "behind", "we", "approach", "modify", "intensity", "distribution", "order", "make", "light", "area", "change", "desire", "i.e.", "so", "become", "intensity", "distribution", "scalar", "function", "so", "greatly", "simplify", "problem", "when", "compare", "work", "directly", "light", "vector", "normal", "overall", "strategy", "follow", "we", "first", "construct", "offset", "function", "-lrb-", "-rrb-", "define", "globally", "prescribe", "new", "light", "area", "replace", "original", "intensity", "distribution", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "see", "Figure", "-rrb-", "note", "though", "globally", "define", "offset", "function", "should", "mostly", "zero", "except", "region", "immediately", "surround", "desire", "edit", "after", "make", "modification", "one", "keyframe", "we", "can", "create", "different", "offset", "function", "define", "light", "area", "second", "keyframe", "smoothly", "interpolate", "offset", "function", "between", "keyframe", "we", "can", "achieve", "smooth", "animation", "light", "area", "between", "frame", "well", "procedure", "can", "repeat", "every", "pair", "adjacent", "keyframe", "result", "animated", "light", "area", "use", "just", "local", "edit", "paint-brush", "next", "we", "describe", "how", "construct", "offset", "function", "paint", "light", "area", "give", "original", "light", "area", "from", "-lrb-", "-rrb-", "paint", "area", "show", "figure", "offset", "function", "-lrb-", "-rrb-", "should", "satisfy", "3.2", "offset", "function", "key-framing", "-lcb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-rcb-", "where", "-lrb-", "-rrb-", "generate", "when", "user", "finish", "draw", "fulfill", "condition", "-lrb-", "-rrb-", "clear", "offset", "function", "should", "take", "value", "equal", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "new", "boundary", "other", "hand", "make", "offset", "function", "active", "only", "neighborhood", "we", "wish", "have", "area", "which", "include", "limit", "extent", "domain", "where", "modification", "lighting", "apply", "-lrb-", "see", "Figure", "-rrb-", "we", "current", "implementation", "distance", "between", "control", "slider", "user", "interface", "size", "region", "give", "user", "way", "limit", "scope", "modification", "-lrb-", "also", "see", "detail", "section", "-rrb-", "therefore", "-lrb-", "-rrb-", "should", "minimally", "satisfy", "following", "condition", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-lrb-", "-rrb-", "-rrb-", "-lrb-", "-rrb-", "we", "choose", "continuous", "function", "satisfy", "above", "condition", "resultant", "area", "have", "continuous", "boundary", "we", "can", "consider", "new", "shaded", "area", "have", "generalize", "intensity", "distribution", "give", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "instead", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "above", "procedure", "can", "repeat", "each", "stroke", "building", "upon", "offset", "function", "create", "previous", "stroke", "user?s", "kth", "stroke", "provide", "from", "new", "input", "result", "light", "area", "can", "define", "recursively", "-lrb-", "-rrb-", "figure", "boundary", "constraint", "point", "use", "find", "new", "offset", "function", "+1", "-lrb-", "-rrb-", "orange", "point", "-lcb-", "-rcb-", "take", "value", "while", "blue", "point", "constrain", "-lrb-", "-rrb-", "+1", "-lcb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "+1", "-lrb-", "-rrb-", "-rcb-", "where", "we", "assume", "+1", "-lrb-", "-rrb-", "continuous", "function", "satisfy", "constraint", "+1", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-lrb-", "-rrb-", "-rrb-", "-lrb-", "-rrb-", "include", "serve", "same", "role", "do", "condition", "-lrb-", "-rrb-", "can", "see", "special", "case", "-lrb-", "-rrb-", "we", "define", "again", "we", "note", "outside", "modification", "make", "lighting", "-lrb-", "i.e.", "+1", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-rrb-", "region", "modification", "visible", "under", "current", "lighting", "condition", "some", "modification", "may", "visible", "when", "either", "light", "model", "move", "have", "band", "allow", "smooth", "transition", "from", "modify", "-lrb-", "-rrb-", "value", "original", "value", "make", "above", "strategy", "computationally", "tractable", "interactive", "rate", "we", "represent", "offset", "function", "-lrb-", "-rrb-", "sum", "Radial", "Basis", "function", "-lrb-", "rbf", "-rrb-", "denote", "-lrb-", "-rrb-", "thus", "practice", "we", "use", "-lcb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-rcb-", "place", "boundary", "constraint", "-lrb-", "-rrb-", "only", "discretely", "enforce", "finite", "number", "point", "rbf", "approximation", "make", "from", "shaded", "area", "obtain", "paint", "operation", "rigorously", "boundary", "may", "exactly", "match", "original", "painted", "area", "allow", "fine", "adjustment", "we", "provide", "two", "additional", "type", "brush", "intensity", "brush", "smoothing", "brush", "which", "describe", "section", "3.4", "Keyframing", "modification", "make", "accord", "above", "algorithm", "integrate", "smoothly", "standard", "lighting", "equation", "many", "animation", "single", "offset", "function", "may", "suffice", "however", "order", "create", "more", "elaborate", "modification", "possible", "create", "several", "keyframe", "unique", "offset", "function", "each", "frame", "lead", "more", "complex", "animation", "light", "shade", "Lighting", "animation", "whole", "can", "accomplish", "interpolate", "offset", "function", "we", "prototype", "we", "have", "use", "simple", "linear", "blending", "purpose", "though", "more", "complicated", "blend", "function", "possible", "worth", "explore", "suppose", "consist", "polygon", "mesh", "show", "Figure", "we", "assume", "simplicity", "after", "obtain", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "we", "want", "find", "+1", "-lrb-", "-rrb-", "which", "satisfy", "boundary", "condition", "-lrb-", "-rrb-", "finite", "number", "discrete", "point", "we", "find", "set", "point", "-lcb-", "-rcb-", "follow", "procedure", "each", "vertex", "inside", "we", "check", "adjacent", "edge", "intersection", "boundary", "each", "intersect", "edge", "linear", "interpolation", "between", "vertex", "other", "end", "use", "determine", "approximate", "location", "boundary", "point", "note", "we", "record", "stroke", "datum", "per-vertex", "only", "reconstruct", "stroke", "linearly", "thus", "edge", "can", "cross", "boundary", "more", "than", "once", "now", "let", "+1", "we", "find", "continuous", "satisfy", "-lrb-", "-rrb-", "-lcb-", "-rcb-", "following", "form", "-lsb-", "Duchon", "1977", "Wahba", "1990", "Turk", "O?Brien", "1999", "-rsb-", "ACM", "transaction", "Graphics", "Vol", "26", "no.", "Article", "17", "publication", "date", "July", "2007", "17-4", "Todo", "et", "al.", "3.3", "rbf", "approximation", "offset", "function", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lcb-", "-rcb-", "where", "radial", "basis", "function", "weight", "polynomial", "whose", "degree", "depend", "upon", "choice", "we", "case", "number", "boundary", "constraint", "point", "show", "Figure", "we", "employ", "-lrb-", "-rrb-", "basis", "function", "after", "experiment", "various", "option", "correspond", "solution", "generalize", "thin-plate", "spline", "problem", "-lsb-", "Duchon", "1977", "Wahba", "1990", "-rsb-", "curvature", "minimize", "property", "basis", "function", "seem", "well", "suit", "task", "satisfy", "discretize", "version", "-lrb-", "-rrb-", "reduce", "solve", "linear", "system", "equation", "unknown", "weight", "-lcb-", "-rcb-", "four", "coefficient", "linear", "polynomial", "previous", "section", "describe", "how", "we", "enable", "user", "add", "edit", "light", "area", "use", "paint-brush", "metaphor", "similar", "way", "we", "can", "add", "edit", "dark", "area", "case", "only", "difference", "selection", "boundary", "point", "use", "-lrb-", "-rrb-", "instead", "use", "we", "use", "opposite", "half", "user", "simply", "switch", "editing", "mode", "from", "light", "dark", "both", "case", "paint", "brush", "use", "roughly", "specify", "shade", "boundary", "we", "call", "type", "brush", "boundary", "brush", "boundary", "brush", "work", "well", "get", "desire", "shape", "intensity", "distribution", "may", "change", "smoothly", "desire", "can", "due", "radial", "basis", "function", "we", "select", "due", "too", "many", "conflict", "constraint", "example", "we", "have", "see", "we", "experiment", "even", "smooth", "radial", "basis", "function", "may", "result", "rapidly", "change", "intensity", "distribution", "area", "where", "distribution", "contour", "very", "close", "one", "another", "may", "cause", "result", "keyframe", "animation", "look", "unnatural", "case", "we", "have", "create", "smoothing", "brush", "painting", "surface", "smoothing", "brush", "offset", "value", "filter", "while", "preserve", "original", "value", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "we", "implementation", "offset", "value", "store", "per", "vertex", "update", "use", "simple", "weighted", "average", "value", "connected", "vertex", "each", "stroke", "operation", "way", "we", "achieve", "shading", "effect", "fade", "out", "more", "gradually", "have", "smoother", "boundary", "-lrb-", "see", "Figure", "-rrb-", "some", "case", "useful", "able", "simply", "add", "remove", "isolate", "light", "dark", "area", "situation", "we", "provide", "simpler", "alternative", "boundary", "brush", "which", "we", "call", "intensity", "brush", "brush", "simply", "add", "subtract", "from", "offset", "function", "amount", "add", "determine", "magnitude", "parameter", "radius", "brush", "magnitude", "amount", "add", "along", "centerline", "stroke", "we", "fade", "add", "intensity", "smoothly", "zero", "edge", "stroke", "use", "smooth-step", "cubic", "polynomial", "falloff", "Figure", "show", "simple", "example", "how", "use", "brush", "Figure", "-lrb-", "-rrb-", "initial", "intensity", "distribution", "character", "display", "use", "green", "contour", "line", "boundary", "brush", "apply", "-lrb-", "-rrb-", "after", "get", "offset", "function", "-lrb-", "-rrb-", "we", "have", "new", "intensity", "distribution", "show", "-lrb-", "-rrb-", "use", "smoothing", "brush", "make", "smoother", "show", "-lrb-", "-rrb-", "order", "get", "more", "variation", "stylized", "light", "shade", "we", "add", "few", "simple", "useful", "extension", "main", "algorithm", "above", "Specular", "Highlight", "we", "can", "deal", "stylized", "highlight", "same", "framework", "shaded", "area", "we", "system", "we", "simply", "need", "replace", "lambertian", "term", "-lrb-", "dot", "product", "-rrb-", "-lrb-", "-rrb-", "from", "blinn?s", "specular", "highlight", "model", "-lsb-", "Blinn", "1977", "-rsb-", "where", "normalize", "half-way", "vector", "between", "light", "eye", "user", "can", "easily", "edit", "highlight", "brush", "same", "manner", "shaded", "area", "continuous", "tone", "control", "threshold", "-lrb-", "-rrb-", "global", "constant", "which", "control", "shaded", "area", "accordance", "-lrb-", "-rrb-", "essential", "assumption", "similarly", "we", "can", "use", "paintbrush", "metaphor", "locally", "control", "edit", "continuous", "tone", "surface", "dispense", "threshold", "define", "lightness", "give", "point", "simply", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "any", "continuous", "function", "thereof", "3.4", "additional", "brush", "figure", "Contours", "intensity", "distribution", "influence", "we", "brush", "operation", "-lrb-", "-rrb-", "initial", "distribution", "-lrb-", "-rrb-", "boundary", "brush", "specify", "region", "which", "should", "become", "dark", "-lrb-", "-rrb-", "new", "distribution", "offset", "function", "prescribe", "region", "-lrb-", "-rrb-", "distribution", "modify", "smoothing", "brush", "-lrb-", "e?f", "-rrb-", "detail", "from", "-lrb-", "c?d", "-rrb-", "3.5", "extension", "ACM", "transaction", "Graphics", "Vol", "26", "no.", "Article", "17", "publication", "date", "July", "2007", "locally", "Controllable", "Stylized", "shade", "17-5", "YOUN", "IN-WAN", "YANG", "KYUNG-IL/Shin", "Angyo", "Project", "2004", "Figure", "editing", "shade", "highlight", "animation", "-lrb-", "left", "-rrb-", "create", "use", "standard", "cartoon", "shader", "modify", "-lrb-", "right", "-rrb-", "use", "technique", "describe", "section", "first", "excessive", "highlight", "forehead", "remove", "use", "intensity", "brush", "boundary", "brush", "use", "create", "light", "region", "around", "chin", "which", "otherwise", "invisible", "implementation", "we", "prototype", "system", "currently", "implement", "maya", "plug", "use", "Maya?s", "hardware", "shader", "functionality", "allow", "shader", "code", "write", "use", "standard", "opengl", "glsl", "we", "prototype", "system", "user", "can", "freely", "add", "localized", "light", "shade", "object", "see", "result", "together", "conventional", "lighting", "real-time", "we", "GPU", "implementation", "each", "vertex", "position", "surface", "mesh", "offset", "function", "value", "-lrb-", "-rrb-", "assign", "store", "vertex", "color", "datum", "maya", "transfer", "from", "maya", "GPU", "vary", "parameter", "we", "paint-brush", "metaphor", "we", "need", "find", "all", "vertex", "inside", "brush", "stroke", "region", "calculate", "distance", "from", "stroke", "centerline", "information", "use", "determine", "location", "point", "boundary", "Figure", "well", "implement", "smooth", "falloff", "intensity", "brush", "we", "accomplish", "use", "depth", "first", "search", "from", "seed", "point", "along", "brush", "centerline", "from", "each", "seed", "point", "we", "find", "all", "vertex", "distance", "less", "than", "brush", "radius", "set", "distance", "value", "use", "minimum", "current", "value", "distance", "from", "current", "seed", "point", "datum", "need", "only", "duration", "single", "stroke", "operation", "can", "discard", "immediately", "afterward", "result", "discussion", "we", "have", "apply", "we", "prototype", "system", "make", "various", "stylistic", "animation", "we", "system", "currently", "run", "interactive", "rate", "2.16", "GHz", "Intel", "p4", "Core", "Duo", "CPU", "NVIDIA", "GeForce", "QuadroFX", "350M", "GPU", "editing", "preview", "animation", "frame", "rate", "range", "from", "20", "fp", "all", "example", "paper", "accompany", "video", "make", "facial", "animation", "control", "light", "shade", "face", "crucial", "Figure", "first", "half", "accompany", "video", "illustrate", "how", "effectively", "efficiently", "we", "algorithm", "work", "important", "case", "show", "video", "even", "make", "simple", "facial", "animation", "3d", "head", "model", "often", "create", "many", "unnecessary", "dark", "area", "very", "hard", "remove", "they", "selectively", "use", "conventional", "lighting", "control", "other", "hand", "we", "approach", "can", "eliminate", "they", "easily", "interactively", "moreover", "allow", "user", "successfully", "add", "variety", "effect", "each", "which", "dramatically", "2006", "DELTORA", "QUEST", "PARTNERS", "Figure", "editing", "light", "shade", "highly", "deforming", "object", "-lrb-", "left", "-rrb-", "original", "frame", "-lrb-", "right", "-rrb-", "edit", "frame", "use", "intensity", "brush", "we", "edit", "light", "and/or", "dark", "area", "deform", "cape", "under", "rapidly", "change", "lighting", "condition", "see", "also", "video", "change", "character?s", "impression", "Figure", "latter", "half", "video", "demonstrate", "typical", "case", "where", "animator", "use", "we", "system", "make", "animation", "less", "realistic", "more", "expressive", "compare", "animation", "under", "conventional", "lighting", "-lrb-", "left", "Figure", "-rrb-", "we", "note", "several", "effect", "have", "be", "add", "animation", "most", "obvious", "smoothing", "simplification", "move", "highlight", "protrude", "forehead", "also", "example", "animator", "have", "add", "light", "area", "accentuate", "jawline", "bright", "firm", "line", "above", "left", "eye", "delay", "emergence", "face", "light", "show", "right", "Figure", "some", "effect", "might", "achieve", "conventional", "lighting", "technique", "however", "almost", "impossible", "add", "all", "they", "same", "shot", "without", "resort", "frame-by-frame", "modification", "Figure", "first", "animation", "example", "video", "show", "use", "we", "technique", "animated", "character", "highly", "deforming", "cape", "use", "move", "point", "light", "fix", "directional", "light", "type", "situation", "can", "result", "light", "shade", "area", "distract", "because", "change", "too", "rapidly", "animation", "video", "demonstrate", "we", "technique", "effective", "eliminate", "unnecessary", "shading", "simplify", "light", "shade", "make", "suitable", "cartoon", "animation", "second", "animation", "video", "demonstrate", "local", "controllability", "continuous", "tone", "we", "intensity", "brush", "describe", "section", "3.5", "show", "movie", "even", "when", "adjust", "continuous", "tone", "object", "we", "approach", "allow", "local", "tone", "control", "add", "backlight", "effect", "around", "character?s", "shoulder", "-lrb-", "see", "Figure", "-rrb-", "we", "be", "able", "create", "animation", "without", "modify", "initial", "lighting", "setup", "however", "case", "where", "viewpoint", "and/or", "light", "move", "more", "dynamically", "may", "more", "difficult", "achieve", "same", "effect", "use", "we", "technique", "make", "animation", "we", "use", "either", "boundary", "brush", "intensity", "brush", "depend", "type", "modification", "desire", "boundary", "brush", "appropriate", "when", "user", "want", "specify", "exactly", "where", "new", "boundary", "should", "lie", "goal", "just", "generally", "make", "light", "dark", "shape", "bigger", "smaller", "intensity", "brush", "more", "effective", "example", "we", "determine", "size", "paint", "brush", "experimentation", "example", "we", "choose", "width", "boundary", "brush", "so", "one", "stroke", "ACM", "transaction", "Graphics", "Vol", "26", "no.", "Article", "17", "publication", "date", "July", "2007", "17-6", "Todo", "et", "al.", "2006", "DELTORA", "QUEST", "PARTNERS", "Figure", "modify", "shade", "gradation", "here", "we", "prototype", "system", "have", "be", "use", "make", "directional", "lighting", "setup", "appear", "more", "dramatic", "back-lit", "situation", "#verts", "-lcb-", "-rcb-", "rbf", "-lrb-", "solve", "-rrb-", "rbf", "-lrb-", "dist", "-rrb-", "transfer", "total", "2011", "68", "0.63", "5.0", "38.8", "44.4", "8001", "114", "3.96", "19.5", "154", "178", "31921", "311", "27.3", "88", "630", "745", "#verts", "-lcb-", "-rcb-", "rbf", "-lrb-", "solve", "-rrb-", "rbf", "-lrb-", "dist", "-rrb-", "transfer", "total", "2011", "68", "0.63", "5.0", "38.8", "44.4", "8001", "114", "3.96", "19.5", "154", "178", "31921", "311", "27.3", "88 630 745", "Table", "algorithm", "performance", "stroke", "various", "size", "-lrb-", "all", "time", "millisecond", "-rrb-", "#verts", "number", "vertex", "stroke", "region", "-lcb-", "-rcb-", "number", "unknown", "weight", "rbf", "sy", "tem", "be", "solve", "while", "rbf", "-lrb-", "solve", "-rrb-", "time", "take", "solve", "linear", "system", "rbf", "-lrb-", "dist", "-rrb-", "time", "take", "compute", "rbf", "distance", "function", "calculate", "-lrb-", "-rrb-", "transfer", "time", "take", "transfer", "vertex", "datum", "from", "maya", "we", "plug", "brush", "include", "least", "two", "adjacent", "vertex", "surface", "mesh", "similarly", "distance", "between", "figure", "also", "set", "include", "least", "two", "adjacent", "vertex", "mesh", "which", "can", "accomplish", "use", "slider", "small", "value", "offset", "function", "specify", "intensity", "brush", "section", "3.4", "also", "set", "empirically", "give", "interactivity", "we", "system", "result", "particular", "parameter", "setting", "can", "see", "immediately", "so", "we", "have", "find", "burdensome", "search", "value", "via", "trial", "error", "Table", "show", "performance", "we", "current", "implementation", "computation", "cost", "however", "depend", "number", "vertex", "contain", "since", "we", "do", "paint", "very", "large", "region", "practice", "cost", "seem", "serious", "bottleneck", "we", "system", "most", "significant", "part", "basic", "cost", "transfer", "vertex", "datum", "between", "maya", "we", "plug", "performance", "datum", "Table", "also", "make", "clear", "algorithm", "itself", "sufficiently", "fast", "interactive", "editing", "we", "prototype", "system", "have", "be", "make", "test", "close", "collaboration", "professional", "animator", "we", "workplace", "since", "very", "early", "stage", "development", "initially", "we", "give", "20-minute", "tutorial", "animator", "since", "we", "system", "implement", "maya", "plugin", "be", "able", "try", "out", "own", "model", "immediately", "reaction", "have", "be", "positive", "do", "seem", "find", "system", "capable", "produce", "desire", "result", "easily", "quickly", "most", "animation", "video", "be", "design", "animator", "so", "clearly", "display", "capability", "propose", "technique", "typically", "animation", "those", "show", "video", "take", "few", "hour", "complete", "which", "drastic", "improvement", "over", "prevus", "ous", "technique", "available", "animator", "also", "claim", "conventional", "trick", "texture", "animation", "modification", "character?s", "geometry", "would", "make", "difficult", "maintain", "consistency", "between", "different", "shot", "same", "character", "therefore", "conventional", "technique", "kind", "edit", "would", "simply", "infeasible", "production", "schedule", "currently", "we", "add", "system", "actual", "production", "pipeline", "so", "soon", "ready", "use", "forthcoming", "project", "even", "limit", "discussion", "cartoon", "shading", "show", "paper", "we", "still", "feel", "considerable", "application", "we", "algorithm", "only", "feature", "film", "also", "television", "animation", "even", "illustrative", "visualization", "contrast", "direct", "application", "we", "method", "interactive", "video", "game", "may", "difficult", "however", "even", "context", "could", "useful", "non-interactive", "cut-scene", "since", "playback", "use", "we", "technique", "lightweight", "real-time", "any", "modern", "GPU", "Limitations", "future", "work", "we", "have", "present", "few", "simple", "algorithm", "step", "toward", "new", "methodology", "truly", "directable", "stylistic", "depiction", "light", "shade", "3d", "animation", "we", "prototype", "system", "allow", "user", "locally", "interactively", "edit", "light", "shade", "painting", "directly", "3d", "object", "moreover", "local", "edit", "integrate", "seamlessly", "conventional", "global", "lighting", "animate", "smoothly", "regardless", "conventional", "lighting", "setup", "use", "animation", "example", "video", "illustrate", "advantage", "over", "previous", "method", "algorithm", "however", "exploratory", "several", "thing", "leave", "accomplish", "we", "approach", "rbf-based", "algorithm", "use", "obtain", "rough", "boundary", "paint", "shaded", "area", "addition", "we", "make", "assumption", "vertex", "define", "object", "add", "remove", "during", "animation", "we", "do", "handle", "object", "change", "topology", "during", "animation", "we", "may", "need", "more", "sophisticated", "algorithm", "obtain", "more", "precise", "approximation", "paint", "area", "when", "apply", "method", "cartoon", "animation", "highlight", "very", "sharp", "edge", "sometimes", "desire", "smoothing", "rbf-based", "method", "can", "give", "sharp", "highlight", "directly", "provide", "boolean", "operation", "-lsb-", "Anjyo", "et", "al.", "2006", "-rsb-", "may", "use", "here", "we", "method", "allow", "we", "add", "locally", "controllable", "light", "shade", "same", "time", "conventional", "lighting", "control", "can", "replace", "we", "approach", "example", "very", "simple", "case", "suppose", "we", "want", "move", "small", "round", "highlight", "ball", "from", "one", "location", "another", "could", "easily", "accomplish", "move", "light", "source", "however", "approach", "present", "paper", "highlight", "would", "move", "fade", "off", "original", "point", "fade", "destination", "clearly", "demonstrate", "difference", "between", "we", "approach", "conventional", "one", "we", "believe", "approach", "complementary", "we", "approach", "local", "which", "mean", "only", "enable", "local", "editing", "also", "movement", "light", "shade", "local", "we", "currently", "investigate", "how", "make", "cast", "shadow", "also", "locally", "controllable", "we", "believe", "modify", "version", "approach", "describe", "here", "have", "promise", "achieve", "paper", "we", "have", "focus", "area", "3d", "stylized", "animation", "however", "important", "practical", "area", "where", "clear", "need", "new", "technique", "help", "bridge", "gap", "between", "artistic", "direction", "animator?s", "heavy", "load", "we", "hope", "we", "approach", "indicate", "promising", "direction", "serve", "practical", "need", "ACM", "transaction", "Graphics", "Vol", "26", "no.", "Article", "17", "publication", "date", "July", "2007", "locally", "Controllable", "Stylized", "shade", "17-7", "acknowledgment", "we", "would", "like", "thank", "SIGGRAPH", "reviewer", "substantial", "feedback", "improve", "paper", "many", "thanks", "also", "Shinji", "Morohashi", "Yosuke", "Katsura", "Ayumi", "Kimura", "dedicated", "help", "make", "animation", "example", "work", "support", "part", "Japan", "Science", "Technology", "Agency", "CREST", "project", "first", "author", "fund", "part", "grant", "from", "japanese", "Information-Technology", "Promotion", "Agency", "reference", "ker", "D.", "OSASSO", "F.", "LINGNER", "J.", "GRAWALA", "M.", "ICK", "J.", "ANRAHAN", "P.", "2003", "convey", "shape", "feature", "image-based", "relighting", "IEEE", "visualization", "-lrb-", "Proceedings", "visualization2003", "-rrb-", "349", "354", "njyo", "K.", "EMLER", "S.", "AXTER", "W.", "2006", "tweakable", "light", "shade", "cartoon", "animation", "npar", "06", "Proceedings", "4th", "international", "symposium", "non-photorealistic", "animation", "rendering", "133", "139", "arlum", "P.", "hollot", "J.", "ARKOSIAN", "L.", "2006", "x-toon", "extended", "toon", "shader", "npar", "06", "Proceedings", "4th", "international", "symposium", "non-photorealistic", "animation", "rendering", "127", "132", "linn", "J.", "1977", "model", "light", "reflection", "computer", "synthesize", "picture", "Computer", "Graphics", "11", "192", "198", "uchon", "J.", "1977", "spline", "minimize", "rotation-invariant", "seminorm", "sobolev", "space", "constructive", "Theory", "function", "several", "variable", "number", "571", "Lecture", "Notes", "Mathematics", "Springer-Verlag", "85", "100", "ooch", "B.", "ooch", "a.", "2001", "Non-Photorealistic", "Rendering", "AK", "Peters", "Ltd.", "ALNINS", "R.", "ARKOSIAN", "L.", "eier", "B.", "OWALSKI", "M.", "EE", "J.", "AVIVN", "P.", "M.W", "EBB", "UGHES", "J.", "inkel", "stein", "a.", "2002", "WYSIWYG", "NPR", "draw", "stroke", "directly", "3d", "model", "ACM", "transaction", "graphic", "-lrb-", "Proceedings", "siggraph2002", "-rrb-", "21", "755", "762", "AWAI", "J.", "K.", "ainter", "J.", "S.", "OHEN", "M.", "F.", "1993", "Radioptimization", "goal", "base", "rendering", "Proceedings", "SIGGRAPH", "1993", "Computer", "Graphics", "Proceedings", "annual", "Conference", "Series", "147", "154", "ake", "a.", "arshall", "C.", "ARRIS", "M.", "LACKSTEIN", "M.", "2000", "stylized", "render", "technique", "scalable", "real-time", "3d", "animation", "npar", "00", "Proceedings", "1st", "international", "symposium", "non-photorealistic", "animation", "rendering", "13", "20", "ee", "C.", "H.", "ao", "X.", "arshney", "a.", "2006", "geometrydependent", "lighting", "IEEE", "transaction", "visualization", "computer", "graphic", "12", "197", "207", "kabe", "m.", "ENG", "G.", "atsushita", "Y.", "garashi", "T.", "UAN", "L.", "hum", "h.-y", "2006", "single-view", "relight", "normal", "map", "painting", "Proceedings", "Pacific", "Graphics", "2006", "27", "34", "ellacinus", "F.", "ole", "P.", "REENBERG", "D.", "P.", "2002", "user", "interface", "interactive", "cinematic", "shadow", "design", "ACM", "transaction", "graphic", "-lrb-", "Proceedings", "siggraph2002", "-rrb-", "21", "563", "566", "usinkiewicz", "S.", "URNS", "M.", "arlo", "D.", "2006", "exaggerated", "shade", "depict", "shape", "detail", "ACM", "Trans", "action", "graphic", "-lrb-", "Proceedings", "siggraph2006", "-rrb-", "25", "1199", "1205", "choeneman", "C.", "ORSEY", "J.", "mit", "B.", "RVO", "J.", "REENBURG", "D.", "1993", "paint", "light", "Proceedings", "SIGGRAPH", "1993", "Computer", "Graphics", "Proceedings", "annual", "Conference", "Series", "143", "146", "LOAN", "p.-p", "J.", "ARTIN", "W.", "OOCH", "a.", "ooch", "B.", "2001", "light", "sphere", "model", "capture", "npr", "shade", "from", "art", "Proceedings", "Graphics", "Interface", "2001", "143", "150", "urk", "G.", "O?B", "RIEN", "J.", "F.", "1999", "shape", "transformation", "use", "variational", "implicit", "function", "Proceedings", "SIGGRAPH", "1999", "Computer", "Graphics", "Proceedings", "annual", "Conference", "Series", "335", "342", "AHBA", "G.", "1990", "Spline", "model", "Observational", "Data", "SIAM", "ACM", "transaction", "Graphics", "Vol", "26", "no.", "Article", "17", "publication", "date", "July", "2007" ],
  "content" : "\n  \n    4ba84e2facbb30ac8212135c4f5e62922cce4541808327ce94076ef152dc80b9\n    osc\n    10.1145/1239451.1239468\n    Name identification was not possible. \n  \n  \n    \n      \n        Locally Controllable Stylized Shading\n      \n      Hideki Todo ? Ken-ichi Anjyo ? The University of Tokyo OLM Digital, Inc.\n      \n        \n        Figure 1: Comparison of conventional toon shading (leftmost image) with our result (remaining images). Edits were made at the three key frames indicated: (left) added shaded area below left eye for expressive impact, (middle) deleted dark area around right eye, and (right) added shaded area below nose to emphasize three-dimensionality. These local edits integrate seamlessly with the global lighting, animate smoothly, and require no modification to the external lighting setup.\n      \n      Recent progress in non-photorealistic rendering (NPR) has led to many stylized shading techniques that efficiently convey visual information about the objects depicted. Another crucial goal of NPR is to give artists simple and direct ways to express the abstract ideas born of their imaginations. In particular, the ability to add intentional, but often unrealistic, shading effects is indispensable for many applications. We propose a set of simple stylized shading algorithms that allow the user to freely add localized light and shade to a model in a manner that is consistent and seamlessly integrated with conventional lighting techniques. The algorithms provide an intuitive, direct manipulation method based on a paint-brush metaphor, to control and edit the light and shade locally as desired. Our prototype system demonstrates how our method can enhance both the quality and range of applicability of conventional stylized shading for offline animation and interactive applications.  CR Categories: I.3.3 [Computer Graphics]: Picture/Image Generation?Display Algorithms; I.3.6 [Computer Graphics]: Methodology and Techniques?Interaction Techniques; I.3.7 [Computer Graphics]: Animation Keywords: non-photorealistic rendering, stylized shading, direct manipulation\n      ? e-mail: td-rg7@ui.is.s.u-tokyo.ac.jp ? e-mail: anjyo@olm.co.jp ? e-mail: baxter@olm.co.jp ? e-mail: takeo@acm.org\n    \n    \n      \n        ACM Reference Format\n        Todo, H., Anjyo, K., Baxter, W., Igarashi, T. 2007. Locally Controllable Stylized Shading. ACM Trans. Graph. 26, 3, Article 17 (July 2007), 7 pages. DOI = 10.1145/1239451.1239468 http://doi.acm.org/10.1145/12394 51.1239468.\n      \n      \n        Copyright Notice\n        Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or direct commercial advantage and that copies show this notice on the first page or initial screen of a display along with the full citation. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers, to redistribute to lists, or to use any component of this work in other works requires prior specific permission and/or a fee. Permissions may be requested from Publications Dept., ACM, Inc., 2 Penn Plaza, Suite 701, New York, NY 10121-0701, fax +1 (212) 869-0481, or permissions@acm.org . ? 2007 ACM 0730-0301/2007/03-ART17 $5.00 DOI 10.1145/1239451.1239468 http://doi.acm.org/10.1145/1239451.1239468\n        William Baxter ? Takeo Igarashi ? OLM Digital, Inc. The University of Tokyo\n      \n      \n        1 Introduction\n      \n      We consider the problem of how to provide users with intuitive, fine-grained control over stylized light and shade on a 3D object. Over the past decade, a variety of non-photorealistic rendering techniques have been developed to facilitate visual interpretation of 3D objects. Most of these techniques are designed to elucidate particular attributes inherent to the object. For example, Gooch and Gooch [2001] developed a lighting model that changes hue to convey surface orientation, edge locations, and highlights for 3D technical illustration. The multi-scale shading method by [Rusinkiewicz et al. 2006] makes detailed 3D shape depiction at all frequencies possible. On the other hand, in application fields such as digital animation and video games, there is a significant demand for locally controllable stylized light and shade, which can achieve results that are directable, intentional, and often fictive, yet ultimately more attractive for it. For example, the canonical cartoon shader used routinely in 3D animation often creates undesirable shaded areas. These can arise from the complexity of the underlying geometry or the complexity of the lighting, or just as a result of the basic physics of illumination. The left image in Figure 1 shows such an example, where the dark area partly covers the right eye of the character. Directors would like to have the ability have such features removed while retaining other dark areas. In other cases, they might like to request that a shaded area be added below the left eye, as shown in the second image from the left in Figure 1 , in order to emphasize the character?s fierceness. However, satisfying these diverse artistic requirements simultaneously would be very hard or almost impossible using only existing conventional lighting control and/or by finetuning the parameters used. Changing the geometry of the model or animating textures or light maps might be helpful for achieving this, but these are time-consuming and impractical on a production schedule. Despite the crucial importance of such fine-grained artistic control of stylized light and shade, very little research exists on how to provide such control or suitable interactive techniques to support it. Our goal is to develop such ?director-friendly? methodologies for stylistic depiction of light and shade. To explain our approach more concisely, we restrict the discussion for now to making 3D cartoon animation. In this case, due to the nature of stylistic depiction, the techniques used need not be physically realistic; however, they must possess a certain sense of plausibility while meeting directorial demands. This emphasis on expressiveness over physical-realism implies that we must rely on the animator?s creativity?more than automatic physically-based algorithms?to get a desired animation. Therefore, a stylized shading approach should provide a simple, intuitive user interface so that the animator can easily and interactively translate his or her creative vision into reality. A keyframebased technique is appropriate, since it allows fine-tuning of stylistic animation in a traditional, but convenient and familiar way for animators. Additionally, real-time preview of the animation is also indispensable. These basic requirements for making stylized animation have led us to consider na?ve key-framing as a first approach towards a new methodology. The overall process of the approach we propose is: 1. Begin by making an initial 3D scene, which includes the lighting and animation settings, using a conventional 3D software tool. 2. At each keyframe, the user designs and/or modifies the shaded area on a surface, using a paint-brush interface. This process is performed at interactive rates, prescribing the boundary constraint of the obtained area. Thereafter the new surface brightness distribution is automatically generated considering the boundary constraint. 3. The new surface brightness distributions at the keyframes are automatically transmitted to all the frames by linear interpolation. We thus obtain real-time preview of the stylistic animation. The central idea of our approach is to effect the desired changes to light and shade boundaries by modifying the Lambertian L?N lighting term directly, adding a scalar offset function. This avoids the need to manipulate light vectors and normals and can be efficiently implemented using scalar-valued radial basis functions ([Wahba 1990]). The right images in Figure 1 are from an animation created using our techniques, while the leftmost shows the scene before modifications. The rest of the paper is organized as follows. After briefly surveying related work in section 2, we describe the main ideas underlying the algorithms in section 3. In section 4, we describe some implementation details of our prototype system. Section 5 demonstrates animation examples and discusses our results. We conclude with some limitations and future work in section 6.\n      ACM Transactions on Graphics, Vol. 26, No. 3, Article 17, Publication date: July 2007.\n      17-2\n      ?\n      Todo et al.\n      \n        2 Related work\n        A number of NPR techniques, such as those in [Gooch and Gooch 2001], have been developed to emulate various stylistic appearances. For stylized rendering of 3D objects, Lake et al.[2000] proposed several fundamental real-time rendering techniques, including a traditional cartoon shader. The Lit-Sphere method by Sloan et al.[2001] can describe view-independent tone detail, using a painted spherical environment map. The WYSIWYG system by Kalnins et al.[2002] allows direct drawing of strokes onto 3D objects, while learning strokes by example. The multi-scale shading technique by Rusinkiewicz et al.[2006] can also control the appearance of shape detail by tuning parameters of the lighting model. Barla et al.[2006] proposed an extension of the traditional cartoon shader, which can control view-dependent tone detail, including such effects as aerial perspective and depth of field. The cartoon highlight shader in [Anjyo et al. 2006] allows a user to directly click-and-drag the highlights on a surface to design and animate them. Previous work on user-specified indirect lighting design for photo-\n        \n          \n        \n        modified (L?N+o 1 ) d 0 original (L?N) o 1 (p)\n        \n          Figure 2: Modifying a shaded area B 0 with the paint brush in-\n        \n        terface: The resulting new area B 0 ? C 0 can be represented functionally by introducing an offset function that modifies the standard L ? N lighting term. The bottom graph shows a 1-d intensity distribution along the green line.\n        realistic scene rendering is to some extent related to our approach as well. The design issue in photorealistic lighting is to find the light placement that results in the user-specified highlights and shadows in the scene (see [Lee et al. 2006] for more detailed discussion). There exist several good approaches ([Schoeneman et al. 1993; Kawai et al. 1993; Pellacini et al. 2002], for instance). The geometry-dependent lighting method by [Lee et al. 2006] may also be a useful indirect light design tool for visualizing scientific data. Okabe et al.[2006] and Akers et al.[2003] take other approaches to modifying lighting, providing an intuitive painting method for modifying the illumination of 3D models. Our approach is inspired by all of the above methods. However, ours is unique in that it allows a user to add light and shade by painting them directly onto 3D objects without elaborate lighting control, to make stylistic animation by key-framing. In addition, we demonstrate that continuous tone detail can also be painted and animated as an extension of our approach.\n      \n      \n        3 Algorithm\n        3.1 Overall process\n        We begin by restricting ourselves to 3D cartoon animation, where each shaded area is assigned a uniform color by thresholded Lambertian shading ([Lake et al. 2000]). Starting from a 3D scene created using conventional lighting and key-framing techniques, we consider how to locally add light and shade onto surfaces. In particular, we describe how to use a paint-brush metaphor to design the shaded area at keyframes. The painting process at a given keyframe involves interactively adding light and shade details or sculpting the shapes of shade boundaries. Such editing is straightforward with our technique, while it would be very time-consuming and difficult to manage using conventional lighting. Our implementation is capable of dealing with deforming geometry and multiple directional and/or point light sources; however, without loss of generality, we explain our idea below in the context of  a single light source. The extension to deformations and multiple light sources is straightforward. For a given threshold 0 < d 0 < 1 a thresholded Lambertian shader creates two (possibly disconnected) regions, which we will call the light and dark areas. More precisely, using set notation we define the light area B 0 on a surface S, for a given threshold d 0 to be:\n        ACM Transactions on Graphics, Vol. 26, No. 3, Article 17, Publication date: July 2007.\n        Locally Controllable Stylized Shading\n        ?\n        17-3\n        \n          1\n          B 0 := {p ? S | L(p) ? N(p) ? d 0 },\n        \n        where L(p) and N(p) are the unit vectors representing the light direction and surface normal at a point p on S, respectively. The boundary between light and dark areas is obtained by replacing inequality (? d 0 ) with equality (= d 0 ) above. We will refer to the dot product L(p) ? N(p) in (1) as the intensity distribution. Given these definitions, let us consider how to enlarge a portion of the light area, for example on the character?s face in Figure 2 , where the light area B 0 is flesh colored. Let the area C 0 with boundary ? C 0 (drawn in red in Figure 2 ) be an area painted with our brush-type interface (see the next section for specifics). The area C 0 ? B 0 is the area that the user wishes to add to the original area B 0 . The core idea behind our approach is to modify the intensity distribution in order to make the light area change as desired, i.e. so that it becomes B 0 ?C 0 . The intensity distribution is a scalar function, so this greatly simplifies the problem when compared to working directly with light vectors and normals. The overall strategy is as follows. We first construct an offset function o 1 (p) defined globally on S. This prescribes the new light area by replacing the original intensity distribution in (1) with L(p) ? N(p) + o 1 (p)(see Figure 2 ). Note that, though globally defined, the offset function should be mostly zero except in the region immediately surrounding the desired edit. After making a modification at one keyframe, we can create a different offset function to define the light area at a second keyframe. By smoothly interpolating the offset functions between keyframes, we can achieve smooth animation of the light areas between frames as well. The procedure can be repeated for every pair of adjacent keyframes, resulting in an animated light area on S using just local edits with a paint-brush. Next, we describe how to construct the offset function for a ?painted? light area. Given the original light area B 0 from (1) and the painted area C 0 , as shown in Figure 2 . The offset function o 1 (p) for B 0 ? C 0 should satisfy\n        3.2 The offset function and key-framing\n        \n          2\n          B 1 := {p ? S | L(p) ? N(p) + o 1 (p) ? d 0 } = B 0 ? C 0 ,\n        \n        where o 1 (p) is generated when the user finishes drawing C 0 . To fulfill condition (2), it is clear that the offset function should take values that are equal to d 0 ? L(p) ? N(p)(? 0) on the new boundary ? C 0 ? B 0 . On the other hand, to make the offset function ?active? only in the neighborhood of C 0 , we wish to have an area D 0 , which includes C 0 , that limits the extent of the domain where modifications to the lighting are applied (see Figure 2 ). In our current implementation, the distance between ? D 0 and ? C 0 is controlled by a slider in the user interface. The size of this region gives the user a way to limit the scope of modification (also see the detail in section 5). Therefore o 1 (p) should minimally satisfy the following conditions: o 1 (p) = 0 d 0 ? L(p) ? N(p) p p ? ? (S ? C ? 0 ? D 0 B ) 0 ? (? B 0 ? (D 0 ? C 0 )) (3) If we choose for o 1 a continuous function satisfying the above conditions, then the resultant area B 1 will have a continuous boundary. We can consider the new shaded area B 1 , to have a ?generalized? intensity distribution given by L(p) ? N(p) + o 1 (p), instead of L(p) ? N(p). The above procedure can be repeated for each stroke, building upon the offset function created by the previous stroke. The user?s kth stroke provides C k and D k . From this new input, the resulting light area can be defined recursively as:\n        \n          \n        \n        ?B k ?(D k -C k ) ?C k -B k\n        \n          Figure 3: The boundary constraint points used in finding the new offset function o ? k+1 (p). The orange points {x i } take the value d 0 ? L ? N, while the blue points are constrained to o k (p).\n        \n        \n          4\n          B k+1 := {p ? S | L(p) ? N(p) + o k+1 (p) ? d 0 } = B k ? C k ,\n        \n        where we assume that o k+1 (p) is a continuous function satisfying the constraints: o k+1 (p) = d o 0 k (p) ? L(p) ? N(p) p p ? ? ? (S C ? k ? D k B ) k ? (? B k ? (D k ? C k ))\n        .\n        (5) D k includes C k and serves the same role for C k as D 0 does for C 0 . The conditions in (3) can be seen to be a special case of (5) if we define o 0 = 0. Again we note that, outside of D k , no modifications will be made to the lighting (i.e., o k+1 (p) = o k (p)). In the D k ? C k region, no modification will be visible under the current lighting conditions, but some modification may be visible when either the lights or the model are moved. Having a D k ? C k band allows for smooth transition from modified o k (p) values to the original values. To make the above strategy computationally tractable at interactive rates, we represent the offset function o k (p) with a sum of Radial Basis Functions (RBF), denoted by o ? k (p). Thus in practice we use:\n        \n          6\n          B ? k := {p ? S | L(p) ? N(p) + o ? k (p) ? d 0 }\n        \n        in place of B k , and the boundary constraint (5) is only discretely enforced at a finite number of points. The RBF approximation B ? k is made from the shaded area obtained by the paint operation. Rigorously, the boundary of B ? k may not exactly match that of the original painted area. To allow fine adjustment, we provide two additional types of brushes: an intensity brush and a smoothing brush, which will be described in section 3.4. Keyframing: Modifications made according to the above algorithm integrate smoothly with standard lighting equations, and for many animations a single offset function o k may suffice. However, in order to create more elaborate modifications, it is possible to create several keyframes, with a unique offset function o k, f at each frame f , leading to more complex animation of light and shade. Lighting of the animation as a whole can then be accomplished by interpolating the offset functions o k, f . In our prototype we have used simple linear blending for this purpose, though more complicated blending functions are possible and worth exploring.  Suppose that S consists of polygon meshes, as shown in Figure 3 . We will assume for simplicity that B ? k = B k . After obtaining o ? k (p) and B k in (6), we want to find o ? k+1 (p), which satisfies the boundary conditions (5) at a finite number of discrete points. We find a set of such points {x i } ? ? C k ? B k by the following procedure. For each vertex p m inside C k , we check adjacent edges for intersection with the boundary ? C k ? B k . For each intersecting edge, linear interpolation between p m and the vertex at the other end, p n , is used to determine the approximate location of the boundary point x i . Note that we record stroke data per-vertex only and reconstruct the stroke linearly, thus no edge can cross the boundary more than once. Now let f ? o ? k+1 . We find a continuous f satisfying (5) for {x i } in the following form [Duchon 1977; Wahba 1990; Turk and O?Brien 1999]:\n        ACM Transactions on Graphics, Vol. 26, No. 3, Article 17, Publication date: July 2007.\n        17-4\n        ?\n        Todo et al.\n        3.3 RBF approximation of the offset function\n        \n          7\n          l f (x) = ? w i ? (x ? x i ) + P(x), i=1 {w }\n        \n        where ? is a radial basis function, i are weights, and P is a polynomial whose degree depends upon the choice of ? . In our case, l is the number of the boundary constraint points shown in Figure 3 . We employ ? (x) = x as the basis function after experimenting with various options. This corresponds to the solution of a generalized thin-plate spline problem on R 3 [Duchon 1977; Wahba 1990], and the curvature minimizing properties of this basis function seem to be well suited to this task. Satisfying a discretized version of (5) reduces to solving a linear system of equations for the unknown weights {w i }, and the four coefficients of the linear polynomial P on 3 . The previous sections described how we enable users to add and edit light areas using a paint-brush metaphor. In a similar way we can add and edit dark areas. In that case the only difference is the selection of boundary points used in (5). Instead of using ? C k ? B k , we use the opposite half of ? C k , that is, ? C k ? B k . The user simply switches the editing mode from light to dark. In both cases, the paint brush is used for roughly specifying the shading boundary. We call this type of brush a boundary brush. The boundary brush works well to get a desired shape, but the intensity distribution may not change as smoothly as desired. This can be due to the radial basis function we select or due to too many conflicting constraints. For example, we have seen in our experiments that even a smooth radial basis function may result in a rapidly changing intensity distribution in the area where the distribution contours are very close to one another. This may cause the resulting keyframe animation to look unnatural. For this case, we have created a smoothing brush. By painting on the surface with the smoothing brush, the offset values are filtered, while preserving the original value of L(p) ? N(p). In our implementation, the offset values stored per vertex are updated using a simple weighted average of values at connected vertices for each stroke operation. In this way we achieve shading effects that fade in and out more gradually and have smoother boundaries (see Figure 4 ). In some cases it is useful to be able simply to add or remove an isolated light or dark area. For these situations we provide a simpler alternative to the boundary brush, which we call the intensity brush. This brush simply adds to or subtracts from the offset function o k . The amount added is determined by a magnitude parameter and the radius of the brush. The magnitude is the amount to add to o k along the centerline of the stroke. We fade the added intensity smoothly to zero at the edges of the stroke using a ?smooth-step? cubic polynomial falloff. Figure 4 shows a simple example of how to use these brushes. In Figure 4(a) , an initial intensity distribution on the character is displayed using green contour lines. The boundary brush is then applied in (b). After getting the offset function in (6), we have the new intensity distribution as shown in (c). Using the smoothing brush, it is made smoother, as shown in (d). In order to get more variations of stylized light and shade, we add a few simple, but useful, extensions of the main algorithms above. Specular Highlight: We can deal with stylized highlights in the same framework as the shaded area. In our system we simply need to replace the Lambertian term (the dot product, L ? N) in (6) with H ? N from Blinn?s specular highlight model [Blinn 1977], where H is the normalized half-way vector between the light and the eye. The user can easily edit the highlights by the brushes in the same manner as the shaded area. Continuous tone control: The threshold d 0 in (1) is a global constant which controls the shaded area in accordance with (6), but this is not an essential assumption. Similarly, we can use the paintbrush metaphors to locally control and edit continuous tone on a surface by dispensing with the threshold and defining the lightness at a given point to be simply L(p) ? N(p) + o k (p), or any continuous function thereof.\n        R\n        3.4 Additional brushes\n        \n          \n          Figure 4: Contours of the intensity distribution, L ? N, as influenced by our brush operations. (a) Initial distribution. (b) A boundary brush specifies a region which should become dark. (c) The new distribution with the offset function prescribed by the region. (d) The distribution modified by a smoothing brush. (e?f) Details from (c?d).\n        \n        3.5 Extensions\n        ACM Transactions on Graphics, Vol. 26, No. 3, Article 17, Publication date: July 2007.\n        Locally Controllable Stylized Shading\n        ?\n        17-5\n        \n          \n        \n        c YOUN IN-WAN, YANG KYUNG-IL/Shin Angyo Project 2004\n        \n          Figure 5: Editing shade and highlights. The animation (left) created using a standard cartoon shader was modified (right) using the techniques described in section 3. First the excessive highlight on the forehead was removed using the intensity brush, and then the boundary brush was used to create a light region around the chin, which was otherwise invisible.\n        \n      \n      \n        4 Implementation\n        Our prototype system is currently implemented as a Maya plug in, using Maya?s hardware shader functionality that allows shader code to be written using standard OpenGL and GLSL. With our prototype system, the user can freely add localized light and shade to objects, and see the results, together with the conventional lighting, in real-time. In our GPU implementation, for each vertex i with position v i on surface meshes, the offset function value o k (v i ) is assigned and stored as a vertex color data in Maya, and is transferred from Maya to GPU as a varying parameter. As for our paint-brush metaphor, we need to find all of the vertices inside the brush stroke region and calculate their distances from the stroke centerline. This information is used to determine the locations of the points on the boundary in Figure 3 , as well as to implement the smooth falloff of the intensity brush. We accomplish this using a depth first search from seed points along the brush centerline. From each seed point, we find all the vertices with distance less than the brush radius, and set their distance values using the minimum of their current value and their distance from the current seed point. This data is needed only for the duration of a single stroke operation and can be discarded immediately afterward.\n      \n      \n        5 Results and discussion\n        We have applied our prototype system to making various stylistic animations. Our system currently runs at interactive rates on a 2.16GHz Intel P4 Core Duo CPU with an NVIDIA GeForce QuadroFX 350M GPU. In editing and previewing the animations, the frame rate ranges from 6 to 20 fps for all the examples in this paper and in the accompanying videos. In making facial animation, controlling light and shade on the face is crucial. Figure 1 and the first half of the accompanying video 1 illustrate how effectively and efficiently our algorithms work for this important case. As shown in the video, even for making a simple facial animation, a 3D head model often creates many unnecessary dark areas, and it is very hard to remove them selectively using conventional lighting control. On the other hand, our approach can eliminate them easily and interactively. Moreover it allows the user to successfully add a variety of effects, each of which dramatically\n        \n          \n        \n        c 2006 DELTORA QUEST PARTNERS\n        \n          Figure 6: Editing light and shade on a highly deforming object. (left) original frame. (right) edited frame. Using the intensity brush, we edited the light and/or dark areas on the deforming cape under rapidly changing lighting conditions. See also video 2.\n        \n        changes the character?s impression.\n         Figure 5 and the latter half of the video 1 demonstrate a typical case where an animator uses our system to make the animation less realistic, but more expressive. Comparing with the animation under conventional lighting (left of Figure 5 ), we note several effects that have been added to the animation. Most obvious is the smoothing and simplification of the moving highlight on the protruding forehead. But also for example, the animator has added a light area to accentuate the jawline; a bright, firm line above the left eye; and delayed emergence of the face into the light, as shown in the right of Figure 5 . Some of these effects might be achieved by conventional lighting techniques. However, it is almost impossible to add all of them into the same shot without resorting to frame-by-frame modifications. Figure 6 and the first animation example in video 2 show the use of our techniques on an animated character with a highly deforming cape using a moving point light and a fixed directional light. This type of situation can result in light and shade areas that are distracting because they change too rapidly. The animation in the video demonstrates that our techniques are effective in eliminating such unnecessary shading and in simplifying light and shade to make it suitable for cartoon animation. The second animation in video 2 demonstrates local controllability of continuous tone with our intensity brush described in section 3.5. As shown in the movie, even when adjusting the continuous tone on this object, our approach allows local tone control, adding a backlight effect around the character?s shoulder (see Figure 7 ). We were able to create this animation without modifying the initial lighting setup. However, in cases where the viewpoint and/or lights are moving more dynamically, it may be more difficult to achieve the same effect using our technique. In making these animations, we used either of boundary brush or the intensity brush, depending on the type of modification desired. The boundary brush is appropriate when the user wants to specify exactly where the new boundary should lie. If the goal is just to generally make a light or dark shape bigger or smaller, then the intensity brush is more effective. In the examples we determined the size of the paint brushes by experimentation. For example, we chose the width of the boundary brush so that one stroke of the\n        ACM Transactions on Graphics, Vol. 26, No. 3, Article 17, Publication date: July 2007.\n        17-6\n        ?\n        Todo et al.\n        \n          \n        \n        c 2006 DELTORA QUEST PARTNERS\n        \n          Figure 7: Modifying shading with gradations. Here our prototype system has been used to make a directional lighting setup appear to be a more dramatic back-lit situation.\n        \n        \n          \n            \n              \n                \n                   #Verts\n                   |{w i }|\n                   RBF(solve)\n                   RBF(dist)\n                   Transfer\n                   Total\n                \n              \n              \n                \n                   2011\n                   68\n                   0.63\n                   5.0\n                   38.8\n                   44.4\n                \n                \n                   8001\n                   114\n                   3.96\n                   19.5\n                   154\n                   178.\n                \n                \n                   31921\n                   311\n                   27.3\n                   88\n                   630\n                   745.\n                \n              \n            \n          \n          #Verts |{w i }| RBF(solve) RBF(dist) Transfer Total 2011 68 0.63 5.0 38.8 44.4 8001 114 3.96 19.5 154 178. 31921 311 27.3 88 630 745.\n          Table 1: Algorithm performance for strokes of various sizes. (All times in milliseconds). #Verts is the number of vertices in the stroke region. |{w i }| is the number of unknown weights in the RBF sys-\n        \n        tem being solved for, while RBF(solve) is the time taken to solve the linear system. RBF(dist) is the time taken to compute the RBF distance function for calculating o k (p). Transfer is the time taken to transfer vertex data to and from Maya in our plug in.\n        brush includes at least two adjacent vertices of the surface mesh. Similarly, the distance between ? C 0 and ? D 0 in Figure 2 , it is also set to include at least two adjacent vertices of the mesh, which can be accomplished using a slider. The small value of the offset function specified by the intensity brush in section 3.4 is also set empirically. Given the interactivity of our system, results of a particular parameter setting can be seen immediately, so we have not found it burdensome to search for these values via trial and error. Table 1 shows the performance of our current implementation. The computation cost, however, depends on the number of vertices contained in D k . Since we do not paint very large regions D k in practice, this cost seems not to be a serious bottleneck in our system. The most significant part was the basic cost of transferring vertex data between Maya and our plug in. The performance data in Table 1 also makes it clear that the algorithm itself is sufficiently fast for interactive editing. Our prototype system has been made and tested in close collaboration with professional animators in our workplace since the very early stages of development. Initially, we gave a 20-minute tutorial to the animators. Since our system is implemented as a Maya plugin, they were able to try it out on their own models immediately. The reaction has been positive they do seem to find the system capable of producing the desired results easily and quickly. Most of the animations in the videos were designed with the animators so as to clearly display the capabilities of the proposed technique. Typically animations such as those shown in the videos take a few hours to complete, which is a drastic improvement over the previ- ous techniques available to the animators. They also claimed that the conventional tricks such as texture animation or modifications to the character?s geometry would make it difficult to maintain consistency between different shots with the same character. Therefore, with such conventional techniques, these kind of edits would simply be infeasible on a production schedule. Currently we are adding this system to an actual production pipeline, so it will soon be ready for use in forthcoming projects. Even limiting the discussion to cartoon shading as shown in this paper, we still feel there are considerable applications of our algorithms not only in feature films, but also for television animation and even illustrative visualization. In contrast, the direct application of our method to interactive video games may be difficult; however, even in that context, it could be useful for non-interactive cut-scenes, since playback using our technique is lightweight and real-time on any modern GPU.\n      \n      \n        6 Limitations and future work\n        We have presented a few simple algorithms as steps toward a new methodology for truly directable stylistic depiction of light and shade in 3D animation. Our prototype system allows the user to locally and interactively edit light and shade by painting directly on 3D objects. Moreover the local edits integrate seamlessly with the conventional global lighting and animate smoothly regardless of the conventional lighting setup used. The animation examples and the videos illustrate these advantages over previous methods.  These algorithms, however, are exploratory. There are several things left to accomplish. In our approach, the RBF-based algorithm is used to obtain the rough boundary of the painted shaded area. In addition, we make the assumption that the vertices defining the object will not be added or removed during animation. We do not handle objects that change topology during an animation. We may need a more sophisticated algorithm to obtain a more precise approximation of the painted area. When applying this method to cartoon animation, highlights with very sharp edges are sometimes desired. But a smoothing RBF-based method cannot give such a sharp highlight directly. Providing boolean operations as in [Anjyo et al. 2006] may be of use here. Our method allows us to add locally controllable light and shade, but at the same time conventional lighting control cannot be replaced by our approach. For example, as a very simple case, suppose that we want to move a small rounded highlight on a ball from one location to another. This could be easily accomplished by moving the light source. However, with the approach presented in this paper, the highlight would not move, but fade off at the original point, and fade in at the destination. This clearly demonstrates a difference between our approach and the conventional one. We believe that these approaches are complementary. Our approach is local, which means not only that it enables local editing, but also that the movement of light and shade is local. We are currently investigating how to make cast shadows also locally controllable. We believe that a modified version of the approach described here has promise for achieving this. In this paper we have focused on the area of 3D stylized animation. However, this is an important practical area where there is a clear need for new techniques to help bridge the gap between artistic direction and the animator?s heavy load. We hope our approach indicates a promising direction to serving such a practical need.\n        ACM Transactions on Graphics, Vol. 26, No. 3, Article 17, Publication date: July 2007.\n        Locally Controllable Stylized Shading\n        ?\n        17-7\n      \n      \n        Acknowledgments\n        We would like to thank the SIGGRAPH reviewers for their substantial feedback to improve the paper. Many thanks also to Shinji Morohashi, Yosuke Katsura, and Ayumi Kimura for their dedicated help in making the animation examples. This work was supported in part by the Japan Science and Technology Agency, CREST project, and the first author was funded in part by grants from the Japanese Information-Technology Promotion Agency.\n      \n      \n        References\n        \n          A KERS , D., L OSASSO , F., K LINGNER , J., A GRAWALA , M., R ICK , J., AND H ANRAHAN , P. 2003. Conveying shape and features with image-based relighting. In IEEE Visualization. (Proceedings of Visualization2003), 349?354.\n          A NJYO , K., W EMLER , S., AND B AXTER , W. 2006. Tweakable light and shade for cartoon animation. In NPAR ?06: Proceedings of the 4th international symposium on Non-photorealistic animation and rendering, 133?139.\n          B ARLA , P., T HOLLOT , J., AND M ARKOSIAN , L. 2006. X-Toon: an extended toon shader. In NPAR ?06: Proceedings of the 4th international symposium on Non-photorealistic animation and rendering, 127?132.\n          B LINN , J. 1977. Models of light reflection for computer synthesized pictures. Computer Graphics 11, 2, 192?198.\n          D UCHON , J. 1977. Splines minimizing rotation-invariant seminorms in sobolev spaces. In Constructive Theory of Functions of Several Variables number 571 in Lecture Notes in Mathematics, Springer-Verlag, 85?100.\n          G OOCH , B., AND G OOCH , A. 2001. Non-Photorealistic Rendering. AK Peters Ltd.\n          K ALNINS , R., M ARKOSIAN , L., M EIER , B., K OWALSKI , M., L EE , J., D AVIVN , P., M.W EBB , H UGHES , J., AND F INKEL STEIN , A. 2002. WYSIWYG NPR: drawing strokes directly on 3D models. ACM Transactions on Graphics. (Proceedings of SIGGRAPH2002) 21, 3, 755?762.\n          K AWAI , J. K., P AINTER , J. S., AND C OHEN , M. F. 1993. Radioptimization: goal based rendering. In Proceedings of SIGGRAPH 1993, Computer Graphics Proceedings, Annual Conference Series, 147?154.\n          L AKE , A., M ARSHALL , C., H ARRIS , M., AND B LACKSTEIN , M. 2000. Stylized rendering techniques for scalable real-time 3D animation. In NPAR ?00: Proceedings of the 1st international symposium on Non-photorealistic animation and rendering, 13? 20.\n          L EE , C. H., H AO , X., AND V ARSHNEY , A. 2006. Geometrydependent lighting. IEEE Transactions on Visualization and Computer Graphics 12, 2, 197?207.\n          O KABE , M., Z ENG , G., M ATSUSHITA , Y., I GARASHI , T., Q UAN , L., AND S HUM , H.-Y. 2006. Single-view relighting with normal map painting. In Proceedings of Pacific Graphics 2006, 27?34.\n          P ELLACINI , F., T OLE , P., AND G REENBERG , D. P. 2002. A user interface for interactive cinematic shadow design. ACM Transactions on Graphics. (Proceedings of SIGGRAPH2002) 21, 3, 563?566.\n          R USINKIEWICZ , S., B URNS , M., AND D E C ARLO , D. 2006. Exaggerated shading for depicting shape and detail. ACM Trans-\n          actions on Graphics. (Proceedings of SIGGRAPH2006) 25, 3, 1199?1205.\n          S CHOENEMAN , C., D ORSEY , J., S MITS , B., A RVO , J., AND G REENBURG , D. 1993. Painting with light. In Proceedings of SIGGRAPH 1993, Computer Graphics Proceedings, Annual Conference Series, 143?146.\n          S LOAN , P.-P. J., M ARTIN , W., G OOCH , A., AND G OOCH , B. 2001. The lit sphere: a model for capturing npr shading from art. In Proceedings of Graphics Interface 2001, 143?150.\n          T URK , G., AND O?B RIEN , J. F. 1999. Shape transformation using variational implicit functions. In Proceedings of SIGGRAPH 1999, Computer Graphics Proceedings, Annual Conference Series, 335?342.\n          W AHBA , G. 1990. Spline Models for Observational Data. SIAM.\n        \n        ACM Transactions on Graphics, Vol. 26, No. 3, Article 17, Publication date: July 2007.\n      \n    \n  ",
  "resources" : [ ]
}