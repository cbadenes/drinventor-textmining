{
  "uri" : "sig2010-a33-ho_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2010/a33-ho_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Spatial Relationship Preserving Character Motion Adaptation",
    "published" : "2010",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Edmond S. L.-Ho",
      "name" : "Edmond S. L.",
      "surname" : "Ho"
    }, {
      "uri" : "http://drinventor/Taku-Komura",
      "name" : "Taku",
      "surname" : "Komura"
    }, {
      "uri" : "http://drinventor/Chiew-Lan-Tai",
      "name" : "Chiew-Lan",
      "surname" : "Tai"
    } ]
  },
  "bagOfWords" : [ "section", "we", "show", "experimental", "result", "from", "apply", "we", "motion", "retargeting", "method", "character", "animation", "we", "apply", "several", "type", "motion", "close", "interaction", "namely", "between", "body", "part", "single", "character", "multiple", "character", "between", "character", "its", "environment", "we", "also", "demonstrate", "its", "usefulness", "real-time", "character", "control", "height", "foot", "all", "snapshot", "back", "break", "attack", "motion", "-lrb-", "left", "-rrb-", "retarget", "character", "different", "morphology", "-lrb-", "middle", "right", "-rrb-", "constrain", "original", "value", "hard", "constraint", "default", "which", "necessary", "especially", "when", "character", "stand", "ground", "reader", "refer", "supplementary", "video", "further", "detail", "first", "we", "show", "result", "retargeting", "motion", "involve", "only", "character", "we", "use", "motion", "involve", "much", "tangling", "contact", "judo", "well", "those", "few", "contact", "dancing", "attackers/defenders", "fight", "game", "Judo", "attack", "we", "first", "motion", "example", "judo", "Ogoshi", "throw", "which", "attacker", "hold", "arm", "waist", "defender", "throw", "defender", "carry", "him/her", "onto", "back", "we", "retarget", "motion", "thrower", "defender", "character", "various", "morphology", "we", "use", "body", "size", "character", "Allen", "et", "al.", "-lsb-", "2003", "-rsb-", "reference", "-lrb-", "see", "fig.", "-rrb-", "here", "although", "proportion", "bound", "volume", "new", "character", "completely", "different", "from", "those", "original", "character", "we", "system", "can", "still", "produce", "Ogoshi", "throw", "note", "previous", "motion", "editing/retargeting", "approach", "difficult", "apply", "kind", "close", "interaction", "since", "only", "consider", "joint", "angle", "original", "motion", "spatial", "relationship", "result", "retarget", "motion", "may", "have", "different", "context", "-lrb-", "e.g.", "arm", "extend", "other", "side", "defender?s", "body", "-rrb-", "also", "require", "animator", "manually", "specify", "all", "positional", "constraint", "all", "frame", "attacker?s", "hand", "hold", "defender?s", "body", "can", "tedious", "task", "animator", "fighting", "scene", "we", "next", "two", "motion", "example", "fight", "scene", "involve", "two", "character", "provide", "game", "company", "first", "scene", "involve", "character", "hold", "sword", "attack", "its", "enemy", "sword", "penetrate", "through", "enemy", "character", "when", "enemy", "stab", "therefore", "we", "turn", "off", "collision", "constraint", "those", "frame", "second", "scene", "from", "same", "game", "character", "hold", "sword", "break", "back", "enemy", "both", "arm", "drop", "sword", "unintentionally", "pass", "through", "arm", "defender", "some", "frame", "which", "due", "manual", "design", "again", "we", "turn", "off", "collision", "constraint", "those", "frame", "both", "attacker?s", "defender?s", "morphology", "change", "animation", "different", "combination", "body", "create", "snapshot", "original", "synthesize", "motion", "show", "Fig.", "Fig.", "respectively", "note", "manual", "editing", "would", "-lrb-", "leave", "-rrb-", "posture", "turn", "kick", "interaction", "-lrb-", "middle", "right", "-rrb-", "animator", "drag", "left", "foot", "yellow", "character", "mouse", "other", "character", "move", "preserve", "spatial", "relationship", "original", "dancing", "motion", "-lrb-", "middle", "-rrb-", "retarget", "result", "monkey", "model", "long", "arm", "use", "joint-angle", "base", "method", "-lrb-", "left", "-rrb-", "use", "we", "method", "-lrb-", "right", "-rrb-", "require", "lot", "care", "avoid", "unintentional", "penetration", "sword", "body", "we", "method", "can", "automatically", "produce", "motion", "pass", "sword", "space", "between", "enemy?s", "arm", "torso", "example", "show", "we", "method", "can", "also", "use", "manually", "design", "motion", "which", "penetration-free", "case", "context", "penetration", "-lrb-", "e.g.", "stab", "enemy", "-rrb-", "preserve", "synthesize", "result", "feedback", "from", "game", "company", "indicate", "quality", "we", "retarget", "movement", "high", "enough", "game", "usage", "interactive", "character", "control", "next", "we", "show", "demo", "use", "interaction", "mesh", "real-time", "control", "character", "pause", "animation", "interaction", "some", "frame", "we", "can", "let", "user", "interactively", "control", "body", "part", "use", "inverse", "kinematic", "while", "maintain", "its", "spatial", "relationship", "other", "character", "-lrb-", "-rrb-", "case", "we", "solve", "eq", "-lrb-", "11", "-rrb-", "single", "frame", "rather", "than", "entire", "motion", "which", "provide", "real-time", "performance", "other", "character", "-lrb-", "-rrb-", "follow", "movement", "controlled", "character", "accord", "interaction", "mesh", "frame", "controlled", "body", "part", "softly", "constrain", "additional", "positional", "constraint", "example", "editing", "posture", "turn-kick", "motion", "show", "fig.", "update", "edit", "frame", "can", "propagate", "whole", "motion", "iteratively", "solve", "eq", "-lrb-", "10", "-rrb-", "use", "edit", "posture", "constraint", "single", "character", "motion", "we", "use", "dancing", "motion", "which", "character", "perform", "arm", "cycling", "motion", "retarget", "character", "monkey", "proportion", "-lrb-", "fig.", "-rrb-", "we", "method", "can", "preserve", "context", "motion", "despite", "much", "longer", "arm", "monkey", "character", "contrast", "method", "-lsb-", "lyard", "MagnenatThalmann", "2008", "-rsb-", "result", "motion", "many", "collision", "cause", "movement", "appear", "unstable", "note", "since", "motion", "do", "involve", "any", "tangle", "topology", "coordinate", "-lsb-", "Ho", "Komura", "2009a", "-rsb-", "also", "difficult", "apply", "snapshot", "character", "get", "ride", "car", "model", "-lrb-", "top", "-rrb-", "original", "character", "-lrb-", "bottom", "-rrb-", "tall", "fat", "character", "motion", "constrain", "environment", "get", "out", "car", "involve", "close", "maneuver", "collision", "avoidance", "retarget", "motion", "character", "different", "size", "adapt", "motion", "environment", "different", "parameter", "-lrb-", "e.g.", "size", "car", "-rrb-", "have", "great", "demand", "CAD", "design", "digital", "mannequin", "-lsb-", "Badler", "et", "al.", "1999", "-rsb-", "here", "we", "show", "example", "use", "interaction", "mesh", "purpose", "we", "capture", "motion", "person", "get", "car", "hold", "steer", "wheel", "environment", "compose", "simple", "polyline", "represent", "car", "door", "ceiling", "floor", "seat", "steer", "wheel", "interaction", "mesh", "compose", "vertex", "environment", "skeleton", "joint", "end", "effector", "snapshot", "input", "motion", "retarget", "scale", "character", "show", "fig.", "observe", "character?s", "motion", "successfully", "adapt", "new", "character", "size", "since", "some", "interaction", "character", "car", "duck", "pass", "through", "narrow", "space", "can", "describe", "only", "explicit", "constraint", "contact", "motion", "difficult", "handle", "previous", "method", "main", "bottleneck", "we", "method", "solve", "large", "linear", "equation", "eq", "we", "use", "UMFPACK", "-lsb-", "Davis", "2004", "-rsb-", "gotobla", "-lsb-", "Goto", "Van", "De", "Geijn", "2008", "-rsb-", "since", "laplacian", "matrix", "constraint", "matrix", "both", "sparse", "computation", "only", "increase", "linearly", "respect", "number", "vertex", "all", "interaction", "mesh", "therefore", "complexity", "problem", "-lrb-", "-rrb-", "where", "number", "vertex", "each", "mesh", "number", "frame", "all", "retargeting", "example", "show", "paper", "computation", "require", "each", "motion", "around", "minute", "animation", "100", "frame", "use", "one", "core", "core", "i7", "2.67", "GHz", "CPU", "since", "most", "computation", "computation", "laplacian", "constraint", "matrix", "solve", "large", "linear", "system", "-lsb-", "Bolz", "et", "al.", "2003", "-rsb-", "highly", "parallelizable", "much", "faster", "response", "can", "expect", "GPU", "implementation", "first", "we", "show", "result", "retargeting", "motion", "involve", "only", "character", "we", "use", "motion", "involve", "much", "tangling", "contact", "judo", "well", "those", "few", "contact", "dancing", "attackers/defenders", "fight", "game", "Judo", "attack", "we", "first", "motion", "example", "judo", "Ogoshi", "throw", "which", "attacker", "hold", "arm", "waist", "defender", "throw", "defender", "carry", "him/her", "onto", "back", "we", "retarget", "motion", "thrower", "defender", "character", "various", "morphology", "we", "use", "body", "size", "character", "Allen", "et", "al.", "-lsb-", "2003", "-rsb-", "reference", "-lrb-", "see", "fig.", "-rrb-", "here", "although", "proportion", "bound", "volume", "new", "character", "completely", "different", "from", "those", "original", "character", "we", "system", "can", "still", "produce", "Ogoshi", "throw", "note", "previous", "motion", "editing/retargeting", "approach", "difficult", "apply", "kind", "close", "interaction", "since", "only", "consider", "joint", "angle", "original", "motion", "spatial", "relationship", "result", "retarget", "motion", "may", "have", "different", "context", "-lrb-", "e.g.", "arm", "extend", "other", "side", "defender?s", "body", "-rrb-", "also", "require", "animator", "manually", "specify", "all", "positional", "constraint", "all", "frame", "attacker?s", "hand", "hold", "defender?s", "body", "can", "tedious", "task", "animator", "fighting", "scene", "we", "next", "two", "motion", "example", "fight", "scene", "involve", "two", "character", "provide", "game", "company", "first", "scene", "involve", "character", "hold", "sword", "attack", "its", "enemy", "sword", "penetrate", "through", "enemy", "character", "when", "enemy", "stab", "therefore", "we", "turn", "off", "collision", "constraint", "those", "frame", "second", "scene", "from", "same", "game", "character", "hold", "sword", "break", "back", "enemy", "both", "arm", "drop", "sword", "unintentionally", "pass", "through", "arm", "defender", "some", "frame", "which", "due", "manual", "design", "again", "we", "turn", "off", "collision", "constraint", "those", "frame", "both", "attacker?s", "defender?s", "morphology", "change", "animation", "different", "combination", "body", "create", "snapshot", "original", "synthesize", "motion", "show", "Fig.", "Fig.", "respectively", "note", "manual", "editing", "would", "-lrb-", "leave", "-rrb-", "posture", "turn", "kick", "interaction", "-lrb-", "middle", "right", "-rrb-", "animator", "drag", "left", "foot", "yellow", "character", "mouse", "other", "character", "move", "preserve", "spatial", "relationship", "original", "dancing", "motion", "-lrb-", "middle", "-rrb-", "retarget", "result", "monkey", "model", "long", "arm", "use", "joint-angle", "base", "method", "-lrb-", "left", "-rrb-", "use", "we", "method", "-lrb-", "right", "-rrb-", "require", "lot", "care", "avoid", "unintentional", "penetration", "sword", "body", "we", "method", "can", "automatically", "produce", "motion", "pass", "sword", "space", "between", "enemy?s", "arm", "torso", "example", "show", "we", "method", "can", "also", "use", "manually", "design", "motion", "which", "penetration-free", "case", "context", "penetration", "-lrb-", "e.g.", "stab", "enemy", "-rrb-", "preserve", "synthesize", "result", "feedback", "from", "game", "company", "indicate", "quality", "we", "retarget", "movement", "high", "enough", "game", "usage", "interactive", "character", "control", "next", "we", "show", "demo", "use", "interaction", "mesh", "real-time", "control", "character", "pause", "animation", "interaction", "some", "frame", "we", "can", "let", "user", "interactively", "control", "body", "part", "use", "inverse", "kinematic", "while", "maintain", "its", "spatial", "relationship", "other", "character", "-lrb-", "-rrb-", "case", "we", "solve", "eq", "-lrb-", "11", "-rrb-", "single", "frame", "rather", "than", "entire", "motion", "which", "provide", "real-time", "performance", "other", "character", "-lrb-", "-rrb-", "follow", "movement", "controlled", "character", "accord", "interaction", "mesh", "frame", "controlled", "body", "part", "softly", "constrain", "additional", "positional", "constraint", "example", "editing", "posture", "turn-kick", "motion", "show", "fig.", "update", "edit", "frame", "can", "propagate", "whole", "motion", "iteratively", "solve", "eq", "-lrb-", "10", "-rrb-", "use", "edit", "posture", "constraint", "single", "character", "motion", "we", "use", "dancing", "motion", "which", "character", "perform", "arm", "cycling", "motion", "retarget", "character", "monkey", "proportion", "-lrb-", "fig.", "-rrb-", "we", "method", "can", "preserve", "context", "motion", "despite", "much", "longer", "arm", "monkey", "character", "contrast", "method", "-lsb-", "lyard", "MagnenatThalmann", "2008", "-rsb-", "result", "motion", "many", "collision", "cause", "movement", "appear", "unstable", "note", "since", "motion", "do", "involve", "any", "tangle", "topology", "coordinate", "-lsb-", "Ho", "Komura", "2009a", "-rsb-", "also", "difficult", "apply", "snapshot", "character", "get", "ride", "car", "model", "-lrb-", "top", "-rrb-", "original", "character", "-lrb-", "bottom", "-rrb-", "tall", "fat", "character", "motion", "constrain", "environment", "get", "out", "car", "involve", "close", "maneuver", "collision", "avoidance", "retarget", "motion", "character", "different", "size", "adapt", "motion", "environment", "different", "parameter", "-lrb-", "e.g.", "size", "car", "-rrb-", "have", "great", "demand", "CAD", "design", "digital", "mannequin", "-lsb-", "Badler", "et", "al.", "1999", "-rsb-", "here", "we", "show", "example", "use", "interaction", "mesh", "purpose", "we", "capture", "motion", "person", "get", "car", "hold", "steer", "wheel", "environment", "compose", "simple", "polyline", "represent", "car", "door", "ceiling", "floor", "seat", "steer", "wheel", "interaction", "mesh", "compose", "vertex", "environment", "skeleton", "joint", "end", "effector", "snapshot", "input", "motion", "retarget", "scale", "character", "show", "fig.", "observe", "character?s", "motion", "successfully", "adapt", "new", "character", "size", "since", "some", "interaction", "character", "car", "duck", "pass", "through", "narrow", "space", "can", "describe", "only", "explicit", "constraint", "contact", "motion", "difficult", "handle", "previous", "method", "main", "bottleneck", "we", "method", "solve", "large", "linear", "equation", "eq", "we", "use", "UMFPACK", "-lsb-", "Davis", "2004", "-rsb-", "gotobla", "-lsb-", "Goto", "Van", "De", "Geijn", "2008", "-rsb-", "since", "laplacian", "matrix", "constraint", "matrix", "both", "sparse", "computation", "only", "increase", "linearly", "respect", "number", "vertex", "all", "interaction", "mesh", "therefore", "complexity", "problem", "-lrb-", "-rrb-", "where", "number", "vertex", "each", "mesh", "number", "frame", "all", "retargeting", "example", "show", "paper", "computation", "require", "each", "motion", "around", "minute", "animation", "100", "frame", "use", "one", "core", "core", "i7", "2.67", "GHz", "CPU", "since", "most", "computation", "computation", "laplacian", "constraint", "matrix", "solve", "large", "linear", "system", "-lsb-", "Bolz", "et", "al.", "2003", "-rsb-", "highly", "parallelizable", "much", "faster", "response", "can", "expect", "GPU", "implementation", "paper", "we", "have", "present", "new", "method", "edit", "retarget", "character", "animation", "involve", "many", "close", "interaction", "introduce", "new", "representation", "call", "interaction", "mesh", "when", "update", "motion", "spatial", "relationship", "between", "different", "body", "component", "object", "can", "preserve", "apply", "spacetime", "optimization", "minimize", "deformation", "interaction", "mesh", "subject", "collision", "constraint", "well", "bone-length", "positional", "constraint", "method", "fully", "automatic", "require", "manual", "intervention", "from", "user", "we", "have", "demonstrate", "effectiveness", "propose", "method", "show", "realistic", "synthesize", "animation", "various", "type", "close", "interaction", "which", "difficult", "produce", "use", "previous", "method", "future", "work", "we", "plan", "numerically", "evaluate", "topological", "geometric", "feature", "interaction", "mesh", "introduce", "metric", "compare", "motion", "level", "interaction", "mesh", "we", "method", "can", "extend", "use", "reinforcement", "learning", "enable", "computer-controlled", "character", "smartly", "interact", "usercontrolled", "character", "closely", "interact", "environment", "another", "possible", "research", "direction", "apply", "we", "method", "control", "character", "physically-based", "environment", "combine", "balance", "keep", "technique", "-lsb-", "da", "Silva", "et", "al.", "2008", "Macchietto", "et", "al.", "2009", "-rsb-", "tackle", "problem", "may", "also", "lead", "solution", "control", "multi-biped", "robot", "cooperatively", "accomplish", "task", "carry", "object", "together" ],
  "content" : "In this section, we show experimental results from applying our motion retargeting method to character animation. We apply it to several types of motions with close interactions, namely, between body parts of a single character or multiple characters, and between a character and its environment. We also demonstrate its usefulness for real-time character control. The heights of the feet are all Snapshots of a back breaking attacking motion (left) retargeted to characters of different morphologies (middle, right). constrained to the original values by hard constraints by default, which are necessary especially when the characters are standing on the ground. The readers are referred to the supplementary video for further details. First we show the results of retargeting motions involving only characters. We use motions involving much tangling and contacts, such as judo, as well as those with few contacts, such as dancing and attackers/defenders in fighting games. Judo attacks Our first motion example is a judo ?Ogoshi throw? in which the attacker holds the arm and the waist of the defender and throws the defender by carrying him/her onto the back. We retarget the motions of the thrower and the defender to characters of various morphologies. We use the body sizes of characters in Allen et al. [2003] as reference (See Fig. 1 ). Here, although the proportions and the bounding volumes of the new characters are completely different from those of the original characters, our system can still produce the Ogoshi throw. Note that previous motion editing/retargeting approaches are difficult to apply to this kind of close interactions since they only consider the joint angles of the original motion but not the spatial relationships. As a result, the retargeted motion may have a different context (e.g. the arms extend to the other side of the defender?s body). They also require the animators to manually specify all the positional constraints in all the frames, such as the attacker?s hand holding the defender?s body. This can be a tedious task for the animator. Fighting scenes Our next two motion examples are fighting scenes involving two characters provided by a game company. The first scene involves a character holding a sword attacking its enemy. The sword penetrates through the enemy character when the enemy is stabbed, and therefore, we turned off the collision constraint in those frames. The second scene is from the same game. The character holding the sword breaks the back of the enemy with both arms and drops it. The sword unintentionally passes through the arm of the defender in some of the frames, which is due to the manual design. Again, we turned off the collision constraint in those frames. Both the attacker?s and defender?s morphologies are changed and animations of different combination of bodies are created. Snapshots of the original and synthesized motions are shown in Fig. 4 and Fig. 5 , respectively. Note that manual editing would (left) A posture of a turn kick interaction. (middle, right) The animator drags the left foot of the yellow character by mouse and the other character moves to preserve the spatial relationship. Original dancing motion (middle) and the retargeted results to a monkey model with long arms using a joint-angle based method (left) and using our method (right). require a lot of care to avoid unintentional penetrations of the sword into the body. Our method can automatically produce the motion of passing the sword into the space between the enemy?s arm and torso. These examples show that our method can also be used for manually designed motions which are not penetration-free. In such cases, the context of the penetrations (e.g. stabbing the enemy) are preserved in the synthesized results. Feedback from the game company indicates that the quality of our retargeted movements is high enough for games usage. Interactive character control Next, we show a demo of using the interaction mesh for real-time control of characters. Pausing the animation of interaction at some frame, we can let the user interactively control a body part using inverse kinematics while maintaining its spatial relationships with the other character(s). In such cases, we solve Eq. (11) for a single frame rather than for the entire motion, which provides real-time performance. The other character(s) will follow the movements of the controlled character according to the interaction mesh at that frame. The controlled body part is softly constrained by an additional positional constraint. An example of editing a posture in a turn-kick motion is shown in Fig. 6 . The updates in the edited frame can be propagated to the whole motion by iteratively solving Eq. (10) using the edited posture as a constraint. Single character motions We use a dancing motion in which the character performs an arms cycling motion and retarget it to a character with monkey proportions ( Fig. 7 ). Our method can preserve the context of the motion despite the much longer arms of the monkey character. In contrast, the method of [Lyard and MagnenatThalmann 2008] results in a motion with many collisions, causing the movements to appear unstable. Note that since this motion does not involve any tangles, the topology coordinates [Ho and Komura 2009a] are also difficult to apply. Snapshots of a character getting into and riding a car model; (top) original character and (bottom) a tall fat character. Motions in a constrained environment, such as getting in and out of a car, involve close maneuvers and collision avoidance. Retargeting such motions to characters of different sizes or adapting the motions to environment with different parameters (e.g. size of car) has a great demand in CAD design and digital mannequins [Badler et al. 1999]. Here we show examples of using the interaction mesh for such a purpose. We captured the motion of a person getting into a car and holding the steering wheel. The environment is composed of simple polylines representing the car doors, ceiling, floor, seats, and steering wheel. The interaction mesh is composed of the vertices of the environment and the skeleton joints and end effectors. Snapshots of the input motion and that retargeted to a scaled character are shown in Fig. 8 . Observe that the character?s motion is successfully adapted to the new character size. Since some of the interactions of the character with the car, such as ducking and passing through the narrow space, cannot be described only with explicit constraints such as contacts, these motions are difficult to handle for previous methods. The main bottleneck of our method is solving the large linear equation in Eq. We use UMFPACK [Davis 2004] and GotoBLAS [Goto and Van De Geijn 2008]. Since the Laplacian matrix M and the constraint matrix C k are both sparse, the computation only increases linearly with respect to the number of vertices in all the interaction meshes. Therefore, the complexity of the problem is O(m ? n), where m is the number of vertices in each mesh and n is the number of frames. For all the retargeting examples shown in this paper, the computation required for each motion is around 1 minute for an animation of 100 frames, using one core of a Core i7 2.67GHz CPU. Since most of the computation, such as the computation of the Laplacian and constraint matrices and solving the large linear system [Bolz et al. 2003] are highly parallelizable, much faster response can be expected with GPU implementations. First we show the results of retargeting motions involving only characters. We use motions involving much tangling and contacts, such as judo, as well as those with few contacts, such as dancing and attackers/defenders in fighting games. Judo attacks Our first motion example is a judo ?Ogoshi throw? in which the attacker holds the arm and the waist of the defender and throws the defender by carrying him/her onto the back. We retarget the motions of the thrower and the defender to characters of various morphologies. We use the body sizes of characters in Allen et al. [2003] as reference (See Fig. 1 ). Here, although the proportions and the bounding volumes of the new characters are completely different from those of the original characters, our system can still produce the Ogoshi throw. Note that previous motion editing/retargeting approaches are difficult to apply to this kind of close interactions since they only consider the joint angles of the original motion but not the spatial relationships. As a result, the retargeted motion may have a different context (e.g. the arms extend to the other side of the defender?s body). They also require the animators to manually specify all the positional constraints in all the frames, such as the attacker?s hand holding the defender?s body. This can be a tedious task for the animator. Fighting scenes Our next two motion examples are fighting scenes involving two characters provided by a game company. The first scene involves a character holding a sword attacking its enemy. The sword penetrates through the enemy character when the enemy is stabbed, and therefore, we turned off the collision constraint in those frames. The second scene is from the same game. The character holding the sword breaks the back of the enemy with both arms and drops it. The sword unintentionally passes through the arm of the defender in some of the frames, which is due to the manual design. Again, we turned off the collision constraint in those frames. Both the attacker?s and defender?s morphologies are changed and animations of different combination of bodies are created. Snapshots of the original and synthesized motions are shown in Fig. 4 and Fig. 5 , respectively. Note that manual editing would (left) A posture of a turn kick interaction. (middle, right) The animator drags the left foot of the yellow character by mouse and the other character moves to preserve the spatial relationship. Original dancing motion (middle) and the retargeted results to a monkey model with long arms using a joint-angle based method (left) and using our method (right). require a lot of care to avoid unintentional penetrations of the sword into the body. Our method can automatically produce the motion of passing the sword into the space between the enemy?s arm and torso. These examples show that our method can also be used for manually designed motions which are not penetration-free. In such cases, the context of the penetrations (e.g. stabbing the enemy) are preserved in the synthesized results. Feedback from the game company indicates that the quality of our retargeted movements is high enough for games usage. Interactive character control Next, we show a demo of using the interaction mesh for real-time control of characters. Pausing the animation of interaction at some frame, we can let the user interactively control a body part using inverse kinematics while maintaining its spatial relationships with the other character(s). In such cases, we solve Eq. (11) for a single frame rather than for the entire motion, which provides real-time performance. The other character(s) will follow the movements of the controlled character according to the interaction mesh at that frame. The controlled body part is softly constrained by an additional positional constraint. An example of editing a posture in a turn-kick motion is shown in Fig. 6 . The updates in the edited frame can be propagated to the whole motion by iteratively solving Eq. (10) using the edited posture as a constraint. Single character motions We use a dancing motion in which the character performs an arms cycling motion and retarget it to a character with monkey proportions ( Fig. 7 ). Our method can preserve the context of the motion despite the much longer arms of the monkey character. In contrast, the method of [Lyard and MagnenatThalmann 2008] results in a motion with many collisions, causing the movements to appear unstable. Note that since this motion does not involve any tangles, the topology coordinates [Ho and Komura 2009a] are also difficult to apply. Snapshots of a character getting into and riding a car model; (top) original character and (bottom) a tall fat character. Motions in a constrained environment, such as getting in and out of a car, involve close maneuvers and collision avoidance. Retargeting such motions to characters of different sizes or adapting the motions to environment with different parameters (e.g. size of car) has a great demand in CAD design and digital mannequins [Badler et al. 1999]. Here we show examples of using the interaction mesh for such a purpose. We captured the motion of a person getting into a car and holding the steering wheel. The environment is composed of simple polylines representing the car doors, ceiling, floor, seats, and steering wheel. The interaction mesh is composed of the vertices of the environment and the skeleton joints and end effectors. Snapshots of the input motion and that retargeted to a scaled character are shown in Fig. 8 . Observe that the character?s motion is successfully adapted to the new character size. Since some of the interactions of the character with the car, such as ducking and passing through the narrow space, cannot be described only with explicit constraints such as contacts, these motions are difficult to handle for previous methods. The main bottleneck of our method is solving the large linear equation in Eq. We use UMFPACK [Davis 2004] and GotoBLAS [Goto and Van De Geijn 2008]. Since the Laplacian matrix M and the constraint matrix C k are both sparse, the computation only increases linearly with respect to the number of vertices in all the interaction meshes. Therefore, the complexity of the problem is O(m ? n), where m is the number of vertices in each mesh and n is the number of frames. For all the retargeting examples shown in this paper, the computation required for each motion is around 1 minute for an animation of 100 frames, using one core of a Core i7 2.67GHz CPU. Since most of the computation, such as the computation of the Laplacian and constraint matrices and solving the large linear system [Bolz et al. 2003] are highly parallelizable, much faster response can be expected with GPU implementations. In this paper, we have presented a new method to edit and retarget character animation that involves many close interactions by introducing a new representation called interaction mesh. When updating the motion, the spatial relationships between different body components and objects can be preserved by applying a spacetime optimization to minimize the deformation of the interaction meshes subject to collision constraints as well as bone-length and positional constraints. The method is fully automatic, not requiring manual intervention from the user. We have demonstrated the effectiveness of the proposed method by showing realistic synthesized animations of various types of close interactions, which are difficult to produce using previous methods. As a future work, we plan to numerically evaluate the topological and geometric features of the interaction meshes, and introduce a metric to compare motions at the level of interaction meshes. Our method can then be extended for use in reinforcement learning, enabling computer-controlled characters to smartly interact with usercontrolled characters in closely interacting environments. Another possible research direction is to apply our method for controlling characters in physically-based environments, such as by combining it with the balance keeping techniques in [da Silva et al. 2008; Macchietto et al. 2009]. Tackling such a problem may also lead to solutions for controlling multi-biped robots to cooperatively accomplish tasks such as carrying objects together.",
  "resources" : [ ]
}