{
  "uri" : "sig2007-a1-yuan_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2007/a1-yuan_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Image Deblurring with Blurred/Noisy Image Pairs",
    "published" : null,
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ ]
  },
  "bagOfWords" : [ "capture", "satisfactory", "photo", "under", "low", "light", "condition", "use", "hand-held", "camera", "can", "frustrating", "experience", "often", "photo", "take", "blur", "noisy", "brightness", "image", "can", "increase", "three", "way", "first", "reduce", "shutter", "speed", "shutter", "speed", "below", "safe", "shutter", "speed", "-lrb-", "reciprocal", "focal", "length", "lens", "unit", "seconds", "-rrb-", "camera", "shake", "result", "blur", "image", "second", "use", "large", "aperture", "large", "aperture", "however", "reduce", "depth", "field", "moreover", "range", "aperture", "many", "camera", "very", "limited", "Third", "set", "high", "iso", "however", "high", "iso", "image", "very", "noisy", "because", "noise", "amplify", "camera?s", "gain", "increase", "take", "sharp", "image", "dim", "lighting", "environment", "best", "setting", "safe", "shutter", "speed", "largest", "aperture", "highest", "iso", "even", "combination", "capture", "image", "may", "still", "dark", "very", "noisy", "typically", "two", "kind", "degraded", "image", "can", "take", "low", "light", "condition", "one", "blur", "image", "which", "take", "slow", "shutter", "speed", "low", "iso", "setting", "show", "Figure", "-lrb-", "-rrb-", "enough", "light", "have", "correct", "color", "intensity", "high", "SignalNoise", "Ratio", "-lrb-", "SNR", "-rrb-", "blurry", "due", "camera", "shake", "other", "underexposed", "noisy", "image", "fast", "shutter", "speed", "high", "iso", "setting", "show", "Figure", "-lrb-", "-rrb-", "sharp", "very", "noisy", "due", "insufficient", "exposure", "high", "camera", "gain", "color", "image", "also", "partially", "lose", "due", "low", "contrast", "recover", "high", "quality", "image", "from", "very", "noisy", "image", "easy", "task", "fine", "image", "detail", "texture", "conceal", "noise", "denoising", "-lsb-", "Portilla", "et", "al.", "2003", "-rsb-", "can", "completely", "separate", "signal", "from", "noise", "other", "hand", "deblurr", "from", "single", "blur", "image", "challenging", "blind", "deconvolution", "problem", "both", "blur", "kernel", "-lrb-", "point", "spread", "function", "-rrb-", "estimation", "image", "deconvolution", "highly", "under-constrained", "moreover", "unpleasant", "artifact", "-lrb-", "e.g.", "ring", "-rrb-", "from", "image", "deconvolution", "even", "when", "use", "perfect", "kernel", "also", "appear", "reconstructed", "image", "deblurr", "blurred/noisy", "image", "pair", "have", "be", "propose", "Lim", "Silverstein", "-lsb-", "2006", "-rsb-", "paper", "we", "also", "use", "blurred/noisy", "image", "pair", "describe", "approach", "estimate", "much", "more", "accurate", "blur", "kernel", "produce", "deblurred", "image", "almost", "ringing", "like", "most", "previous", "image", "deblurr", "approach", "we", "we", "thank", "reviewer", "point", "out", "Lim", "Silverstein", "-lsb-", "2006", "-rsb-", "work", "during", "rebuttal", "phase", "inspire", "-lsb-", "Fergus", "et", "al.", "2006", "-rsb-", "we", "convert", "blind", "deconvolution", "problem", "two", "non-blind", "deconvolution", "problem", "non-blind", "kernel", "estimation", "non-blind", "image", "deconvolution", "kernel", "estimation", "we", "show", "very", "accurate", "initial", "kernel", "can", "recover", "from", "blur", "image", "exploit", "large", "scale", "sharp", "image", "structure", "noisy", "image", "we", "approach", "also", "able", "handle", "larger", "kernel", "than", "those", "recover", "-lsb-", "Fergus", "et", "al.", "2006", "-rsb-", "use", "single", "blur", "image", "greatly", "reduce", "ring", "artifact", "commonly", "result", "from", "image", "deconvolution", "we", "propose", "residual", "deconvolution", "approach", "we", "also", "propose", "gain-controlled", "deconvolution", "further", "suppress", "ringing", "artifact", "smooth", "image", "region", "all", "three", "step", "kernel", "estimation", "residual", "deconvolution", "gaincontrolled", "deconvolution", "take", "advantage", "both", "image", "final", "reconstructed", "image", "sharper", "than", "blur", "image", "clearer", "than", "noisy", "image", "show", "Figure", "-lrb-", "-rrb-", "we", "approach", "practical", "despite", "we", "require", "two", "image", "we", "have", "find", "motion", "between", "two", "blurred/noisy", "image", "when", "take", "quick", "succession", "mainly", "translation", "significant", "because", "kernel", "estimation", "independent", "translation", "which", "only", "result", "offset", "kernel", "we", "describe", "how", "acquire", "align", "image", "pair", "section", "single", "image", "deblurring", "image", "deblurring", "can", "categorize", "two", "type", "blind", "deconvolution", "non-blind", "deconvolution", "former", "more", "difficult", "since", "blur", "kernel", "unknown", "comprehensive", "literature", "review", "can", "find", "-lsb-", "Kundur", "Hatzinakos", "1996", "-rsb-", "demonstrate", "-lsb-", "Fergus", "et", "al.", "2006", "-rsb-", "real", "kernel", "cause", "camera", "shake", "complex", "beyond", "simple", "parametric", "form", "-lrb-", "e.g.", "single", "one-direction", "motion", "gaussian", "-rrb-", "assume", "previous", "approach", "-lsb-", "reeve", "Mersereau", "1992", "Y.", "Yitzhaky", "Kopeika", "1998", "Caron", "et", "al.", "2002", "Jalobeanu", "et", "al.", "2002", "-rsb-", "-lsb-", "Fergus", "et", "al.", "2006", "-rsb-", "natural", "image", "statistics", "together", "sophisticated", "variational", "baye", "inference", "algorithm", "use", "estimate", "kernel", "image", "reconstruct", "use", "standard", "non-blind", "deconvolution", "algorithm", "very", "nice", "result", "obtain", "when", "kernel", "small", "-lrb-", "e.g.", "30", "30", "pixel", "fewer", "-rrb-", "-lsb-", "Fergus", "et", "al.", "2006", "-rsb-", "Kernel", "estimation", "large", "blur", "however", "inaccurate", "unreliable", "use", "single", "image", "even", "known", "kernel", "non-blind", "deconvolution", "-lsb-", "geman", "Reynolds", "1992", "Zarowin", "1994", "Neelamani", "et", "al.", "2004", "-rsb-", "still", "under-constrained", "reconstruction", "artifact", "e.g.", "ring", "effect", "color", "speckle", "inevitable", "because", "high", "frequency", "loss", "blur", "image", "error", "due", "sensor", "noise", "quantization", "image/kernel", "also", "amplify", "deconvolution", "process", "example", "more", "iteration", "Richardson-Lucy", "-lrb-", "RL", "-rrb-", "algorithm", "-lsb-", "h.", "Richardson", "1972", "-rsb-", "result", "more", "ring", "artifact", "we", "approach", "we", "significantly", "reduce", "artifact", "non-blind", "deconvolution", "take", "advantage", "noisy", "image", "recently", "spatially", "variant", "kernel", "estimation", "have", "also", "be", "propose", "-lsb-", "Bardsley", "et", "al.", "2006", "-rsb-", "-lsb-", "Levin", "2006", "-rsb-", "image", "segmented", "several", "layer", "different", "kernel", "kernel", "each", "layer", "uni-directional", "layer", "motion", "velocity", "constant", "hardware", "base", "solution", "-lsb-", "Nikon", "2005", "-rsb-", "reduce", "image", "blur", "include", "lens", "stabilization", "sensor", "stabilization", "both", "technique", "physically", "move", "element", "lens", "sensor", "counterbalance", "camera", "shake", "typically", "capture", "image", "can", "sharp", "be", "take", "shutter", "speed", "2-3", "stop", "faster", "single", "image", "denoising", "image", "denoising", "classic", "problem", "extensively", "study", "challenge", "image", "denoising", "how", "compromise", "between", "remove", "noise", "preserve", "edge", "texture", "commercial", "software", "e.g.", "NeatImage", "-lrb-", "www.neatimage.com", "-rrb-", "imagenomic", "-lrb-", "www.imagenomic.com", "-rrb-", "use", "wavelet-based", "approach", "-lsb-", "simoncellus", "Adelson", "1996", "Portilla", "et", "al.", "2003", "-rsb-", "bilateral", "filter", "-lsb-", "Tomasi", "Manduchi", "1998", "Durand", "Dorsey", "2002", "-rsb-", "have", "also", "be", "simple", "effective", "method", "widely", "use", "computer", "graphic", "other", "approach", "include", "anisotropic", "diffusion", "-lsb-", "Perona", "Malik", "1990", "-rsb-", "pde-based", "method", "-lsb-", "Rudin", "et", "al.", "1992", "-rsb-", "field", "expert", "-lsb-", "Roth", "Black", "2005", "-rsb-", "nonlocal", "method", "-lsb-", "buade", "et", "al.", "2005", "-rsb-", "multiple", "image", "deblurr", "denoise", "deblurr", "denoise", "can", "benefit", "from", "multiple", "image", "image", "different", "blur", "direction", "-lsb-", "Bascle", "et", "al.", "1996", "Rav-Acha", "Peleg", "2000", "Rav-Acha", "Peleg", "2005", "-rsb-", "can", "use", "kernel", "estimation", "-lsb-", "Liu", "Gamal", "2001", "-rsb-", "CMOS", "sensor", "can", "capture", "multiple", "high-speed", "frame", "within", "normal", "exposure", "time", "pixel", "motion", "replace", "pixel", "one", "high-speed", "frame", "Raskar", "et", "al.", "-lsb-", "2006", "-rsb-", "propose", "flutter", "shutter", "camera", "which", "open", "close", "shutter", "during", "normal", "exposure", "time", "pseudo-random", "sequence", "approach", "preserve", "high", "frequency", "spatial", "detail", "blur", "image", "produce", "impressive", "result", "assume", "blur", "kernel", "know", "denoise", "can", "perform", "joint/cross", "bilateral", "filter", "use", "flash/no-flash", "image", "-lsb-", "Petschnigg", "et", "al.", "2004", "Eisemann", "Durand", "2004", "-rsb-", "spatio-temporal", "filter", "video", "sequence", "-lsb-", "Bennett", "McMillan", "2005", "-rsb-", "hybrid", "imaging", "system", "-lsb-", "Ben-Ezra", "Nayar", "2003", "-rsb-", "consist", "primary", "sensor", "-lrb-", "high", "spatial", "resolution", "-rrb-", "secondary", "sensor", "-lrb-", "high", "temporal", "resolution", "-rrb-", "secondary", "sensor", "capture", "number", "low", "resolution", "sharp", "image", "kernel", "estimation", "we", "approach", "estimate", "kernel", "only", "from", "two", "image", "without", "need", "special", "hardware", "another", "related", "work", "-lsb-", "Jia", "et", "al.", "2004", "-rsb-", "also", "use", "pair", "image", "where", "color", "blur", "image", "transfer", "noisy", "image", "without", "kernel", "estimation", "approach", "limit", "case", "noisy", "image", "have", "high", "snr", "fine", "detail", "work", "most", "related", "ours", "-lsb-", "Lim", "Silverstein", "2006", "-rsb-", "which", "also", "make", "use", "short", "exposure", "image", "help", "estimate", "kernel", "deconvolution", "kernel", "estimate", "linear", "leastsquare", "sense", "use", "two", "image", "work", "have", "also", "suggest", "application", "defocus", "use", "large/small", "aperture", "image", "however", "work", "do", "show", "any", "result", "analysis", "paper", "we", "demonstrate", "we", "propose", "technique", "can", "obtain", "much", "accurate", "kernel", "compare", "Lim", "Silverstein?s", "approach", "produce", "almost", "artifact-free", "image", "propose", "de-ringing", "approach", "deconvolution" ],
  "content" : "Capturing satisfactory photos under low light conditions using a hand-held camera can be a frustrating experience. Often the photos  taken are blurred or noisy. The brightness of the image can be increased in three ways. First, to reduce the shutter speed. But with a shutter speed below a safe shutter speed (the reciprocal of the focal length of the lens, in the unit of seconds), camera shake will result in a blurred image. Second, to use a large aperture. A large aperture will however reduce the depth of field. Moreover, the range of apertures in many cameras is very limited. Third, to set a high ISO. However, the high ISO image is very noisy because the noise is amplified as the camera?s gain increases. To take a sharp image in a dim lighting environment, the best settings are: safe shutter speed, the largest aperture, and the highest ISO. Even with this combination, the captured image may still be dark and very noisy. Typically, two kinds of degraded image can be taken in the low light conditions. One is a blurred image which is taken with a slow shutter speed and a low ISO setting, as shown in Figure 1(a) . With enough light, it has the correct color, intensity and a high SignalNoise Ratio (SNR). But it is blurry due to camera shake. The other is an underexposed and noisy image with a fast shutter speed and a high ISO setting, as shown in Figure 1(b) . It is sharp but very noisy due to insufficient exposure and high camera gain. The colors of this image are also partially lost due to low contrast. Recovering a high quality image from a very noisy image is no easy task as fine image details and textures are concealed in noise. Denoising [Portilla et al. 2003] cannot completely separate signals from noise. On the other hand, deblurring from a single blurred image is a challenging blind deconvolution problem both blur kernel (or Point Spread Function) estimation and image deconvolution are highly under-constrained. Moreover, unpleasant artifacts (e.g., ringing) from image deconvolution, even when using a perfect kernel, also appear in the reconstructed image. Deblurring with blurred/noisy image pair has been proposed by Lim and Silverstein [2006] 1 . In this paper, we also use a blurred/noisy image pair, but describe an approach that estimates a much more accurate blur kernel and produces a deblurred image with almost no ringing. Like most previous image deblurring approaches, we 1 We thank the reviewers for pointing out Lim and Silverstein [2006]?s work during the rebuttal phase. Inspired by [Fergus et al. 2006], we convert the blind deconvolution problem into two non-blind deconvolution problems non-blind kernel estimation and non-blind image deconvolution. In kernel estimation, we show that a very accurate initial kernel can be recovered from the blurred image by exploiting the large scale, sharp image structures in the noisy image. Our approach is also able to handle larger kernels than those recovered by [Fergus et al. 2006] using a single blurred image. To greatly reduce the ?ringing? artifacts that commonly result from the image deconvolution, we propose a residual deconvolution approach. We also propose a gain-controlled deconvolution to further suppress the ringing artifacts in smooth image regions. All three steps kernel estimation, residual deconvolution, and gaincontrolled deconvolution take advantage of both images. The final reconstructed image is sharper than the blurred image and clearer than the noisy image, as shown in Figure 1(d) . Our approach is practical despite that we require two images. We have found that the motion between two blurred/noisy images, when taken in a quick succession, is mainly a translation. This is significant because the kernel estimation is independent of the translation, which only results in an offset of the kernel. We will describe how to acquire and align such image pairs in Section 7. Single image deblurring. Image deblurring can be categorized into two types: blind deconvolution and non-blind deconvolution. The former is more difficult since the blur kernel is unknown. A comprehensive literature review can be found in [Kundur and Hatzinakos 1996]. As demonstrated in [Fergus et al. 2006], the real kernel caused by camera shake is complex, beyond a simple parametric form (e.g., single one-direction motion or a gaussian) assumed in previous approaches [Reeves and Mersereau 1992; Y. Yitzhaky and Kopeika. 1998; Caron et al. 2002; Jalobeanu et al. 2002]. In [Fergus et al. 2006], natural image statistics together with a sophisticated variational Bayes inference algorithm are used to estimate the kernel. The image is then reconstructed using a standard non-blind deconvolution algorithm. Very nice results are obtained when the kernel is small (e.g. 30 ? 30 pixels or fewer) [Fergus et al. 2006]. Kernel estimation for a large blur is, however, inaccurate and unreliable using a single image. Even with a known kernel, non-blind deconvolution [Geman and Reynolds 1992; Zarowin 1994; Neelamani et al. 2004] is still under-constrained. Reconstruction artifacts, e.g., ?ringing? effects or color speckles, are inevitable because of high frequency loss in the blurred image. The errors due to sensor noise and quantizations of the image/kernel are also amplified in the deconvolution process. For example, more iterations in the Richardson-Lucy (RL) algorithm [H. Richardson 1972] will result in more ?ringing? artifacts. In our approach, we significantly reduce the artifacts in a non-blind deconvolution by taking advantage of the noisy image. Recently, spatially variant kernel estimation has also been proposed in [Bardsley et al. 2006]. In [Levin 2006], the image is segmented into several layers with different kernels. The kernel in each layer is uni-directional and the layer motion velocity is constant. Hardware based solutions [Nikon 2005] to reduce image blur include lens stabilization and sensor stabilization. Both techniques physically move an element of the lens, or the sensor, to counterbalance the camera shake. Typically, the captured image can be as sharp as if it were taken with a shutter speed 2-3 stops faster. Single image denoising. Image denoising is a classic problem extensively studied. The challenge of image denoising is how to compromise between removing noise and preserving edge or texture. Commercial softwares, e.g., ?NeatImage? (www.neatimage.com) and ?Imagenomic? (www.imagenomic.com), use wavelet-based approaches [Simoncelli and Adelson 1996; Portilla et al. 2003]. Bilateral filtering [Tomasi and Manduchi 1998; Durand and Dorsey 2002] has also been a simple and effective method widely used in computer graphics. Other approaches include anisotropic diffusion [Perona and Malik 1990], PDE-based methods [Rudin et al. 1992], fields of experts [Roth and Black 2005], and nonlocal methods [Buades et al. 2005]. Multiple images deblurring and denoising. Deblurring and denoising can benefit from multiple images. Images with different blurring directions [Bascle et al. 1996; Rav-Acha and Peleg 2000; Rav-Acha and Peleg 2005] can be used for kernel estimation. In [Liu and Gamal 2001], a CMOS sensor can capture multiple high-speed frames within a normal exposure time. The pixel with motion replaced with the pixel in one of the high-speed frames. Raskar et al. [2006] proposed a ?fluttered shutter? camera which opens and closes the shutter during a normal exposure time with a pseudo-random sequence. This approach preserves high frequency spatial details in the blurred image and produces impressive results, assuming the blur kernel is known. Denoising can be performed by a joint/cross bilateral filter using flash/no-flash images [Petschnigg et al. 2004; Eisemann and Durand 2004], or by a spatio-temporal filter for video sequences [Bennett and McMillan 2005]. Hybrid imaging system [Ben-Ezra and Nayar 2003] consists of a primary sensor (high spatial resolution) and a secondary sensor (high temporal resolution). The secondary sensor captures a number of low resolution, sharp images for kernel estimation. Our approach estimates the kernel only from two images, without the need for special hardware. Another related work [Jia et al. 2004] also uses a pair of images, where the colors of the blurred image are transferred into the noisy image without kernel estimation. But this approach is limited to the case that the noisy image has a high SNR and fine details. The work most related to ours is [Lim and Silverstein 2006] which also makes use of a short exposure image to help estimate the kernel and deconvolution. The kernel is estimated in the linear leastsquares sense using two images. Their works has also suggested an application for defocus using large/small aperture images. However, their work does not show any results or analysis. In this paper, we demonstrate that our proposed techniques can obtain much accurate kernel compared with Lim and Silverstein?s approach, and produce almost artifact-free image by a proposed de-ringing approach in deconvolution.",
  "resources" : [ ]
}