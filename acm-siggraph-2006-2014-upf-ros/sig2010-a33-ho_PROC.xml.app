{
  "uri" : "sig2010-a33-ho_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2010/a33-ho_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Spatial Relationship Preserving Character Motion Adaptation",
    "published" : "2010",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Edmond S. L.-Ho",
      "name" : "Edmond S. L.",
      "surname" : "Ho"
    }, {
      "uri" : "http://drinventor/Taku-Komura",
      "name" : "Taku",
      "surname" : "Komura"
    }, {
      "uri" : "http://drinventor/Chiew-Lan-Tai",
      "name" : "Chiew-Lan",
      "surname" : "Tai"
    } ]
  },
  "bagOfWords" : [ "paper", "present", "new", "method", "editing", "retargeting", "motion", "involve", "close", "interaction", "between", "body", "part", "single", "multiple", "articulate", "character", "dancing", "wrestling", "sword", "fighting", "between", "character", "restricted", "environment", "get", "car", "we", "introduce", "simple", "structure", "call", "interaction", "mesh", "represent", "spatial", "relationship", "interaction", "mesh", "representation", "general", "applicable", "various", "kind", "close", "interaction", "also", "work", "well", "interaction", "involve", "contact", "tangle", "well", "those", "without", "any", "contact", "method", "computationally", "efficient", "allow", "real-time", "character", "control", "we", "demonstrate", "its", "effectiveness", "versatility", "synthesize", "wide", "variety", "motion", "close", "interaction", "close", "interaction", "necessarily", "any", "contact", "between", "different", "body", "part", "single", "multiple", "character", "environment", "common", "computer", "animation", "3d", "computer", "game", "motion", "spatial", "relationship", "between", "different", "body", "part", "character", "important", "capture", "semantics", "scene", "when", "animator", "synthesize", "edit", "movement", "special", "care", "need", "preserve", "spatial", "relationship", "example", "arch", "back", "avoid", "punch", "hand", "extend", "around", "each", "other", "two", "body", "move", "synchronously", "close", "proximity", "get", "small", "car", "bend", "down", "however", "traditionally", "spatial", "relationship", "exist", "only", "animator?s", "mind", "digitally", "embed", "datum", "although", "human", "use", "spatial", "relationship", "recognize", "semantics", "interaction", "usage", "have", "be", "consider", "much", "character", "animation", "exist", "scene", "representation", "have", "fundamental", "limitation", "handle", "close", "interaction", "currently", "motion", "typically", "describe", "term", "joint", "angle", "kinematic", "constraint", "contact", "representation", "automatically", "compute", "valid", "motion", "require", "randomize", "exploration", "significant", "computation", "collision", "detection", "animator", "also", "need", "shoulder", "burden", "specify", "all", "kinematic", "constraint", "advance", "from", "animator?s", "perspective", "impractical", "conductive", "manual", "editing", "competitive", "automatic", "solution", "require", "effective", "representation", "allow", "extraction", "spatial", "relationship", "from", "exist", "motion", "datum", "synthesis", "new", "animation", "preserve", "relationship", "representation", "only", "allow", "quantitative", "evaluation", "way", "different", "body", "part", "interact", "also", "facilitate", "qualitative", "characterization", "scene", "semantics", "paper", "we", "propose", "simple", "representation", "which", "we", "call", "interaction", "mesh", "represent", "spatial", "relationship", "between", "nearby", "body", "part", "interaction", "mesh", "volumetric", "mesh", "define", "joint", "character", "vertex", "objects/environment", "which", "character", "interact", "result", "applicable", "many", "type", "scenario", "when", "single", "character?s", "action", "involve", "close", "interaction", "between", "different", "body", "part", "-lrb-", "dancing", "-rrb-", "multi-character", "interaction", "-lrb-", "wrestling", "fight", "game", "-rrb-", "Motion", "adaptation", "interaction", "mesh", "fully", "automatic", "when", "animator", "change", "size", "morphology", "character", "edit", "part", "motion", "system", "automatically", "deform", "interaction", "mesh", "all", "frame", "use", "spacetime", "optimization", "create", "new", "motion", "sequence", "preserve", "original", "context", "scene", "constraint", "need", "specify", "animator", "since", "all", "encode", "interaction", "mesh", "desire", "user", "may", "add", "extra", "constraint", "anchor", "body", "foot", "approach", "efficient", "allow", "real-time", "control", "character", "virtual", "environment", "specifically", "computational", "cost", "increase", "only", "linearly", "number", "frame", "complexity", "articulate", "body", "structure", "we", "demonstrate", "its", "usefulness", "character", "animation", "retargeting", "capture", "human", "motion", "character", "very", "different", "proportion", "volume", "monkey", "also", "editing", "motion", "multiple", "character", "while", "preserve", "original", "context", "scene", "we", "present", "automatic", "method", "use", "interaction", "mesh", "editing", "retargeting", "motion", "close", "interaction", "most", "exist", "motion", "synthesis", "method", "use", "kinematic", "constraint", "positional", "constraint", "enforce", "spatial", "relationship", "between", "character", "environment", "few", "more", "recent", "work", "character", "animation", "consider", "implicit", "spatial", "relationship", "constraint-based", "motion", "synthesis", "since", "kinematic", "constraint", "can", "usually", "represent", "single", "equation", "can", "easily", "embed", "optimization", "problem", "motion", "synthesis", "other", "method", "avoid", "penetration", "interact", "body", "part", "use", "inequality", "constraint", "-lsb-", "Liu", "et", "al.", "2006", "-rsb-", "combination", "collision", "detection", "equality", "constraint", "-lsb-", "Xu", "et", "al.", "2007", "Shi", "et", "al.", "2007", "-rsb-", "method", "produce", "excellent", "result", "interaction", "contact", "however", "applicable", "maintain", "spatial", "relationship", "less", "explicit", "because", "represent", "they", "single", "equation", "difficult", "example", "Lambada", "dance", "dancer", "twist", "body", "around", "each", "other", "without", "necessarily", "any", "body", "contact", "handle", "motion", "where", "interaction", "condition", "largely", "implicit", "difficult", "since", "context", "scene", "must", "preserve", "while", "avoid", "penetration", "collision", "without", "good", "representation", "implicit", "spatial", "relationship", "motion", "synthesis", "require", "complex", "global", "path", "planner", "involve", "significant", "collision", "detection", "effort", "randomize", "exploration", "-lsb-", "LaValle", "Kuffner", "2001", "Yamane", "et", "al.", "2004", "Shapiro", "et", "al.", "2007", "-rsb-", "which", "difficult", "large", "number", "degree", "freedom", "contrast", "we", "method", "aim", "preserve", "spatial", "relationship", "between", "body", "3d", "articulate", "character", "which", "require", "consider", "connection", "joint", "rigidity", "body", "component", "penetration", "between", "they", "however", "extension", "motion", "involve", "character", "shape", "seem", "difficult", "since", "relationship", "between", "rigid", "body", "surface", "need", "encode", "further", "method", "can", "handle", "close", "interaction", "without", "any", "tangle", "section", "we", "describe", "how", "we", "compute", "interaction", "mesh", "give", "motion", "note", "spatial", "relationship", "which", "we", "want", "preserve", "those", "between", "body", "part", "close", "proximity", "occlude", "other", "part", "orientation", "some", "body", "segment", "can", "compute", "only", "from", "position", "joint", "bound", "segment", "order", "compute", "orientation", "we", "sample", "one", "extra", "virtual", "vertex", "surface", "each", "bound", "volume", "-lsb-", "Shi", "et", "al.", "2007", "-rsb-", "each", "morph-step", "each", "animation", "frame", "target", "length", "each", "bone", "compute", "linearly", "blend", "original", "final", "length", "single", "character", "motion", "we", "use", "dancing", "motion", "which", "character", "perform", "arm", "cycling", "motion", "retarget", "character", "monkey", "proportion", "-lrb-", "fig.", "-rrb-", "although", "collision", "detection", "can", "avoid", "interpenetration", "body", "part", "movement", "one", "part", "do", "affect", "movement", "other", "part", "until", "collision", "occur" ],
  "content" : "This paper presents a new method for editing and retargeting motions that involve close interactions between body parts of single or multiple articulated characters, such as dancing, wrestling, and sword fighting, or between characters and a restricted environment, such as getting into a car. We introduce a simple structure called an interaction mesh to represent such spatial relationships. The interaction mesh representation is general and applicable to various kinds of close interactions. It also works well for interactions involving contacts and tangles as well as those without any contacts. The method is computationally efficient, allowing real-time character control. We demonstrate its effectiveness and versatility in synthesizing a wide variety of motions with close interactions. Close interactions, not necessarily with any contacts, between different body parts of single or multiple characters or with the environment are common in computer animation and 3D computer games. In such motions, the spatial relationships between different body parts of characters are important in capturing the semantics of the scene. When an animator synthesizes or edits such movements, special care is needed to preserve these spatial relationships, for example, ?arching back to avoid a punch?, ?hands extending around each other?, ?two bodies moving synchronously in close proximity? or ?getting into a small car by bending down?. However, traditionally, such spatial relationships exist only in the animator?s mind and are not digitally embedded into the data. Although humans use spatial relationships to recognize semantics of interactions, their usage has not been considered much in character animation. Existing scene representations have a fundamental limitation in handling such close interactions. Currently, a motion is typically described in terms of joint angles and kinematic constraints such as contacts. With this representation, automatically computing a valid motion requires randomized exploration and significant computation for collision detection. The animator also needs to shoulder the burden of specifying all the kinematic constraints in advance. From the animator?s perspective, this is impractical and not conductive to manual editing. Competitive automatic solutions require an effective representation that allows the extraction of spatial relationships from existing motion data and synthesis of new animations that preserve these relationships. Such a representation will not only allow quantitative evaluation of the way different body parts are interacting, but also facilitate qualitative characterization of scene semantics. In this paper, we propose a simple representation which we call the interaction mesh to represent the spatial relationships between nearby body parts. The interaction mesh is a volumetric mesh defined by the joints of the characters and the vertices of the objects/environment with which the characters are interacting. As a result, it is applicable to many types of scenarios, such as when single character?s actions involve close interactions between different body parts (dancing) or multi-character interactions (wrestling, fighting games). Motion adaptation with the interaction mesh is fully automatic. When the animator changes the size or morphology of the characters or edits parts of the motion, the system automatically deforms the interaction meshes at all the frames using a spacetime optimization and creates a new motion sequence that preserves the original context of the scene. No constraints need to be specified by the animator since they are all encoded in the interaction meshes. If desired, the user may add extra constraints such as anchoring the bodies at the feet. The approach is efficient, allowing real-time control of characters in virtual environments. Specifically, the computational cost increases only linearly in the number of frames and the complexity of the articulated body structures. We demonstrate its usefulness in character animation by retargeting captured human motions to characters of very different proportions and volumes, such as a monkey and also by editing the motions of multiple characters while preserving the original context of the scene. We then present an automatic method that uses the interaction mesh for editing or retargeting motions with close interactions. Most existing motion synthesis methods use kinematic constraints such as positional constraints to enforce a spatial relationship between characters and the environment. A few more recent works on character animation consider implicit spatial relationships. Constraint-based motion synthesis Since kinematic constraints can usually be represented by single equations, they can be easily embedded into optimization problems for motion synthesis. Other methods avoid penetrations of interacting body parts by using inequality constraints [Liu et al. 2006] or a combination of collision detections and equality constraints [Xu et al. 2007; Shi et al. 2007]. These methods produce excellent results for interactions with contacts, however, they are not applicable for maintaining spatial relationships that are less explicit, because representing them as single equations is difficult. For example, in Lambada dances, the dancers twist their bodies around each other without necessarily any body contact. Handling such motions where the interaction conditions are largely implicit is difficult since the context of the scene must be preserved while avoiding penetrations and collisions. Without a good representation of such implicit spatial relationships, the motion synthesis requires complex global path planners involving significant collision detection effort and randomized exploration [LaValle and Kuffner 2001; Yamane et al. 2004; Shapiro et al. 2007], which is difficult for large numbers of degrees of freedom. In contrast, our method aims to preserve the spatial relationships between the bodies of 3D articulated characters, which requires considering the connections at the joints, rigidity of the body components and penetrations between them. However, extension to motions involving character shapes seems difficult since relationships between rigid bodies or surfaces need to be encoded. Further, these methods cannot handle close interactions without any tangles. In this section, we describe how we compute the interaction meshes for a given motion. Note that the spatial relationships which we want to preserve are those between body parts that are in close proximity and are not occluded by other parts. The orientation of some body segments cannot be computed only from the positions of joints bounding that segment. In order to compute such orientations, we sample one extra virtual vertex on the surface of each bounding volume, as in [Shi et al. 2007]. In each morph-step and each animation frame, the target length l e for each bone e is computed by linearly blending the original and final lengths. Single character motions We use a dancing motion in which the character performs an arms cycling motion and retarget it to a character with monkey proportions ( Fig. 7 ). Although collision detection can avoid interpenetration of body parts, the movement of one part does not affect the movements of the other parts until collision occurs.",
  "resources" : [ ]
}