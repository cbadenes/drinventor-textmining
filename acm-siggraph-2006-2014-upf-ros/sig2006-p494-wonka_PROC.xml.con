{
  "uri" : "sig2006-p494-wonka_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2006/p494-wonka_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Guided Visibility Sampling",
    "published" : "2006",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Peter-Wonka",
      "name" : "Peter",
      "surname" : "Wonka"
    }, {
      "uri" : "http://drinventor/Michael-Wimmer",
      "name" : "Michael",
      "surname" : "Wimmer"
    }, {
      "uri" : "http://drinventor/Kaichi-Zhou",
      "name" : "Kaichi",
      "surname" : "Zhou"
    }, {
      "uri" : "http://drinventor/Stefan-Maierhofer",
      "name" : "Stefan",
      "surname" : "Maierhofer"
    }, {
      "uri" : "http://drinventor/Gerd-Hesina",
      "name" : "Gerd",
      "surname" : "Hesina"
    }, {
      "uri" : "http://drinventor/Alexander-Reshetov",
      "name" : "Alexander",
      "surname" : "Reshetov"
    } ]
  },
  "bagOfWords" : [ "compare", "efficiency", "we", "algorithm", "previous", "work", "we", "use", "follow", "algorithm", "gv", "we", "guide", "visibility", "sampling", "algorithm", "adaptive", "border", "sampling", "-lrb-", "ab", "-rrb-", "reverse", "sampling", "-lrb-", "r", "-rrb-", "RAND", "random", "sampling", "-lrb-", "GVS", "value", "epsilon", "5e-5", "use", "enlarge", "triangle", "-rrb-", "we", "have", "dedicate", "separate", "subsection", "comparison", "nir", "main", "other", "exist", "visibility", "sampling", "method", "publish", "Nirenstein", "Blake", "-lsb-", "2004", "-rsb-", "-lrb-", "mainly", "because", "algorithm", "have", "slightly", "different", "goal", "than", "gv", "-rrb-", "EXACT", "Bittner?s", "-lsb-", "2003", "-rsb-", "exact", "visibility", "algorithm", "test", "scene", "select", "-lrb-", "see", "Figure", "Table", "-rrb-", "PPLANT", "complete", "UNC", "Power", "Plant", "model", "CITY", "city", "model", "ancient", "city", "Pompeii", "generate", "use", "cityengine", "-lsb-", "m?ller", "et", "al.", "2006", "-rsb-", "CANYON", "dataset", "Grand", "Canyon", "CUBES", "simple", "scene", "random", "cube", "test", "be", "conduct", "Intel", "pentium4", "3.2", "ghz", "4gb", "main", "memory", "graphic", "card", "NIR", "NVIDIA", "GeForce", "7900GTX", "512mb", "top", "left", "city", "top", "right", "CUBES", "bottom", "leave", "PPLANT", "bottom", "right", "CANYON", "Inlays", "view", "from", "view", "cell", "gv", "rand", "we", "use", "intel?s", "multi-level", "ray", "tracer", "-lrb-", "mlrta", "-lsb-", "Reshetov", "et", "al.", "2005", "-rsb-", "-rrb-", "which", "allow", "sampling", "rate", "between", "about", "800k/s", "1200k/s", "peak", "up", "several", "million", "samples/s", "sampling", "rate", "depend", "scene", "type", "-lrb-", "so", "much", "size?pplant", "have", "higher", "sampling", "rate", "than", "CANYON", "example", "-rrb-", "coherence", "ray", "-lrb-", "random", "sample", "ab", "sample", "be", "faster", "depend", "again", "scene", "-rrb-", "overhead", "sampling", "selection", "process", "vary", "between", "15", "depend", "relative", "distribution", "random", "ab", "r", "ray", "we", "first", "analyze", "theoretical", "property", "algorithm", "term", "sampling", "behavior", "i.e.", "sample-by-sample", "basis", "since", "only", "comparison", "do", "depend", "individual", "implementation", "since", "we", "do", "have", "exact", "visibility", "algorithm", "run", "reasonable", "time", "larger", "scene", "we", "can", "only", "study", "asymptotic", "behavior", "small", "number", "view", "cell", "Figure", "provide", "detailed", "analysis", "CANYON", "scene", "graph", "pixel", "error", "-lrb-", "calculate", "count", "false", "pixel", "large", "number", "random", "rendering", "-lsb-", "nirenstein", "Blake", "2004", "-rsb-", "-rrb-", "number", "triangle", "find", "over", "number", "sample", "gv", "rand", "top", "left", "image", "show", "gv", "converge", "linearly", "long", "deterministic", "strategy", "-lrb-", "ab", "r", "-rrb-", "can", "use", "most", "triangle", "black", "dot", "each", "view", "cell", "curve", "show", "when", "we", "termination", "criterion", "terminate", "pv", "search", "-lrb-", "we", "use", "50", "less", "new", "triangle", "find", "per", "1m", "sample", "-rrb-", "can", "see", "happen", "fairly", "well", "converged", "state", "already", "graph", "also", "show", "behavior", "very", "similar", "all", "view", "cell", "length", "linear", "segment", "only", "depend", "final", "pv", "size", "lower", "right", "image", "show", "blue", "view", "cell", "from", "other", "image", "top", "right", "figure", "show", "rand", "comparison", "convergence", "rand", "look", "mainly", "logarithmic", "have", "very", "quick", "falloff", "after", "initial", "strong", "phase", "especially", "noteworthy", "even", "15m", "sample", "when", "GVS", "have", "already", "long", "converge", "rand", "still", "50k", "triangle", "behind", "gv", "most", "view", "cell", "bottom", "right", "figure", "analyze", "behavior", "even", "larger", "scale", "dark", "blue", "view", "cell", "from", "other", "graph", "figure", "confirm", "quick", "convergence", "gv", "show", "even", "after", "200m", "sample", "rand", "still", "several", "thousand", "triangle", "behind", "gv", "can", "conclude", "would", "take", "rand", "several", "order", "magnitude", "longer", "find", "pv", "GVS", "can", "find", "about", "7M", "8m", "sample", "finally", "bottom", "left", "figure", "prove", "PVS", "size", "correlate", "strongly", "average", "pixel", "error", "termination", "criterion", "discuss", "above", "work", "well", "practice", "bring", "average", "pixel", "error", "below", "30", "pixel", "1000x1000", "screen", "due", "better", "distribution", "initial", "sample", "rand", "show", "lower", "average", "pixel", "error", "phase", "where", "gv", "search", "mainly", "deterministically", "however", "reach", "same", "pixel", "error", "provide", "gv", "converged", "state", "rand", "have", "calculate", "similar", "number", "triangle", "PVS", "lead", "same", "observation", "before", "similar", "pixel", "error", "require", "order", "magnitude", "more", "sample", "than", "gv", "next", "we", "demonstrate", "finding", "generalize", "larger", "number", "scene", "provide", "practical", "analysis", "include", "run", "time", "Table", "summarize", "we", "finding", "we", "use", "same", "convergence", "criterion", "50", "triangle", "per", "1m", "sample", "gv", "constant", "150m", "ray", "rand", "can", "see", "result", "very", "similar", "average", "maximum", "error", "both", "algorithm", "however", "run", "time", "differ", "more", "than", "order", "magnitude", "which", "reflect", "good", "convergence", "behavior", "gv", "respect", "rand", "show", "above", "table", "also", "list", "result", "NIR", "which", "discuss", "follow", "subsection", "addition", "error", "we", "also", "give", "size", "pv", "term", "whole", "model", "size", "-lrb-", "ev", "available", "reasonable", "time", "-rrb-", "higher", "value", "mean", "more", "accurate", "solution", "512x512", "1024x1024", "resolution", "intrinsic", "parameter", "have", "adjust", "each", "scene", "obtain", "reasonable", "result", "-lrb-", "see", "comment", "section", "4.4", "-rrb-", "last", "column", "show", "average", "size", "calculate", "pv", "percentage", "whole", "model", "Nirenstein", "Blake", "-lsb-", "2004", "-rsb-", "recently", "publish", "interesting", "adaptive", "regular", "sampling", "algorithm", "which", "use", "graphic", "hardware", "adaptively", "sample", "hemi-cube", "view", "cell", "difficult", "directly", "compare", "NIR", "GVS", "one", "hand", "both", "base", "same", "atomic", "operation?taking", "visibility", "sample", "because", "sampling", "graphic", "hardware", "ray", "tracer", "functionally", "practically", "equivalent", "due", "available", "sub-pixel", "precision", "-lrb-", "usually", "12", "bit", "-rrb-", "current", "graphic", "hardware", "time", "complexity", "however", "differ", "significantly", "between", "two", "algorithm", "time", "complexity", "ray", "casting", "linear", "number", "ray", "due", "spatial", "datum", "structure", "logarithmic", "number", "object", "practice", "we", "have", "also", "observe", "strong", "dependence", "type", "scene", "implementation", "ray", "tracer", "which", "make", "general", "prediction", "scalability", "respect", "scene", "size", "very", "hard", "graphic", "hardware", "basic", "operation", "item-buffer", "render", "depend", "whether", "particular", "view", "mostly", "fill", "geometry", "limited", "resolution", "item", "buffer", "have", "more", "less", "impact", "render", "time", "we", "implementation", "NIR", "render", "model", "from", "multiple", "vertex", "buffer", "store", "directly", "video", "memory", "which", "provide", "triangle", "throughput", "near", "theoretical", "maximum", "card", "we", "use", "-lrb-", "between", "130", "190m", "triangles/s", "depend", "how", "many", "vertex", "be", "share", "model?note", "some", "vertex", "have", "duplicated", "allow", "item", "buffer", "rendering", "-rrb-", "only", "CANYON", "model", "do", "we", "observe", "fill", "rate", "limitation", "-lrb-", "vs.", "12", "hemicubes/s", "512", "vs.", "1024", "resolution", "-rrb-", "whereas", "city", "pplant", "be", "geometry", "limited", "-lrb-", "hemicubes/s", "-rrb-", "efficient", "acceleration", "algorithm", "exist", "both", "architecture", "certain", "amount", "preprocessing", "tolerate", "particular", "importance", "visibility", "processing", "complexity", "scene", "can", "handle", "ray", "trace", "limit", "only", "available", "storage", "space", "ray", "caster", "can", "work", "efficiently", "out", "core", "-lrb-", "e.g.", "Wald", "et", "al.", "-lsb-", "2004", "-rsb-", "have", "demonstrate", "350", "million", "polygon", "model", "can", "ray", "cast", "2-3", "frame", "per", "second", "-rrb-", "furthermore", "should", "point", "out", "rasterization", "benefit", "from", "hardware", "acceleration", "whereas", "ray", "trace", "still", "run", "software", "recent", "advance", "hardware", "ray", "trace", "-lsb-", "Woop", "et", "al.", "2005", "-rsb-", "promise", "huge", "po", "tential", "improve", "speed", "sampling-based", "algorithm", "like", "gv", "even", "further", "once", "technology", "become", "more", "commonplace", "however", "main", "difference", "between", "algorithm", "principal", "goal", "NIR", "aim", "increase", "render", "speed", "aggressively", "cull", "more", "object", "than", "actually", "occluded", "rationale", "be", "large", "gain", "render", "speed", "can", "obtain", "error", "final", "image", "tolerate", "indeed", "nir", "consistently", "underestimate", "pv", "show", "Table", "-lrb-", "note", "even", "error", "threshold", "significant", "rest-error", "report", "nir", "-lsb-", "nirenstein", "Blake", "2004", "-rsb-", "-rrb-", "while", "approach", "valuable", "application", "like", "quick", "preview", "etc.", "where", "resolution", "can", "fix", "average", "example", "1000", "false", "pixel", "tolerable", "many", "application", "require", "more", "accurate", "pv", "where", "GVS", "excel", "gv", "algorithm", "aim", "provide", "most", "accurate", "pv", "possible", "minimum", "number", "sample", "therefore", "performance", "metric", "gv", "total", "percentage", "culled", "object", "degree", "which", "actual", "pv", "can", "approximate", "we", "result", "show", "gv", "use", "limited", "number", "sample", "consistently", "find", "largest", "pv", "result", "average", "pixel", "error", "below", "0.005", "important", "any", "visualization", "application", "rely", "visibility", "preprocessing", "-lrb-", "especially", "antialiasing", "use", "output", "resolution", "fix", "advance", "-rrb-", "also", "number", "other", "application", "where", "reliable", "-lrb-", "practically", "exact", "-rrb-", "visibility", "require", "e.g.", "computational", "geometry", "gi", "robotic", "should", "note", "result", "Table", "NIR", "result", "derive", "through", "pv", "subdivision", "threshold", "which", "work", "differently", "from", "method", "use", "gv", "rand", "can", "therefore", "compare", "directly", "we", "find", "threshold", "very", "sensitive", "type", "scene", "have", "tune", "so", "lead", "excessive", "subdivision", "too", "early", "termination", "each", "scene", "separately", "-lrb-", "example", "once", "case", "error", "1024", "resolution", "significantly", "worse", "than", "512", "due", "premature", "termination", "-rrb-", "reason", "nir?s", "inability", "pick", "up", "complete", "pv", "lie", "both", "regular", "sampling", "strategy", "which", "force", "very", "fine", "subdivision", "view", "cell", "order", "pick", "up", "sub-pixel", "triangle", "thresholding", "adaptive", "subdivision", "which", "can", "prematurely", "terminate", "subdivision", "we", "compare", "we", "algorithm", "EXACT", "CUBES", "scene", "from", "view", "cell", "about", "1.5", "x1", ".5", "m.", "EXACT", "take", "19", "piv", "1.7", "GHz", "PC", "find", "3,743", "visible", "triangle", "find", "same", "number", "triangle", "gv", "require", "about", "3", "gv", "screenspace", "error", "0.001", "already", "report", "after", "2", "more", "interesting", "however", "fact", "both", "gv", "rand", "find", "significantly", "more", "visible", "triangle", "than", "EXACT", "give", "enough", "sample", "example", "3,850", "triangle", "be", "find", "after", "only", "15s", "gv", "note", "EXACT", "use", "basis?better", "result", "could", "certainly", "achieve", "tuning", "numerical", "threshold", "intrinsic", "method", "show", "clearly", "accuracy", "visibility", "algorithm", "even", "exact", "one", "ultimately", "limit", "numerical", "issue", "compare", "efficiency", "we", "algorithm", "previous", "work", "we", "use", "follow", "algorithm", "gv", "we", "guide", "visibility", "sampling", "algorithm", "adaptive", "border", "sampling", "-lrb-", "ab", "-rrb-", "reverse", "sampling", "-lrb-", "r", "-rrb-", "RAND", "random", "sampling", "-lrb-", "GVS", "value", "epsilon", "5e-5", "use", "enlarge", "triangle", "-rrb-", "we", "have", "dedicate", "separate", "subsection", "comparison", "nir", "main", "other", "exist", "visibility", "sampling", "method", "publish", "Nirenstein", "Blake", "-lsb-", "2004", "-rsb-", "-lrb-", "mainly", "because", "algorithm", "have", "slightly", "different", "goal", "than", "gv", "-rrb-", "EXACT", "Bittner?s", "-lsb-", "2003", "-rsb-", "exact", "visibility", "algorithm", "test", "scene", "select", "-lrb-", "see", "Figure", "Table", "-rrb-", "PPLANT", "complete", "UNC", "Power", "Plant", "model", "CITY", "city", "model", "ancient", "city", "Pompeii", "generate", "use", "cityengine", "-lsb-", "m?ller", "et", "al.", "2006", "-rsb-", "CANYON", "dataset", "Grand", "Canyon", "CUBES", "simple", "scene", "random", "cube", "test", "be", "conduct", "Intel", "pentium4", "3.2", "ghz", "4gb", "main", "memory", "graphic", "card", "NIR", "NVIDIA", "GeForce", "7900GTX", "512mb", "top", "left", "city", "top", "right", "CUBES", "bottom", "leave", "PPLANT", "bottom", "right", "CANYON", "Inlays", "view", "from", "view", "cell", "gv", "rand", "we", "use", "intel?s", "multi-level", "ray", "tracer", "-lrb-", "mlrta", "-lsb-", "Reshetov", "et", "al.", "2005", "-rsb-", "-rrb-", "which", "allow", "sampling", "rate", "between", "about", "800k/s", "1200k/s", "peak", "up", "several", "million", "samples/s", "sampling", "rate", "depend", "scene", "type", "-lrb-", "so", "much", "size?pplant", "have", "higher", "sampling", "rate", "than", "CANYON", "example", "-rrb-", "coherence", "ray", "-lrb-", "random", "sample", "ab", "sample", "be", "faster", "depend", "again", "scene", "-rrb-", "overhead", "sampling", "selection", "process", "vary", "between", "15", "depend", "relative", "distribution", "random", "ab", "r", "ray", "we", "first", "analyze", "theoretical", "property", "algorithm", "term", "sampling", "behavior", "i.e.", "sample-by-sample", "basis", "since", "only", "comparison", "do", "depend", "individual", "implementation", "since", "we", "do", "have", "exact", "visibility", "algorithm", "run", "reasonable", "time", "larger", "scene", "we", "can", "only", "study", "asymptotic", "behavior", "small", "number", "view", "cell", "Figure", "provide", "detailed", "analysis", "CANYON", "scene", "graph", "pixel", "error", "-lrb-", "calculate", "count", "false", "pixel", "large", "number", "random", "rendering", "-lsb-", "nirenstein", "Blake", "2004", "-rsb-", "-rrb-", "number", "triangle", "find", "over", "number", "sample", "gv", "rand", "top", "left", "image", "show", "gv", "converge", "linearly", "long", "deterministic", "strategy", "-lrb-", "ab", "r", "-rrb-", "can", "use", "most", "triangle", "black", "dot", "each", "view", "cell", "curve", "show", "when", "we", "termination", "criterion", "terminate", "pv", "search", "-lrb-", "we", "use", "50", "less", "new", "triangle", "find", "per", "1m", "sample", "-rrb-", "can", "see", "happen", "fairly", "well", "converged", "state", "already", "graph", "also", "show", "behavior", "very", "similar", "all", "view", "cell", "length", "linear", "segment", "only", "depend", "final", "pv", "size", "lower", "right", "image", "show", "blue", "view", "cell", "from", "other", "image", "top", "right", "figure", "show", "rand", "comparison", "convergence", "rand", "look", "mainly", "logarithmic", "have", "very", "quick", "falloff", "after", "initial", "strong", "phase", "especially", "noteworthy", "even", "15m", "sample", "when", "GVS", "have", "already", "long", "converge", "rand", "still", "50k", "triangle", "behind", "gv", "most", "view", "cell", "bottom", "right", "figure", "analyze", "behavior", "even", "larger", "scale", "dark", "blue", "view", "cell", "from", "other", "graph", "figure", "confirm", "quick", "convergence", "gv", "show", "even", "after", "200m", "sample", "rand", "still", "several", "thousand", "triangle", "behind", "gv", "can", "conclude", "would", "take", "rand", "several", "order", "magnitude", "longer", "find", "pv", "GVS", "can", "find", "about", "7M", "8m", "sample", "finally", "bottom", "left", "figure", "prove", "PVS", "size", "correlate", "strongly", "average", "pixel", "error", "termination", "criterion", "discuss", "above", "work", "well", "practice", "bring", "average", "pixel", "error", "below", "30", "pixel", "1000x1000", "screen", "due", "better", "distribution", "initial", "sample", "rand", "show", "lower", "average", "pixel", "error", "phase", "where", "gv", "search", "mainly", "deterministically", "however", "reach", "same", "pixel", "error", "provide", "gv", "converged", "state", "rand", "have", "calculate", "similar", "number", "triangle", "PVS", "lead", "same", "observation", "before", "similar", "pixel", "error", "require", "order", "magnitude", "more", "sample", "than", "gv", "next", "we", "demonstrate", "finding", "generalize", "larger", "number", "scene", "provide", "practical", "analysis", "include", "run", "time", "Table", "summarize", "we", "finding", "we", "use", "same", "convergence", "criterion", "50", "triangle", "per", "1m", "sample", "gv", "constant", "150m", "ray", "rand", "can", "see", "result", "very", "similar", "average", "maximum", "error", "both", "algorithm", "however", "run", "time", "differ", "more", "than", "order", "magnitude", "which", "reflect", "good", "convergence", "behavior", "gv", "respect", "rand", "show", "above", "table", "also", "list", "result", "NIR", "which", "discuss", "follow", "subsection", "addition", "error", "we", "also", "give", "size", "pv", "term", "whole", "model", "size", "-lrb-", "ev", "available", "reasonable", "time", "-rrb-", "higher", "value", "mean", "more", "accurate", "solution", "512x512", "1024x1024", "resolution", "intrinsic", "parameter", "have", "adjust", "each", "scene", "obtain", "reasonable", "result", "-lrb-", "see", "comment", "section", "4.4", "-rrb-", "last", "column", "show", "average", "size", "calculate", "pv", "percentage", "whole", "model", "Nirenstein", "Blake", "-lsb-", "2004", "-rsb-", "recently", "publish", "interesting", "adaptive", "regular", "sampling", "algorithm", "which", "use", "graphic", "hardware", "adaptively", "sample", "hemi-cube", "view", "cell", "difficult", "directly", "compare", "NIR", "GVS", "one", "hand", "both", "base", "same", "atomic", "operation?taking", "visibility", "sample", "because", "sampling", "graphic", "hardware", "ray", "tracer", "functionally", "practically", "equivalent", "due", "available", "sub-pixel", "precision", "-lrb-", "usually", "12", "bit", "-rrb-", "current", "graphic", "hardware", "time", "complexity", "however", "differ", "significantly", "between", "two", "algorithm", "time", "complexity", "ray", "casting", "linear", "number", "ray", "due", "spatial", "datum", "structure", "logarithmic", "number", "object", "practice", "we", "have", "also", "observe", "strong", "dependence", "type", "scene", "implementation", "ray", "tracer", "which", "make", "general", "prediction", "scalability", "respect", "scene", "size", "very", "hard", "graphic", "hardware", "basic", "operation", "item-buffer", "render", "depend", "whether", "particular", "view", "mostly", "fill", "geometry", "limited", "resolution", "item", "buffer", "have", "more", "less", "impact", "render", "time", "we", "implementation", "NIR", "render", "model", "from", "multiple", "vertex", "buffer", "store", "directly", "video", "memory", "which", "provide", "triangle", "throughput", "near", "theoretical", "maximum", "card", "we", "use", "-lrb-", "between", "130", "190m", "triangles/s", "depend", "how", "many", "vertex", "be", "share", "model?note", "some", "vertex", "have", "duplicated", "allow", "item", "buffer", "rendering", "-rrb-", "only", "CANYON", "model", "do", "we", "observe", "fill", "rate", "limitation", "-lrb-", "vs.", "12", "hemicubes/s", "512", "vs.", "1024", "resolution", "-rrb-", "whereas", "city", "pplant", "be", "geometry", "limited", "-lrb-", "hemicubes/s", "-rrb-", "efficient", "acceleration", "algorithm", "exist", "both", "architecture", "certain", "amount", "preprocessing", "tolerate", "particular", "importance", "visibility", "processing", "complexity", "scene", "can", "handle", "ray", "trace", "limit", "only", "available", "storage", "space", "ray", "caster", "can", "work", "efficiently", "out", "core", "-lrb-", "e.g.", "Wald", "et", "al.", "-lsb-", "2004", "-rsb-", "have", "demonstrate", "350", "million", "polygon", "model", "can", "ray", "cast", "2-3", "frame", "per", "second", "-rrb-", "furthermore", "should", "point", "out", "rasterization", "benefit", "from", "hardware", "acceleration", "whereas", "ray", "trace", "still", "run", "software", "recent", "advance", "hardware", "ray", "trace", "-lsb-", "Woop", "et", "al.", "2005", "-rsb-", "promise", "huge", "po", "tential", "improve", "speed", "sampling-based", "algorithm", "like", "gv", "even", "further", "once", "technology", "become", "more", "commonplace", "however", "main", "difference", "between", "algorithm", "principal", "goal", "NIR", "aim", "increase", "render", "speed", "aggressively", "cull", "more", "object", "than", "actually", "occluded", "rationale", "be", "large", "gain", "render", "speed", "can", "obtain", "error", "final", "image", "tolerate", "indeed", "nir", "consistently", "underestimate", "pv", "show", "Table", "-lrb-", "note", "even", "error", "threshold", "significant", "rest-error", "report", "nir", "-lsb-", "nirenstein", "Blake", "2004", "-rsb-", "-rrb-", "while", "approach", "valuable", "application", "like", "quick", "preview", "etc.", "where", "resolution", "can", "fix", "average", "example", "1000", "false", "pixel", "tolerable", "many", "application", "require", "more", "accurate", "pv", "where", "GVS", "excel", "gv", "algorithm", "aim", "provide", "most", "accurate", "pv", "possible", "minimum", "number", "sample", "therefore", "performance", "metric", "gv", "total", "percentage", "culled", "object", "degree", "which", "actual", "pv", "can", "approximate", "we", "result", "show", "gv", "use", "limited", "number", "sample", "consistently", "find", "largest", "pv", "result", "average", "pixel", "error", "below", "0.005", "important", "any", "visualization", "application", "rely", "visibility", "preprocessing", "-lrb-", "especially", "antialiasing", "use", "output", "resolution", "fix", "advance", "-rrb-", "also", "number", "other", "application", "where", "reliable", "-lrb-", "practically", "exact", "-rrb-", "visibility", "require", "e.g.", "computational", "geometry", "gi", "robotic", "should", "note", "result", "Table", "NIR", "result", "derive", "through", "pv", "subdivision", "threshold", "which", "work", "differently", "from", "method", "use", "gv", "rand", "can", "therefore", "compare", "directly", "we", "find", "threshold", "very", "sensitive", "type", "scene", "have", "tune", "so", "lead", "excessive", "subdivision", "too", "early", "termination", "each", "scene", "separately", "-lrb-", "example", "once", "case", "error", "1024", "resolution", "significantly", "worse", "than", "512", "due", "premature", "termination", "-rrb-", "reason", "nir?s", "inability", "pick", "up", "complete", "pv", "lie", "both", "regular", "sampling", "strategy", "which", "force", "very", "fine", "subdivision", "view", "cell", "order", "pick", "up", "sub-pixel", "triangle", "thresholding", "adaptive", "subdivision", "which", "can", "prematurely", "terminate", "subdivision", "we", "compare", "we", "algorithm", "EXACT", "CUBES", "scene", "from", "view", "cell", "about", "1.5", "x1", ".5", "m.", "EXACT", "take", "19", "piv", "1.7", "GHz", "PC", "find", "3,743", "visible", "triangle", "find", "same", "number", "triangle", "gv", "require", "about", "3", "gv", "screenspace", "error", "0.001", "already", "report", "after", "2", "more", "interesting", "however", "fact", "both", "gv", "rand", "find", "significantly", "more", "visible", "triangle", "than", "EXACT", "give", "enough", "sample", "example", "3,850", "triangle", "be", "find", "after", "only", "15s", "gv", "note", "EXACT", "use", "basis?better", "result", "could", "certainly", "achieve", "tuning", "numerical", "threshold", "intrinsic", "method", "show", "clearly", "accuracy", "visibility", "algorithm", "even", "exact", "one", "ultimately", "limit", "numerical", "issue", "although", "guide", "visibility", "sampling", "generally", "find", "major", "part", "PVS", "very", "quickly", "fact", "stochastic", "one", "hand", "guide", "visibility", "scene", "other", "hand", "make", "final", "accuracy", "dependent", "structure", "scene", "therefore", "we", "can", "give", "any", "hard", "guarantee", "pixel", "error", "calculate", "pv", "also", "ability", "explore", "connected", "ray", "space", "subset", "far", "distance", "limit", "numerical", "precision", "ray", "direction", "vector", "ab", "mean", "triangle", "have", "solid", "angle", "less", "than", "double", "precision", "accuracy", "when", "see", "from", "ray", "origin", "most", "likely", "miss", "worst", "case", "scene", "complexity", "scene", "consist", "large", "set", "small", "disconnect", "triangle", "forest", "scene", "synthetic", "scene", "random", "triangle", "visibility", "scene", "so", "complex", "even", "sampling-based", "solution", "either", "have", "high", "error", "take", "long", "time", "compute", "still", "important", "point", "out", "sampling-based", "algorithm", "only", "one", "able", "even", "process", "scene", "respect", "avenue", "future", "work", "incorporate", "geometric", "lod", "sampling", "framework", "similar", "vlod", "system", "propose", "Chhugani", "et", "al.", "-lsb-", "2005", "-rsb-", "geometric", "lod", "could", "potentially", "increase", "speed", "ray", "tracer", "make", "intersection", "computation", "more", "robust", "because", "small", "triangle", "distance", "get", "replace", "larger", "one", "however", "robust", "geometric", "lod", "available", "all", "scene", "integrate", "lod", "ray", "tracer", "current", "topic", "research", "furthermore", "error", "metric", "use", "create", "lod", "impact", "accuracy", "visibility", "algorithm", "therefore", "usable", "output", "resolution", "we", "have", "present", "visibility", "sampling", "algorithm", "compute", "full", "3d", "visibility", "solution", "from", "region", "space", "propose", "algorithm", "improve", "efficiency", "previous", "sampling", "strategy", "over", "two", "order", "magnitude", "thereby", "allow", "visibility", "solution", "negligible", "error", "compute", "reasonable", "time", "propose", "algorithm", "work", "arbitrary", "so-called", "polygon", "soup", "do", "require", "any", "memory", "beyond", "use", "ray", "caster", "due", "new", "sampling", "strategy", "employ", "algorithm", "its", "accuracy", "competitive", "even", "exact", "conservative", "approach", "while", "also", "extremely", "simple", "implement", "we", "have", "provide", "evidence", "guided", "visibility", "sample", "close", "important", "gap", "visibility", "research", "combine", "speed", "ease", "implementation", "sampling-based", "special-purpose", "conservative", "algorithm", "most", "accuracy", "exact", "solution", "thus", "gv", "can", "use", "general", "purpose", "visibility", "tool" ],
  "content" : "To compare the efficiency of our algorithm to previous work, we use the following algorithms: GVS, our guided visibility sampling algorithm with adaptive border sampling (ABS) and reverse sampling (RS); and RAND, random sampling (in GVS, a value of epsilon of 5e-5 was used for enlarging triangles). We have dedicated separate subsections to the comparisons with NIR, the main other existing visibility sampling method published by Nirenstein and Blake [2004] (mainly because this algorithm has a slightly different goal than GVS); and EXACT, Bittner?s [2003] exact visibility algorithm. The test scenes selected are (see Figure 7 and Table 1 ): PPLANT, the complete UNC Power Plant model; CITY, a city model of the ancient city of Pompeii generated using the CityEngine [M?ller et al. 2006]; CANYON, a dataset of the Grand Canyon; and CUBES, a simple scene of random cubes. The tests were conducted on an Intel Pentium4 3.2GHz with 4GB of main memory. The graphics card for NIR was an NVIDIA GeForce 7900GTX 512MB. Top left: CITY. Top right: CUBES. Bottom left: PPLANT. Bottom right: CANYON. Inlays: view from a view cell. For GVS and RAND, we used Intel?s multi-level ray tracer (MLRTA [Reshetov et al. 2005]), which allowed sampling rates between about 800K/s and 1200K/s, with peaks up to several million samples/s. The sampling rate depends on the scene type (not so much on the size?PPLANT had a higher sampling rate than CANYON, for example), and on the coherence of the rays (with random samples and ABS samples being faster depending again on the scene). The overhead of the sampling selection process varied between 5 and 15%, depending on the relative distribution of random, ABS and RS rays. We first analyze the theoretical properties of the algorithms in terms of their sampling behavior, i.e., on a sample-by-sample basis, since this is the only comparison that does not depend on the individual implementation. Since we do not have an exact visibility algorithm that runs in reasonable time on larger scenes, we can only study their asymptotic behavior on a small number of view cells. Figure 8 provides a detailed analysis of the CANYON scene, graphing the pixel error (calculated by counting the false pixels in a large number of random renderings [Nirenstein and Blake 2004]) and the number of triangles found over the number of samples for GVS and RAND. The top left image shows that GVS converges linearly as long as the deterministic strategies (ABS and RS) can be used for most triangles. The black dot on each view cell curve shows when our termination criteria terminates the PVS search (we used 50 or less new triangles found per 1M samples). It can be seen that this happens in a fairly well converged state already. The graph also shows that the behavior is very similar for all view cells. The length of the linear segment only depends on the final PVS size. the lower right image show the blue view cell from the other images. The top right figure shows RAND in comparison. The convergence of RAND looks mainly logarithmic and has a very quick falloff after an initial strong phase. It is especially noteworthy that even at 15M samples, when GVS has already long converged, RAND is still 50K triangles behind GVS for most view cells. The bottom right figure analyzes this behavior on an even larger scale for the dark blue view cell from the other graphs. This figure confirms the quick convergence of GVS, and shows that even after 200M samples, RAND is still several thousand triangles behind GVS. It can be concluded that it would take RAND several orders of magnitude longer to find a PVS that GVS can find with about 7M to 8M samples. Finally, the bottom left figure proves that the PVS size correlates strongly to average pixel error, and that the termination criterion discussed above works well in practice, bringing the average pixel error below 30 pixels on a 1000x1000 screen. Due to the better distribution of initial samples, RAND shows lower average pixel error in the phase where GVS searches mainly deterministically. However, to reach the same pixel errors as provided by GVS in a converged state, RAND has to calculate a similar number of triangles in the PVS, leading to the same observation as before, that similar pixel error requires orders of magnitude more samples than with GVS. Next, we demonstrate that these findings generalize to a larger number of scenes, and provide a practical analysis including running times. Table 2 summarizes our findings. We used the same convergence criterion of 50 triangles per 1M samples for GVS, and a constant 150M rays for RAND. It can be seen that this results in very similar average and maximum errors for both algorithms. However, the running times differ by more than an order of magnitude, which reflects the good convergence behavior of GVS with respect to RAND shown above. The table also lists results for NIR, which are discussed in the following subsection. In addition to the error we also give the size of the PVS in terms of the whole model size (an EVS was not available in reasonable time). A higher value means a more accurate solution. 512x512 and 1024x1024 resolution. The intrinsic parameters had to be adjusted for each scene to obtain reasonable results (see the comments in Section 4.4). The last column shows the average size of the calculated PVS as a percentage of the whole model. Nirenstein and Blake [2004] recently published an interesting adaptive regular sampling algorithm which uses graphics hardware to adaptively sample hemi-cubes on the view cell. It is difficult to directly compare NIR and GVS. On the one hand, they are both based on the same atomic operation?taking a visibility sample. This is because sampling with graphics hardware and with a ray tracer is functionally practically equivalent due to the available sub-pixel precision (usually 12 bit) in current graphics hardware. The time complexity, however, differs significantly between the two algorithms. The time complexity of ray casting is linear in the number of rays and, due to spatial data structures, logarithmic in the number of objects. In practice, we have also observed a strong dependence on the type of the scene and the implementation of the ray tracer, which makes general predictions on the scalability with respect to scene size very hard. For graphics hardware, the basic operation is an item-buffer render. Depending on whether a particular view is mostly fill or geometry limited, the resolution of this item buffer has more or less impact on the rendering time. Our implementation of NIR rendered models from multiple vertex buffers stored directly in video memory, which provided triangle throughput near the theoretical maximum on the card we used (between 130 and 190M triangles/s, depending on how many vertices were shared in the model?note that some vertices had to be duplicated to allow item buffer rendering). Only on the CANYON model did we observe a fill rate limitation (9 vs. 12 hemicubes/s for 512 vs. 1024 resolutions), whereas CITY and PPLANT were geometry limited (7 and 2 hemicubes/s). Efficient acceleration algorithms exist for both architectures, if a certain amount of preprocessing is tolerated. Of particular importance for visibility processing is that the complexity of scenes that can be handled by ray tracing is limited only by the available storage space, as ray casters can work efficiently out of core (e.g., Wald et al. [2004] have demonstrated that a 350 million polygon model can be ray cast at 2-3 frames per second). Furthermore, it should be pointed out that rasterization benefits from hardware acceleration, whereas ray tracing is still run in software. Recent advances in hardware for ray tracing [Woop et al. 2005] promise a huge po tential for improving the speed of sampling-based algorithms like GVS even further, once this technology becomes more commonplace. However, the main difference between the algorithms is the principal goal. NIR aims to increase rendering speed by aggressively culling more objects than are actually occluded, the rationale being that large gains in rendering speed can be obtained if errors in the final image are tolerated. Indeed, NIR consistently underestimates the PVS, as shown in Table 2 (note that even for an error threshold of 0, a significant rest-error is reported for NIR [Nirenstein and Blake 2004]). While this approach is valuable for applications like quick previewing etc., where a resolution can be fixed, and an average of, for example, 1000 false pixels is tolerable, many applications require a more accurate PVS. This is where GVS excels. The GVS algorithm aims to provide the most accurate PVS possible with a minimum number of samples. Therefore, the performance metric for GVS is not the total percentage of culled objects, but the degree to which the actual PVS can be approximated. Our results show that GVS, using a limited number of samples, consistently finds the largest PVS, resulting in average pixel errors below 0.005%. This is important for any visualization application that relies on visibility preprocessing (especially if antialiasing is used or the output resolution is not fixed in advance), but also for a number of other applications where reliable (and practically exact) visibility is required, e.g., computational geometry, GI, and robotics. It should be noted for the results in Table 2 that NIR results are derived through a PVS subdivision threshold, which works differently from the method used in GVS and RAND and can therefore not be compared directly. We found that this threshold was very sensitive to the type of the scene and had to be tuned so as not to lead to excessive subdivision or too early termination in each scene separately (for example, in once case the error for the 1024 resolution was significantly worse than for 512, due to premature termination). The reason for NIR?s inability to pick up the complete PVS lies both in the regular sampling strategy, which forces a very fine subdivision on the view cell in order to pick up sub-pixel triangles, and in the thresholding for the adaptive subdivision, which can prematurely terminate the subdivision. We compared our algorithm to EXACT on the CUBES scene, from a view cell of about 1.5x1.5m. EXACT took 19s on a PIV 1.7GHz PC to find 3,743 visible triangles. To find the same number of triangles, GVS required about 3s. For GVS, a screenspace error of 0.001% was already reported after 2s. More interesting, however, is the fact that both GVS and RAND found significantly more visible triangles than EXACT if given enough samples. For example, 3,850 triangles were found after only 15s by GVS. Note that EXACT was used on an ?as is? basis?better results could certainly be achieved by tuning numerical thresholds intrinsic to the method. This shows clearly that the accuracy of visibility algorithms, even exact ones, is ultimately limited by numerical issues. To compare the efficiency of our algorithm to previous work, we use the following algorithms: GVS, our guided visibility sampling algorithm with adaptive border sampling (ABS) and reverse sampling (RS); and RAND, random sampling (in GVS, a value of epsilon of 5e-5 was used for enlarging triangles). We have dedicated separate subsections to the comparisons with NIR, the main other existing visibility sampling method published by Nirenstein and Blake [2004] (mainly because this algorithm has a slightly different goal than GVS); and EXACT, Bittner?s [2003] exact visibility algorithm. The test scenes selected are (see Figure 7 and Table 1 ): PPLANT, the complete UNC Power Plant model; CITY, a city model of the ancient city of Pompeii generated using the CityEngine [M?ller et al. 2006]; CANYON, a dataset of the Grand Canyon; and CUBES, a simple scene of random cubes. The tests were conducted on an Intel Pentium4 3.2GHz with 4GB of main memory. The graphics card for NIR was an NVIDIA GeForce 7900GTX 512MB. Top left: CITY. Top right: CUBES. Bottom left: PPLANT. Bottom right: CANYON. Inlays: view from a view cell. For GVS and RAND, we used Intel?s multi-level ray tracer (MLRTA [Reshetov et al. 2005]), which allowed sampling rates between about 800K/s and 1200K/s, with peaks up to several million samples/s. The sampling rate depends on the scene type (not so much on the size?PPLANT had a higher sampling rate than CANYON, for example), and on the coherence of the rays (with random samples and ABS samples being faster depending again on the scene). The overhead of the sampling selection process varied between 5 and 15%, depending on the relative distribution of random, ABS and RS rays. We first analyze the theoretical properties of the algorithms in terms of their sampling behavior, i.e., on a sample-by-sample basis, since this is the only comparison that does not depend on the individual implementation. Since we do not have an exact visibility algorithm that runs in reasonable time on larger scenes, we can only study their asymptotic behavior on a small number of view cells. Figure 8 provides a detailed analysis of the CANYON scene, graphing the pixel error (calculated by counting the false pixels in a large number of random renderings [Nirenstein and Blake 2004]) and the number of triangles found over the number of samples for GVS and RAND. The top left image shows that GVS converges linearly as long as the deterministic strategies (ABS and RS) can be used for most triangles. The black dot on each view cell curve shows when our termination criteria terminates the PVS search (we used 50 or less new triangles found per 1M samples). It can be seen that this happens in a fairly well converged state already. The graph also shows that the behavior is very similar for all view cells. The length of the linear segment only depends on the final PVS size. the lower right image show the blue view cell from the other images. The top right figure shows RAND in comparison. The convergence of RAND looks mainly logarithmic and has a very quick falloff after an initial strong phase. It is especially noteworthy that even at 15M samples, when GVS has already long converged, RAND is still 50K triangles behind GVS for most view cells. The bottom right figure analyzes this behavior on an even larger scale for the dark blue view cell from the other graphs. This figure confirms the quick convergence of GVS, and shows that even after 200M samples, RAND is still several thousand triangles behind GVS. It can be concluded that it would take RAND several orders of magnitude longer to find a PVS that GVS can find with about 7M to 8M samples. Finally, the bottom left figure proves that the PVS size correlates strongly to average pixel error, and that the termination criterion discussed above works well in practice, bringing the average pixel error below 30 pixels on a 1000x1000 screen. Due to the better distribution of initial samples, RAND shows lower average pixel error in the phase where GVS searches mainly deterministically. However, to reach the same pixel errors as provided by GVS in a converged state, RAND has to calculate a similar number of triangles in the PVS, leading to the same observation as before, that similar pixel error requires orders of magnitude more samples than with GVS. Next, we demonstrate that these findings generalize to a larger number of scenes, and provide a practical analysis including running times. Table 2 summarizes our findings. We used the same convergence criterion of 50 triangles per 1M samples for GVS, and a constant 150M rays for RAND. It can be seen that this results in very similar average and maximum errors for both algorithms. However, the running times differ by more than an order of magnitude, which reflects the good convergence behavior of GVS with respect to RAND shown above. The table also lists results for NIR, which are discussed in the following subsection. In addition to the error we also give the size of the PVS in terms of the whole model size (an EVS was not available in reasonable time). A higher value means a more accurate solution. 512x512 and 1024x1024 resolution. The intrinsic parameters had to be adjusted for each scene to obtain reasonable results (see the comments in Section 4.4). The last column shows the average size of the calculated PVS as a percentage of the whole model. Nirenstein and Blake [2004] recently published an interesting adaptive regular sampling algorithm which uses graphics hardware to adaptively sample hemi-cubes on the view cell. It is difficult to directly compare NIR and GVS. On the one hand, they are both based on the same atomic operation?taking a visibility sample. This is because sampling with graphics hardware and with a ray tracer is functionally practically equivalent due to the available sub-pixel precision (usually 12 bit) in current graphics hardware. The time complexity, however, differs significantly between the two algorithms. The time complexity of ray casting is linear in the number of rays and, due to spatial data structures, logarithmic in the number of objects. In practice, we have also observed a strong dependence on the type of the scene and the implementation of the ray tracer, which makes general predictions on the scalability with respect to scene size very hard. For graphics hardware, the basic operation is an item-buffer render. Depending on whether a particular view is mostly fill or geometry limited, the resolution of this item buffer has more or less impact on the rendering time. Our implementation of NIR rendered models from multiple vertex buffers stored directly in video memory, which provided triangle throughput near the theoretical maximum on the card we used (between 130 and 190M triangles/s, depending on how many vertices were shared in the model?note that some vertices had to be duplicated to allow item buffer rendering). Only on the CANYON model did we observe a fill rate limitation (9 vs. 12 hemicubes/s for 512 vs. 1024 resolutions), whereas CITY and PPLANT were geometry limited (7 and 2 hemicubes/s). Efficient acceleration algorithms exist for both architectures, if a certain amount of preprocessing is tolerated. Of particular importance for visibility processing is that the complexity of scenes that can be handled by ray tracing is limited only by the available storage space, as ray casters can work efficiently out of core (e.g., Wald et al. [2004] have demonstrated that a 350 million polygon model can be ray cast at 2-3 frames per second). Furthermore, it should be pointed out that rasterization benefits from hardware acceleration, whereas ray tracing is still run in software. Recent advances in hardware for ray tracing [Woop et al. 2005] promise a huge po tential for improving the speed of sampling-based algorithms like GVS even further, once this technology becomes more commonplace. However, the main difference between the algorithms is the principal goal. NIR aims to increase rendering speed by aggressively culling more objects than are actually occluded, the rationale being that large gains in rendering speed can be obtained if errors in the final image are tolerated. Indeed, NIR consistently underestimates the PVS, as shown in Table 2 (note that even for an error threshold of 0, a significant rest-error is reported for NIR [Nirenstein and Blake 2004]). While this approach is valuable for applications like quick previewing etc., where a resolution can be fixed, and an average of, for example, 1000 false pixels is tolerable, many applications require a more accurate PVS. This is where GVS excels. The GVS algorithm aims to provide the most accurate PVS possible with a minimum number of samples. Therefore, the performance metric for GVS is not the total percentage of culled objects, but the degree to which the actual PVS can be approximated. Our results show that GVS, using a limited number of samples, consistently finds the largest PVS, resulting in average pixel errors below 0.005%. This is important for any visualization application that relies on visibility preprocessing (especially if antialiasing is used or the output resolution is not fixed in advance), but also for a number of other applications where reliable (and practically exact) visibility is required, e.g., computational geometry, GI, and robotics. It should be noted for the results in Table 2 that NIR results are derived through a PVS subdivision threshold, which works differently from the method used in GVS and RAND and can therefore not be compared directly. We found that this threshold was very sensitive to the type of the scene and had to be tuned so as not to lead to excessive subdivision or too early termination in each scene separately (for example, in once case the error for the 1024 resolution was significantly worse than for 512, due to premature termination). The reason for NIR?s inability to pick up the complete PVS lies both in the regular sampling strategy, which forces a very fine subdivision on the view cell in order to pick up sub-pixel triangles, and in the thresholding for the adaptive subdivision, which can prematurely terminate the subdivision. We compared our algorithm to EXACT on the CUBES scene, from a view cell of about 1.5x1.5m. EXACT took 19s on a PIV 1.7GHz PC to find 3,743 visible triangles. To find the same number of triangles, GVS required about 3s. For GVS, a screenspace error of 0.001% was already reported after 2s. More interesting, however, is the fact that both GVS and RAND found significantly more visible triangles than EXACT if given enough samples. For example, 3,850 triangles were found after only 15s by GVS. Note that EXACT was used on an ?as is? basis?better results could certainly be achieved by tuning numerical thresholds intrinsic to the method. This shows clearly that the accuracy of visibility algorithms, even exact ones, is ultimately limited by numerical issues. Although guided visibility sampling generally finds the major part of the PVS very quickly, the fact that it is stochastic on the one hand and guided by the visibility in the scene on the other hand makes the final accuracy dependent on the structure of the scene. Therefore, we cannot give any hard guarantees for the pixel error of the calculated PVS. Also, the ability to explore connected ray space subsets in the far distance is limited by the numerical precision of the ray direction vector. For ABS, this means that triangles that have a solid angle of less than double precision accuracy when seen from the ray origin will most likely be missed. The worst case of scene complexity is in scenes that consist of a large set of small disconnected triangles, such as forest scenes or synthetic scenes of random triangles. The visibility of such scenes is so complex that even sampling-based solutions will either have high error or take a long time to compute. Still, it is important to point out that sampling-based algorithms are the only ones that are able to even process these scenes. In this respect, an avenue of future work is to incorporate geometric LOD into the sampling framework, similar to the vLOD system proposed by Chhugani et al. [2005]. Geometric LODs could potentially increase the speed of the ray tracer, and make intersection computations more robust because small triangles in the distance get replaced by larger ones. However, robust geometric LOD is not available for all scenes, and integrating LODs into ray tracers is a current topic of research. Furthermore, the error metric used to create the LODs impacts the accuracy of the visibility algorithm and therefore the usable output resolutions. We have presented a visibility sampling algorithm to compute a full 3D visibility solution from a region in space. The proposed algorithm improves the efficiency of previous sampling strategies by over two orders of magnitude, thereby allowing visibility solutions with negligible error to be computed in reasonable time. The proposed algorithm works on arbitrary so-called polygon soups and does not require any memory beyond that used by the ray caster. Due to the new sampling strategies employed in the algorithm, its accuracy is competitive even with exact and conservative approaches, while it is also extremely simple to implement. We have provided evidence that Guided Visibility Sampling closes an important gap in visibility research. It combines the speed and ease of implementation of sampling-based and special-purpose conservative algorithms with most of the accuracy of exact solutions. Thus, GVS can be used as a general purpose visibility tool.",
  "resources" : [ ]
}