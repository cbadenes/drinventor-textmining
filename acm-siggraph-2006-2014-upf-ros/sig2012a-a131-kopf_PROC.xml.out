{
  "uri" : "sig2012a-a131-kopf_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2012a/a131-kopf_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Quality Prediction for Image Completion",
    "published" : "2012",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Johannes-Kopf",
      "name" : "Johannes",
      "surname" : "Kopf"
    }, {
      "uri" : "http://drinventor/Wolf-Kienzle",
      "name" : "Wolf",
      "surname" : "Kienzle"
    }, {
      "uri" : "http://drinventor/Steven M.-Drucker",
      "name" : "Steven M.",
      "surname" : "Drucker"
    }, {
      "uri" : "http://drinventor/Sing Bing-Kang",
      "name" : "Sing Bing",
      "surname" : "Kang"
    } ]
  },
  "bagOfWords" : [ "addition", "extensive", "comparative", "result", "we", "run", "several", "user", "study", "validate", "we", "predictive", "feature", "good", "relative", "quality", "we", "result", "against", "those", "other", "state-of-the-art", "algorithm", "we", "automatic", "crop", "algorithm", "support", "prediction", "we", "design", "we", "image", "completion", "algorithm", "produce", "high", "quality", "result", "allow", "association", "between", "complete", "pixel", "know", "pixel", "create", "constraint", "allow", "we", "design", "simple", "method", "predict", "algorithm", "performance", "we", "test", "we", "algorithm", "extensive", "collection", "input", "image", "another", "user", "study", "compare", "we", "result", "those", "various", "state-of-the-art", "completion", "algorithm", "be", "able", "predict", "quality", "would", "allow", "system", "determine", "input", "image", "can", "properly", "restore", "edit", "we", "case", "estimate", "desire", "crop", "panorama", "difficult", "anticipate", "degree", "success", "failure", "within", "miss", "region", "we", "algorithm", "build", "non-parametric", "optimization", "algorithm", "introduce", "Wexler", "et", "al.", "-lsb-", "2007", "-rsb-", "we", "implement", "optimization", "describe", "paper", "use", "weighted", "average", "update", "rule", "-lrb-", "we", "do", "find", "necessary", "use", "much", "slower", "mean-shift", "base", "update", "rule", "-rrb-", "we", "describe", "more", "implementation", "detail", "algorithm", "supplementary", "document", "we", "bias", "we", "algorithm", "toward", "continue", "image", "content", "near", "boundary", "missing", "region", "each", "miss", "pixel", "may", "only", "fill", "from", "tightly", "constrain", "part", "known", "region", "low-level", "feature", "include", "color", "edge", "density", "edge", "orientation", "contour", "length", "region", "size", "we", "prediction", "function", "learn", "validate", "from", "datum", "we", "collect", "mechanical", "Turk", "user", "study", "where", "subject", "be", "ask", "categorize", "random", "patch", "from", "complete", "region", "good", "bad", "next", "section", "we", "review", "optimization", "framework", "we", "algorithm", "base", "describe", "we", "extension", "improve", "result", "quality", "make", "algorithm", "more", "predictable", "we", "algorithm", "minimize", "texture", "energy", "term", "which", "measure", "extent", "which", "synthesize", "region", "deviate", "from", "known", "region", "over", "set", "overlap", "local", "patch", "where", "set", "center", "pixel", "all", "patch", "completely", "contain", "within", "image", "domain", "overlap", "least", "one", "miss", "pixel", "image", "domain", "we", "mean", "minimum", "bound", "box", "contain", "panorama", "denote", "-lrb-", "target", "-rrb-", "patch", "center", "pixel", "-lrb-", "source", "-rrb-", "patch", "known", "region", "close", "appearance", "energy", "minimize", "iterative", "fashion", "alternate", "between", "minimize", "respect", "set", "while", "other", "set", "Input", "prediction", "-lrb-", "brighter", "higher", "quality", "-rrb-", "Adobe", "Photoshop", "CS5", "-lrb-", "Content", "Aware", "fill", "-rrb-", "minimize", "assignment", "require", "find", "nearest", "neighbor", "each", "synthesize", "patch", "task", "most", "compute-intensive", "require", "use", "approximative", "technique", "keep", "run", "time", "reasonable", "-lrb-", "we", "use", "PatchMatch", "algorithm", "-lsb-", "Barnes", "et", "al.", "2009", "-rsb-", "-rrb-", "minimize", "amount", "simple", "averaging", "overlap", "assignment", "we", "result", "compute", "coarse-to-fine", "fashion", "use", "image", "pyramid", "most", "successful", "application", "initialization", "already", "close", "final", "result", "image", "retargeting", "-lsb-", "Simakov", "et", "al.", "2008", "-rsb-", "use", "scale", "copy", "input", "while", "image", "reshuffling", "-lsb-", "Barnes", "et", "al.", "2009", "-rsb-", "from", "copy", "known", "region", "both", "case", "amount", "repair", "small", "plain", "image", "completion", "algorithm", "typically", "initialize", "randomly", "which", "make", "quality", "result", "hard", "predict", "other", "work", "search", "space", "constrain", "use", "simple", "heuristic", "P?rez", "et", "al.", "-lsb-", "2004", "-rsb-", "restrict", "source", "region", "band", "constant", "radius", "around", "missing", "region", "however", "simple", "solution", "we", "algorithm", "we", "algorithm", "automatic", "constraint", "problematic", "radius", "too", "small", "enough", "datum", "can", "sample", "effective", "completion", "which", "may", "result", "repetition", "radius", "too", "large", "result", "suffer", "from", "same", "problem", "observe", "unconstrained", "result", "figure", "Bornard", "et", "al.", "-lsb-", "2002", "-rsb-", "describe", "more", "localized", "heuristic", "while", "largely", "avoid", "problem", "select", "incorrect", "texture", "window", "still", "well", "adapt", "image", "content", "we", "experiment", "several", "superpixel", "algorithm", "include", "normalize", "cut", "-lsb-", "yu", "Shi", "2003", "-rsb-", "graph-based", "base", "segmentation", "-lsb-", "felzenszwalb", "Huttenlocher", "2004", "-rsb-", "three", "-lrb-", "non-disjunct", "-rrb-", "category", "tile", "boundary", "tile", "overlap", "touch", "known", "image", "boundary", "know", "tile", "contain", "least", "one", "known", "pixel", "miss", "tile", "contain", "least", "one", "miss", "pixel", "-lrb-", "figure", "3a", "-rrb-", "note", "each", "boundary", "tile", "also", "either", "know", "miss", "both", "next", "we", "associate", "each", "miss", "tile", "restriction", "region", "form", "union", "several", "overlap", "segment", "union", "contain", "segment", "all", "boundary", "tile", "within", "1.5", "time", "distance", "closest", "boundary", "tile", "we", "associate", "every", "pixel", "within", "miss", "tile", "restriction", "region", "tile", "algorithm", "have", "desire", "effect", "produce", "small", "restriction", "region", "near", "image", "boundary", "force", "completion", "continue", "semantic", "region", "whereas", "further", "away", "from", "boundary", "result", "larger", "restriction", "region", "give", "completion", "algorithm", "more", "freedom", "work", "both", "hole", "outside", "image", "-lrb-", "panorama", "-rrb-", "interior", "image", "algorithm", "illustrate", "Figure", "right", "compute", "homogeneous", "segment", "around", "boundary", "tile", "we", "consider", "tile", "four-connected", "grid", "graph", "we", "also", "try", "euclidean", "distance", "achieve", "slightly", "better", "result", "use", "EMD", "each", "boundary", "tile", "we", "compute", "shortest", "distance", "path", "every", "other", "tile", "use", "dijkstra?s", "algorithm", "we", "define", "segment", "union", "all", "tile", "whose", "distance", "smaller", "than", "threshold", "-lrb-", "distance", "between", "two", "bin", "EMD", "set", "-rrb-", "segment", "have", "fewer", "than", "32", "tile", "threshold", "automatically", "adjust", "select", "least", "32", "tile", "we", "conduct", "user", "study", "13", "participant", "-lrb-", "female", "10", "male", "-rrb-", "we", "test", "we", "algorithm", "against", "three", "competitor", "we", "algorithm", "without", "automatic", "search", "space", "constraint", "Adobe", "Photoshop", "CS5?s", "Content", "Aware", "fill", "resynthesizer", "popular", "plugin", "GIMP", "image", "editor", "mechanical", "Turk", "use", "because", "high", "resolution", "display", "requirement", "each", "participant", "present", "60", "pair", "image", "two", "monitor", "-lrb-", "each", "image", "show", "full", "24", "diagonal", "monitor", "-rrb-", "30", "image", "be", "panorama", "hole", "outside", "other", "30", "have", "hole", "interior", "image", "order", "pseudo-randomly", "varied", "each", "participant", "compare", "we", "algorithm", "against", "20", "example", "from", "each", "other", "technique", "result", "show", "Figure", "analysis", "between", "each", "condition", "indicate", "we", "algorithm", "significantly", "prefer", "over", "each", "other", "technique", "automatic", "search", "space", "constraint", "design", "part", "facilitate", "prediction", "quality", "section", "we", "describe", "how", "we", "generate", "prediction", "function", "map", "give", "miss", "pixel", "measure", "perceptual", "quality", "from", "set", "125", "complete", "panorama", "we", "randomly", "select", "64", "64", "square", "least", "half", "miss", "pixel", "mark", "they", "red", "bound", "box", "image", "we", "crop", "380", "380", "region", "around", "square", "provide", "visual", "context", "ask", "subject", "rate", "completion", "square", "either", "good", "bad", "we", "generate", "1,500", "batch", "twelve", "question", "each", "each", "batch", "contain", "ten", "real", "question", "two", "control", "question", "obvious", "answer", "control", "question", "enable", "we", "prune", "subject", "who", "be", "perform", "task", "properly", "common", "problem", "mechanical", "Turk", "subject", "consider", "invalid", "fewer", "than", "80", "control", "question", "be", "incorrectly", "answer", "after", "pruning", "we", "have", "66", "valid", "subject", "-lrb-", "down", "from", "117", "subject", "-rrb-", "generate", "total", "8,738", "good", "802", "bad", "label", "example", "complete", "region", "last", "two", "number", "suggest", "average", "user", "find", "about", "92", "we", "filled-in", "region", "good", "i.e.", "plausible-looking", "we", "use", "label", "datum", "learn", "function", "predict", "perceive", "quality", "complete", "miss", "region", "recall", "each", "miss", "pixel", "constrain", "come", "from", "certain", "restriction", "region", "compose", "union", "several", "homogeneous", "segment", "we", "prediction", "function", "learn", "correlation", "between", "perceive", "quality", "complete", "pixel", "some", "low-level", "feature", "segment", "comprise", "restriction", "region", "feature", "vector", "segment", "have", "follow", "component", "color", "histogram", "-lrb-", "separate", "each", "channel", "-rrb-", "edge", "density", "-lrb-", "percentage", "pixel", "edge", "pixel", "-rrb-", "edge", "orientation", "histogram", "histogram", "contour", "straight", "line", "length", "each", "histogram", "characterize", "its", "entropy", "mean", "standard", "deviation", "we", "provide", "additional", "implementation", "detail", "supplementary", "document", "where", "image", "coordinate", "miss", "pixel", "-lrb-", "normalize", "so", "each", "range", "between", "-rrb-", "its", "distance", "boundary", "nearest", "known", "region", "size", "segment", "area", "-lrb-", "typically", "smaller", "than", "can", "deduce", "from", "Figure", "-rrb-", "let", "label", "pixel", "-lrb-", "good", "bad", "-rrb-", "we", "use", "gentle", "adaboost", "-lsb-", "Friedman", "et", "al.", "2000", "-rsb-", "standard", "machine", "learn", "algorithm", "binary", "classification", "combine", "we", "feature", "vector", "scalar", "quality", "prediction", "which", "sum", "regression", "stump", "where", "denote", "th", "element", "feature", "vector", "which", "penalize", "positive", "value", "bad", "example", "negative", "value", "good", "example", "here", "denote", "set", "label", "training", "example", "number", "regression", "stump", "design", "parameter", "learning", "algorithm", "set", "empirically", "cross-validation", "we", "randomly", "split", "training", "datum", "five", "validation", "fold", "each", "fold", "learn", "prediction", "function", "use", "datum", "from", "remain", "four", "training", "fold", "average", "prediction", "performance", "five", "validation", "fold", "provide", "estimate", "generalization", "performance", "model", "we", "repeat", "process", "...", "128", "find", "performance", "increase", "until", "about", "32", "level", "off", "Figure", "illustrate", "effectiveness", "learn", "approach", "discriminative", "power", "we", "learn", "predictor", "higher", "than", "any", "feature", "take", "itself", "-lrb-", "individual", "element", "-rrb-", "aside", "we", "also", "test", "pixel-wise", "energy", "eq", "feature", "find", "poor", "quality", "predictor", "-lrb-", "auc", "0.53", "standard", "error", "0.006", "-rrb-", "compare", "we", "dedicated", "quality", "feature", "-lrb-", "eq", "auc", "0.77", "-rrb-", "please", "note", "evaluation", "all", "other", "result", "present", "here", "be", "compute", "image", "be", "part", "training", "set", "we", "show", "example", "we", "quality", "prediction", "throughout", "paper", "supplementary", "material", "quality", "prediction", "-lrb-", "-rrb-", "arbitrary", "unit", "make", "quality", "parameter", "we", "method", "more", "intuitive", "we", "transform", "quality", "prediction", "probability", "use", "platt?s", "method", "-lsb-", "1999", "-rsb-", "method", "construct", "sigmoid", "mapping", "from", "raw", "quality", "prediction", "-lrb-", "-rrb-", "estimate", "good", "bad", "label", "probability", "-lsb-", "-rsb-", "note", "since", "sum", "regression", "stump", "both", "real-valued", "piecewise", "constant", "very", "fast", "compute", "since", "require", "only", "32", "compare-add", "per", "pixel", "we", "use", "we", "prediction", "function", "compute", "optimal", "crop", "shape", "include", "many", "known", "pixel", "possible", "while", "avoid", "ing", "pixel", "predict", "low", "quality", "objective", "achieve", "solve", "optimization", "problem", "where", "denote", "region", "outside", "crop", "shape", "-lrb-", "-rrb-", "average", "predict", "quality", "inside", "crop", "shape", "-lrb-", "known", "pixel", "-rrb-", "solution", "minimize", "number", "exclude", "known", "pixel", "while", "ensure", "minimum", "average", "probability", "inside", "crop", "shape", "parameter", "balance", "between", "two", "high-level", "objective", "higher", "value", "lead", "more", "aggressive", "crop", "since", "less", "potentially", "low-quality", "area", "allow", "crop", "practice", "we", "find", "-lsb-", "0.99", "-rsb-", "reasonable", "range", "value", "value", "upper", "range", "because", "subject", "user", "study", "from", "section", "rate", "about", "9/10", "all", "sample", "good", "result", "relatively", "high", "everywhere", "Figure", "illustrate", "effect", "vary", "all", "other", "result", "paper", "supplementary", "material", "we", "set", "0.9925", "setting", "score", "best", "evaluation", "study", "describe", "below", "generally", "seem", "work", "well", "across", "wide", "range", "panorama", "-lrb-", "please", "refer", "result", "supplementary", "material", "-rrb-", "Figure", "illustrate", "how", "we", "crop", "optimization", "behave", "panorama", "predict", "mostly", "high", "mostly", "low", "quality", "while", "most", "commonly", "use", "shape", "rectangle", "formulation", "above", "support", "arbitrary", "parametric", "crop", "shape", "we", "have", "experiment", "various", "shape", "include", "trapezoid", "convex", "ngon", "ellipsis", "t-shape", "l-shape", "Figure", "show", "various", "result", "use", "general", "shape", "solve", "constrain", "optimization", "problem", "eq", "we", "first", "replace", "sequence", "unconstrained", "subproblem", "use", "logarithmic", "barrier", "method", "-lsb-", "nocedal", "Wright", "2000", "-rsb-", "instead", "solve", "eq", "we", "solve", "unconstrained", "combined", "objective/barrier", "problem", "minimizer", "eq", "approach", "solution", "eq", "we", "use", "Simplex", "algorithm", "-lsb-", "nelder", "mead", "1965", "-rsb-", "implement", "GNU", "scientific", "library", "-lsb-", "Galassi", "et", "al.", "2009", "-rsb-", "solve", "problem", "since", "objective", "function", "may", "contain", "local", "minimum", "we", "approximate", "global", "minimizer", "start", "optimization", "from", "100", "random", "initial", "state", "use", "best", "result", "we", "run", "user", "study", "involve", "13", "subject", "-lrb-", "10", "male", "female", "-rrb-", "evaluate", "we", "automatic", "crop", "technique", "each", "subject", "show", "20", "full", "panorama", "randomly", "select", "from", "subset", "50", "panorama", "high-resolution", "24", "monitor", "each", "panorama", "input", "prediction", "-lrb-", "brighter", "better", "-rrb-", "more", "aggressive", "crop", "input", "prediction", "crop", "follow", "-lrb-", "brighter", "higher", "quality", "-rrb-", "image", "completion", "we", "generate", "version", "full", "uncropped", "completion", "three", "autocrop", "0.9925", "0.9950", "0.9975", "conservative", "crop", "-lrb-", "i.e.", "maximum", "know", "region", "crop", "-rrb-", "we", "also", "add", "overcrop", "version", "eliminate", "known", "pixel", "help", "determine", "when", "subject", "be", "crop", "base", "frame", "judgement", "oppose", "noticeable", "artifact", "each", "set", "panorama", "original", "stitch", "photograph", "be", "first", "show", "subject", "subject", "could", "use", "left/right", "arrow", "key", "cycle", "through", "differently", "crop", "panorama", "subject", "be", "ask", "choose", "panorama", "would", "want", "share", "friend", "subject", "finish", "average", "7.5", "min", "-lrb-", "standard", "deviation", "2.67", "min", "-rrb-", "0.9975", "less", "aggressive", "crop", "0.9925", "input", "prediction", "crop", "follow", "-lrb-", "brighter", "higher", "quality", "-rrb-", "image", "completion", "result", "study", "show", "participant", "prefer", "some", "form", "guide", "crop", "52", "time", "use", "uncropped", "version", "35", "conservative", "crop", "only", "11.5", "time", "-lrb-", "see", "Figure", "leave", "-rrb-", "analysis", "show", "only", "part", "picture", "depend", "prediction", "distribution", "different", "crop", "choice", "may", "appear", "very", "similar", "example", "show", "figure", "where", "we", "smart", "crop", "almost", "same", "full", "image", "conservative", "crop", "respectively", "case", "arbitrary", "decision", "may", "make", "skewing", "result", "account", "issue", "we", "perform", "another", "analysis", "take", "account", "relative", "shape", "distance", "between", "different", "crop", "each", "crop", "version", "select", "user", "we", "compute", "symmetric", "hausdorff", "distance", "all", "available", "crop", "choice", "-lrb-", "normalize", "longer", "dimension", "image", "-rrb-", "Hausdorff", "distance", "commonly", "use", "shape", "similarity", "metric", "e.g.", "template", "matching", "computer", "vision", "application", "result", "analysis", "-lrb-", "blue", "bar", "Figure", "middle", "-rrb-", "show", "we", "guide", "crop", "have", "smallest", "average", "Hausdorff", "distance", "crop", "select", "subject", "show", "clear", "preference", "we", "guide", "crop", "over", "full", "image", "conservatively", "crop", "image", "we", "also", "compare", "various", "na?ve", "crop", "user", "choice", "-lrb-", "figure", "right", "-rrb-", "result", "red", "show", "average", "distance", "crop", "achieve", "interpolate", "crop", "shape", "between", "full", "conservative", "version", "result", "green", "be", "achieve", "use", "same", "optimization", "we", "result", "-lrb-", "use", "0.9925", "-rrb-", "use", "same", "constant", "quality", "value", "every", "miss", "pixel", "both", "case", "distance", "significantly", "higher", "-lrb-", "hence", "less", "desirable", "-rrb-", "than", "we", "best", "setting", "we", "test", "we", "algorithm", "several", "hundred", "panorama", "image", "hole", "interior", "supplementary", "material", "we", "show", "extensive", "comparison", "various", "state-of-the-art", "algorithm", "Input", "prediction", "-lrb-", "brighter", "higher", "quality", "-rrb-", "Adobe", "Photoshop", "CS5", "-lrb-", "Content", "Aware", "fill", "-rrb-", "input", "prediction", "-lrb-", "brighter", "higher", "quality", "-rrb-", "best", "-lrb-", "axis-aligned", "-rrb-", "rectangular", "crop", "best", "rotate", "rectangle", "best", "isosceles", "trapezoid", "-lrb-", "Adobe", "Photoshop", "CS5", "Content", "Aware", "fill", "GIMP", "Resynthesizer", "-lsb-", "Pritch", "et", "al.", "2009", "-rsb-", "-lsb-", "Komodakis", "Tziritas", "2007", "-rsb-", "-lsb-", "Criminisi", "et", "al.", "2003", "-rsb-", "-rrb-", "25", "representative", "sample", "from", "each", "class", "example", "show", "Figure", "10", "addition", "we", "show", "automatic", "crop", "result", "25", "panorama", "representative", "result", "show", "throughout", "paper", "we", "result", "-lrb-", "automatic", "crop", "show", "here", "-rrb-", "Komodakis", "Tziritas", "-lsb-", "2007", "-rsb-", "dual", "Intel", "Xeon", "E5640", "PC", "we", "observe", "follow", "median", "timing", "25", "panorama", "include", "supplementary", "material", "we", "believe", "number", "can", "reduce", "code", "optimization", "full", "completion", "auto-cropping", "restriction", "region", "0.32", "0.22", "feature", "extraction", "applicable", "0.93", "crop", "optimization", "applicable", "1.78", "Completion", "13.29", "6.52", "total", "13.70", "9.17", "panorama", "we", "automatic", "crop", "contain", "average", "slightly", "less", "than", "50", "miss", "pixel", "since", "completion", "algorithm", "runtime", "roughly", "linear", "number", "miss", "pixel", "lead", "significant", "speed-up", "compare", "first", "complete", "full", "panorama", "before", "crop", "image", "completion", "remain", "very", "challenging", "problem", "like", "other", "recent", "approach", "we", "algorithm", "lack", "higher-level", "-lrb-", "object-level", "-rrb-", "understanding", "input", "image", "thus", "occasion", "generate", "semantically", "implausible", "result", "although", "we", "source", "location", "restriction", "significantly", "reduce", "problem", "we", "crop", "optimization", "currently", "ignore", "scene", "context", "may", "crop", "out", "important", "object", "scene", "see", "Figure", "12", "fail", "realize", "importance", "two", "subject", "possible", "solution", "use", "face", "and/or", "saliency", "detector", "we", "prediction", "function", "fit", "perfect", "most", "likely", "due", "occasional", "mismatch", "subject", "rating", "training", "database", "result", "we", "prediction", "function", "would", "occasion", "mislabel", "miss", "region", "-lrb-", "e.g.", "Figure", "11", "where", "mislabeling", "result", "smaller", "crop", "-rrb-", "input", "prediction", "entire", "completion", "-lrb-", "brighter", "higher", "quality", "-rrb-", "input", "prediction", "crop", "completion", "-lrb-", "brighter", "higher", "quality", "-rrb-" ],
  "content" : "In addition to extensive comparative results, we ran several user studies validating our predictive feature, good relative quality of our results against those of other state-of-the-art algorithms, and our automatic cropping algorithm. To support this prediction, we design our image completion algorithm to produce high quality results and to allow associations between completed pixels and known pixels to be created. These constraints allow us to design a simple method to predict algorithm performance. We tested our algorithm on an extensive collection of input images, and in another user study, compared our results with those of various state-of-the-art completion algorithms. Being able to predict quality would allow the system to determine if the input image can be properly restored or edited, or in our case, estimate the desired crop of a panorama. It is difficult to anticipate the degree of success or failure within the missing regions. Our algorithm builds on the non-parametric optimization algorithm introduced by Wexler et al. [2007]. We implemented the optimization as described in that paper using the weighted average updating rule (we did not find it necessary to use the much slower mean-shift based updating rule). We describe more implementation details of the algorithm in a supplementary document. We bias our algorithm toward continuing image content near the boundary into the missing region. Each missing pixel may only be filled from a tightly constrained part of the known region. The low-level features include color, edge density, edge orientation, contour length, and region size. Our prediction function is learnt and validated from data that we collected in a Mechanical Turk user study, where subjects were asked to categorize random patches from the completed regions as ?good? or ?bad?. In the next section, we review the optimization framework that our algorithm is based on and then describe our extension that improves the result quality and makes the algorithm more predictable. Our algorithm minimizes a ?texture energy? term which measures the extent to which the synthesized region deviates from the known region over a set of overlapping local patches. where ? is the set of center pixels of all 7?7 patches that are completely contained within the image domain and overlap at least one missing pixel. By ?image domain,? we mean the minimum bounding box containing the panorama. t i denotes a (target) patch centered at pixel i, and s i is a (source) patch in the known region K that is close in appearance to t i . The energy is minimized in an iterative fashion, alternating between minimizing with respect to set of t i or s i while the other set is Input and prediction (brighter is higher quality) Adobe Photoshop CS5 (Content Aware Fill) Minimizing the s i assignments requires finding the nearest neighbor for each synthesized patch t i . This task is the most compute-intensive, and requires using approximative techniques to keep the run time reasonable (we use the PatchMatch algorithm [Barnes et al. 2009]). Minimizing t i amounts to a simple averaging of the overlapping s i assignments. Our results are computed in a coarse-to-fine fashion using an image pyramid. The most successful applications start with initializations that are already close to the final result: image retargeting [Simakov et al. 2008] uses a scaled copy of the input, while image reshuffling [Barnes et al. 2009] starts from a copied known region. In both cases, the amount of repair is small. For plain image completion the algorithm is typically initialized randomly, which makes the quality of the results hard to predict. In other works, the search space is constrained using simple heuristics. P?rez et al. [2004] restrict the source region to a band of constant radius around the missing region. However, this simple solution\n          Our algorithm Our Algorithm with automatic constraints\n        is problematic: if the radius is too small, not enough data can be sampled for effective completion, which may result in repetitions; if the radius is too large, the results will suffer from the same problems as observed in the unconstrained result in Figure 2 . Bornard et al. [2002] describe a more localized heuristic. While this largely avoids the problem of selecting incorrect textures the windows are still not well adapted to the image content. We experimented with several superpixel algorithms including normalized cuts [Yu and Shi 2003] and graph-based based segmentation [Felzenszwalb and Huttenlocher 2004]. There are three (non-disjunct) categories of tiles: boundary tiles overlap or touch the known image boundary, known tiles contain at least one known pixel, and missing tiles contain at least one missing pixel ( Figure 3a ). Note that each boundary tile is also either ?known?, ?missing?, or both. Next, we associate with each missing tile a restriction region that is formed as the union of several overlapping segments. This union contains the segments of all boundary tiles within 1.5 times the distance of the closest boundary tile. We associate every pixel within a missing tile with the restriction region of that tile. This algorithm has the desired effect of producing small restriction regions near to the image boundary, forcing the completion to continue semantic regions, whereas further away from the boundary it results in larger restriction regions giving the completion algorithm more freedom. It works both for holes on the outside of the image (panoramas) and in the interior of the image. The algorithm is illustrated in Figure 3 , right. For computing the homogeneous segments around boundary tiles, we consider the tiles as a four-connected grid graph. We also tried ? 2 and Euclidean distance but achieved slightly better results using EMD. For each boundary tile, we compute the shortest distance path to every other tile using Dijkstra?s algorithm. We define the segment as the union of all tiles whose distance is smaller than the threshold ? = 5 (the distance between two bins in the EMD is set to 1). If the segment has fewer than 32 tiles, the threshold is automatically adjusted to select at least 32 tiles. We conducted a user study with 13 participants (3 female and 10 male). We tested our algorithm against three competitors: our algorithm without automatic search space constraints, Adobe Photoshop CS5?s Content Aware Fill, and Resynthesizer 2 , a popular plugin for the GIMP image editor. Mechanical Turk was not used because of the high resolution display requirement. Each participant was presented with 60 pairs of images on two monitors (each image was shown on a full 24? diagonal monitor). 30 of these images were panoramas with holes on the outside, and the other 30 had holes in the interior of the image. The ordering was pseudo-randomly varied such that each participant compared our algorithm against 20 examples from each of the other techniques. Results are shown in Figure 4 . A ? 2 analysis between each condition indicates that our algorithm was significantly preferred over each of the other techniques. The automatic search space constraints are designed in part to facilitate prediction of quality. In this section, we describe how we generate the prediction function that maps a given missing pixel to a measure of perceptual quality. From a set of 125 completed panoramas, we randomly selected 64?64 squares with at least half missing pixels and marked them with red bounding boxes in the image. We cropped 380?380 regions around the squares to provide visual context and asked subjects to rate the completion in the square as either ?good? or ?bad?. We generated 1,500 batches with twelve questions each. Each batch contained ten real questions and two control questions with obvious answers. These control questions enabled us to prune subjects who were not performing the task properly, a common problem on Mechanical Turk. A subject is considered invalid if fewer than 80% of the control questions were incorrectly answered. After pruning, we have 66 valid subjects (down from 117 subjects), generating a total of 8,738 ?good? and 802 ?bad? labeled examples of completed regions. The last two numbers suggest that, on average, users will find about 92% of our filled-in regions ?good?, i.e., plausible-looking. We use the labeled data to learn a function that predicts the perceived quality of a completed missing region. Recall that each missing pixel i is constrained to come from a certain restriction region R i = S j , composed as the union of several homogeneous segments S j . Our prediction function learns the correlation between the perceived quality of a completed pixel and some low-level features of the segments comprising the restriction region. The feature vector u j of a segment S j has the following components: color histograms (separate for each channel), edge density (percentage of pixels that are edge pixels), edge orientation histogram, and histograms of contour and straight line lengths. Each histogram is characterized by its entropy, mean, and standard deviation. We provide additional implementation details in a supplementary document. where x i , y i are the image coordinates of the missing pixel (normalized so that each ranges between 0 and 1), d i is its distance to the boundary of the nearest known region, a j is the size of segment j, and b i is the area of R i (typically smaller than j a j , as can be deduced from Figure 3 ). Let t i be the label of pixel i (?good? = 1 or ?bad? = ?1). We use Gentle AdaBoost [Friedman et al. 2000], a standard machine learning algorithm for binary classification, to combine our feature vector into a scalar quality prediction. which is a sum of m regression stumps e where v i e k denotes the e k th element of the feature vector v i . which penalizes positive values of f on ?bad? examples and negative values on ?good? that examples. Here, T denotes the set of labeled training examples. The number of regression stumps m is a design parameter of the learning algorithm. It is set empirically by cross-validation: we randomly split the training data into five validation folds, and then for each fold learn a prediction function using the data from the remaining four training folds. The average prediction performance on the five validation folds provides an estimate of the generalization performance of the model. We repeated this process for m = 1, . . . , 128 and found that the performance increased with m until about m = 32, and then leveled off. Figure 5 illustrates the effectiveness of the learning approach. The discriminative power of our learned predictor f is higher than any feature taken by itself (the individual elements of v i ). As an aside, we also tested the pixel-wise energy Eq. 1 as a feature, but found it to be a poor quality predictor (AUC = 0.53, standard error: 0.006) compared to our dedicated quality features (Eq. 2, AUC = 0.77). Please note that this evaluation and all other results presented here were computed on images that were not part of the training set. We show examples of our quality prediction throughout the paper and in the supplementary material. The quality predictions f (v i ) are in arbitrary units. To make the quality parameter in our method more intuitive, we transform the quality predictions into probabilities using Platt?s method [1999]. This method constructs a sigmoid mapping from the raw quality predictions f (v i ) to estimates of ?good? or ?bad? label probabilities, p i ? [0; 1]. Note that since f is a sum of regression stumps both f and p i are real-valued and piecewise constant. p i is very fast to compute, since it requires only m = 32 compare-adds per pixel. We use our prediction function to compute an optimal crop shape C that includes as many of the known pixels as possible while avoid ing pixels that are predicted as low quality. These objectives are achieved by solving the optimization problem where C denotes the region outside the crop shape, and ? p (C) is the average predicted quality inside the crop shape (p i = 1 for known pixels). The solution minimizes the number of excluded known pixels while ensuring a minimum average probability ? p inside the crop shape. The parameter ? p balances between the two high-level objectives: higher values lead to more aggressive crops, since less potentially low-quality areas are allowed in the crop. In practice, we found ? p ? [0.99, 1] to be a reasonable range of values. The values for ? p are in the upper range because the subjects of the user study from Section 5 rated about 9/10 of all samples ?good?, resulting in relatively high p i ?s everywhere. Figure 6 illustrates the effect of varying ? p . For all other results in this paper and in the supplementary materials we set ? p = 0.9925, the setting that scored best in the evaluation study described below and generally seems to work well across a wide range of panoramas (please refer to the results in the supplementary material). Figure 7 illustrates how our cropping optimization behaves on panoramas that are predicted mostly high or mostly low quality. While the most commonly used shape is a rectangle, the formulation above supports arbitrary parametric crop shapes. We have experimented with various shapes including trapezoids, convex ngons, ellipses, T-shapes, and L-shapes. Figure 9 shows various results using general shapes. To solve the constrained optimization problem in Eq. 6, we first replace it with a sequence of unconstrained subproblems using the logarithmic barrier method [Nocedal and Wright 2000]. Instead of solving Eq. 6, we solve the unconstrained combined objective/barrier problem The minimizer of Eq. 7 approaches the solution of Eq. 6 as ? ? 0. We use the Simplex algorithm [Nelder and Mead 1965] as implemented in the GNU scientific library [Galassi et al. 2009] to solve this problem. Since the objective function may contain local minima, we approximate the global minimizer by starting the optimization from 100 random initial states and use the best result. We ran a user study involving 13 subjects (10 males and 3 females) to evaluate our automatic cropping technique. Each subject was shown 20 full panoramas randomly selected from a subset of 50 panoramas on a high-resolution 24? monitor. For each panorama, Input and prediction (brighter is better) More aggressive crop, Input and prediction Cropped followed by (brighter is higher quality) image completion we generated 5 versions: the full uncropped completion, three autocrops with ? p = 0.9925, 0.9950, 0.9975, and a conservative crop (i.e., maximum known region crop). We also added an overcropped version that eliminated known pixels to help determine when subjects were cropping based on framing judgements as opposed to noticeable artifacts. For each set of panoramas, the original stitched photographs were first shown to the subject and subjects could use the left/right arrow keys to cycle through the differently cropped panoramas. Subjects were asked to choose a panorama that they would want to share with friends. Subjects finished on average in 7.5 mins (standard deviation of 2.67 mins). ? p = 0.9975 Less aggressive crop, ? p = 0.9925\n          Input and prediction Cropped followed by (brighter is higher quality) image completion\n          The results of the study showed that participants preferred some form of guided cropping 52% of the time. They used the uncropped version 35% and the conservative cropping only 11.5% of the time (see Figure 8 , left). This analysis shows only part of the picture; depending on the prediction distribution, different crop choices may appear to be very similar. Such examples are shown in Figure 7 , where our smart cropping is almost the same as the full image and conservative crop, respectively. In such cases, arbitrary decisions may be made, skewing the results. To account for this issue, we performed another analysis that takes into account the relative shape distances between different crops. For each crop version selected by a user, we compute the symmetric Hausdorff distance to all available crop choices (normalized by the longer dimension of the image). The Hausdorff distance is a commonly used shape similarity metric, e.g., for template matching in computer vision applications. The results of this analysis (blue bars in Figure 8 , middle) show that our guided crops have the smallest average Hausdorff distances to the crops selected by the subjects. This shows a clear preference for our guided crops over the full image or conservatively cropped images. We also compare various na?ve crops to the user choices ( Figure 8 , right). The results in red show the average distances of crops achieved by interpolating the crop shapes between the full and conservative versions. The results in green were achieved using the same optimization as our results (using ? p = 0.9925), but using the same constant quality value for every missing pixel. For both cases, the distances are significantly higher (and hence less desirable) than for our best setting. We tested our algorithm on several hundred panoramas and images with holes in the interior. In the supplementary material, we show an extensive comparison to various state-of-the-art algorithms Input and prediction (brighter is higher quality) Adobe Photoshop CS5 (Content Aware Fill) Input and prediction (brighter is higher quality) Best (axis-aligned) rectangular crops Best rotated rectangle Best isosceles trapezoid (Adobe Photoshop CS5 Content Aware Fill, GIMP Resynthesizer, [Pritch et al. 2009], [Komodakis and Tziritas 2007], [Criminisi et al. 2003]) on 25 representative samples from each class. An example is shown in Figure 10 . In addition, we show automatic cropping results for the 25 panoramas; representative results are shown throughout the paper. Our result (automatic crop not shown here)\n        Komodakis and Tziritas [2007]\n        On a dual Intel Xeon E5640 PC, we observe the following median timings for the 25 panoramas included in the supplementary material. We believe these numbers can be reduced with code optimization. Full completion With auto-cropping Restriction regions 0.32s 0.22s Feature extraction not applicable 0.93s Crop optimization not applicable 1.78s Completion 13.29s 6.52s Total 13.70s 9.17s  For these panoramas, our automatic crops contain on average slightly less than 50% of the missing pixels. Since the completion algorithm runtime is roughly linear in the number of missing pixels, this leads to a significant speed-up compared to first completing the full panoramas before cropping. Image completion remains a very challenging problem. Like other recent approaches, our algorithm lacks higher-level (object-level) understanding of the input image. Thus, it will on occasion generate semantically implausible results, although our source location restriction significantly reduces these problems. Our cropping optimization currently ignores scene context and may crop out important objects in the scene. As seen in Figure 12 , it fails to realize the importance of the two subjects. A possible solution is to use face and/or saliency detectors. Our prediction function fit is not perfect, most likely due to occasional mismatches in subject ratings in the training database. As a result, our prediction function would, on occasion, mislabel the missing regions (e.g., Figure 11 , where mislabeling resulted in a smaller crop). Input and prediction Entire completion (brighter is higher quality) Input and prediction Cropped completion (brighter is higher quality)",
  "resources" : [ ]
}