{
  "uri" : "sig2007-a5-cooper_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2007/a5-cooper_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Active Learning for Real-Time Motion Controllers",
    "published" : "2007",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Seth-Cooper",
      "name" : "Seth",
      "surname" : "Cooper"
    }, {
      "uri" : "http://drinventor/Aaron-Hertzmann",
      "name" : "Aaron",
      "surname" : "Hertzmann"
    }, {
      "uri" : "http://drinventor/Zoran-Popovic",
      "name" : "Zoran",
      "surname" : "Popovic"
    } ]
  },
  "bagOfWords" : [ "kinematic", "character", "controller", "build", "on-the-fly", "during", "capture", "session", "update", "after", "each", "new", "motion", "clip", "acquire", "cr", "category", "i.", "3.7", "-lsb-", "Computer", "Graphics", "-rsb-", "three-dimensional", "graphic", "realism?animation", "Keywords", "Motion", "Capture", "human", "Motion", "active", "Learning", "we", "controller", "kinematic", "produce", "character?s", "motion", "interpolate", "motion", "capture", "rather", "than", "produce", "motion", "dynamically", "through", "force", "torque", "because", "space", "structure", "nearby", "motion", "space", "can", "often", "interpolate", "produce", "valid", "new", "motion", "selection", "which", "motion", "capture", "should", "greatly", "reduce", "number", "sample", "need", "task", "present", "user", "candidate", "additional", "datum", "sample", "key", "contribution", "work", "use", "active", "learning", "method", "animation", "produce", "compact", "controller", "complex", "task", "common", "theme", "computer", "animation", "research", "create", "new", "motion", "from", "exist", "motion", "capture", "datum", "most", "method", "create", "animation", "off-line", "example", "interpolate", "similar", "set", "motion", "accord", "user-specified", "control", "parameter", "-lsb-", "Witkin", "Popovi", "1995", "Kovar", "Gleicher", "2004", "Mukai", "Kuriyama", "2005", "Rose", "et", "al.", "1998", "Wiley", "Hahn", "1997", "-rsb-", "optimize", "motion", "accord", "probabilistic", "time-series", "model", "-lsb-", "brand", "hertzmann", "2000", "Li", "et", "al.", "2002", "-rsb-", "concatenate", "blend", "example", "sequence", "-lsb-", "Arikan", "et", "al.", "2003", "Kovar", "et", "al.", "2002", "Torresani", "et", "al.", "2007", "-rsb-", "combine", "modeland", "data-driven", "technique", "-lsb-", "Yamane", "et", "al.", "2004", "Zordan", "et", "al.", "2005", "Liu", "Popovi", "2002", "Liu", "et", "al.", "2005", "-rsb-", "method", "generate", "motion", "off-line", "whereas", "we", "consider", "problem", "real-time", "synthesis", "Reitsma", "Pollard", "-lsb-", "2004", "-rsb-", "present", "method", "evaluate", "possible", "motion", "generate", "approach", "Park", "et", "al.", "-lsb-", "2004", "-rsb-", "Kwon", "Shin", "-lsb-", "2005", "-rsb-", "combine", "interpolation", "motion", "graph", "structure", "generate", "new", "locomotion", "sequence", "statistics", "optimal", "experimental", "design", "method", "seek", "most", "informative", "test", "point", "estimate", "unknown", "nonlinear", "function", "-lsb-", "Atkinson", "Donev", "1992", "Santner", "et", "al.", "2003", "-rsb-", "however", "often", "possible", "determine", "advance", "which", "region", "input", "space", "need", "most", "datum", "active", "learning", "method", "select", "test", "datum", "sequentially", "after", "each", "datum", "point", "acquire", "next", "test", "point", "choose", "maximize", "objective", "function", "-lsb-", "Cohn", "et", "al.", "1994", "-rsb-", "active", "learning", "have", "be", "study", "most", "extensively", "classification", "problem", "-lrb-", "e.g.", "-lsb-", "Lindenbaum", "et", "al.", "2004", "-rsb-", "-rrb-", "example", "catch", "controller", "consist", "two", "task", "one", "catch", "ball", "come", "give", "speed", "direction", "idle", "controller", "invoke", "when", "ball", "catch", "order", "compare", "blend", "visualize", "motion", "translationand", "rotationinvariant", "way", "we", "decouple", "each", "pose", "from", "its", "translation", "ground", "plane", "rotation", "its", "hip", "about", "up", "axis", "ik", "controller", "ik", "define", "term", "simple", "blend", "controller", "ik", "-lrb-", "-rrb-", "ik", "-lrb-", "-lrb-", "-rrb-", "-rrb-", "however", "formal", "guarantee", "how", "controller", "perform", "new", "task", "where", "index", "over", "element", "control", "vector", "cubic", "profile", "curve", "??", "scale", "factor", "after", "weight", "produce", "function", "clamp", "range", "-lsb-", "-rsb-", "normalize", "sum", "each", "time", "new", "example", "datum", "point", "-lrb-", "-rrb-", "provide", "we", "solve", "linear", "weight", "use", "least", "square", "system", "first", "attempt", "improve", "performance", "select", "task", "generate", "new", "motion", "call", "pseudoexample", "-lsb-", "Sloan", "et", "al.", "2001", "-rsb-", "pseudoexample", "can", "represent", "directly", "term", "weight", "use", "generate", "motion", "incoming", "height", "from", "0.25", "2.0", "meter", "distance", "front", "character", "aim", "from", "0.25", "1.0", "meter", "incoming", "angle", "from", "??", "radian", "incoming", "height", "from", "0.5", "2.0", "meter", "distance", "right", "character", "from", "-2.0", "2.0", "meter", "incoming", "speed", "from", "0.1", "0.2", "meter", "per", "frame", "be", "ask", "define", "blend-space", "cluster", "determine", "compact", "number", "sample", "best", "cover", "controller", "space" ],
  "content" : "A kinematic character controller is built on-the-fly during a capture session, and updated after each new motion clip is acquired. CR Categories: I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism?Animation; Keywords: Motion Capture, Human Motion, Active Learning Our controllers are kinematic: they produce the character?s motion by interpolating motion capture, rather than producing motion dynamically through forces and torques. Because the space is structured ? that is, nearby motions in the space can often be interpolated to produce valid new motions ? selection of which motions to capture should greatly reduce the number of samples needed. These tasks are presented to the user as candidates for additional data samples. A key contribution of this work is the use of an active learning method for animation that produces compact controllers for complex tasks. A common theme in computer animation research is to create new motion from existing motion capture data. Most methods create animation off-line, for example, by interpolating a similar set of motions according to user-specified control parameters [Witkin and Popovi? 1995; Kovar and Gleicher 2004; Mukai and Kuriyama 2005; Rose et al. 1998; Wiley and Hahn 1997], by optimizing motion according to probabilistic time-series models [Brand and Hertzmann 2000; Li et al. 2002], by concatenating and blending example sequences [Arikan et al. 2003; Kovar et al. 2002; Torresani et al. 2007], or by combining modeland data-driven techniques [Yamane et al. 2004; Zordan et al. 2005; Liu and Popovi? 2002; Liu et al. 2005]. These methods generate motion off-line, whereas we consider the problem of real-time synthesis. Reitsma and Pollard [2004] present a method for evaluating the possible motions generated by such approaches. Park et al. [2004] and Kwon and Shin [2005] combine interpolation of motions with a graph structure to generate new locomotion sequences. In statistics, optimal experimental design methods seek the most informative test points to estimate unknown nonlinear functions [Atkinson and Donev 1992; Santner et al. 2003]. However, it is often not possible to determine in advance which regions of input space will need the most data. Active learning methods select test data sequentially: after each data point is acquired, the next test point is chosen to maximize an objective function [Cohn et al. 1994]. Active learning has been studied most extensively for classification problems  (e.g., [Lindenbaum et al. 2004]). For example, a catching controller consists of two tasks: one that catches the ball coming at given speed and direction, and the idle controller that is invoked when there is no ball to be caught. In order to compare, blend, and visualize motions in a translationand rotationinvariant way, we decouple each pose from its translation in the ground plane and the rotation of its hips about the up axis. An IK controller C IK : S ? T ? U ? M is defined in terms of the simple blend controller as C IK (s, t, u) = IK(C (s, t, u), u). However, there is no formal guarantee as to how the controller will perform in new tasks. where indexes over the elements of a control vector, and h is a cubic profile curve 3 , and the ??s are scale factors. After weights are produced by this function, they are clamped to the range [0, 1] and then normalized to sum to 1. Each time a new example data point (u j , w j ) is provided, we solve for the linear weights a i and c i using least squares. The system first attempts to improve performance at the selected task by generating a new motion called a ?pseudoexample? [Sloan et al. 2001]. A pseudoexample can be represented directly in terms of the weights w used to generate the motion. They are the incoming height, from 0.25 ? 2.0 meters, the distance in front of the character to be aimed at, from 0.25 ? 1.0 meters, and the incoming angle, from ??/2 to ?/2 radians. They are the incoming height, from 0.5 to 2.0 meters, the distance to the right of the character, from -2.0 to 2.0 meters, and the incoming speed, from 0.1 to 0.2 meters per frame. They were asked to define the blend-space clusters, and determine a compact number of samples to best cover the controller space.",
  "resources" : [ ]
}