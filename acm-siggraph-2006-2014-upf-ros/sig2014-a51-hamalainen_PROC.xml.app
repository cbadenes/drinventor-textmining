{
  "uri" : "sig2014-a51-hamalainen_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2014/a51-hamalainen_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Online Motion Synthesis Using Sequential Monte Carlo",
    "published" : null,
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ ]
  },
  "bagOfWords" : [ "each", "animation", "frame", "we", "system", "generate", "trajectory", "character", "control", "parameter", "near", "future", "few", "seconds", "use", "sequential", "Monte", "Carlo", "sampling", "we", "main", "technical", "contribution", "multimodal", "tree-based", "sampler", "simultaneously", "explore", "multiple", "different", "near-term", "control", "strategy", "represent", "parameter", "spline", "best", "strategy", "determine", "objective", "function", "measure", "goal", "achievement", "fluidity", "motion", "etc.", "use", "control", "signal", "current", "frame", "maintain", "multiple", "hypothesis", "crucial", "adapt", "dynamically", "change", "environment", "production", "3d", "character", "animation", "slow", "laborious", "process", "further", "one", "aim", "expressive", "interaction", "realism", "amount", "animation", "require", "interactive", "software", "like", "game", "practically", "infinite", "long", "line", "research", "address", "problem", "seek", "transform", "animator", "game", "designer", "choreographer", "who", "command", "virtual", "agent", "algorithmically", "synthesize", "desire", "motion", "base", "high-level", "goal", "successful", "synthesis", "result", "physical", "validity", "-lrb-", "realistic", "body", "part", "mass", "muscle", "force", "respect", "non-penetrating", "contact", "friction", "-rrb-", "lead", "naturally", "movement", "quality", "like", "squash-and-stretch", "anticipation", "-lsb-", "Witkin", "Kass", "1988", "Lasseter", "1987", "-rsb-", "however", "online", "interactive", "synthesis", "difficult", "contact-rich", "movement", "acrobatics", "remain", "challenge", "particularly", "unpredictable", "dynamic", "environment", "where", "prior", "animation", "motion", "capture", "datum", "unavailable", "paper", "tackle", "problem", "use", "novel", "approach", "base", "sequential", "Monte", "Carlo", "-lrb-", "SMC", "-rrb-", "method", "multimodal", "tracking", "here", "apply", "trajectory", "optimization", "Model-Predictive", "Control", "-lrb-", "MPC", "-rrb-", "we", "present", "trajectory", "optimization", "system", "two", "key", "design", "goal", "-rrb-", "result", "movement", "should", "creative", "interesting", "minimal", "input", "datum", "i.e.", "goal", "constraint", "instead", "pre-made", "animation", "motion", "capture", "datum", "-rrb-", "system", "should", "operate", "interactive", "frame", "rate", "design", "time", "enable", "rapid", "iteration", "goal", "constraint", "furthermore", "output", "can", "map", "more", "lightweight", "runtime", "controller", "use", "standard", "machine", "learning", "technique", "function", "highly", "non-convex", "multimodal", "reflect", "fact", "many", "strategy", "may", "lead", "desire", "goal", "naturally", "some", "better", "than", "other", "smoother", "use", "less", "energy", "more", "natural", "however", "find", "global", "maximum", "use", "standard", "nonlinear", "optimization", "robust", "approach", "since", "change", "environment", "may", "unpredictably", "change", "objective", "function", "attain", "robustness", "face", "uncertainty", "we", "maintain", "discrete", "family", "potential", "control", "strategy", "allow", "optimizer", "switch", "strategy", "change", "environment", "so", "dictate", "we", "further", "exploit", "temporal", "coherence", "form", "sample", "generation", "prior", "current", "frame", "base", "previous", "frame", "sampler", "utilize", "kd-tree", "adaptive", "sampling", "online", "near-real-time", "synthesis", "complex", "get", "up", "strategy", "e.g.", "plant", "hand", "ground", "lean", "hand", "allow", "move", "foot", "closer", "finally", "shift", "weight", "foot", "rise", "up", "we", "character", "able", "balance", "give", "pose", "dodge", "projectile", "improvise", "variety", "complex", "get", "up", "strategy", "force", "lose", "balance", "all", "without", "precomputation", "training", "datum", "physically", "valid", "Procedural", "Character", "Animation", "vast", "research", "procedural", "character", "animation", "challenge", "review", "thoroughly", "within", "scope", "paper", "central", "work", "spacetime", "constraint", "Witkin", "Kass", "-lsb-", "1988", "-rsb-", "have", "hundred", "cite", "papers", "we", "do", "discuss", "procedural", "animation", "technique", "parametric", "motion", "graph", "-lsb-", "heck", "Gleicher", "2007", "-rsb-", "enable", "goal-driven", "behavior", "base", "library", "animation", "datum", "do", "enforce", "physical", "constraint", "non-penetrating", "contact", "technique", "cover", "e.g.", "review", "Pejsa", "pandzic", "-lsb-", "2010", "-rsb-", "Offline", "Optimization", "problem", "synthesize", "diverse", "physically", "valid", "motion", "base", "spacetime", "constraint", "-lrb-", "e.g.", "jump", "land", "specific", "pose", "specify", "time", "while", "minimize", "energy", "expenditure", "-rrb-", "have", "largely", "be", "solve", "offline", "case", "much", "work", "have", "focus", "extension", "quadratic", "programming", "-lrb-", "qp", "-rrb-", "formulation", "Witkin", "Kass", "-lsb-", "Witkin", "Kass", "1988", "Cohen", "1992", "Fang", "Pollard", "2003", "Safonova", "et", "al.", "2004", "-rsb-", "where", "optimize", "variable", "include", "root", "position", "rotation", "joint", "rotation", "each", "animation", "frame", "qp", "well", "suit", "spacetime", "optimization", "target", "pose", "can", "define", "equality", "constraint", "contact", "inequality", "constraint", "energy", "minimization", "smoothness", "can", "include", "quadratic", "cost", "case", "optimize", "variable", "describe", "evolution", "control", "parameter", "joint", "torque", "over", "time", "result", "motion", "compute", "forward", "dynamics", "simulation", "-lsb-", "ngo", "mark", "1993", "Wampler", "Popovi", "2009", "Al", "Borno", "et", "al.", "2013", "-rsb-", "way", "problem", "fall", "domain", "MPC", "control", "optimization", "have", "benefit", "physics", "constraint", "continuity", "contact", "handle", "frame-by-frame", "physics", "engine", "do", "have", "include", "optimization", "approach", "also", "handle", "additional", "dynamic", "object", "whereas", "direct", "Witkin", "Kass", "style", "spacetime", "formulation", "need", "additional", "variable", "each", "move", "object", "have", "drawback", "limited", "generalization", "novel", "situation", "exist", "controller", "can", "also", "combine", "form", "novel", "controller", "new", "goal", "-lsb-", "da", "Silva", "et", "al.", "2009", "-rsb-", "Online", "Optimization", "without", "prior", "datum", "operate", "without", "reference", "motion", "controller", "complicate", "online", "synthesis", "general", "trade-off", "between", "minimize", "computational", "cost", "-lrb-", "short", "planning", "horizon", "-rrb-", "minimize", "amount", "prior", "information", "assumption", "need", "form", "motion", "datum", "state", "machine", "definition", "we", "work", "perhaps", "closest", "Tassa", "et", "al.", "-lsb-", "2012", "-rsb-", "who", "also", "study", "action", "balancing", "get", "up", "use", "multithreaded", "physics", "engine", "forward-simulate", "candidate", "trajectory", "character", "Tassa", "et", "al.", "able", "get", "up", "from", "lie", "position", "single", "bounce", "imply", "rather", "loose", "limit", "control", "torque", "which", "simplify", "planning", "problem", "SMC", "have", "also", "be", "recently", "introduce", "control", "optimization", "-lsb-", "Stahl", "Hauth", "2011", "Kantas", "et", "al.", "2009", "de", "villiers", "et", "al.", "2011", "-rsb-", "best", "we", "knowledge", "have", "be", "apply", "motion", "synthesis", "complex", "articulate", "character", "addition", "h?m?l?inen", "Kajiya", "many", "other", "have", "combine", "kd-tree", "sampling", "analogous", "how", "many", "stochastic", "optimization", "method", "mutate", "sample", "explore", "parameter", "space", "we", "seek", "control", "physical", "character", "towards", "attain", "goal", "Doucet", "Johansen", "-lsb-", "2009", "-rsb-", "show", "particle", "filter", "can", "interpret", "special", "case", "generic", "smc", "algorithm", "which", "however", "require", "all", "sample", "draw", "from", "known", "proposal", "density", "however", "show", "Figure", "na?ve", "kd-tree", "sampling", "easily", "lead", "bias", "value", "-lrb-", "-rrb-", "evaluate", "sample", "representative", "whole", "hypercube", "support", "change", "landscape", "we", "now", "construct", "sequential", "Monte", "Carlo", "sampler", "-lrb-", "algorithm", "-rrb-", "base", "adaptive", "sampler", "describe", "above", "crucial", "avoid", "persistent", "spatial", "bias", "sampling", "tree", "building", "order", "affect", "hypercube", "volume", "consequently", "sample", "weight", "paper", "we", "goal", "balance", "character", "upright", "predetermine", "ready", "stance", "define", "pose", "vector", "show", "first", "frame", "figure", "function", "soft", "threshold", "function", "-lrb-", "-rrb-", "0.5", "0.5", "tanh", "-lsb-", "-lrb-", "-rrb-", "-rsb-", "where", "threshold", "steepness", "parameter", "however", "we", "do", "need", "define", "explicit", "state", "transition", "target", "location", "foot", "placement", "sampler", "may", "freely", "pick", "best", "strategy", "each", "situation", "we", "use", "small", "10", "40", "because", "we", "want", "character", "keep", "improvise", "alternative", "get", "up", "strategy", "possible", "we", "achieve", "write", "spline", "evaluator", "recursively", "spline", "only", "ever", "evaluate", "step", "forward", "handle", "change", "knot", "control", "point", "we", "use", "approximate", "nearest", "neighbor", "query", "use", "FLANN", "library", "-lsb-", "muja", "Lowe", "2009", "-rsb-", "map", "feature", "vector", "set", "control", "strategy", "inject", "guess", "line", "12", "take", "step", "emerge", "avoidance", "strategy", "-lrb-", "02:42", "Figure", "11", "-rrb-", "although", "always", "successfully", "-lrb-", "01:48", "-rrb-", "torque", "limit", "optimization", "do", "help", "e.g.", "soften", "landing", "however", "sampling", "and/or", "goal", "able", "relax", "character?s", "hand", "many", "case", "heuristic", "balancing", "initial", "guess", "can", "also", "cause", "character", "assume", "target", "pose", "prematurely", "while", "still", "move", "-lrb-", "02:03", "-rrb-" ],
  "content" : "For each animation frame, our system generates trajectories of character control parameters for the near future ? a few seconds ? using Sequential Monte Carlo sampling. Our main technical contribution is a multimodal, tree-based sampler that simultaneously explores multiple different near-term control strategies represented as parameter splines. The best strategy, as determined by an objective function measuring goal achievement, fluidity of motion, etc., is used as the control signal for the current frame, but maintaining multiple hypotheses is crucial for adapting to dynamically changing environments. Production of 3D character animation is a slow, laborious process. Further, if one aims for expressive interaction and realism, the amount of animation required in interactive software like games is practically infinite. A long line of research addresses these problems by seeking to transform the animator or game designer into a choreographer who commands virtual agents that algorithmically synthesize the desired motions based on high-level goals. Successful synthesis results in physical validity (realistic body part masses and muscle forces, respecting non-penetrating contacts and friction), and leads naturally to movement qualities like ?squash-and-stretch? and anticipation [Witkin and Kass 1988; Lasseter 1987]. However, online, interactive synthesis of difficult, contact-rich movements, such as acrobatics, remains a challenge, particularly in unpredictable dynamic environments where prior animation or motion capture data is unavailable. This paper tackles the problem using a novel approach based on Sequential Monte Carlo (SMC) methods for multimodal tracking, here applied to trajectory optimization and Model-Predictive Control (MPC). We present a trajectory optimization system with two key design goals: 1) the resulting movement should be creative and interesting with minimal input data, i.e., goals and constraints instead of pre-made animation or motion capture data, and 2) the system should operate at an interactive frame rate at design time, enabling rapid iteration of the goals and constraints. Furthermore, the output can be mapped to a more lightweight runtime controller using standard machine learning techniques. The function is highly non-convex and multimodal, reflecting the fact that many strategies may lead to the desired goal. Naturally, some are better than others ? smoother, use less energy, ?more natural?; however, finding the global maximum using standard nonlinear optimization is not a robust approach, since changes in the environment may unpredictably change the objective function. To attain robustness in the face of this uncertainty, we maintain a discrete family of potential control strategies. This allows the optimizer to switch strategies if changes in the environment so dictate. We further exploit temporal coherence by forming a sample generation prior for the current frame based on previous frames. The sampler utilizes kD-trees for adaptive sampling; ? online, near-real-time synthesis of complex get up strategies, e.g., planting a hand on the ground, leaning on the hand to allow moving a foot closer, and finally shifting weight on the foot to rise up. Our character is able to balance in a given pose, dodge projectiles, and improvise a variety of complex get up strategies if forced to lose balance, all without precomputation or training data. Physically Valid Procedural Character Animation The vast research on procedural character animation is challenging to review thoroughly within the scope of this paper, as central work such as spacetime constraints by Witkin and Kass [1988] has hundreds of citing papers. We do not discuss procedural animation techniques such as parametric motion  graphs [Heck and Gleicher 2007] that enable goal-driven behavior based on a library of animation data, but do not enforce physical constraints such as non-penetrating contacts. Such techniques are covered, e.g., in the review by Pejsa and Pandzic [2010]. Offline Optimization The problem of synthesizing diverse and physically valid motion based on spacetime constraints (e.g., jump and land in a specific pose at a specified time while minimizing energy expenditure) has largely been solved in the offline case. Much of the work has focused on extensions of the quadratic programming (QP) formulation of Witkin and Kass [Witkin and Kass 1988; Cohen 1992; Fang and Pollard 2003; Safonova et al. 2004], where the optimized variables include the root position and rotation, and joint rotations for each animation frame. QP is well suited for spacetime optimization, as target poses can be defined as equality constraints, contacts as inequality constraints, and energy minimization and smoothness can be included in the quadratic cost. In this case, the optimized variables describe the evolution of control parameters such as joint torques over time, and the resulting motion is computed by forward dynamics simulation [Ngo and Marks 1993; Wampler and Popovi? 2009; Al Borno et al. 2013]. This way, the problem falls in the domain of MPC. Control optimization has the benefit that physics constraints such as continuity and contacts are handled frame-by-frame by the physics engine and do not have to be included in the optimization. The approach also handles additional dynamic objects, whereas a direct Witkin and Kass -style spacetime formulation needs additional variables for each moving object. This has the drawback of limited generalization to novel situations. Existing controllers can also be combined to form novel controllers for new goals [da Silva et al. 2009]. Online Optimization Without Prior Data Operating without reference motions or controllers complicates online synthesis. In general, there is a trade-off between minimizing computational cost (a short planning horizon), and minimizing the amount of prior information and assumptions needed in the form of motion data or a state machine definition. Our work is perhaps closest to Tassa et al. [2012] who also studied the actions of balancing and getting up, and used a multithreaded physics engine to forward-simulate candidate trajectories. The character of Tassa et al. is able to get up from a lying position in a single bounce, implying rather loose limits on the control torques, which simplifies the planning problem. SMC has also been recently introduced to control optimization [Stahl and Hauth 2011; Kantas et al. 2009; de Villiers et al. 2011], but to the best of our knowledge, it has not been applied to motion synthesis with complex articulated characters. In addition to H?m?l?inen and Kajiya, many others have combined kD-trees with sampling. This is analogous to how many stochastic optimization methods mutate samples to explore the parameter space. We seek to control a physical character towards attaining goals. Doucet and Johansen [2009] show that particle filters can be interpreted as special cases of a generic SMC algorithm, which however requires all samples to be drawn from known proposal densities. However, as shown in Figure 5 , this na?ve kD-tree sampling easily leads to biases if the value of f (x) evaluated at a sample is not representative of the whole hypercube. To support changing landscapes, we now construct a Sequential Monte Carlo sampler (Algorithm 2) based on the adaptive sampler described above. This is crucial to avoid persistent spatial biases in the sampling, as the tree building order affects the hypercube volumes and, consequently, the sample weights. In this paper, our goal is to balance the character upright in a predetermined ?ready? stance defined by a pose vector q r , shown in the first frame of Figure 1 . The function g is a soft threshold function g(x) = 0.5 + 0.5 tanh[c(t d ? x)], where t d is the threshold and c is a steepness parameter. However, we do not need to define explicit state transitions or target locations for foot placement, and the sampler may freely pick the best strategy in each situation. We use a small w r = 10 ?40 because we want the character to keep improvising alternative get up strategies if possible. We achieve this by writing the spline evaluator recursively, such that splines are only ever evaluated at t = 0, and stepping forward by ?t is handled by changing the knots and control points. We use approximate nearest neighbors query using the FLANN library [Muja and Lowe 2009] to map a feature vector to a set of control strategies that are injected as guesses on line 12. Taking steps emerges as an avoidance strategy (02:42, Figure 11 ), although not always successfully (01:48). The torque limit optimization does help, e.g., in softening landings; however, the sampling and/or the goals are not able to relax the character?s hands in many cases. The heuristic balancing initial guess can also cause the character to assume the target pose prematurely while still moving (02:03).",
  "resources" : [ ]
}