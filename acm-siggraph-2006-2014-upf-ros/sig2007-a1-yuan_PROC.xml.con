{
  "uri" : "sig2007-a1-yuan_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2007/a1-yuan_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Image Deblurring with Blurred/Noisy Image Pairs",
    "published" : null,
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ ]
  },
  "bagOfWords" : [ "we", "apply", "we", "approach", "variety", "blurred/noisy", "image", "pair", "low", "lighting", "environment", "use", "compact", "camera", "-lrb-", "canon", "s60", "5m", "pixel", "-rrb-", "DSLR", "camera", "-lrb-", "canon", "20d", "8m", "pixel", "-rrb-", "comparison", "we", "compare", "we", "approach", "denoising", "-lsb-", "Portilla", "et", "al.", "2003", "-rsb-", "standard", "rl", "algorithm", "Figure", "from", "leave", "right", "show", "blur", "image", "noisy", "image", "-lrb-", "enhance", "-rrb-", "denoise", "image", "standard", "rl", "result", "-lrb-", "use", "we", "estimate", "kernel", "-rrb-", "we", "result", "kernel", "size", "31", "31", "33", "33", "40", "40", "three", "example", "we", "manually", "tune", "noise", "parameter", "-lrb-", "standard", "deviation", "-rrb-", "denoising", "algorithm", "achieve", "best", "visual", "balance", "between", "noise", "removal", "detail", "preservation", "compare", "denoise", "result", "show", "Figure", "-lrb-", "-rrb-", "we", "result", "Figure", "-lrb-", "-rrb-", "contain", "much", "more", "fine", "detail", "tiny", "texture", "fabric", "first", "example", "thin", "grid", "structure", "crown", "second", "example", "clear", "text", "camera", "last", "example", "because", "noise", "image", "scale", "up", "from", "very", "dark", "low", "contrast", "image", "partial", "color", "information", "also", "lose", "we", "approach", "recover", "correct", "color", "through", "image", "deblurring", "Figure", "-lrb-", "-rrb-", "show", "standard", "rl", "deconvoution", "result", "which", "exhibit", "unpleasant", "ringing", "artifact", "large", "noise", "Figure", "10", "show", "blurred/noisy", "pair", "contain", "thin", "hair", "sweater", "detailed", "structure", "image", "capture", "compact", "camera", "noisy", "image", "have", "very", "strong", "noise", "most", "fabric", "texture", "sweater", "faithfully", "recover", "we", "result", "last", "column", "second", "row", "Figure", "10", "show", "estimate", "initial", "kernel", "refine", "kernel", "iterative", "optimization", "iteration", "number", "typically", "we", "experiment", "refined", "kernel", "have", "sharper", "sparser", "shape", "than", "initial", "one", "large", "kernel", "Figure", "11", "show", "example", "large", "blur", "compact", "camera", "kernel", "size", "87", "87", "original", "resolution", "1200", "1600", "image", "show", "here", "crop", "975", "1146", "compare", "state-of-art", "single", "image", "kernel", "estimation", "approach", "-lsb-", "Fergus", "et", "al.", "2006", "-rsb-", "which", "largest", "kernel", "30", "pixel", "we", "approach", "use", "image", "pair", "significantly", "extend", "degree", "blur", "can", "handle", "small", "noise", "kernel", "moderately", "dim", "lighting", "environment", "we", "may", "capture", "input", "image", "small", "noise", "blur", "show", "Figure", "12", "typical", "case", "assume", "Jia?s", "approach", "-lsb-", "2004", "-rsb-", "which", "color", "transfer", "base", "algorithm", "third", "fourth", "column", "Figure", "12", "color", "transfer", "result", "-lsb-", "Jia", "et", "al.", "2004", "-rsb-", "histogram", "equalization", "result", "from", "blur", "image", "denoise", "image", "note", "color", "can", "accurately", "transfer", "-lrb-", "e.g.", "Buddha?s", "golden", "hat", "-rrb-", "because", "both", "approach", "use", "global", "mapping", "we", "result", "only", "recover", "more", "detail", "-lrb-", "e.g.", "horizontal", "line", "background", "-rrb-", "also", "have", "similar", "color", "blur", "image", "all", "detail", "Table", "show", "shutter", "speed", "iso", "setting", "example", "Figure", "-12", "we", "able", "reduce", "exposure", "time", "-lrb-", "shutter", "speed", "iso", "-rrb-", "about", "10", "stop", "we", "have", "propose", "image", "deblurr", "approach", "use", "pair", "blurred/noisy", "image", "we", "approach", "take", "advantage", "both", "image", "produce", "high", "quality", "reconstruct", "image", "formulate", "image", "deblurr", "problem", "use", "two", "image", "we", "have", "develop", "iterative", "deconvolution", "algorithm", "which", "can", "estimate", "very", "good", "initial", "kernel", "significantly", "reduce", "deconvolution", "artifact", "special", "hardware", "require", "we", "propose", "approach", "use", "off-the-shelf", "hand-held", "camera", "Limitations", "remain", "we", "approach", "however", "we", "approach", "share", "common", "limitation", "most", "image", "deblurr", "technique", "assume", "single", "spatial-invariant", "blur", "kernel", "spatial-variant", "kernel", "possible", "locally", "estimate", "kernel", "different", "part", "image", "blend", "deconvolution", "result", "most", "significantly", "we", "approach", "require", "two", "image", "we", "envision", "ability", "capture", "pair", "eventually", "move", "camera", "firmware", "thereby", "make", "two-shot", "capture", "easier", "faster", "future", "we", "plan", "extend", "we", "approach", "other", "image", "deblurr", "application", "deblurr", "video", "sequence", "outof-focus", "deblurring", "we", "technique", "can", "also", "apply", "hybrid", "image", "system", "-lsb-", "Ben-Ezra", "Nayar", "2003", "-rsb-", "combine", "code", "exposure", "photography", "-lsb-", "raskar", "et", "al.", "2006", "-rsb-" ],
  "content" : "We apply our approach to a variety of blurred/noisy image pairs in low lighting environments using a compact camera (Canon S60, 5M pixels) and a DSLR camera (Canon 20D, 8M pixels). Comparison. We compare our approach with denoising [Portilla et al. 2003], and a standard RL algorithm. Figure 9 , from left to right, shows a blurred image, noisy image (enhanced), denoised image, standard RL result (using our estimated kernel), and our result. The kernel sizes are 31 ? 31, 33 ? 33, and 40 ? 40 for the three examples. We manually tune the noise parameter (standard deviation) in the denoising algorithm to achieve a best visual balance between noise removal and detail preservation. Compared with denoised results shown in Figure 9(c) , our results in Figure 9(e) contain much more fine details, such as tiny textures on the fabric in the first example, thin grid structures on the crown in the second example, and clear text on the camera in the last example. Because the noise image is scaled up from a very dark, low contrast image, partial color information is also lost. Our approach recovers correct colors through image deblurring. Figure 9(d) shows standard RL deconvoution results which exhibit unpleasant ringing artifacts. Large noise. Figure 10 shows a blurred/noisy pair containing thin hairs and a sweater with detailed structures. The images are captured by the compact camera and the noisy image has very strong noises. Most fabric textures on the sweater are faithfully recovered in our result. The last column in the second row of Figure 10 shows the estimated initial kernel and the refined kernel by the iterative optimization. The iteration number is typically 2 or 3 in our experiments. The refined kernel has a sharper and sparser shape than the initial one. Large kernel. Figure 11 shows an example with a large blur by the compact camera. The kernel size is 87 ? 87 at the original resolution 1200 ? 1600. The image shown here is cropped to 975 ? 1146. Compared with the state-of-art single image kernel estimation approach [Fergus et al. 2006] in which the largest kernel is 30 pixels, our approach using an image pair significantly extends the degree of blur that can be handled. Small noise and kernel. In a moderately dim lighting environment, we may capture input images with small noise and blur, as shown in Figure 12 . This is a typical case assumed in Jia?s approach [2004] which is a color transfer based algorithm. The third and fourth columns in Figure 12 are color transferred result [Jia et al. 2004] and histogram equalization result from the blurred image to the denoised image. Note that the colors cannot be accurately transferred (e.g., Buddha?s golden hat) because both approaches use global mappings. Our result not only recovers more details (e.g., horizontal lines on background) but also has similar colors to the blurred image for all details. Table 1 shows the shutter speeds and ISO settings of examples in Figure 9 -12. We are able to reduce exposure time (shutter speed ? ISO) by about 10 stops. We have proposed an image deblurring approach using a pair of blurred/noisy images. Our approach takes advantage of both images to produce a high quality reconstructed image. By formulating the image deblurring problem using two images, we have developed an iterative deconvolution algorithm which can estimate a very good initial kernel and significantly reduce deconvolution artifacts. No special hardware is required. Our proposed approach uses off-the-shelf, hand-held cameras. Limitations remain in our approach, however. Our approach shares the common limitation of most image deblurring techniques: assuming a single, spatial-invariant blur kernel. For spatial-variant kernel, it is possible to locally estimate kernels for different parts of the image and blend deconvolution results. Most significantly, our approach requires two images. We envision that the ability to capture such pairs will eventually move into the camera firmware, thereby making two-shots capture easier and faster. In the future, we plan to extend our approach to other image deblurring applications, such as deblurring video sequences, or outof-focus deblurring. Our techniques can also be applied in a hybrid image system [Ben-Ezra and Nayar 2003] or combined with coded exposure photography [Raskar et al. 2006].",
  "resources" : [ ]
}