{
  "uri" : "sig2013-a78-liu_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2013/a78-liu_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Bundled Camera Paths for Video Stabilization",
    "published" : "2013",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Shuaicheng-Liu",
      "name" : "Shuaicheng",
      "surname" : "Liu"
    }, {
      "uri" : "http://drinventor/Lu-Yuan",
      "name" : "Lu",
      "surname" : "Yuan"
    }, {
      "uri" : "http://drinventor/Ping-Tan",
      "name" : "Ping",
      "surname" : "Tan"
    }, {
      "uri" : "http://drinventor/Jian Sun-null",
      "name" : "Jian Sun",
      "surname" : null
    } ]
  },
  "bagOfWords" : [ "video", "capture", "hand-held", "device", "-lrb-", "e.g.", "cell-phone", "portable", "camcorder", "-rrb-", "often", "appear", "remarkably", "shaky", "undirected", "Digital", "video", "stabilization", "improve", "video", "quality", "remove", "unwanted", "camera", "motion", "great", "practical", "importance", "because", "device", "-lrb-", "mobile", "phone", "tablet", "camcorder", "-rrb-", "capable", "capture", "video", "have", "become", "widespread", "online", "sharing", "so", "ubiquitous", "prior", "video", "stabilization", "method", "synthesize", "new", "stabilize", "video", "estimate", "smooth", "2d", "camera", "motion", "-lsb-", "Matsushita", "et", "al.", "2006", "Grundmann", "et", "al.", "2011", "-rsb-", "3d", "camera", "motion", "-lsb-", "Liu", "et", "al.", "2009", "Liu", "et", "al.", "2012", "-rsb-", "general", "2d", "method", "more", "robust", "faster", "because", "only", "estimate", "linear", "transformation", "-lrb-", "affine", "homography", "-rrb-", "between", "consecutive", "frame", "2d", "linear", "motion", "model", "too", "weak", "fundamentally", "handle", "parallax", "cause", "non-trivial", "depth", "variation", "scene", "contrary", "3d", "method", "can", "deal", "parallax", "principle", "generate", "strongly", "stabilize", "result", "however", "motion", "model", "estimation", "less", "robust", "various", "degeneration", "feature", "tracking", "failure", "motion", "blur", "camera", "zooming", "rapid", "rotation", "briefly", "2d", "method", "more", "robust", "may", "sacrifice", "quality", "-lrb-", "e.g.", "introduce", "unpleasant", "geometrical", "distortion", "produce", "less", "stabilize", "output", "-rrb-", "while", "3d", "method", "can", "achieve", "high-quality", "result", "more", "fragile", "some", "recent", "method", "-lsb-", "Liu", "et", "al.", "2011", "Goldstein", "Fattal", "2012", "-rsb-", "have", "successfully", "combine", "advantage", "two", "kind", "method", "Liu", "et", "al.", "-lsb-", "2011", "-rsb-", "apply", "low-rank", "subspace", "constraint", "2d", "feature", "trajectory", "which", "effective", "simplification", "3d", "reconstruction", "Goldstein", "Fattal", "-lsb-", "2012", "-rsb-", "avoid", "3d", "reconstruction", "exploit", "epipolar", "transfer", "technique", "method", "relax", "requirement", "from", "3d", "reconstruction", "2d", "long", "feature", "tracking", "nevertheless", "require", "long", "feature", "tracking", "-lrb-", "typically", "over", "20", "frame", "-rrb-", "make", "difficult", "handle", "more", "challenging", "case", "-lrb-", "e.g.", "rapid", "motion", "fast", "scene", "transition", "large", "occlusion", "-rrb-", "consumer", "video", "paper", "aim", "same", "goal", "robust", "high-quality", "result", "from", "opposite", "direction", "we", "propose", "more", "powerful", "2d", "camera", "motion", "model", "specifically", "we", "present", "bundle", "camera", "path", "model", "which", "maintain", "multiple", "spatially-variant", "camera", "path", "other", "word", "each", "different", "location", "video", "have", "its", "own", "camera", "path", "flexible", "model", "allow", "we", "fundamentally", "deal", "nonlinear", "motion", "cause", "parallax", "roll", "shutter", "effect", "-lsb-", "Liang", "et", "al.", "2008", "Baker", "et", "al.", "2010", "Grundmann", "et", "al.", "2012", "-rsb-", "same", "time", "model", "enjoy", "robustness", "simplicity", "2d", "method", "because", "only", "require", "feature", "correspondence", "between", "two", "consecutive", "frame", "we", "bundle", "camera", "path", "model", "build", "two", "novel", "component", "warping-based", "motion", "representation", "-lrb-", "estimation", "-rrb-", "adaptive", "space-time", "path", "smoothing", "first", "component", "represent", "motion", "between", "two", "consecutive", "frame", "mesh-based", "spatially-variant", "homography", "-lrb-", "figure", "-lrb-", "-rrb-", "-rrb-", "as-similar-aspossible", "regularization", "constraint", "-lsb-", "Igarashi", "et", "al.", "2005", "Schaefer", "et", "al.", "2006", "-rsb-", "constraint", "critical", "because", "estimate", "model", "high", "degree", "freedom", "usually", "risky", "case", "insufficient", "feature", "large", "occlusion", "best", "we", "knowledge", "first", "work", "employ", "mesh-based", "as-similar-aspossible", "regularization", "spatially-variant", "motion", "estimation", "video", "stabilization", "Notice", "as-similar-as-possible", "warp", "use", "-lsb-", "Liu", "et", "al.", "2009", "Liu", "et", "al.", "2011", "-rsb-", "video", "stabilization", "we", "directly", "use", "mesh", "vertex", "motion", "model", "itself", "intermediate", "representation", "use", "3d", "reconstruction", "-lsb-", "Liu", "et", "al.", "2009", "-rsb-", "subspace", "-lsb-", "Liu", "et", "al.", "2011", "-rsb-", "base", "propose", "motion", "representation", "we", "construct", "bundle", "camera", "path", "each", "which", "concatenation", "local", "homography", "same", "grid", "cell", "over", "time", "-lrb-", "figure", "-lrb-", "-rrb-", "-rrb-", "we", "second", "component", "smooth", "all", "bundle", "camera", "path", "whole", "maintain", "both", "spatial", "temporal", "coherence", "furthermore", "avoid", "excessive", "cropping/geometrical", "distortion", "approximate", "cinematography", "favor", "path", "we", "adopt", "discontinuity-preserving", "idea", "similar", "bilateral", "filter", "-lsb-", "Tomasi", "Manduchi", "1998", "-rsb-", "adaptively", "control", "strength", "smoothing", "quantitative", "evaluation", "we", "provide", "comprehensive", "dataset", "-lrb-", "include", "both", "public", "example", "we", "own", "video", "clip", "different", "kind", "motion", "-rrb-", "we", "show", "we", "new", "2d", "method", "comparable", "outperform", "other", "competitive", "2d", "3d", "method", "2d", "method", "estimate", "2d", "transformation", "between", "consecutive", "video", "frame", "smooth", "they", "over", "time", "generate", "steady", "video", "most", "previously", "develop", "method", "apply", "affine", "homography", "model", "focus", "design", "smoothing", "algorithm", "earlier", "work", "-lsb-", "Morimoto", "Chellappa", "1998", "Matsushita", "et", "al.", "2006", "-rsb-", "apply", "low-pass", "filter", "individual", "model", "parameter", "some", "method", "assume", "prior", "motion", "model", "polynomial", "curve", "-lsb-", "Chen", "et", "al.", "2008", "-rsb-", "desire", "camera", "trajectory", "Gleicher", "Liu", "-lsb-", "2007", "-rsb-", "divide", "original", "camera", "trajectory", "multiple", "segment", "subsequent", "individual", "smoothing", "more", "recently", "Grundmann", "et", "al.", "-lsb-", "2011", "-rsb-", "gracefully", "apply", "norm", "optimization", "generate", "camera", "path", "consist", "constant", "linear", "parabolic", "motion", "which", "follow", "cinematography", "rule", "Grundmann", "et", "al.", "-lsb-", "2012", "-rsb-", "further", "adopt", "homography-array-based", "motion", "model", "deal", "roll", "shutter", "effect", "two", "technique", "have", "be", "integrate", "Google", "YouTube", "robust", "follow", "cinematography", "rule", "perform", "well", "many", "consumer", "video", "we", "method", "belong", "category", "we", "use", "spatially-variant", "model", "represent", "motion", "between", "video", "frame", "design", "appropriate", "smoothing", "technique", "model", "3d", "method", "often", "rely", "robust", "feature", "tracking", "stabilization", "Beuhler", "et", "al.", "-lsb-", "2001", "-rsb-", "perform", "stabilization", "projective", "3d", "reconstruction", "scene", "from", "uncalibrated", "camera", "Liu", "et", "al.", "-lsb-", "2009", "-rsb-", "develop", "first", "successful", "3d", "video", "stabilization", "system", "first", "introduce", "content-preserving", "warp", "stabilization", "since", "3d", "reconstruction", "difficult", "recent", "method", "directly", "smooth", "trajectory", "track", "feature", "Liu", "et", "al.", "-lsb-", "2011", "-rsb-", "smooth", "some", "basis", "trajectory", "-lrb-", "preferably", "longer", "than", "50", "frame", "-rrb-", "subspace", "form", "feature", "track", "method", "achieve", "similar", "quality", "3d", "reconstruction-based", "method", "while", "reduce", "require", "ment", "from", "3d", "reconstruction", "long", "feature", "tracking", "have", "be", "transfer", "Adobe", "after", "effect", "feature", "call", "Warp", "Stabilizer", "Goldstein", "Fattal", "-lsb-", "2012", "-rsb-", "utilize", "epipolar", "transfer", "technique", "avoid", "fragile", "3d", "reconstruction", "technique", "also", "alleviate", "strain", "long", "feature", "track", "still", "require", "moderate", "feature", "track", "length", "-lrb-", "typically", "over", "20", "frame", "-rrb-", "feature", "track", "smoothing", "also", "use", "light-field", "camera", "video", "stabilization", "work", "-lsb-", "Smith", "et", "al.", "2009", "-rsb-", "address", "occlusion", "issue", "Lee", "et", "al.", "-lsb-", "2009", "-rsb-", "introduce", "feature", "pruning", "choose", "robust", "feature", "trajectory", "smoothing", "nearly", "all", "method", "involve", "feature", "tracking", "face", "common", "obstacle", "many", "consumer", "video", "obtain", "long", "feature", "track", "fragile", "due", "occlusion", "motion", "blur", "rapid", "camera", "motion", "we", "method", "do", "encounter", "issue", "since", "only", "compute", "relative", "motion", "between", "consecutive", "frame", "Motion", "Estimation", "compute", "transition", "between", "two", "image", "view", "overlap", "Optical", "flow", "algorithm", "-lsb-", "Lucas", "Kanade", "1981", "-rsb-", "model", "transition", "individual", "displacement", "vector", "every", "pixel", "when", "parallax", "transition", "can", "represent", "elegantly", "global", "homography", "transformation", "-lsb-", "Hartley", "Zisserman", "2003", "-rsb-", "local", "alignment", "-lsb-", "shum", "Szeliski", "2000", "-rsb-", "dual-homography", "model", "-lsb-", "Gao", "et", "al.", "2011", "-rsb-", "can", "reduce", "alignment", "error", "cause", "parallax", "Szeliski", "Shum", "-lsb-", "1996", "-rsb-", "represent", "motion", "use", "mixture", "spline", "model", "spatially", "variant", "spatial", "support", "facilitate", "registration", "Lin", "et", "al.", "-lsb-", "2011", "-rsb-", "estimate", "smoothly", "vary", "affine", "field", "align", "image", "large", "viewpoint", "change", "model", "can", "potentially", "use", "video", "stabilization", "however", "its", "current", "motion", "estimation", "technique", "slow", "-lrb-", "may", "take", "minute", "process", "720p", "frame", "-rrb-", "we", "motion", "model", "essentially", "mesh-based", "spatially-variant", "homography", "model", "inspire", "recent", "image", "warping", "technique", "-lsb-", "Igarashi", "et", "al.", "2005", "Schaefer", "et", "al.", "2006", "Liu", "et", "al.", "2009", "-rsb-", "we", "extend", "as-similar-as-possible", "idea", "from", "image", "synthesis", "motion", "estimation", "apply", "video", "stabilization", "very", "efficient", "estimate", "we", "motion", "model", "-lrb-", "may", "take", "only", "50", "millisecond", "process", "720p", "frame", "-rrb-", "Rolling", "Shutter", "removal", "estimate", "correct", "inter-row", "motion", "cause", "row-parallel", "readout", "i.e.", "electronic", "rolling", "shutter", "-lsb-", "Nakamura", "2005", "-rsb-", "mainly", "CMOS", "sensor", "prior", "work", "design", "different", "parametric", "inter-row", "motion", "model", "include", "per-row", "translation", "model", "-lsb-", "Liang", "et", "al.", "2008", "Baker", "et", "al.", "2010", "-rsb-", "3d", "rotation", "model", "-lsb-", "forss?n", "Ringaby", "2010", "-rsb-", "recently", "Grundmann", "et", "al.", "-lsb-", "2012", "-rsb-", "propose", "calibration-free", "homography", "mixture", "model", "which", "show", "significant", "improvement", "Karpenko", "et", "al.", "-lsb-", "2011", "-rsb-", "use", "dedicate", "hardware", "gyroscope", "mobile", "device", "correct", "rolling", "shutter", "effect", "real-time", "similar", "-lsb-", "Grundmann", "et", "al.", "2012", "-rsb-", "we", "method", "correct", "roll", "shutter", "effect", "without", "any", "prior", "calibration", "we", "warping-based", "model", "naturally", "handle", "rolling", "shutter", "effect", "special", "kind", "spatially", "variant", "motion", "so", "we", "do", "need", "separate", "rolling", "shutter", "correction", "step", "we", "stabilization" ],
  "content" : "A video captured with a hand-held device (e.g., a cell-phone or a portable camcorder) often appears remarkably shaky and undirected. Digital video stabilization improves the video quality by removing unwanted camera motion. It is of great practical importance because the devices (mobile phones, tablets, camcorders) capable  of capturing video have become widespread and online sharing is so ubiquitous. Prior video stabilization methods synthesized a new stabilized video by estimating and smoothing 2D camera motion [Matsushita et al. 2006; Grundmann et al. 2011] or 3D camera motion [Liu et al. 2009; Liu et al. 2012]. In general, 2D methods are more robust and faster because they only estimate a linear transformation (affine or homography) between consecutive frames. But the 2D linear motion model is too weak to fundamentally handle the parallax caused by non-trivial depth variation in the scene. On the contrary, the 3D methods can deal with the parallax in principle and generate strongly stabilized results. However, their motion model estimation is less robust to various degenerations such as feature tracking failure, motion blur, camera zooming, and rapid rotation. Briefly, 2D methods are more robust but may sacrifice quality (e.g., introducing unpleasant geometrical distortion or producing less stabilized output), while 3D methods can achieve high-quality results but are more fragile. Some recent methods [Liu et al. 2011; Goldstein and Fattal 2012] have successfully combined the advantages of these two kinds of methods. Liu et al. [2011] applied a low-rank, subspace constraint on 2D feature trajectories, which is an effective simplification of 3D reconstruction. Goldstein and Fattal [2012] avoided 3D reconstruction by exploiting the ?epipolar transfer? technique. These methods relax the requirement from 3D reconstruction to 2D long feature tracking. Nevertheless, requiring long feature tracking (typically over 20 frames) makes it difficult to handle more challenging cases (e.g., rapid motion, fast scene transition, large occlusion) in the consumer videos. This paper aims at the same goal of robust high-quality result but from an opposite direction: we propose a more powerful 2D camera motion model. Specifically, we present bundled camera paths model which maintains multiple, spatially-variant camera paths. In other words, each different location in the video has its own camera path. This flexible model allows us to fundamentally deal with nonlinear motion caused by parallax and rolling shutter effects [Liang et al. 2008; Baker et al. 2010; Grundmann et al. 2012]. At the same time, the model enjoys the robustness and simplicity of 2D methods, because it only requires feature correspondences between two consecutive frames. Our bundled camera paths model is built on two novel components: a warping-based motion representation (and estimation), and an adaptive space-time path smoothing. The first component represents the motion between two consecutive frames by mesh-based, spatially-variant homographies ( Figure 1(b) ) with a ?as-similar-aspossible? regularization constraint [Igarashi et al. 2005; Schaefer et al. 2006]. This constraint is critical because estimating a model with such a high degree of freedom is usually risky in the cases of insufficient features or large occlusions. To the best of our knowledge, this is the first work to employ the mesh-based ?as-similar-aspossible? regularization for spatially-variant motion estimation in video stabilization. Notice that the ?as-similar-as-possible? warping was used in [Liu et al. 2009; Liu et al. 2011] for video stabilization. But we directly use the mesh vertices as the motion model itself. No intermediate representation is used, such as 3D reconstruction [Liu et al. 2009] or subspace [Liu et al. 2011]. Based on the proposed motion representation, we construct a bundle of camera paths, each of which is the concatenation of local homographies at the same grid cell over time ( Figure 1(b) ). Our second component smooths all bundled camera paths as a whole to maintain both spatial and temporal coherences. Furthermore, to avoid excessive cropping/geometrical distortion and approximate cinematography favored path, we adopt a discontinuity-preserving idea similar to bilateral filtering [Tomasi and Manduchi 1998] to adaptively control the strength of smoothing. For a quantitative evaluation, we provide a comprehensive dataset (including both public examples and our own video clips of different kinds of motions). We show that our new 2D method is comparable to or outperforms other competitive 2D or 3D methods. 2D Methods estimate 2D transformations between consecutive video frames and smooth them over time to generate a steady video. Most previously developed methods apply an affine or homography model, and focus on the design of the smoothing algorithm. Earlier works [Morimoto and Chellappa 1998; Matsushita et al. 2006] apply low-pass filters to individual model parameters. Some methods assume prior motion models such as polynomial curves [Chen et al. 2008] for desired camera trajectories. Gleicher and Liu [2007] divide the original camera trajectory into multiple segments for subsequent individual smoothing. More recently, Grundmann et al. [2011] gracefully apply L 1 -norm optimization to generate a camera path consisting of constant, linear and parabolic motions, which follow cinematography rules. Grundmann et al. [2012] further adopt a homography-array-based motion model to deal with rolling shutter effects. These two techniques have been integrated into Google YouTube. It is robust, follows cinematography rules, and performs well on many consumer videos. Our method belongs to this category. But we use a spatially-variant model to represent the motion between video frames and design an appropriate smoothing technique for this model. 3D Methods often rely on robust feature tracking for stabilization. Beuhler et al. [2001] perform stabilization with a projective 3D reconstruction of the scene from an uncalibrated camera. Liu et al. [2009] develop the first successful 3D video stabilization system and are the first to introduce ?content-preserving? warping for stabilization. Since 3D reconstruction is difficult, recent methods directly smooth the trajectories of tracked features. Liu et al. [2011] smooth some basis trajectories (preferably longer than 50 frames) of the subspace formed by the feature tracks. This method achieves similar quality to 3D reconstruction-based methods, while reducing the require ment from 3D reconstruction to long feature tracking. It has been transferred to Adobe After Effects as a feature called ?Warp Stabilizer?. Goldstein and Fattal [2012] utilize an ?epipolar transfer? technique to avoid the fragile 3D reconstruction. This technique also alleviates the strain on long feature tracks. But it still requires moderate feature track length (typically over 20 frames). Feature track smoothing is also used in light-field camera video stabilization work [Smith et al. 2009]. To address the occlusion issue, Lee et al. [2009] introduce feature pruning to choose robust feature trajectories for smoothing. Nearly all methods involving feature tracking face a common obstacle ? in many consumer videos obtaining long feature tracks is fragile due to occlusion, motion blur or rapid camera motion. Our method does not encounter this issue since it only computes relative motion between consecutive frames. Motion Estimation computes the transition between two images with view overlap. Optical flow algorithms [Lucas and Kanade 1981] model this transition by individual displacement vectors at every pixel. When there is no parallax, this transition can be represented elegantly by a global homography transformation [Hartley and Zisserman 2003]. Local alignment [Shum and Szeliski 2000] or a dual-homography model [Gao et al. 2011] can reduce alignment error caused by parallax. Szeliski and Shum [1996] represent motion using a mixture of spline models with spatially variant spatial support to facilitate registration. Lin et al. [2011] estimate a smoothly varying affine field to align images of large viewpoint changes. This model can be potentially used for video stabilization. However, its current motion estimation technique is slow (may take 8 minutes to process a 720p frame). Our motion model is essentially a mesh-based, spatially-variant homography model, inspired by recent image warping techniques [Igarashi et al. 2005; Schaefer et al. 2006; Liu et al. 2009]. We extend the ?as-similar-as-possible? idea from image synthesis to motion estimation, and apply it to video stabilization. It is very efficient to estimate our motion model (may take only 50 milliseconds to process a 720p frame). Rolling Shutter Removal estimates and corrects inter-row motion caused by the row-parallel readout, i.e., electronic rolling shutter [Nakamura 2005] mainly in CMOS sensors. Prior works design different parametric inter-row motion models, including a per-row translation model [Liang et al. 2008; Baker et al. 2010] and 3D rotation model [Forss?n and Ringaby 2010]. Recently, Grundmann et al. [2012] proposed a calibration-free homography mixture model, which shows significant improvement. Karpenko et al. [2011] use dedicated hardware ? the gyroscope on mobile devices, to correct the rolling shutter effects in real-time. Similar to [Grundmann et al. 2012], our method corrects rolling shutter effects without any prior calibration. Our warping-based model naturally handles the rolling shutter effects as a special kind of spatially variant motion. So we do not need a separate rolling shutter correction step in our stabilization.",
  "resources" : [ ]
}