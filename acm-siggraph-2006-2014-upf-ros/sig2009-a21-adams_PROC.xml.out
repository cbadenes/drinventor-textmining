{
  "uri" : "sig2009-a21-adams_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2009/a21-adams_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Gaussian KD-Trees for Fast High-Dimensional Filtering",
    "published" : null,
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ ]
  },
  "bagOfWords" : [ "we", "have", "value", "filter", "each", "assign", "position", "d-dimensional", "space", "we", "space", "complexity", "-lrb-", "dn", "-rrb-", "we", "time", "complexity", "-lrb-", "dn", "log", "-rrb-", "whereas", "exist", "method", "typically", "either", "exponential", "quadratic", "n.", "let", "we", "begin", "simple", "case", "bilateral", "filter", "however", "we", "argue", "section", "3.1", "memory", "require", "represent", "grid", "grow", "exponentially", "number", "dimension", "do", "time", "require", "each", "stage", "algorithm", "would", "preferable", "subsample", "set", "neighbour", "statistically", "efficient", "manner", "query", "use", "implement", "embedding", "blur", "sampling", "space", "describe", "section", "do", "so", "computational", "complexity", "independent", "filter", "size", "linear", "dimensionality", "we", "method", "fact", "slightly", "faster", "when", "search", "completely", "unbounded", "fewer", "dimension", "consider", "section", "3.2", "we", "demonstrate", "fast", "non-local", "means", "denoise", "space-time", "volume", "filtering", "most", "generally", "describe", "replace", "each", "value", "set", "size", "linear", "combination", "all", "other", "value", "we", "assume", "value", "represent", "homogeneous", "coordinate", "homogeneous", "coordinate", "filter", "along", "other", "joint", "bilateral", "filter", "-lrb-", "describe", "-lsb-", "Eisemann", "Durand", "2004", "-rsb-", "-lsb-", "Petschnigg", "et", "al.", "2004", "-rsb-", "-rrb-", "instead", "use", "color", "distance", "from", "some", "other", "image", "formulation", "first", "propose", "-lsb-", "d.barash", "2002", "-rsb-", "pixel", "value", "now", "associate", "position", "five-dimensional", "space", "whose", "axis", "-lrb-", "-rrb-", "scale", "inverse", "standard", "deviation", "filter", "respective", "dimension", "Improved", "fast", "Gauss", "transform", "group", "vector", "cluster", "radius", "proportional", "standard", "deviation", "desire", "Gaussian", "compute", "Taylor", "series", "approximation", "result", "each", "cluster", "center", "effective", "tool", "very", "large", "radius", "blur", "few", "cluster", "need", "unfortunately", "standard", "deviation", "commonly", "use", "filter", "small", "enough", "few", "datum", "point", "per", "cluster", "little", "benefit", "derive", "from", "clustering", "we", "find", "when", "apply", "bilateral", "filter", "Improved", "fast", "Gauss", "Transform", "fact", "slower", "than", "naive", "filter", "implementation", "typical", "parameter", "setting", "firstly", "interaction", "further", "than", "three", "standard", "deviation", "apart", "can", "safely", "ignore", "-lrb-", "weight", "become", "very", "small", "-rrb-", "make", "collision", "detection", "problem", "sphere", "d-dimensional", "space", "detail", "we", "tree", "construction", "section", "2.1", "thirdly", "gaussian", "filter", "can", "accelerate", "compute", "filter", "lower", "resolution", "interpolate", "result", "we", "con", "struct", "reduce", "set", "only", "position", "value", "downsample", "use", "gaussian", "kernel", "size", "blur", "smaller", "set", "gaussian", "filter", "size", "upsample", "original", "position", "gaussian", "kernel", "size", "we", "consider", "sampling", "dense", "enough", "when", "maximum", "spacing", "between", "datum", "point", "reduce", "space", "allow", "more", "coarsely", "space", "point", "increase", "number", "sample", "require", "during", "Monte-Carlo", "splatting", "slice", "we", "derive", "we", "reduce", "set", "size", "during", "tree", "building", "describe", "below", "we", "gaussian", "kd-tree", "store", "cloud", "point", "dimension", "one", "point", "per", "leaf", "design", "allow", "fast", "importancesampled", "query", "point", "-lrb-", "section", "2.2", "-rrb-", "key", "difference", "between", "tree", "conventional", "kd-tree", "we", "store", "max", "min", "well", "cut", "maximum", "bind", "compute", "minimum", "cut", "value", "all", "ancestor", "which", "cut", "along", "same", "dimension", "have", "larger", "cut", "value", "minimum", "bind", "similarly", "maximum", "cut", "value", "all", "ancestor", "which", "cut", "along", "same", "dimension", "have", "smaller", "cut", "value", "see", "Figure", "comparison", "tree", "bilateral", "grid", "fortunately", "we", "know", "ahead", "time", "we", "only", "ever", "sample", "position", "use", "construct", "tree", "raytracing", "example", "mean", "can", "advantageous", "have", "highly", "unbalanced", "tree", "which", "carve", "off", "empty", "space", "commonly", "hit", "area", "early", "however", "we", "never", "sample", "unpopulated", "area", "so", "how", "we", "deal", "empty", "space", "irrelevant", "typical", "datum", "each", "we", "leaf", "node", "likely", "reach", "any", "other", "so", "tree", "should", "balance", "recursively", "turn", "list", "position", "tree", "we", "first", "compute", "bound", "box", "scheme", "descend", "cell", "have", "small", "diagonal", "quickly", "possible", "while", "have", "advantage", "place", "most", "commonly", "access", "leave", "closer", "root", "tree", "practice", "we", "find", "do", "improve", "performance", "query", "we", "gaussian", "tree", "design", "facilitate", "gather", "from", "-lrb-", "scatter", "-rrb-", "value", "around", "give", "query", "position", "purpose", "compute", "importance-sampled", "approximation", "equation", "number", "sample", "set", "infinity", "list", "return", "include", "all", "point", "within", "three", "standard", "deviation", "query", "weight", "proportional", "gaussian", "kernel", "give", "standard", "deviation", "-lrb-", "q?p", "-rrb-", "each", "inner", "node", "we", "compute", "expect", "number", "sample", "lie", "within", "left", "right", "child", "compute", "area", "Gaussian", "truncate", "min", "max", "lie", "either", "side", "cut", "expect", "number", "sample", "split", "each", "way", "round", "down", "nearest", "integer", "many", "sample", "assign", "left", "right", "child", "respectively", "splitting", "scheme", "save", "work", "compare", "individually", "simulate", "every", "sample", "result", "runtime", "which", "sublinear", "number", "sample", "bound", "number", "cell", "overlap", "ping", "query", "also", "stratify", "sampling", "result", "less", "noise", "output", "fixed", "number", "sample", "we", "arrive", "give", "leaf", "node", "probability", "proportional", "integral", "Gaussian", "over", "corresponding", "cell", "correct", "weight", "however", "we", "tree", "store", "value", "point", "cell", "correct", "we", "keep", "track", "-lrb-", "unrounded", "-rrb-", "expect", "number", "sample", "reach", "leaf", "compute", "probability", "which", "we", "should", "have", "reach", "point", "evaluate", "Gaussian", "return", "weight", "which", "latter", "divide", "former", "weighted", "importance", "sampling", "describe", "-lsb-", "Bekaert", "et", "al.", "2000", "-rsb-", "context", "radiosity", "correction", "allow", "we", "use", "piecewise", "quadratic", "approximation", "gaussian", "-lrb-", "give", "convolution", "three", "identical", "rect", "filter", "-rrb-", "while", "descend", "tree", "its", "integral", "easier", "compute", "than", "Gaussian", "see", "Algorithm", "relevant", "snippet", "C++", "code", "recall", "we", "d-dimensional", "datum", "point", "reduce", "during", "tree", "building", "we", "use", "sample", "when", "query", "tree", "we", "filter", "datum", "set", "first", "construct", "we", "gaussian", "kdtree", "tree", "construction", "must", "process", "-lrb-", "-rrb-", "node", "each", "level", "tree", "do", "-lrb-", "-rrb-", "work", "per", "node", "we", "splitting", "scheme", "balance", "tree", "so", "we", "can", "expect", "depth", "-lrb-", "log", "-rrb-", "tree", "construction", "therefore", "take", "-lrb-", "nd", "log", "-rrb-", "time", "we", "initialize", "leaf", "node", "have", "value", "zero", "do", "gaussian", "query", "sample", "each", "input", "datum", "point", "scatter", "value", "tree", "gaussian", "query", "have", "runtime", "bound", "-lrb-", "-lrb-", "log", "-rrb-", "-rrb-", "so", "stage", "take", "-lrb-", "sn", "-lrb-", "log", "-rrb-", "-rrb-", "time", "next", "we", "blur", "gaussian", "query", "each", "leaf", "node", "which", "gather", "nearby", "value", "cost", "-lrb-", "sm", "-lrb-", "log", "-rrb-", "-rrb-", "finally", "we", "slice", "gaussian", "query", "each", "input", "position", "cost", "-lrb-", "sn", "-lrb-", "log", "-rrb-", "-rrb-", "all", "result", "total", "complexity", "-lrb-", "-lrb-", "-lrb-", "-rrb-", "log", "sd", "-rrb-", "-rrb-", "result", "simplify", "expression", "-lrb-", "dn", "log", "-rrb-", "give", "earlier", "once", "tree", "build", "all", "stage", "we", "algorithm", "data-parallel", "across", "query", "mind", "we", "implement", "algorithm", "CUDA", "-lsb-", "Buck", "2007", "-rsb-", "run", "NVIDIA", "GeForce", "GTX", "260", "we", "observe", "typical", "speedup", "10x", "over", "we", "single-threaded", "CPU", "implementation", "run", "Intel", "core", "duo", "e6400", "2.13", "GHz", "few", "interesting", "issue", "relate", "run", "algorithm", "GPU", "firstly", "recursion", "query", "method", "algorithm", "possible", "GPU", "which", "have", "function", "call", "stack", "we", "convert", "recursive", "code", "iterative", "code", "store", "argument", "pend", "call", "query", "method", "share", "memory", "each", "thread", "block", "take", "work", "from", "structure", "when", "idle", "work", "represent", "leaf", "node", "thread", "either", "scatter", "memory", "-lrb-", "splat", "-rrb-", "gather", "-lrb-", "blur", "slice", "-rrb-", "use", "atomic", "float", "point", "add", "memory", "either", "case", "work", "represent", "inner", "node", "thread", "walk", "sample", "down", "tree", "until", "reach", "leaf", "node", "diverge", "over", "split", "pend", "work", "structure", "fill", "thread", "revert", "independently", "simulate", "each", "sample", "case", "single", "sample", "algorithm", "become", "tail-recursive", "can", "convert", "iteration", "without", "use", "extra", "space", "secondly", "build", "kd-tree", "GPU", "difficult", "have", "be", "subject", "recent", "research", "-lrb-", "-lsb-", "Zhou", "et", "al.", "2008", "-rsb-", "-rrb-", "stage", "we", "again", "mimic", "recursive", "structure", "CPU", "algorithm", "use", "explicit", "pend", "work", "queue", "store", "global", "graphic", "memory", "we", "algorithm", "build", "tree", "stage", "breadth-first", "manner", "use", "pair", "queue", "contain", "build", "job", "initial", "few", "large", "build", "job", "CPU", "run", "algorithm", "recursively", "use", "GPU", "kernel", "accelerate", "task", "bound", "box", "computation", "sort", "datum", "over", "pivot", "once", "enough", "build", "job", "parallelize", "across", "they", "effectively", "GPU", "take", "over", "each", "stage", "all", "job", "from", "first", "queue", "process", "create", "same", "number", "node", "new", "job", "create", "build", "any", "child", "place", "second", "queue", "between", "stage", "queue", "swap", "final", "phase", "after", "construction", "each", "node", "parallel", "walk", "up", "tree", "root", "calculate", "min", "max", "graphic", "card", "typically", "have", "less", "memory", "than", "host", "system", "so", "may", "able", "fit", "all", "vector", "memory", "tree", "building", "even", "final", "tree", "only", "use", "-lrb-", "md", "-rrb-", "memory", "overcome", "we", "build", "tree", "use", "large", "random", "subset", "datum", "we", "perform", "two-phase", "query", "include", "vector", "be", "initially", "select", "first", "we", "parallelize", "across", "input", "vector", "send", "each", "leaf", "node", "contain", "we", "parallelize", "across", "leaf", "node", "process", "vector", "arrive", "each", "locally", "extend", "tree", "necessary", "initial", "random", "subset", "select", "cover", "space", "well", "we", "typically", "see", "only", "small", "growth", "tree", "datum", "set", "too", "large", "fit", "host", "memory", "we", "can", "pick", "some", "position", "dimension", "large", "extent", "subdivide", "datum", "overlap", "block", "process", "each", "block", "individually", "typically", "dimension", "largest", "extent", "those", "represent", "spatial", "coordinate", "make", "block", "easy", "we", "have", "describe", "high-speed", "low-memory", "way", "compute", "filter", "set", "value", "-lrb-", "equation", "-rrb-", "every", "value", "replace", "weighted", "linear", "combination", "all", "other", "value", "weight", "give", "gaussian", "function", "distance", "between", "arbitrary", "vector", "associate", "each", "value", "very", "general", "method", "which", "we", "now", "apply", "three", "particular", "problem", "each", "which", "have", "be", "solve", "its", "own", "separate", "way", "past", "bilateral", "filter", "first", "propose", "work", "-lsb-", "Aurich", "Weule", "1995", "-rsb-", "-lsb-", "Tomasi", "Manduchi", "1998", "-rsb-", "-lsb-", "Smith", "Brady", "1997", "-rsb-", "non-linear", "filter", "replace", "each", "pixel", "value", "weighted", "average", "all", "pixel", "value", "weight", "respect", "distance", "both", "position", "color", "small", "spatial", "extent", "effective", "way", "denoise", "large", "spatial", "extent", "use", "decomposition", "base", "detail", "layer", "-lsb-", "Durand", "Dorsey", "2002", "-rsb-", "accelerate", "filter", "use", "subsample", "conjunction", "piecewise", "linear", "approximation", "spatial", "domain", "-lsb-", "Chen", "et", "al.", "2007", "-rsb-", "accelerate", "filter", "same", "way", "treat", "three-dimensional", "bilateral", "grid", "also", "apply", "grid", "related", "problem", "-lsb-", "Weiss", "2006", "-rsb-", "take", "different", "approach", "accelerate", "filter", "maintain", "partial", "histogram", "during", "scan", "image", "which", "make", "cheap", "compute", "local", "histogram", "any", "one", "pixel", "fly", "from", "which", "bilateral", "filter", "can", "approximate", "bilateral", "grid", "equivalent", "decouple", "position", "image", "manifold", "volume", "from", "value", "store", "along", "most", "common", "implementation", "bilateral", "filter", "directly", "evaluate", "appropriate", "weighted", "sum", "each", "pixel", "run", "faster", "than", "-lrb-", "-rrb-", "imply", "equation", "only", "consider", "neighbour", "pixel", "within", "some", "small", "number", "spatial", "standard", "deviation", "approach", "fine", "small", "spatial", "standard", "deviation", "run", "time", "scale", "square", "spatial", "standard", "deviation", "thus", "process", "10", "megapixel", "image", "use", "spatial", "standard", "deviation", "more", "than", "16", "pixel", "take", "hour", "-lrb-", "figure", "-lrb-", "-rrb-", "-rrb-", "fortunately", "human", "eye", "more", "sensitive", "luminance", "variation", "than", "chrominance", "variation", "demosaicing", "algorithm", "exploit", "so", "most", "photograph", "full", "resolution", "have", "locally", "constant", "chrominance", "when", "spatial", "standard", "deviation", "small", "enough", "condition", "hold", "large", "enough", "naive", "algorithm", "run", "slowly", "3d", "bilateral", "grid", "perform", "well", "-lrb-", "see", "Figure", "-rrb-", "one", "way", "respect", "full", "color", "distance", "extend", "bilateral", "grid", "five", "dimension", "represent", "two", "spatial", "three", "color", "dimension", "image", "describe", "-lsb-", "Paris", "Durand", "2009", "-rsb-", "we", "implement", "grid", "use", "tent", "filter", "splat", "slice", "Gaussian", "blur", "filter", "width", "design", "so", "combined", "effect", "three", "approximate", "gaussian", "blur", "standard", "deviation", "one", "while", "result", "very", "close", "naive", "bilateral", "filter", "-lrb-", "figure", "-lrb-", "-rrb-", "-rrb-", "memory", "usage", "prohibitive", "small", "filter", "size", "-lrb-", "figure", "-lrb-", "-rrb-", "-rrb-", "sample", "grid", "place", "proportionally", "filter", "size", "furthermore", "run", "time", "memory", "use", "both", "scale", "exponentially", "so", "grid", "generalize", "poorly", "higher", "dimensional", "filter", "gaussian", "kd-tree", "we", "now", "apply", "gaussian", "kd-tree", "describe", "section", "task", "value", "vector", "-lrb-", "homogeneous", "-rrb-", "pixel", "color", "position", "vector", "location", "-lrb-", "-rrb-", "space", "scale", "inverse", "respective", "standard", "deviation", "after", "perform", "some", "exploratory", "experiment", "we", "settle", "32", "16", "sample", "standard", "devation", "11", "11", "11", "splat", "blur", "slice", "respectively", "we", "do", "use", "we", "faster", "GPU", "implementation", "experiment", "so", "we", "can", "provide", "fair", "comparison", "against", "other", "method", "we", "can", "see", "from", "Figure", "-lrb-", "-rrb-", "memory", "use", "initially", "bound", "drop", "gradually", "higher", "spatial", "standard", "deviation", "space", "more", "coarsely", "sample", "timing", "result", "Figure", "-lrb-", "-rrb-", "show", "method", "respect", "color", "distance", "we", "perform", "best", "moderate", "standard", "deviation", "effect", "further", "illustrate", "Figure", "which", "show", "output", "produce", "various", "technique", "Figure", "-lrb-", "-rrb-", "show", "we", "what", "we", "compute", "quite", "bilateral", "filter", "difference", "relate", "sparsity", "we", "sampling", "consider", "bilateral", "filter", "hard", "edge", "between", "black", "region", "white", "region", "all", "sample", "we", "tree", "either", "black", "white", "pixel", "single", "large", "gaussian", "blur", "range-domain", "space", "may", "allow", "some", "energy", "transfer", "between", "two", "slightly", "gray", "either", "side", "boundary", "however", "each", "stage", "we", "algorithm", "represent", "smaller", "blur", "possible", "energy", "cross", "boundary", "during", "any", "stage", "leave", "input", "unchanged", "instead", "be", "line", "gray", "pixel", "along", "boundary", "serve", "step", "stone", "combined", "effect", "three", "stage", "could", "transfer", "energy", "between", "black", "white", "pixel", "via", "those", "gray", "pixel", "we", "version", "bilateral", "filter", "therefore", "respect", "hard", "boundary", "slightly", "more", "than", "soft", "one", "which", "may", "fact", "benefit", "most", "application", "behaviour", "undesirable", "one", "can", "set", "which", "force", "-lrb-", "i.e.", "we", "allocate", "one", "leaf", "node", "per", "input", "pixel", "-rrb-", "set", "so", "full", "blur", "happen", "during", "blur", "stage", "only", "parameter", "typical", "RMS", "difference", "between", "we", "output", "naive", "output", "drop", "0.002", "half", "quantization", "limit", "however", "under", "setting", "more", "sample", "require", "splat", "slice", "reduce", "performance", "conclusion", "graph", "tell", "mixed", "story", "we", "recommend", "use", "naive", "approach", "small", "spatial", "standard", "deviation", "when", "accuracy", "important", "when", "locally-constant", "chrominance", "assumption", "hold", "across", "filter", "size", "desire", "three-dimensional", "bilateral", "grid", "best", "option", "very", "large", "filter", "five", "dimensional", "grid", "superior", "moderate", "filter", "size", "spatial", "standard", "deviation", "between", "two", "ten", "pixel", "gaussian", "kd-tree", "perform", "best", "appear", "tipping", "point", "which", "grid", "method", "comparable", "tree", "we", "scale", "higher", "follow", "section", "we", "begin", "see", "result", "much", "more", "difficult", "obtain", "exist", "method", "one", "could", "include", "local", "gradient", "well", "output", "any", "set", "local", "filter", "one", "add", "dimension", "position", "way", "become", "more", "specific", "about", "what", "constitute", "good", "match", "between", "two", "pixel", "desirable", "simultaneously", "extend", "spatial", "extent", "filter", "search", "similar", "pixel", "over", "wider", "area", "limit", "expansion", "non-local", "means", "filter", "though", "effective", "filter", "give", "purpose", "may", "lie", "anywhere", "along", "continuum", "between", "bilateral", "non-local", "means", "non-local", "means", "first", "propose", "-lsb-", "Buades", "et", "al.", "2005", "-rsb-", "average", "pixel", "other", "pixel", "whose", "local", "neighborhood", "contain", "similar", "image", "feature", "non-local", "means", "evaluate", "equation", "set", "-lrb-", "homogeneous", "-rrb-", "color", "pixel", "set", "window", "pixel", "value", "around", "pixel", "i.", "non-local", "means", "thus", "very", "effective", "self-similar", "image", "image", "need", "contain", "explicitly", "repeat", "element", "self-similar", "example", "every", "pixel", "along", "straight", "edge", "between", "two", "flat", "region", "have", "similar", "local", "neighborhood", "every", "other", "pixel", "along", "edge", "non-local", "means", "particularly", "effective", "denoise", "without", "remove", "detail", "because", "make", "smoothness", "assumption", "its", "image", "model", "non-local", "means", "however", "intractably", "slow", "its", "basic", "form", "every", "image", "patch", "must", "compare", "every", "other", "patch", "result", "complexity", "-lrb-", "-rrb-", "pixel", "patch", "simplest", "way", "ameliorate", "reduce", "search", "small", "local", "search", "window", "when", "apply", "non-local", "means", "gaussian", "kd-tree", "can", "view", "member", "family", "technique", "discuss", "above", "gridded", "approach", "work", "here", "due", "exponential", "memory", "use", "computational", "complexity", "respect", "dimension", "gaussian", "kd-tree", "can", "use", "accelerate", "non-local", "means", "exactly", "same", "way", "accelerate", "bilateral", "filter", "use", "same", "kd-tree", "implementation", "do", "we", "construct", "position", "vector", "out", "patch", "around", "each", "pixel", "input", "rather", "than", "-lrb-", "-rrb-", "vector", "use", "bilateral", "filter", "dimensionality", "above", "around", "50", "example", "when", "use", "large", "patch", "gaussian", "kd-tree", "begin", "exhibit", "poor", "sampling", "behavior", "time", "any", "give", "sample", "have", "reach", "leaf", "node", "have", "be", "split", "over", "log", "different", "partition", "ameliorate", "preprocess", "we", "perform", "pca", "over", "set", "patch", "compute", "set", "filter", "best", "capture", "variance", "patch", "pca", "help", "even", "we", "do", "use", "reduce", "dimensionality", "transformation", "decorrelate", "dimension", "order", "they", "from", "most", "least", "variance", "across", "datum", "set", "allow", "kd-tree", "split", "dimension", "largest", "variance", "first", "which", "now", "axis-aligned", "once", "query", "make", "down", "leaf", "node", "dimension", "have", "yet", "be", "split", "over", "those", "lowest", "variation", "over", "datum", "set", "so", "much", "more", "likely", "query", "point", "close", "point", "store", "leaf", "node", "practice", "also", "advantageous", "simply", "drop", "dimension", "small", "eigenvalue", "speed", "up", "algorithm", "without", "noticeably", "change", "result", "very", "noisy", "scene", "-lrb-", "top", "Figure", "-rrb-", "fact", "improve", "result", "slightly", "denoise", "position", "vector", "result", "we", "use", "we", "algorithm", "apply", "non-local", "means", "several", "type", "datum", "Figure", "show", "we", "algorithm", "use", "generate", "comparison", "between", "non-local", "means", "non-local", "means", "spatial", "term", "add", "bilateral", "filter", "Figure", "we", "show", "result", "volume", "datum", "set", "bacterium", "produce", "cryo-electron", "tomography", "-lsb-", "Amat", "et", "al.", "2008", "-rsb-", "volume", "typically", "very", "noisy", "because", "bombard", "specimen", "large", "number", "electron", "tend", "alter", "they", "mean", "few", "electron", "must", "use", "limit", "signal-to-noise", "ratio", "obtainable", "non-local", "means", "able", "robustly", "use", "nearby", "similar", "information", "improve", "image", "easiest", "way", "acquire", "similar", "information", "digital", "camera", "take", "second", "noisy", "photograph", "same", "scene", "entire", "burst", "shot", "property", "make", "nonlocal", "means", "excellent", "denoise", "from", "burst", "unaligned", "shot", "which", "may", "contain", "object", "deform", "change", "appearance", "exist", "method", "denoise", "from", "multiple", "shot", "video", "either", "globally", "align", "average", "-lrb-", "work", "-lsb-", "Telleen", "et", "al.", "2007", "-rsb-", "-lsb-", "Adams", "et", "al.", "2008", "-rsb-", "-rrb-", "search", "explicit", "block", "match", "-lrb-", "-lsb-", "Avanaki", "2006", "-rsb-", "-rrb-", "more", "robust", "approach", "work", "-lsb-", "Bennett", "McMillan", "2005", "-rsb-", "which", "average", "either", "space", "time", "appropriate", "do", "denoise", "move", "textured", "object", "-lsb-", "Buades", "et", "al.", "2008", "-rsb-", "find", "apply", "non-local", "means", "volume", "produce", "better", "output", "than", "explicit", "search", "match", "block", "pixel", "trajectory", "Figure", "show", "result", "from", "apply", "non-local", "means", "two", "burst", "run", "time", "we", "implementation", "non-local", "means", "typically", "spend", "half", "perform", "patch", "pca", "-lrb-", "which", "implement", "stack", "convolution", "accelerate", "GPU", "-rrb-", "half", "compute", "denoising", "time", "each", "portion", "typically", "under", "one", "minute", "per", "megapixel", "16", "dimension", "regardless", "size", "search", "due", "success", "3d", "range", "acquisition", "technique", "denoising", "mesh", "point", "cloud", "active", "research", "area", "geometry", "processing", "goal", "same", "image", "denoising", "remove", "noise", "while", "best", "preserve", "underlying", "signal", "which", "case", "come", "set", "3d", "point", "-lrb-", "potentially", "mesh", "connectivity", "-rrb-", "sample", "from", "some", "surface", "isotropic", "geometry", "denoising", "method", "-lsb-", "Taubin", "1995", "-rsb-", "perform", "same", "amount", "smooth", "irrespective", "whether", "sharp", "feature", "edge", "corner", "present", "input", "which", "result", "feature", "appear", "rounded-off", "result", "recently", "several", "approach", "feature-preserving", "denoising", "have", "be", "propose", "base", "geometry", "diffusion", "-lsb-", "desbrun", "et", "al.", "1999", "-rsb-", "projection", "-lsb-", "Fleischman", "et", "al.", "2005", "-rsb-", "bilateral", "filter", "-lsb-", "Jones", "et", "al.", "2003", "-rsb-", "-lsb-", "Fleishman", "et", "al.", "2003", "-rsb-", "its", "extension", "non-local", "means", "-lsb-", "Yoshizawa", "et", "al.", "2006", "-rsb-", "section", "we", "show", "since", "gaussian", "kd-tree", "do", "place", "any", "structural", "constraint", "input", "datum", "can", "use", "filter", "geometry", "refer", "once", "again", "equation", "which", "state", "produce", "output", "value", "point", "generalize", "bilateral", "filter", "average", "together", "set", "value", "weight", "gaussian", "function", "distance", "between", "each", "point", "main", "difficulty", "adapt", "bilateral", "filter", "framework", "from", "image", "domain", "3d", "geometry", "general", "we", "input", "set", "3d", "point", "coordinate", "-lrb-", "-rrb-", "describe", "surface", "which", "do", "come", "parameterize", "over", "some", "regularly", "sample", "domain", "therefore", "unlike", "image", "natural", "decomposition", "input", "position", "-lrb-", "-rrb-", "value", "-lrb-", "-rrb-", "require", "equation", "two", "approach", "decompose", "set", "3d", "point", "spatial", "signal", "domain", "bilateral", "filter", "mesh", "have", "be", "propose", "recently", "-lsb-", "Jones", "et", "al.", "2003", "-rsb-", "compute", "filter", "coordinate", "each", "mesh", "vertex", "weighted", "sum", "its", "projection", "onto", "mesh", "face", "within", "point?s", "neighborhood", "case", "position", "equation", "centroid", "neighbor", "triangle", "value", "projection", "each", "neighbor", "vertex", "projection", "onto", "tangent", "plane", "come", "position", "height", "above", "tangent", "plane", "become", "value", "filter", "vertex", "move", "along", "its", "normal", "average", "height", "compute", "bilateral", "filter", "approach", "-lsb-", "Fleishman", "et", "al.", "2003", "-rsb-", "have", "be", "extend", "non-local", "means", "-lsb-", "Yoshizawa", "et", "al.", "2006", "-rsb-", "add", "geometric", "descriptor", "each", "vertex", "mesh", "above", "approach", "solve", "problem", "separate", "3d", "point", "coordinate", "spatial", "datum", "component", "represent", "neighbor", "each", "vertex", "its", "own", "local", "coordinate", "system", "however", "two", "problem", "use", "decomposition", "-lsb-", "Jones", "et", "al.", "2003", "-rsb-", "-lsb-", "Fleishman", "et", "al.", "2003", "-rsb-", "equation", "first", "since", "local", "projection", "use", "each", "value", "sum", "produce", "output", "value", "depend", "both", "coordinate", "vertex", "vertex", "which", "do", "give", "we", "one-to-one", "mapping", "between", "value", "position", "require", "efficiently", "compute", "blur", "second", "problem", "parameterization", "only", "make", "sense", "locally", "around", "each", "vertex", "since", "use", "tangent", "plane", "approximation", "geometry", "non-local", "means", "denoise", "we", "need", "average", "value", "potentially", "far", "apart", "space", "long", "local", "geometry", "look", "similar", "example", "scale", "front", "back", "dragon", "Figure", "10", "however", "projection", "point", "back", "mesh", "onto", "local", "frame", "point", "front", "can", "very", "far", "away", "from", "especially", "surface", "orientation", "different", "even", "local", "geometry", "similar", "we", "would", "prefer", "global", "notion", "value", "make", "sense", "across", "whole", "mesh", "Computing", "Global", "Positions", "value", "produce", "globally", "meaningful", "value", "we", "can", "average", "across", "all", "point", "mesh", "we", "treat", "feature-preserving", "mesh", "smoothing", "problem", "add", "back", "lose", "detail", "smooth", "base", "layer", "approach", "often", "use", "mesh", "editing", "-lsb-", "sorkine", "et", "al.", "2004", "-rsb-", "where", "smooth", "base", "layer", "use", "produce", "large-scale", "geometric", "deformation", "fine", "detail", "add", "back", "offset", "from", "deform", "geometry", "let", "input", "mesh", "let", "...", "vertex", "position", "vertex", "normal", "compute", "average", "face", "normal", "face", "incident", "vertex", "we", "apply", "laplacian", "smoothing", "produce", "smooth", "base", "layer", "vertex", "position", "normal", "laplacian", "smoothing", "successfully", "remove", "noise", "from", "mesh", "smooth", "across", "sharp", "feature", "difference", "between", "vertex", "coordinate", "give", "we", "noisy", "detail", "layer", "result", "detail", "vector", "translation", "invariant", "however", "still", "dependent", "surface", "orientation", "achieve", "invariance", "rigid", "transformation", "we", "express", "each", "detail", "vector", "principal", "coordinate", "frame", "vertex", "m.", "each", "vertex", "smooth", "base", "layer", "we", "compute", "coordinate", "frame", "-lrb-", "-rrb-", "where", "direction", "minimum", "maximum", "curvature", "vector", "compute", "smooth", "base", "layer", "so", "corrupt", "noise", "final", "offset", "vector", "each", "vertex", "compute", "projection", "principal", "curvature", "frame", "which", "express", "homogeneous", "coordinate", "give", "value", "vector", "each", "vertex", "give", "we", "set", "value", "which", "meaningful", "globally", "can", "average", "across", "entire", "input", "use", "regular", "vector", "addition", "second", "component", "non-local", "means", "denoise", "position", "value", "equation", "which", "should", "relate", "some", "measure", "neighborhood", "similarity", "we", "neighborhood", "descriptor", "should", "robust", "noise", "invariant", "rigid", "transformation", "represent", "vector", "we", "use", "well-known", "spin", "image", "descriptor", "-lsb-", "Johnson", "Hebert", "1999", "-rsb-", "which", "orientationinvariant", "histogram", "cylindrical", "coordinate", "point", "within", "give", "neighborhood", "point", "normal", "spin", "value", "-lrb-", "-rrb-", "point", "neighborhood", "define", "build", "spin", "image", "surface", "patch", "around", "we", "quantize", "pair", "-lrb-", "-rrb-", "set", "bin", "since", "spin", "image", "most", "sensitive", "orientation", "surface", "normal", "we", "use", "normal", "from", "base", "layer", "point", "coordinate", "from", "original", "mesh", "form", "spin", "image", "normal", "robust", "rest", "computation", "relatively", "robust", "noise", "due", "binning", "perform", "compute", "spin", "image", "we", "use", "bin", "value", "10", "bin", "value", "bin", "size", "equal", "sample", "spacing", "mesh", "recommend", "-lsb-", "Johnson", "Hebert", "1999", "-rsb-", "give", "we", "50-dimensional", "position", "vector", "once", "value", "position", "compute", "we", "blur", "use", "gaussian", "kd-tree", "produce", "smooth", "detail", "vector", "which", "add", "back", "offset", "base", "layer", "produce", "final", "denoised", "result", "result", "we", "apply", "we", "non-local", "means", "denoise", "algorithm", "several", "example", "mesh", "corrupt", "gaussian", "noise", "all", "example", "we", "use", "20", "iteration", "laplacian", "smoothing", "produce", "base", "mesh", "smooth", "detail", "layer", "filter", "standard", "deviation", "0.05", "spin", "image", "space", "Figure", "10", "show", "result", "apply", "non-local", "means", "smooth", "dragon", "model", "corrupt", "gaussian", "noise", "denoising", "particularly", "effective", "recover", "self-similar", "area", "mesh", "scale", "back", "ridge", "dragon", "Figure", "11", "we", "apply", "non-local", "means", "noisy", "model", "many", "sharp", "feature", "fine", "detail", "Notice", "we", "able", "maintain", "sharp", "edge", "carving", "box", "well", "recover", "fine", "detail", "petal", "model", "have", "many", "planar", "area", "so", "also", "particularly", "suitable", "algorithm", "-lsb-", "Jones", "et", "al.", "2003", "-rsb-", "which", "use", "local", "planar", "approximation", "right", "Figure", "11", "we", "show", "result", "apply", "bilateral", "smoothing", "produce", "equivalent", "amount", "noise", "reduction", "flat", "area", "while", "bilateral", "smoothing", "preserve", "edge", "better", "than", "laplacian", "smoothing", "use", "produce", "base", "layer", "non-local", "means", "able", "recover", "more", "detail", "petal", "section", "we", "demonstrate", "gaussian", "kd-tree", "can", "use", "non-local", "means", "smoothing", "geometry", "we", "method", "rely", "decompose", "input", "base", "detail", "layer", "decomposition", "have", "also", "be", "address", "context", "mesh", "parameterization", "-lsb-", "Sheffer", "et", "al.", "2006", "-rsb-", "we", "expect", "variety", "parametrization", "decomposition", "approach", "can", "use", "we", "framework", "finally", "we", "expect", "similar", "method", "can", "apply", "point", "cloud", "denoising", "we", "have", "describe", "novel", "method", "compute", "broad", "class", "non-linear", "filter", "which", "can", "describe", "equation", "base", "weighted", "importance", "sampling", "modify", "kd-tree", "class", "filter", "include", "bilateral", "filter", "joint", "bilateral", "filter", "non-local", "means", "filter", "related", "filter", "which", "value", "average", "other", "value", "consider", "nearby", "some", "high-dimensional", "space", "bilateral", "filter", "we", "compare", "method", "5d", "extension", "bilateral", "grid", "-lsb-", "Paris", "Durand", "2006", "-rsb-", "find", "which", "method", "superior", "depend", "filter", "size", "use", "higher", "dimensional", "filter", "non-local", "means", "we", "tree-based", "filter", "exhibit", "excellent", "performance", "its", "runtime", "memory", "use", "both", "scale", "linearly", "dimension", "we", "method", "require", "particular", "structure", "input", "so", "we", "also", "apply", "task", "denoise", "geometry", "produce", "novel", "non-local", "means", "filter", "mesh", "firstly", "we", "tree", "building", "take", "significant", "fraction", "we", "total", "runtime", "so", "we", "use", "very", "simple", "splitting", "scheme", "secondly", "case", "value", "many", "more", "than", "log", "-lrb-", "-rrb-", "dimension", "splitting", "take", "place", "we", "tree", "do", "adequately", "constrain", "sample?s", "location", "before", "reach", "leaf", "many", "sample", "return", "very", "small", "weight", "attach", "work", "we", "solve", "throw", "away", "least", "important", "dimension", "pca", "may", "other", "tree", "structure", "still", "amenable", "weighted", "importance", "sampling", "while", "more", "strongly", "constrain", "sample", "location", "may", "also", "beneficial", "store", "value", "leaf", "cell", "rather", "than", "point", "somewhere", "within", "they", "would", "improve", "complexity", "algorithm", "remove", "distance", "evaluation", "currently", "require", "compute", "correct", "probability", "leaf", "node", "make", "importance", "sampling", "exact", "rather", "than", "weighted", "would", "compute", "different", "function", "value", "one", "far", "more", "dependent", "specific", "way", "which", "tree", "build", "finally", "tree", "traversal", "extremely", "irregular", "algorithm", "speedup", "we", "observe", "from", "we", "GPU", "implementation", "significantly", "less", "than", "theoretically", "possible", "more", "intelligent", "software", "caching", "portion", "tree", "other", "datum", "structure", "may", "speed", "up", "further", "work", "support", "Reed-Hodgson", "Stanford", "Graduate", "Fellowship", "NDSEG", "Graduate", "Fellowship", "from", "United", "States", "Department", "Defense", "NSF", "Graduate", "Fellowship", "from", "National", "Science", "Foundation", "thanks", "also", "Justin", "Talbot", "Leonidas", "Guibas", "Jeremy", "Sugerman", "fruitful", "discussion", "advice", "Hao", "Li", "provide", "we", "mesh", "datum", "also", "we", "human", "canine", "figure", "subject" ],
  "content" : "If we have n values to filter, and each is assigned a position in a d-dimensional space, then our space complexity is O(dn) and our time complexity is O(dn log n), whereas existing methods are typically either exponential in d or quadratic in n. Let us begin with the simple case of a bilateral filter. However, as we argue in Section 3.1, the memory required to represent the grid grows exponentially with the number of dimensions, as does the time required by each stage of the algorithm. It would be preferable to subsample this set of neighbours in a statistically efficient manner. These queries are used to implement the embedding, blurring, and sampling of the space as described in Section 2, and they do so at a computational complexity independent of the filter size and linear in the dimensionality. Our method is in fact slightly faster when the search is completely unbounded, as there are fewer dimensions to consider. In Section 3.2, we demonstrate fast non-local means for denoising space-time volumes. Filtering is most generally described by replacing each value v i in a set of size n with a linear combination of all other values v j : We assume that values are represented by homogeneous coordinates, and the homogeneous coordinate is filtered along with the others. A joint bilateral filter (described by [Eisemann and Durand 2004] and [Petschnigg et al. 2004]) instead uses color distance from some other image. In this formulation, first proposed by [D.Barash 2002], pixel values v i are now associated with positions p i in a five-dimensional  space whose axes are (x, y, r, g, b), scaled by the inverse of the standard deviations of the filter in the respective dimensions. The Improved Fast Gauss Transform groups vectors p i into clusters of radius proportional to the standard deviation of the desired Gaussian, and computes Taylor series approximations of the result at each cluster center. It is an effective tool for very large radius blurs, as few clusters are needed. Unfortunately the standard deviations commonly used in filtering are small enough that there are few data points per cluster, and little benefit is derived from the clustering. We find that when applied to bilateral filtering, the Improved Fast Gauss Transform is in fact slower than a naive filter implementation for typical parameter settings. Firstly, interactions further than three standard deviations apart can be safely ignored (as the weights become very small) making this a collision detection problem for spheres in d-dimensional space. Details of our tree construction are in Section 2.1. Thirdly, Gaussian filtering can be accelerated by computing the filter at a lower resolution and then interpolating the result. We con- struct a reduced set with only m positions and values, downsample to it using a Gaussian kernel of size ? s , blur the smaller set with a Gaussian filter of size ? b , then upsample to the original positions with a Gaussian kernel of size ? s . We consider the sampling dense enough when the maximum spacing between data points in the reduced space is ? s . This allows for more coarsely spaced points, but increases the number of samples required during the Monte-Carlo splatting and slicing. We derive our reduced set of size m during tree building, described below. Our Gaussian kd-tree stores a cloud of m points in d dimensions, one point per leaf, and is designed to allow for fast importancesampled queries of these points (Section 2.2). The key difference between this tree and a conventional kd-tree is that we store ? max and ? min as well as ? cut . The maximum bound is computed as the minimum cut value of all ancestors which cut along the same dimension and have a larger cut value. The minimum bound is similarly the maximum cut value of all ancestors which cut along the same dimension and have a smaller cut value. See Figure 4 for a comparison of the tree to a bilateral grid. Fortunately we know ahead of time that we will only ever sample at the positions used to construct the tree. In raytracing, for example, this means it can be advantageous to have a highly unbalanced tree which carves off empty space and commonly hit areas early. However, we never sample in unpopulated areas, so how we deal with empty space is irrelevant, and for typical data each of our leaf nodes is as likely to be reached as any other, so the tree should be balanced. To recursively turn a list of positions p i into a tree, we first compute their bounding box. This scheme descends to cells that have a small diagonal as quickly as possible. While this has the advantage of placing the most commonly accessed leaves closer to the root of the tree, in practice we found that it did not improve performance. A query into our Gaussian tree is designed to facilitate gathers from (or scatters to) values around a given query position, for the purpose of computing an importance-sampled approximation of Equation 5. If the number of samples is set to infinity, the list returned will include all points within three standard deviations of the query, with weights proportional to a Gaussian kernel of the given standard deviation (w i = e ?|q?p i | 2 /2? ). At each inner node ? we compute the expected number of samples that lie within the left and right child by computing the area of the Gaussian, truncated to with ? min and ? max , that lies on either side of ? cut . The expected number of samples that split each way are rounded down to the nearest integer, and that many samples are assigned to the left or right child respectively. This splitting scheme saves work compared to individually simulating every sample, resulting in a runtime which is sublinear in the number of samples, and bounded by the number of cells overlap- ping a query. It also stratifies the sampling, resulting in less noise in the output for a fixed number of samples. We arrive at a given leaf node with a probability proportional to the integral of the Gaussian over the corresponding cell. This is not the correct weight, however, as our tree stores values at points, not cells. To correct for this, we keep track of the (unrounded) expected number of samples to reach this leaf, compute the probability with which we should have reached this point by evaluating the Gaussian at it, and return a weight which is the latter divided by the former. This is weighted importance sampling, as described by [Bekaert et al. 2000] in the context of radiosity. This correction allows us to use a piecewise quadratic approximation to the Gaussian (given by the convolution of three identical rect filters) while descending the tree, as its integral is easier to compute than that of a Gaussian. See Algorithm 1 for the relevant snippets of C++ code. Recall that we start with n d-dimensional data points, reduced to m during tree building, and that we use s samples when querying the tree. We filter the data set by first constructing our Gaussian kdtree. Tree construction must process O(n) nodes at each level of the tree, doing O(d) work per node. Our splitting scheme balances  the tree, so we can expect a depth of O(log m). Tree construction therefore takes O(nd log m) time. We then initialize the leaf nodes to have a value of zero, and do a Gaussian query with s samples for each of the n input data points to scatter values into the tree. A Gaussian query has a runtime bounded by O(s(log m + d)), so this stage takes O(sn(log m + d)) time. Next we blur with a Gaussian query at each leaf node which gathers nearby values, and costs O(sm(log m + d)), and finally we slice with a Gaussian query at each input position for a cost of O(sn(log m + d)). This all results in a total complexity of O(n((s + d) log m + sd)). This results in the simplified expression O(dn log n) given earlier. Once the tree is built, all stages of our algorithm are data-parallel across queries. With this in mind we implemented the algorithm in CUDA [Buck 2007] and ran it on an NVIDIA GeForce GTX 260. We observed a typical speedup of 10x over our single-threaded CPU implementation running on an Intel Core 2 Duo E6400 at 2.13 GHz. There are a few interesting issues related to running the algorithm on the GPU. Firstly, the recursion of the query method in Algorithm 1 is not possible on the GPU, which has no function call stack. We convert the recursive code to iterative code by storing the arguments to pending calls to the query method in shared memory. Each thread in a block takes work from this structure when idle. If the work represents a leaf node, the thread either scatters to memory (for splatting), or gathers (for blurring or slicing), using atomic floating point adds to memory in either case. If the work represents an inner node the thread walks the samples down the tree until they reach a leaf node or diverge over a split. If the pending work structure fills, threads revert to independently simulating each sample. For the case of a single sample, Algorithm 1 becomes tail-recursive, and can be converted to iteration without using extra space. Secondly, building a kd-tree on the GPU is difficult, and has been the subject of recent research (such as [Zhou et al. 2008]). For this stage we again mimic the recursive structure of the CPU algorithm, using explicit pending work queues stored in global graphics memory. Our algorithm builds the tree in stages in a breadth-first manner using a pair of queues containing build jobs. For the initial few large build jobs, the CPU runs the algorithm recursively, using GPU kernels to accelerate the tasks of bounding box computation and sorting data over a pivot. Once there are enough build jobs to parallelize across them effectively, the GPU takes over. In each stage all the jobs from the first queue are processed, creating the same number of nodes, and the new jobs created to build any children are placed on the second queue. In between stages the queues are swapped. In a final phase after construction, each node ? in parallel walks up the tree to the root to calculate ? min and ? max . The graphics card typically has less memory than the host system, so it may not be able to fit all n vectors in memory for tree building, even if the final tree only uses O(md) memory. To overcome this, we build the tree using a large random subset of the data. We then perform a two-phase query to include the vectors that were not initially selected. First we parallelize across input vectors and send each to the leaf node that contains it. Then we parallelize across leaf nodes, and process the vectors that arrived at each to locally extend the tree if necessary. If the initial random subset selected covers the space well, we will typically see only a small growth of the tree. If the data set is too large to fit into host memory, we can pick some of the position dimensions with large extent and subdivide the data into overlapping blocks, processing each block individually. Typically the dimensions with largest extent will be those representing spatial coordinates, making blocking easy. We have described a high-speed, low-memory way to compute a filtering of a set of values (Equation 5), such that every value is replaced with a weighted linear combination of all other values, with  the weights given by a Gaussian function of the distance between arbitrary vectors associated with each value. This is a very general method, which we will now apply to three particular problems, each of which has been solved in its own separate way in the past. The bilateral filter, first proposed in the work of [Aurich and Weule 1995], [Tomasi and Manduchi 1998], and [Smith and Brady 1997], is a non-linear filter that replaces each pixel value with a weighted average of all pixel values, with weights respecting distance in both position and color. With small spatial extent it is an effective way to denoise, and with large spatial extent it is used for decomposition into base and detail layers. [Durand and Dorsey 2002] accelerated  the filter by using subsampling in conjunction with piecewise linear approximation in the spatial domain. [Chen et al. 2007] accelerates the filter in the same way by treating it as a three-dimensional bilateral grid, and also applies that grid to related problems. [Weiss 2006] takes a different approach, and accelerates the filter by maintaining partial histograms during a scan of the image, which makes it cheap to compute a local histogram at any one pixel on the fly, from which a bilateral filter can be approximated. In the bilateral grid, this is equivalent to decoupling the position of the image manifold in the volume from the values stored along it. The most common implementation of a bilateral filter directly evaluates the appropriate weighted sum at each pixel. It runs faster than the O(n 2 ) implied by Equation 5 by only considering neighbouring pixels within some small number of spatial standard deviations. This approach is fine for small spatial standard deviations, but running time scales with the square of the spatial standard deviation; thus, processing a 10 megapixel image using a spatial standard deviation of more than 16 pixels takes hours ( Figure 5(a) ). Fortunately, human eyes are more sensitive to luminance variation than chrominance variation, and demosaicing algorithms exploit this, so that most photographs at full resolution have locally constant chrominance. When the spatial standard deviation is small enough for this condition to hold, but large enough for a naive algorithm to run slowly, a 3D bilateral grid performs well (see Figure 5 ). One way to respect full color distance is to extend the bilateral grid to five dimensions, representing the two spatial and three color dimensions in an image, as described by [Paris and Durand 2009]. We implemented such a grid, using tent filters for splatting and slicing, and a Gaussian for blurring, with filter widths designed so that the combined effect of the three is an approximate Gaussian blur of standard deviation one. While the results are very close to the naive bilateral filter ( Figure 5(c) ), the memory usage is prohibitive for small filter sizes ( Figure 5(b) ), as samples in the grid are placed proportionally to the filter size. Furthermore, running time and memory use both scale exponentially with d, so the grid generalizes poorly to higher dimensional filters. The Gaussian kd-tree We now apply the Gaussian kd-tree described in Section 2 to this task. The value vectors v i are the (homogeneous) pixel colors, and the position vectors p i are their locations in (x, y, r, g, b) space, scaled by the inverse of the respective standard deviations. After performing some exploratory experiments, we ? settled ? on 8, 32, and ? 16 samples with standard devations of 1/ 11, 3/ 11, and 1/ 11, for splatting, blurring, and slicing respectively. We did not use our faster GPU implementation for these experiments, so that we can provide a fair comparison against the other methods. We can see from Figure 5(b) that the memory use is initially bounded, and then drops gradually with higher spatial standard deviations as the space is more coarsely sampled. The timing results in Figure 5(a) show that, of the methods that respect color distance, we perform the best at moderate standard deviations. This effect is further illustrated in Figure 6 , which shows the outputs produced by the various techniques. Figure 5(c) shows us that what we compute is not quite the bilateral filter. The difference is related to the sparsity of our sampling. Consider a bilateral filter of a hard edge between a black region and a white region. All the samples in our tree are either of black or white pixels. A single large Gaussian blur in range-domain space may allow for some energy transfer between the two, slightly graying either side of the boundary. However, each stage of our algorithm represents a smaller blur, and it is possible for no energy to cross the boundary during any stage, leaving the input unchanged. If instead there were a line of gray pixels along the boundary to serve as a stepping stone, then the combined effect of the three stages could transfer energy between black and white pixels via those gray pixels. Our version of the bilateral filter therefore respects hard boundaries slightly more than soft ones, which may in fact be a benefit in most applications. If this behaviour is undesirable, one can set ? s = 0, which forces n = m (i.e. we allocate one leaf node per input pixel), and then set ? b = 1, so that the full blur happens during the blur stage only. With these parameters, the typical RMS difference between our output and the naive output drops to 0.002, or half of the quantization limit. However, under these settings more samples are required for splatting or slicing, reducing performance. Conclusion The graphs tell a mixed story. We recommend using the naive approach for small spatial standard deviations when accuracy is important. When a locally-constant chrominance assumption holds across the filter size desired, the three-dimensional bilateral grid is the best option. For very large filters, the five- dimensional grid is superior. For moderate filter sizes, with spatial standard deviations between two and ten pixels, the Gaussian kd-tree performs the best. d = 5 appears to be a tipping point, at which grid methods are comparable to the tree. As we scale d higher in the following sections, we begin to see results much more difficult to obtain with existing methods. One could include local gradients as well, or the output of any set of local filters. As one adds dimensions to the position, and in this way becomes more specific about what constitutes a good match between two pixels, it is desirable to simultaneously extend the spatial extent of the filter, to search for similar pixels over a wider area. The limit of this expansion is the non-local means filter, though an effective filter for a given purpose may lie anywhere along the continuum between the bilateral and non-local means. Non-local means, first proposed by [Buades et al. 2005], averages pixels with other pixels whose local neighborhoods contain similar image features. That is, non-local means evaluates Equation 5 with v i set to the (homogeneous) color of pixel i and p i set to a window of pixel values around pixel i. Non-local means is thus very effective for self-similar images. An image need not contain explicitly repeated elements to be self-similar. For example, every pixel along a straight edge between two flat regions has a similar local neighborhood to every other pixel along that edge. Non-local means is particularly effective at denoising without removing detail because it makes no smoothness assumptions in its image model. Non-local means, however, is intractably slow in its basic form, as every image patch must be compared with every other patch, resulting in a complexity of O(f 2 n 2 ) for n pixels and f ?f patches. The simplest way to ameliorate this is to reduce the search to a small local search window. When applied to non-local means, the Gaussian kd-tree can be viewed as a member of this family of techniques. As discussed above, gridded approaches will not work here, due to the exponential memory use and computational complexity with respect to dimension. The Gaussian kd-tree can be used to accelerate non-local means in exactly the same way it accelerates bilateral filtering, using the same kd-tree implementation. To do this, we construct the position vectors p i out of patches around each pixel in the input, rather than the (r, g, b, x, y) vectors used for bilateral filtering. At dimensionalities above around 50, for example when using large patches, the Gaussian kd-tree begins to exhibit poor sampling behavior. By the time any given sample has reached a leaf node, it has been split over log m different partitions. To ameliorate this, as a preprocess we perform PCA over the set of patches to compute a set of filters that best capture the variance in a patch. PCA helps even if we do not use it to reduce dimensionality, as the transformation decorrelates the dimensions, and orders them from most to least variance across the data set. This allows kd-tree to split on dimensions with the largest variance first, which are now axis-aligned. Once a query makes it down to a leaf node, the dimensions that have not yet been split over are those with the lowest variation over the data set, so it is much more likely that the query point is close to the point stored in the leaf node. In practice, it is also advantageous to simply drop the dimensions with small eigenvalues. This speeds up the algorithm without noticeably changing the results. For very noisy scenes (such as the top of Figure 9 ) it in fact improved the results, as it slightly denoises the position vectors. Results We use our algorithm to apply non-local means to several types of data. Figure 7 shows our algorithm used to generate a comparison between non-local means, non-local means with a spatial term added, and bilateral filtering. In Figure 8 we show results on a volume data set of a bacteria produced by cryo-electron tomography by [Amat et al. 2008]. Such volumes are typically very noisy, because bombarding specimens with large numbers of electrons tends to alter them, meaning few electrons must be used, limiting the signal-to-noise ratio obtainable. Non-local means is able to robustly use nearby similar information to improve an image. The easiest way to acquire similar information on a digital camera is to take a second noisy photograph of the same scene, or an entire burst of shots. This property makes nonlocal means excellent for denoising from a burst of unaligned shots, which may contain objects that deform or change their appearance. Existing methods for denoising from multiple shots or videos either globally align and average (such as the work of [Telleen et al. 2007] and [Adams et al. 2008]) or search for explicit block matches (such as [Avanaki 2006]). A more robust approach is the work of [Bennett and McMillan 2005] which averages in either space or time, as appropriate, but does not denoise moving textured objects. [Buades et al. 2008] finds that applying non-local means to the volume produces better output than explicit searches for matching blocks or pixel trajectories. Figure 9 shows results from applying non-local means to such two such bursts. The running time for our implementation of non-local means is typically spent half performing the patch PCA (which is implemented as a stack of convolutions accelerated on the GPU), and half computing the denoising. The time for each portion is typically under one minute per megapixel at 16 dimensions, regardless of the size of the search. Due to the success of 3D range acquisition techniques, denoising of meshes and point clouds is an active research area in geometry processing. The goal is the same as in image denoising, to remove noise while best preserving the underlying signal, which in this case comes as a set of 3d points (potentially with mesh connectivity) sampled from some surface. Isotropic geometry denoising methods, such as [Taubin 1995], perform the same amount of smoothing irrespective of whether sharp features such as edges and corners are present in the input, which results in these features appearing rounded-off in the result. Recently, several approaches for feature-preserving denoising have been proposed based on geometry diffusion [Desbrun et al. 1999], projections [Fleischman et al. 2005], the bilateral filter [Jones et al. 2003] [Fleishman et al. 2003], and its extension to non-local means [Yoshizawa et al. 2006]. In this section, we will show that, since the Gaussian kd-tree does not place any structural constraints on input data, it can be used for filtering of geometry. Refer once again to Equation 5, which states that to produce an output value v ? i at a point p i , a generalized bilateral filter averages together a set of values v j weighted by a Gaussian function of the distance between p i and each point p j . The main difficulty in adapting this bilateral filtering framework from the image domain to 3d geometry is that, in general, our input is a set of 3d point coordinates (x i , y i , z i ) describing a surface, which does not come parameterized over some regularly sampled domain. Therefore, unlike for images, there is no natural decomposition of the input into positions (p i ?s) and values (v i ?s), as required for Equation 5. Two approaches to decompose a set of 3d points into the spatial and signal domains for bilateral filtering of meshes have been proposed recently. [Jones et al. 2003] computes the filtered coordinates of each mesh vertex as a weighted sum of its projections onto the mesh faces within the point?s neighborhood. In this case, the positions in Equation 5 are the centroids of the neighboring triangles, and the values are the projections. For each neighboring vertex, the projection onto the tangent plane be comes the position, and the height above the tangent plane becomes the value. The filtered vertex is then moved along its normal by the averaged height computed by the bilateral filter. The approach of [Fleishman et al. 2003] has been extended to non-local means in [Yoshizawa et al. 2006] by adding a geometric descriptor to each vertex in the mesh. The above approaches solve the problem of separating 3d point coordinates into the spatial and data components by representing the neighbors of each vertex in its own local coordinate system. However, there are two problems in using the decompositions of [Jones et al. 2003] and [Fleishman et al. 2003] in Equation 5. First, since local projections are used, each value v j in the sum to produce the output value v i depends both on coordinates of vertex i and vertex j, which does not give us a one-to-one mapping between values and positions required for efficiently computing the blur. The second problem is that the parameterizations only make sense locally around each vertex since they use tangent plane approximations of the geometry. For non-local means denoising, we need to average values that are potentially far apart in space, as long as the local geometry looks similar, for example the scales on the front and back of the dragon in Figure 10 . However, the projection of a point j on the back of the mesh onto the local frame of a point i on the front can be very far away from i, especially if surface orientation at i and j are different, even if local geometry is similar. We would prefer a global notion of value that makes sense across the whole mesh. Computing Global Positions and Values To produce a globally meaningful value that we can average across all points on the mesh, we will treat feature-preserving mesh smoothing as a problem of adding back lost detail to a smooth base layer. This approach is often used in mesh editing [Sorkine et al. 2004], where a smooth base layer is used to produce large-scale geometric deformations, and fine detail is then added back as offsets from the deformed geometry. Let M be the input mesh, let x i , i = 1 . . . n be the vertex positions, and n i be the vertex normals computed by averaging the face normals for faces incident on vertex i. We apply Laplacian smoothing to M to produce the smooth base layer M  ? with vertex positions x i and normals n i . Laplacian smoothing successfully removes the noise from the mesh, but will smooth across sharp features. The difference between the vertex coordinates of M and M  ? gives us the noisy detail layer, d i = x i ? x i . The resulting detail vectors are translation invariant, however they are still dependent on the surface orientation at x i . To achieve invariance to rigid transformations, we express each detail vector d i in the principal coordinate frame of the vertex i of M.  ? That is, for each vertex on the smoothed base layer, we compute the coordinate frame ( n i , k  ? 1 i , k  ? i 2 ), where k  ? i 1 , k  ? i 2 are the directions of minimum and maximum curvature. These vectors are computed on the smoothed base layer, so they are not corrupted by noise. The final offset vector for each vertex is computed as the projection of d i into the principal curvature frame, which is then expressed in homogeneous coordinates to give the value vector for each vertex: This gives us the set of n values v i , which are meaningful globally and can be averaged across the entire input using the regular vector addition. The second component of the non-local means denoising is the position values in Equation 5, which should be related to some measure of neighborhood similarity. Our neighborhood descriptor should be robust to noise, invariant to rigid transformations, and represented as a vector in R n . We use the well-known spin image descriptors [Johnson and Hebert 1999], which are orientationinvariant histograms of cylindrical coordinates of points within a given neighborhood. For a point x i with normal n i , the spin value (?, ?) of a point x j in the neighborhood of x i is defined as: To build a spin image of a surface patch around x i , we quantize the pairs (?, ?) into a set of bins. Since the spin images are most sensitive to the orientation of the surface normal, we use the normals n i from the base layer and the point coordinates from the original mesh to form the spin images. If the normals are robust, the rest of the computation is relatively robust to noise due to the binning that is performed to compute the spin image. We use 5 bins for the values of ? and 10 bins for the values of ? with the bin size equal to the sample spacing of the mesh as recommended in [Johnson and Hebert 1999]. This gives us 50-dimensional position vectors p i . Once the values are positions are computed, we blur using the Gaussian kd-tree to produce the smoothed detail vectors, which are then added back as offsets to the base layer to produce the final denoised result. Results We apply our non-local means denoising algorithm to several examples of meshes corrupted by Gaussian noise. In all examples, we use 20 iterations of Laplacian smoothing to produce the base mesh, and smooth the detail layer with the filter of standard deviation 0.05 in spin image space. Figure 10 shows the results of applying non-local means smoothing to a dragon model corrupted by Gaussian noise. The denoising is particularly effective at recovering self-similar areas of the mesh such as the scales and the back ridge of the dragon. In Figure 11 we apply non-local means to a noisy model with many sharp features and fine detail. Notice that we are able to maintain sharp edges of the carvings on the box, as well as recover the fine detail in the petals. This model has many planar areas, so it is also particularly suitable for the algorithm of [Jones et al. 2003], which uses local planar approximations. On the right of Figure 11 we show the results of applying bilateral smoothing to produce equivalent amount of noise reduction in the flat areas. While bilateral smoothing preserves edges better than Laplacian smoothing used to produce the base layer, non-local means is able to recover more detail in the petals. In this section, we demonstrated that the Gaussian kd-tree can be used for non-local means smoothing of geometry. Our method relies on decomposing the input into a base and a detail layer. Such decompositions have also been addressed in the context of mesh parameterizations [Sheffer et al. 2006], and we expect that a variety of parametrization and decomposition approaches can be used in our framework. Finally, we expect that a similar method can be applied to point cloud denoising. We have described a novel method for computing the broad class of non-linear filters which can be described by Equation 5, based on weighted importance sampling of a modified kd-tree. This class of filters includes bilateral filters, joint bilateral filters, non-local means filters, and related filters in which values are averaged with other values that are considered nearby in some high-dimensional space. For bilateral filtering, we compare this method to a 5D extension of the bilateral grid of [Paris and Durand 2006], and find that which method is superior depends on the filter size used. For higher dimensional filters, such as non-local means, our tree-based filter exhibits excellent performance, as its runtime and memory use both scale linearly with dimension. Our method requires no particular structure to the input, so we also apply it to the task of denoising  geometry to produce a novel non-local means filter for meshes. Firstly, our tree building takes a significant fraction of our total runtime, and so we use a very simple splitting scheme. Secondly, in cases with n values and many more than log(n) dimensions, the splitting that takes place in our tree does not adequately constrain a sample?s location before it reaches a leaf, and many samples are returned with very small weights attached. In this work, we solved this by throwing away the least important dimensions with PCA, but it may be that other tree structures are still amenable to weighted importance sampling while more strongly constraining sample locations. It may also be beneficial to store values at leaf cells, rather than at a point somewhere within them. This would improve the complexity of the algorithm by removing the distance evaluation currently required to compute the correct probabilities at the leaf nodes, and making the importance sampling exact rather than weighted, but it would compute a different function of the values one far more dependent on the specific way in which the tree was built. Finally, tree traversal is an extremely irregular algorithm, and the speedup we observed from our GPU implementation is significantly less than theoretically possible. More intelligent software caching of portions of the tree and other data structures may speed this up further. This work was supported by a Reed-Hodgson Stanford Graduate Fellowship, an NDSEG Graduate Fellowship from the United States Department of Defense, and an NSF Graduate Fellowship from the National Science Foundation. Thanks also to Justin Talbot, Leonidas Guibas, and Jeremy Sugerman for fruitful discussion and advice, to Hao Li for providing us with mesh data, and also to our human and canine figure subjects.",
  "resources" : [ ]
}