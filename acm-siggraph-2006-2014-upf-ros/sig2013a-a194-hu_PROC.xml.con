{
  "uri" : "sig2013a-a194-hu_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2013a/a194-hu_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Inverse Image Editing: Recovering a Semantic Editing History from a Before-and-After Image Pair",
    "published" : "2013",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Shi-Min-Hu",
      "name" : "Shi-Min",
      "surname" : "Hu"
    }, {
      "uri" : "http://drinventor/Kun-Xu",
      "name" : "Kun",
      "surname" : "Xu"
    }, {
      "uri" : "http://drinventor/Li-Qian-Ma",
      "name" : "Li-Qian",
      "surname" : "Ma"
    }, {
      "uri" : "http://drinventor/Bin-Liu",
      "name" : "Bin",
      "surname" : "Liu"
    }, {
      "uri" : "http://drinventor/Bi-Ye-Jiang",
      "name" : "Bi-Ye",
      "surname" : "Jiang"
    }, {
      "uri" : "http://drinventor/Jue-Wang",
      "name" : "Jue",
      "surname" : "Wang"
    } ]
  },
  "bagOfWords" : [ "we", "have", "implement", "we", "method", "pc", "Intel", "Xeon", "2.4", "GHz", "CPU", "8gb", "memory", "image", "size", "640", "480", "region", "match", "take", "minute", "recover", "appearance", "operator", "recover", "editing", "history", "source", "image", "edit", "image", "generate", "tutorial", "take", "about", "10", "15", "seconds", "depend", "number", "region", "be", "edit", "find", "optimal", "editing", "path", "take", "about", "seconds", "fig.", "show", "number", "input", "before-and-after", "image", "pair", "recover", "editing", "history", "use", "we", "approach", "suggest", "we", "system", "work", "reliably", "even", "large", "geometric", "appearance", "transform", "appearance", "transform", "allow", "spatially", "vary", "-lrb-", "e.g.", "first", "example", "-rrb-", "furthermore", "recover", "editing", "step", "semantically-meaningful", "can", "easily", "use", "drive", "tool", "image", "editing", "software", "note", "how", "system", "generate", "compact", "reasonable", "editing", "history", "2nd", "3rd", "example", "from", "low-level", "region", "matching", "result", "show", "3rd", "4th", "row", "fig.", "next", "we", "illustrate", "how", "recovered", "history", "can", "use", "various", "application", "Automatic", "tutorial", "generation", "straightforward", "application", "use", "recover", "editing", "history", "automatically", "generate", "image", "editing", "tutorial", "fig.", "show", "simple", "example", "turn", "history", "step-by-step", "tutorial", "we", "method", "can", "combine", "source", "image", "edit", "image", "recover", "editing", "history", "more", "powerful", "tutorial", "generate", "system", "-lsb-", "Grabler", "et", "al.", "2009", "-rsb-", "produce", "more", "visually", "appealing", "result", "re-editing", "user", "can", "modify", "recovered", "history", "e.g.", "remove", "step", "change", "parameter", "some", "step", "re-apply", "modify", "history", "source", "image", "generate", "new", "edit", "image", "some", "example", "show", "fig.", "Fig.", "easier", "than", "directly", "editing", "original", "edited", "image", "achieve", "user", "may", "have", "carry", "out", "object", "selection", "use", "other", "editing", "tool", "again", "latter", "case", "user", "may", "also", "longer", "remember", "parameter", "part", "edit", "which", "remain", "unchanged", "edit", "transfer", "recover", "editing", "history", "from", "one", "pair", "image", "can", "transfer", "new", "image", "achieve", "edit", "transfer", "example", "show", "Fig.", "10", "where", "recover", "editing", "history", "from", "image", "apply", "image", "B.", "do", "we", "assume", "have", "similar", "composition", "so", "object", "roughly", "same", "location", "those", "a.", "automatically", "extract", "object", "mask", "we", "first", "identify", "rough", "bound", "box", "which", "1.5", "time", "larger", "than", "actual", "object", "bound", "box", "apply", "grabcut", "-lsb-", "Rother", "et", "al.", "2004", "-rsb-", "segmentation", "other", "dedicated", "approach", "have", "already", "be", "propose", "edit", "transfer", "image", "analogy", "-lsb-", "Hertzmann", "et", "al.", "2001", "-rsb-", "content-adaptive", "macro", "-lsb-", "Berthouzoz", "et", "al.", "2011", "-rsb-", "compare", "image", "analogy", "we", "method", "have", "more", "constraint", "input", "require", "similar", "composition", "image", "B.", "however", "other", "hand", "capable", "object-level", "editing", "also", "handle", "geometric", "editing", "crop", "which", "clear", "advantage", "over", "image", "analogy", "other", "appearance-based", "transfer", "approach", "content-adaptive", "macro", "require", "editing", "history", "know", "so", "we", "system", "can", "potentially", "use", "generate", "editing", "macro", "merge", "editing", "path", "we", "approach", "can", "combine", "image", "revision", "control", "system", "-lsb-", "Chen", "et", "al.", "2011", "-rsb-", "merge", "different", "editing", "path", "example", "show", "Fig.", "11", "where", "we", "system", "recover", "multiple", "different", "editing", "path", "merge", "they", "create", "single", "final", "render", "result", "we", "present", "novel", "system", "recover", "semantically", "meaningful", "editing", "history", "from", "source", "image", "edit", "version", "achieve", "we", "use", "dense", "correspondence", "method", "which", "extend", "NRDC", "approach", "find", "all", "edit", "region", "recover", "appearance", "operation", "apply", "each", "region", "from", "all", "possible", "edit", "path", "we", "recover", "optimal", "one", "base", "semantic", "constraint", "experimental", "user", "study", "result", "show", "we", "system", "can", "recover", "clean", "meaningful", "editing", "history", "involve", "large", "geometric", "appearance", "transformation", "we", "further", "show", "recover", "history", "can", "useful", "wide", "range", "application", "source", "image", "edit", "image", "source", "image", "edit", "image", "original", "history", "artist", "future", "work", "we", "would", "like", "improve", "robustness", "proposed", "system", "replace", "some", "technical", "component", "newly", "develop", "more", "advanced", "method", "example", "we", "could", "potentially", "improve", "robustness", "region", "matching", "step", "use", "recently", "propose", "higher-order", "deformation", "model", "-lsb-", "y?cer", "et", "al.", "2012", "-rsb-", "after", "obtain", "initial", "matching", "we", "propose", "method", "another", "way", "improve", "system", "robustness", "combine", "we", "method", "technique", "propose", "previous", "photo", "manipulation", "detection", "system", "-lsb-", "o?brien", "Farid", "2012", "Kee", "et", "al.", "2013", "-rsb-", "we", "also", "interested", "combine", "we", "system", "work", "-lsb-", "Ma", "et", "al.", "2013", "-rsb-", "automatically", "generate", "change", "blindness", "image", "extend", "we", "method", "handle", "vector", "image", "-lsb-", "Lai", "et", "al.", "2009", "Liao", "et", "al.", "2012", "-rsb-", "another", "potential", "extension", "apply", "we", "method", "large", "image", "library", "-lsb-", "Hu", "et", "al.", "2013", "-rsb-", "analyze", "image", "correlation", "and/or", "dependency", "within", "large", "dataset", "Acknowlegements", "we", "thank", "anonymous", "reviewer", "valuable", "comment", "work", "support", "National", "Basic", "Research", "Project", "China", "-lrb-", "2011CB302205", "-rrb-", "natural", "Science", "Foundation", "China", "-lrb-", "61120106007", "61170153", "-rrb-", "National", "High", "Technology", "Research", "Development", "Program", "China", "-lrb-", "2012aa011802", "-rrb-", "pcsirt", "Tsinghua", "University", "Initiative", "Scientific", "Research", "Program" ],
  "content" : "We have implemented our method on a PC with an Intel Xeon 2.4GHz CPU and 8GB memory. For an image of size 640?480, region matching takes 2?3 minutes, recovering appearance operators\n        recovered editing history source image edited image generated tutorial takes about 10?15 seconds, depending on the number of regions being edited, and finding the optimal editing path takes about 2?5 seconds. Fig. 7 shows a number of input before-and-after image pairs and the recovered editing histories using our approach. It suggests that our system works reliably even for large geometric and appearance transforms, and the appearance transform is allowed to be spatially varying (e.g. the first example). Furthermore, the recovered editing steps are semantically-meaningful, and can easily be used to drive tools in image editing software. Note how the system generates a compact and reasonable editing history for the 2nd and 3rd examples, from the low-level region matching results shown in the 3rd and 4th rows of Fig. 4 . Next, we illustrate how the recovered history can be used in various applications. Automatic tutorial generation. A straightforward application is to use the recovered editing history to automatically generate an image editing tutorial. Fig. 8 shows a simple example of turning the history into a step-by-step tutorial. Our method can be combined with source image A edited image A recovered editing history more powerful tutorial generating systems [Grabler et al. 2009] to produce more visually appealing results. Re-editing. Users can modify the recovered history, e.g. to remove steps, or change parameters of some steps, and re-apply the modified history to the source image A to generate a new edited image A . Some examples are shown in Fig. 1 and Fig. 9 . This is easier than directly editing the original edited image A to achieve A , as the user may have to carry out object selection and use other editing tools again in the latter case; the user may also no longer remember the parameters for the parts of the edit which are to remain unchanged. Edit transfer. The recovered editing history from one pair of images can be transferred to a new image to achieve edit transfer. An example is shown in Fig. 10 , where the recovered editing history from images A and A is applied to image B. To do this, we assume that A and B have similar composition, so that objects in B are roughly at the same locations as those in A. To automatically extract the object mask in B, we first identify a rough bounding box in B which is 1.5 times larger than the actual object bounding box in A, then apply GrabCut [Rother et al. 2004] for segmentation. Other dedicated approaches have already been proposed for edit transfer, such as image analogies [Hertzmann et al. 2001] and content-adaptive macros [Berthouzoz et al. 2011]. Compared to image analogies, our method has more constraints on the input, requiring similar composition of images A and B. However, on the other hand, it is capable of object-level editing, and also handles geometric editing such as cropping, which are clear advantages over image analogies and other appearance-based transfer approaches. Content-adaptive macros requires the editing history to be known, so our system can be potentially used to generate such editing macros. Merging editing paths. Our approach can be combined with the image revision control system [Chen et al. 2011] to merge different editing paths. An example is shown in Fig. 11 , where our system recovers multiple different editing paths and merges them to create a single final rendering result. We present a novel system for recovering a semantically meaningful editing history from a source image and an edited version of it. To achieve this, we use a dense correspondence method which extends the NRDC approach to find all edited regions, and recovers appearance operations applied to each region. From all possible edit paths, we recover an optimal one based on semantic constraints. Experimental and user study results show that our system can recover clean and meaningful editing histories involving large geometric and appearance transformations. We further show that the recovered histories can be useful in a wide range of applications. source image edited image source image edited image original history by artist As future work, we would like to improve the robustness of the proposed system, by replacing some technical components with newly developed, more advanced methods. For example, we could potentially improve the robustness of the region matching step by using recently proposed higher-order deformation models [Y?cer et al. 2012], after obtaining the initial matching by our proposed method. Another way to improve system robustness is to combine our method with techniques proposed in previous photo manipulation detection systems [O?Brien and Farid 2012; Kee et al. 2013]. We are also interested in combining our system with the work of [Ma et al. 2013] to automatically generate change blindness images, and in extending our method to handle vector images [Lai et al. 2009; Liao et al. 2012]. Another potential extension is to apply our method to large image libraries [Hu et al. 2013], for analyzing image correlations and/or dependencies within a large dataset. Acknowlegements. We thank the anonymous reviewers for their valuable comments. This work was supported by National Basic Research Project of China (2011CB302205), Natural Science Foundation of China (61120106007 and 61170153), National High Technology Research and Development Program of China (2012AA011802), PCSIRT and Tsinghua University Initiative Scientific Research Program.",
  "resources" : [ ]
}