{
  "uri" : "sig2010a-a138-lee_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2010a/a138-lee_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Motion Fields for Interactive Character Locomotion",
    "published" : "2014",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Yongjoon-Lee",
      "name" : "Yongjoon",
      "surname" : "Lee"
    }, {
      "uri" : "http://drinventor/Kevin-Wampler",
      "name" : "Kevin",
      "surname" : "Wampler"
    }, {
      "uri" : "http://drinventor/Gilbert-Bernstein",
      "name" : "Gilbert",
      "surname" : "Bernstein"
    }, {
      "uri" : "http://drinventor/Jovan-Popovic",
      "name" : "Jovan",
      "surname" : "Popovic"
    }, {
      "uri" : "http://drinventor/Zoran-Popovic",
      "name" : "Zoran",
      "surname" : "Popovic"
    } ]
  },
  "bagOfWords" : [ "we", "propose", "novel", "representation", "motion", "datum", "control", "enable", "character", "both", "highly", "agile", "response", "user", "input", "natural", "handling", "arbitrary", "external", "disturbance", "we", "runtime", "motion", "synthesis", "mechanism", "freely", "flow", "motion", "field", "capable", "create", "novel", "natural", "motion", "highlyresponsive", "real", "time", "user", "input", "generally", "explicitly", "specify", "datum", "human", "motion", "highly-varied", "continuous", "phenomenon", "quickly", "adapt", "different", "task", "respond", "external", "disturbance", "general", "capable", "continue", "locomotion", "from", "almost", "any", "initial", "state", "video", "game", "increasingly", "demand", "character", "move", "behave", "realistic", "way", "important", "bring", "property", "natural", "human", "motion", "virtual", "world", "unfortunately", "easier", "say", "than", "do", "instance", "despite", "many", "advance", "character", "animation", "technique", "create", "highly", "agile", "realistic", "interactive", "locomotion", "controller", "remain", "common", "difficult", "task", "we", "propose", "new", "motion", "representation", "interactive", "character", "animation", "term", "motion", "field", "which", "provide", "two", "key", "ability", "ability", "user", "control", "character", "real", "time", "ability", "operate", "fully-continuous", "configuration", "space", "character", "although", "exist", "technique", "which", "allow", "one", "other", "ability", "combination", "two", "which", "allow", "highly", "agile", "controller", "which", "can", "respond", "user", "command", "short", "amount", "time", "order", "generate", "animation", "we", "select", "single", "motion", "from", "set", "follow", "single", "frame", "repeat", "from", "character?s", "result", "state", "however", "instead", "single", "fixed", "flow", "motion", "field", "allow", "multiple", "possible", "motion", "each", "frame", "because", "motion", "field", "allow", "range", "action", "every", "frame", "character", "can", "immediately", "respond", "new", "user", "command", "rather", "than", "wait", "pre-determined", "transition", "point", "motion", "graph", "allow", "motion", "field-based", "controller", "significantly", "more", "agile", "than", "graph-based", "counterpart", "further", "alter", "flow", "other", "external", "method", "inverse", "kinematic", "physical", "simulation", "we", "also", "can", "directly", "integrate", "technique", "motion", "synthesis", "control", "process", "primary", "contribution", "work", "lie", "combine", "continuous", "state", "representation", "optimal", "control", "framework", "we", "find", "approach", "provide", "many", "advantage", "character", "animation", "structure", "inherently", "discrete", "coarse", "transition", "ability", "provide", "great", "computational", "advantage", "first", "difficult", "create", "graph", "which", "allow", "very", "quick", "response", "change", "direction", "unexpected", "disturbance", "since", "change", "motion", "can", "only", "happen", "when", "new", "edge", "reach", "-lsb-", "treuille", "et", "al.", "2007", "McCann", "Pollard", "2007", "-rsb-", "more", "generally", "very", "hard", "use", "graph-based", "controller", "when", "character", "from", "arbitrary", "state", "configuration", "-lsb-", "Zordan", "et", "al.", "2005", "-rsb-", "similarly", "when", "method", "anticipate", "some", "type", "upperbody", "push", "-lsb-", "Yin", "et", "al.", "2005", "Arikan", "et", "al.", "2005", "-rsb-", "character", "may", "react", "all", "hand", "pull", "lower-body", "push", "technique", "generally", "able", "synthesize", "start", "from", "any", "initial", "state", "lend", "themselves", "well", "apply", "physical", "disturbance", "-lsb-", "ye", "Liu", "2010", "-rsb-", "estimate", "character?s", "pose", "from", "incomplete", "datum", "-lsb-", "Chai", "Hodgins", "2005", "-rsb-", "preclude", "ability", "optimally", "control", "character", "primary", "difference", "between", "we", "work", "instead", "build", "model", "most", "probable", "single", "motion", "we", "attempt", "model", "set", "possible", "motion", "each", "character", "state", "only", "select", "single", "motion", "use", "runtime", "use", "principle", "from", "optimal", "control", "theory", "principle", "controller", "offer", "best", "possibility", "highly", "realistic", "interactive", "character", "animation", "however", "highfidelity", "physically", "base", "character", "animation", "harder", "attain", "because", "physics", "alone", "do", "tell", "we", "about", "muscle", "force", "need", "propel", "character", "ideal", "approach", "would", "fully", "model", "complete", "space", "natural", "human", "motion", "describe", "every", "conceivable", "way", "character", "can", "move", "from", "give", "state", "rather", "than", "confine", "motion", "can", "motion", "clip", "transition", "model", "would", "enable", "much", "greater", "flexibility", "agility", "motion", "through", "continuous", "space", "motion", "Motion", "States", "we", "represent", "state", "which", "character", "might", "configure", "pose", "velocity", "all", "each", "character?s", "joint", "we", "can", "also", "interpolate", "multiple", "pose", "velocity", "together", "-lrb-", "-rrb-", "use", "linear", "interpolation", "vector", "unit", "quaternion", "interpolation", "-lsb-", "Park", "et", "al.", "2002", "-rsb-", "respective", "component", "pose", "velocity", "we", "use", "analogy", "vector", "addition", "subtraction", "cartesian", "space", "circle", "remind", "reader", "we", "work", "mostly", "quaternion", "finally", "we", "define", "motion", "state", "-lrb-", "-rrb-", "pose", "associate", "velocity", "compute", "from", "pair", "successive", "pose", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "intuitively", "set", "length", "its", "associate", "bone", "de-emphasize", "impact", "small", "bone", "finger", "give", "one", "particular", "action", "-lrb-", "-rrb-", "we", "determine", "next", "state", "use", "transition", "integration", "function", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "let", "range", "over", "neighborhood", "-lrb-", "-rrb-", "we", "use", "function", "passive", "Action", "selection", "give", "choice", "action", "we", "now", "know", "how", "generate", "motion", "which", "action", "should", "we", "pick", "however", "we", "can", "quickly", "implement", "simple", "solution", "use", "similarity", "weight", "-lrb-", "eq", "runtime", "we", "determine", "whether", "foot", "contact", "arbitrary", "motion", "state", "take", "weighted", "vote", "across", "neighborhood", "-lrb-", "-rrb-", "-lrb-", "similarity", "weight", "neighbor", "equation", "-lrb-", "-rrb-", "-rrb-", "contact", "-lrb-", "-rrb-", "0.5", "we", "say", "left", "foot", "contact", "give", "motion", "state", "we", "generate", "action", "modify", "similarity", "weight", "-lrb-", "equation", "-lrb-", "-rrb-", "-rrb-", "transition", "additionally", "we", "must", "extend", "definition", "integration", "function", "-lrb-", "equation", "-lrb-", "-rrb-", "-rrb-", "address", "task", "parameter", "-lrb-", "-rrb-", "-lrb-", "-rrb-", "-lrb-", "-lrb-", "-rrb-", "-rrb-", "goal", "reinforcement", "learning", "find", "best", "rule", "policy", "choose", "which", "action", "perform", "any", "give", "state", "somehow", "we", "need", "consider", "affect", "current", "action", "choice", "character?s", "ability", "accrue", "future", "reward", "we", "describe", "shortly", "how", "we", "represent", "precompute", "value", "function", "moment", "notice", "we", "can", "now", "rewrite", "equation", "10", "replace", "infinite", "future", "search", "value", "function", "lookup", "since", "infinitely", "many", "possible", "task", "state", "we", "can", "represent", "value", "function", "exactly", "instead", "we", "approximate", "store", "value", "finite", "number", "task", "state", "interpolate", "estimate", "value", "other", "point", "-lrb-", "figure", "-rrb-", "here", "we", "observe", "we", "motion", "state", "be", "originally", "obtain", "from", "continuous", "stream", "motion", "datum", "furthermore", "we", "do", "have", "rely", "target", "pose", "trajectory", "tracking", "order", "define", "recovery", "motion", "when", "new", "force", "apply", "during", "ongoing", "blend", "we", "simply", "terminate", "old", "blending", "process", "early", "begin", "again", "new", "force", "however", "many", "case", "visually", "apparent", "even", "when", "multiple", "large", "force", "apply", "quick", "succession", "nevertheless", "useful", "illustration", "how", "perturbation", "can", "easily", "integrate", "synthesis", "process", "Graph-Based", "Control", "vs", "Motion", "Field", "Control", "order", "compare", "how", "quickly", "character", "can", "adjust", "abruptly", "change", "directive", "we", "create", "graph-based", "task", "controller", "-lsb-", "Lee", "et", "al.", "2009", "-rsb-", "use", "same", "motion", "datum", "task", "reward", "function", "order", "maximize", "agility", "we", "allow", "wide", "range", "up", "45", "degree", "directional", "warping", "clip", "give", "minimal", "importance", "physicality", "cost", "approximate", "nearest", "neighborhood", "-lrb-", "ann", "-rrb-", "-lsb-", "Mount", "Arya", "1997", "-rsb-", "query", "represent", "most", "computational", "cost", "instance", "motion", "graph", "usually", "prune", "ensure", "strongly", "connect", "start", "from", "any", "state", "character", "can", "reach", "any", "other", "state", "we", "think", "development", "tool", "would", "useful", "author", "new", "controller", "would", "potentially", "have", "application", "area", "outside", "character", "animation" ],
  "content" : "We propose a novel representation of motion data and control that enables characters with both highly agile responses to user input and natural handling of arbitrary external disturbances. Our runtime motion synthesis mechanism freely ?flows? in the motion field and is capable of creating novel and natural motions that are highlyresponsive to the real time user input, and generally not explicitly specified in the data. Human motion is a highly-varied and continuous phenomenon: it quickly adapts to different tasks, responds to external disturbances, and in general is capable of continuing locomotion from almost any initial state. As video games increasingly demand that characters move and behave in realistic ways, it is important to bring these properties of natural human motion into the virtual world. Unfortunately this is easier said than done. For instance, despite many advances in character animation techniques, creating highly agile and realistic interactive locomotion controllers remains a common but difficult task. We propose a new motion representation for interactive character animation, termed a motion field which provides two key abilities: the ability for a user to control the character in real time and the ability to operate in the fully-continuous configuration space of the character. Although there exist techniques which allow one or the other of these abilities, it is the combination of the two which allows for highly agile controllers which can respond to user commands in a short amount of time. In order to generate an animation we select a single motion from this set, follow it for a single frame, and repeat from the character?s resulting state. However, instead of a single fixed flow, a motion field allows multiple possible motions at each frame. Because motion fields allow a range of actions at every frame, a character can immediately respond to new user commands rather than waiting for pre-determined transition points as in a motion graph. This allows motion field-based controllers to be significantly more agile than their graph-based counterparts. By further altering this flow with other external methods, such as inverse kinematics or physical simulation, we also can directly integrate these techniques into the motion synthesis and control process. The primary contribution of this work lies in the combining of a continuous state representation with an optimal control framework. We find that this approach provides many advantages for character animation. These structures are inherently discrete with coarse transitioning abilities that provide great computational advantages. First, it is difficult to create graphs which allow very quick responses to changes of direction or unexpected disturbances since a change to the motion can only happen when a new edge is reached [Treuille et al. 2007; McCann and Pollard 2007]. More generally, it is very hard to use a graph-based controller when the character starts from an arbitrary state configuration [Zordan et al. 2005]. Similarly, when methods anticipate some types of upperbody pushes [Yin et al. 2005; Arikan et al. 2005], the character may not react at all to hand pulls or lower-body pushes. These techniques are generally able to synthesize starting from any initial  state, and lend themselves well to applying physical disturbances [Ye and Liu 2010] and estimating a character?s pose from incomplete data [Chai and Hodgins 2005]. This precludes the ability to optimally control the character. The primary difference between our work and these is that instead of building a model of the most probable single motion, we attempt to model the set of possible motions at each character state, and only select the single motion to use at runtime by using principles from optimal control theory. In principle, such controllers offer the best possibility for highly realistic interactive character animation. However, highfidelity physically based character animation is harder to attain because physics alone does not tell us about the muscle forces needed to propel the characters. An ideal approach would fully model the complete space of natural human motion, describing every conceivable way that a character can move from a given state. Rather than confine motion to canned motion clips and transitions, such model would enable much greater flexibility and agility of motion through the continuous space of motion. Motion States We represent the states in which a character might be configured by the pose and the velocity of all of each of a character?s joints. We can also interpolate multiple poses or velocities together ( P ? k i=1 w i x i or P ? k i=1 w i v i ) using linear interpolation of vectors and unit quaternion interpolation[Park et al. 2002] on the respective components of a pose or velocity. We use and ? in analogy to vector addition and subtraction in Cartesian spaces, but with circles to remind the reader that we are working mostly with quaternions. Finally, we define a motion state m = (x, v) as a pose and an associated velocity, computed from a pair of successive poses x and x with m = (x, v) = (x, x x). Intuitively, setting ? i to the length of its associated bone de-emphasizes the impact of small bones such as the fingers. Given one particular action a ? A(m), we then determine the next state m using a transition or integration function m = (x , v ) = I(x, v, a) = I(m, a) Letting i range over the neighborhood N (m), we use the function Passive Action Selection Given a choice of action we now know how to generate motion, but which action should we pick? However, we can quickly implement a simple solution using the similarity weights (eq. Then at runtime, we determine whether or not a foot is in contact at an arbitrary motion state m by taking a weighted vote across the neighborhood N (m). (w i are the similarity weights of the neighbors: Equation (2)) If l contact (m) ? 0.5 we say the left foot is in contact. Given a motion state m, we generate k actions by modifying the similarity weights (Equation (2)). Transitions Additionally, we must extend the definition of the integration function I (Equation (4)) to address task parameters: I s (s, a) = I s (m, ? T , a) = (I(m, a), ? T ). The goal of reinforcement learning is to find ?the best? rule or policy for choosing which action to perform at any given state. Somehow, we need to consider the affect of the current action choice on the character?s ability to accrue future rewards. We will describe shortly how we represent and precompute the value function, but for the moment notice that we can now rewrite equation 10 by replacing the infinite future search with a value function lookup: Since there are infinitely many possible task states, we cannot represent the value function exactly. Instead we approximate it by storing values at a finite number of task states s i and interpolating to estimate the value at other points ( Figure 2 ). Here, we observe that our motion states were originally obtained from continuous streams of motion data. Furthermore, we do not have to rely on target poses or trajectory tracking in order to define a recovery motion. When a new force is applied during an ongoing blend, we simply terminate the old blending process early and begin again with the new force. However, in many cases this is not visually apparent, even when multiple large forces are applied in quick succession. Nevertheless, it is useful as an illustration of how perturbations can be easily integrated into the synthesis process. Graph-Based Control vs Motion Field Control In order to compare how quickly the character can adjust to abruptly changing directives, we created a graph-based task controller [Lee et al. 2009] using the same motion data, tasks and reward functions. In order to maximize agility, we allowed a wide range of up to ?45 degrees of directional warping on clips, and gave minimal importance to the physicality cost. The approximate nearest neighborhood (ANN) [Mount and Arya 1997] queries represent most of the computational cost. For instance, motion graphs are usually pruned to ensure that they are strongly connected; starting from any state, a character can reach any other state. We think that the development of such tools would be useful in authoring new controllers, and would potentially have applications in areas outside of character animation.",
  "resources" : [ ]
}