{
  "uri" : "sig2008a-a116-kopf_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2008a/a116-kopf_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Deep Photo: Model-Based Photograph Enhancement and Viewing",
    "published" : "2008",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Johannes-Kopf",
      "name" : "Johannes",
      "surname" : "Kopf"
    }, {
      "uri" : "http://drinventor/Boris-Neubert",
      "name" : "Boris",
      "surname" : "Neubert"
    }, {
      "uri" : "http://drinventor/Billy-Chen",
      "name" : "Billy",
      "surname" : "Chen"
    }, {
      "uri" : "http://drinventor/Michael F.-Cohen",
      "name" : "Michael F.",
      "surname" : "Cohen"
    }, {
      "uri" : "http://drinventor/Daniel-Cohen-Or",
      "name" : "Daniel",
      "surname" : "Cohen-Or"
    }, {
      "uri" : "http://drinventor/Oliver-Deussen",
      "name" : "Oliver",
      "surname" : "Deussen"
    }, {
      "uri" : "http://drinventor/Matthew-Uyttendaele",
      "name" : "Matthew",
      "surname" : "Uyttendaele"
    }, {
      "uri" : "http://drinventor/Dani-Lischinski",
      "name" : "Dani",
      "surname" : "Lischinski"
    } ]
  },
  "bagOfWords" : [ "once", "photograph", "model", "have", "be", "register", "abundance", "information", "depth", "texture", "GIS", "datum", "become", "immediately", "available", "we", "system", "copyright", "Notice", "permission", "make", "digital", "hard", "copy", "part", "all", "work", "personal", "classroom", "use", "grant", "without", "fee", "provide", "copy", "make", "distribute", "profit", "direct", "commercial", "advantage", "copy", "show", "notice", "fus", "rst", "page", "initial", "screen", "display", "along", "full", "citation", "second", "trend", "widespread", "availability", "accurate", "digital", "terrain", "model", "well", "detailed", "urban", "model", "public", "domain", "NASA", "provide", "detailed", "satellite", "imagery", "-lrb-", "e.g.", "landsat", "-lsb-", "NASA", "2008a", "-rsb-", "-rrb-", "elevation", "model", "-lrb-", "e.g.", "Shuttle", "Radar", "Topography", "Mission", "-lsb-", "NASA", "2008b", "-rsb-", "-rrb-", "also", "number", "city", "around", "world", "create", "detailed", "3d", "model", "cityscape", "-lrb-", "e.g.", "Berlin", "3d", "-rrb-", "we", "count", "available", "model", "describe", "distant", "static", "geometry", "scene", "we", "can", "expect", "have", "access", "geometry", "nearby", "-lrb-", "possibly", "dynamic", "-rrb-", "foreground", "object", "people", "car", "tree", "etc.", "Yosemite", "we", "use", "elevation", "datum", "from", "Shuttle", "Radar", "Topography", "Mission", "-lsb-", "NASA", "2008b", "-rsb-", "landsat", "imagery", "-lsb-", "NASA", "2008a", "-rsb-", "datum", "available", "entire", "Earth", "model", "similar", "NYC", "currently", "available", "dozen", "city", "image-based", "modeling", "recent", "year", "much", "work", "have", "be", "do", "image-based", "modeling", "technique", "which", "create", "high", "quality", "3d", "model", "from", "photograph", "one", "example", "pioneering", "Fa", "ade", "system", "-lsb-", "Debevec", "et", "al.", "1996", "-rsb-", "design", "interactive", "modeling", "building", "from", "collection", "photograph", "example", "Oakley", "Satherley", "-lsb-", "1998", "-rsb-", "dehaze", "aerial", "imagery", "use", "estimate", "terrain", "model", "very", "latest", "dehazing", "method", "-lsb-", "fattal", "2008", "Tan", "2008", "-rsb-", "able", "dehaze", "single", "image", "make", "various", "assumption", "about", "color", "scene", "have", "be", "long", "recognize", "add", "depth", "information", "photograph", "provide", "means", "alter", "viewpoint", "subsequent", "papers", "Kang", "-lsb-", "1998", "-rsb-", "Criminisi", "et", "al.", "-lsb-", "2000", "-rsb-", "oh", "et", "al.", "-lsb-", "2001", "-rsb-", "Zhang", "et", "al.", "-lsb-", "2002", "-rsb-", "extend", "provide", "more", "sophisticated", "user-guided", "3d", "modelling", "technique", "relighting", "number", "sophisticated", "relight", "system", "have", "be", "propose", "various", "researcher", "over", "year", "-lrb-", "e.g.", "-lsb-", "Yu", "Malik", "1998", "Yu", "et", "al.", "1999", "Loscos", "et", "al.", "2000", "Debevec", "et", "al.", "2000", "-rsb-", "-rrb-", "another", "alternative", "use", "time-lapse", "video", "sequence", "-lsb-", "Sunkavalli", "et", "al.", "2007", "-rsb-", "Photo", "browse", "also", "related", "Photo", "Tourism", "system", "-lsb-", "Snavely", "et", "al.", "2006", "-rsb-", "which", "enable", "browse", "explore", "large", "collection", "photograph", "certain", "location", "use", "3d", "interface", "Deep", "Photo", "photograph", "register", "model", "world", "make", "possible", "tap", "much", "richer", "source", "information", "work", "geo-referenced", "image", "deep", "Photo", "support", "similar", "labeling", "well", "several", "additional", "visualization", "contrast", "cho?s", "system", "do", "so", "dynamically", "context", "interactive", "photo", "browse", "application", "contrast", "DeepPhoto", "focus", "enhance", "browse", "single", "photograph", "two", "system", "actually", "complementary", "one", "focus", "organize", "large", "photo", "collection", "other", "enhance", "view", "single", "photograph", "register", "photograph", "3d", "geometric", "model", "scene", "suffice", "specify", "four", "more", "corresponding", "pair", "point", "-lsb-", "Gruen", "Huang", "2001", "-rsb-", "detail", "user", "interface", "we", "registration", "system", "describe", "technical", "report", "-lsb-", "Chen", "et", "al.", "2008", "-rsb-", "due", "atmospheric", "absorption", "scattering", "only", "part", "light", "reflect", "from", "distant", "object", "reach", "camera", "thus", "distant", "object", "scene", "typically", "appear", "considerably", "lighter", "featureless", "compare", "nearby", "one", "how", "dehaze", "perform", "number", "papers", "e.g.", "-lsb-", "Schechner", "et", "al.", "2003", "Narasimhan", "Nayar", "2003a", "Narasimhan", "Nayar", "2003b", "-rsb-", "have", "obtain", "model", "haze", "photograph", "we", "can", "insert", "new", "object", "scene", "more", "seamless", "fashion", "apply", "model", "object", "well", "-lrb-", "accordance", "depth", "suppose", "-rrb-", "two", "sky", "dome", "compute", "one", "corresponding", "Input", "Relighted", "Relighted", "Input", "Relighted", "actual", "-lrb-", "known", "estimate", "-rrb-", "time", "day", "photograph", "take", "other", "correspond", "desire", "sun", "position", "lightmap", "may", "compute", "variety", "way", "rural", "area", "typically", "aerial", "image", "terrain", "while", "urban", "model", "texture", "map", "building", "guide", "value", "vector", "-lrb-", "-rrb-", "where", "chrominance", "value", "corresponding", "point", "model", "texture", "distance", "corresponding", "scene", "point", "from", "location", "camera" ],
  "content" : "Once the photograph and the model have been registered, an abundance of information, such as depth, texture, and GIS data, becomes immediately available to our system. Copyright Notice Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or direct commercial advantage and that copies show this notice on the fi rst page or initial screen of a display along with the full citation. The second trend is the widespread availability of accurate digital terrain models, as well as detailed urban models. In the public domain, NASA provides detailed satellite imagery (e.g., Landsat [NASA 2008a]) and elevation models (e.g., Shuttle Radar Topography Mission [NASA 2008b]). Also, a number of cities around the world are creating detailed 3D models of their cityscape (e.g., Berlin 3D). We count on the available models to describe the distant static geometry of the scene, but we cannot expect to have access to the geometry of nearby (and possibly dynamic) foreground objects, such as people, cars, trees, etc. 1 For Yosemite, we use elevation data from the Shuttle Radar Topography Mission [NASA 2008b] with Landsat imagery [NASA 2008a]. Such data is available for the entire Earth. Models similar to that of NYC are currently available for dozens of cities. Image-based modeling. In recent years, much work has been done on image-based modeling techniques, which create high quality 3D models from photographs. One example is the pioneering Fa  ?ade system [Debevec et al. 1996], designed for interactive modeling of buildings from collections of photographs. For example, Oakley and Satherley [1998] dehaze aerial imagery using estimated terrain models. The very latest dehazing methods [Fattal 2008; Tan 2008] are able to dehaze single images by making various assumptions about the colors in the scene. It has been long recognized that adding depth information to photographs provides the means to alter the viewpoint. Subsequent papers, Kang [1998], Criminisi et al. [2000], Oh et al. [2001], Zhang et al. [2002], extend this by providing more sophisticated, user-guided 3D modelling techniques. Relighting. A number of sophisticated relighting systems have been proposed by various researchers over the years (e.g., [Yu and Malik 1998; Yu et al. 1999; Loscos et al. 2000; Debevec et al. 2000]). Another alternative to use a time-lapse video sequence [Sunkavalli et al. 2007]. Photo browsing. Also related is the ?Photo Tourism? system [Snavely et al. 2006], which enables browsing and exploring large collections of photographs of a certain location using a 3D interface. In Deep Photo, photographs are registered to a model of the world, making it possible to tap into a much richer source of information. Working with geo-referenced images. Deep Photo supports similar labeling, as well as several additional visualizations, but in contrast to Cho?s system, it does so dynamically, in the context of an interactive photo browsing application. In contrast, DeepPhoto focuses on enhancing and browsing of a single photograph; the two systems are actually complementary, one focusing on organizing large photo collections, and the other on enhancing and viewing single photographs. To register such a photograph to a 3D geometric model of the scene, it suffices to specify four or more corresponding pairs of points [Gruen and Huang 2001]. The details and user interface of our registration system are described in a technical report [Chen et al. 2008]. Due to atmospheric absorption and scattering, only part of the light reflected from distant objects reaches the camera. Thus, distant objects in the scene typically appear considerably lighter and featureless, compared to nearby ones. This is how dehazing was performed in a number of papers, e.g., [Schechner et al. 2003; Narasimhan and Nayar 2003a; Narasimhan and Nayar 2003b]. Having obtained a model for the haze in the photograph we can insert new objects into the scene in a more seamless fashion by applying the model to these objects as well (in accordance with the depth they are supposed to be at). Two sky domes are computed, one corresponding\n        Input Relighted Relighted\n        Input Relighted\n        to the actual (known or estimated) time of day the photograph was taken, and the other corresponding to the desired sun position. The lightmap may be computed in a variety of ways. In rural areas these are typically aerial images of the terrain, while in urban models these are the texture maps of the buildings. The guiding value is a vector (U,V, D), where U and V are the chrominance values of the corresponding point in the model texture, and D is the distance to the corresponding scene point from the location of the camera.",
  "resources" : [ ]
}