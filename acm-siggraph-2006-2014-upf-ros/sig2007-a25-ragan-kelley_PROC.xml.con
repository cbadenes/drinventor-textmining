{
  "uri" : "sig2007-a25-ragan-kelley_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2007/a25-ragan-kelley_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "The Lightspeed Automatic Interactive Lighting Preview System",
    "published" : "2007",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Jonathan-Ragan-Kelley",
      "name" : "Jonathan",
      "surname" : "Ragan-Kelley"
    }, {
      "uri" : "http://drinventor/Charlie-Kilpatrick",
      "name" : "Charlie",
      "surname" : "Kilpatrick"
    }, {
      "uri" : "http://drinventor/Brian W.-Smith",
      "name" : "Brian W.",
      "surname" : "Smith"
    }, {
      "uri" : "http://drinventor/Doug-Epps",
      "name" : "Doug",
      "surname" : "Epps"
    }, {
      "uri" : "http://drinventor/Paul-Green",
      "name" : "Paul",
      "surname" : "Green"
    }, {
      "uri" : "http://drinventor/Christophe-Hery",
      "name" : "Christophe",
      "surname" : "Hery"
    }, {
      "uri" : "http://drinventor/Fr?do-Durand",
      "name" : "Fr?do",
      "surname" : "Durand"
    } ]
  },
  "bagOfWords" : [ "Figure", "13", "summarize", "we", "system?s", "fully-automatic", "performance", "two", "we", "shot", "-lrb-", "fig.", "12", "-rrb-", "cache", "size", "fit", "within", "current", "GPU", "resource", "though", "we", "system", "scale", "support", "out-of-core", "shot", "much", "higher", "resolution", "even", "more", "complex", "shader", "we", "report", "all", "result", "we", "current", "deploy", "artist", "workstation", "dual", "2.6", "GHz", "AMD", "Opteron", "2218", "processor", "8gb", "RAM", "NVIDIA", "Quadro", "FX", "5500", "-lrb-", "g71", "-rrb-", "graphic", "we", "generally", "limit", "capability/performance", "curve", "we", "current", "hardware", "preliminary", "result", "suggest", "major", "performance", "improvement", "next-generation", "hardware", "Pirate", "-lrb-", "12", "-rrb-", "robot", "-lrb-", "-rrb-", "resolution", "640x376", "914x389", "supersampling", "4x4", "13x13", "light", "42", "RenderMan", "-lrb-", "total", "-rrb-", "409", "sec", "3406", "sec", "irradiance", "shade", "111", "sec", "material", "shader", "material", "instance", "44", "light", "shader", "light", "instance", "42", "caching", "-lrb-", "total", "-rrb-", "1425", "sec", "931", "sec", "initialization", "sec", "18", "sec", "shader", "specialization", "24", "sec", "63", "sec", "deep-framebuffer", "caching", "627", "sec", "499", "sec", "shadow", "geometry", "caching", "105", "sec", "164", "sec", "cache", "compression", "60", "sec", "187", "sec", "octree", "compression", "600", "sec", "preview", "irradiance", "shading", "-lrb-", "light", "-rrb-", "sec", "interaction", "-lrb-", "irradiance", "cache", "-rrb-", "0.5", "sec", "coarse", "refinement", "4x4", "block", "0.1", "sec", "full", "refinement", "-lrb-", "light", "change", "-rrb-", "10", "sec", "2.7", "sec", "full", "refinement", "-lrb-", "light", "-rrb-", "29", "sec", "-lrb-", "light", "-rrb-", "31.7", "-lrb-", "42", "light", "-rrb-", "deep-framebuffer", "104", "mb", "256", "mb", "indirect", "framebuffer", "33", "mb", "29", "mb", "irradiance", "deep-framebuffer", "83", "mb", "scattering", "index", "buffer", "436", "MB", "System", "performance", "compare", "we", "rendermanbased", "offline", "pipeline", "two", "production", "shot", "-lrb-", "fig.", "12", "-rrb-", "both", "initial", "feedback", "accelerate", "several", "order", "magnitude", "interactive", "rate", "cache", "time", "Robot", "significantly", "less", "than", "even", "single", "offline", "render", "-lrb-", "common", "most", "complex", "shot", "-rrb-", "because", "we", "cache", "light", "turn", "off", "cache", "time", "Pirate", "example", "dominate", "unoptimized", "octree", "caching", "compression", "process", "which", "-lrb-", "unnecessarily", "-rrb-", "read", "write", "multiple", "gb", "octree", "datum", "disk", "several", "time", "during", "caching", "we", "system", "have", "be", "integrate", "pipeline", "two", "special", "effect", "studio", "currently", "initial", "release", "number", "artist", "production", "both", "lighting", "look-design", "we", "have", "focus", "we", "effort", "iron", "out", "major", "previously-unsolved", "technical", "challenge", "system", "some", "technically", "straightforward", "significant", "aspect", "we", "implementation", "shadow", "map", "rendering", "currently", "lack", "extensive", "optimization", "while", "significant", "effort", "have", "be", "pay", "ensure", "fidelity", "scalability", "core", "compiler", "preprocessing", "real-time", "shading", "component", "complex", "scene", "subsurface", "scattering", "only", "proof-of-concept", "require", "further", "optimization", "nevertheless", "initial", "feedback", "have", "be", "extremely", "positive", "example", "artist", "love", "freedom", "experiment", "complex", "feature", "noise", "-lsb-", "we", "-rsb-", "usually", "shy", "away", "from", "noise", "because", "take", "so", "long", "edit", "...", "interactivity", "make", "much", "more", "useful", "general", "strong", "feeling", "interactive", "feedback", "only", "accelerate", "adjustment", "key", "parameter", "-lrb-", "get", "level", "right", "-lsb-", "previously", "-rsb-", "take", "I", "hour", "-lsb-", "after", "just", "tuning", "light", "match", "background", "under", "10", "seconds", "-rsb-", "-rrb-", "leave", "user", "more", "willing", "experiment", "aggressively", "GPU", "vs.", "specialization", "speedup", "we", "have", "estimate", "gain", "due", "specialization", "vs.", "GPU", "execution", "since", "we", "do", "have", "software", "preview", "runtime", "we", "can", "only", "perform", "back", "envelope", "calculation", "compare", "GPU", "shader", "RenderMan", "shader", "prman", "timing", "real", "vs.", "trivial", "shader", "include", "scene", "we", "estimate", "specialization", "caching", "provide", "100x", "speedup", "while", "execution", "GPU", "bring", "another", "20x", "coarsest", "level", "refinement", "provide", "extra", "10-100x", "upper-right", "half", "image", "render", "we", "approach", "while", "lower", "left", "final", "RenderMan", "frame", "initial", "refinement", "render", "over", "20", "hz", "we", "full", "4k", "instruction", "specialize", "surface", "shader", "spot", "light", "include", "shadow", "error", "percentage", "max", "pixel", "value", "Figure", "15", "430k", "transparent", "hair", "-lrb-", "0.6", "opacity", "threshold", "0.96", "-rrb-", "render", "720x389", "8x8", "sampling", "generate", "43m", "micropolygon", "58m", "pixel", "sample", "RenderMan", "condense", "11m", "visible", "shade", "sample", "17m", "unique", "visibility", "sample", "through", "lossless", "visibility", "compression", "render", "12", "hz", "fully", "refining", "33", "sec", "compression", "performance", "even", "better", "1.0", "0.1", "-lrb-", "threshold", "0.996", "-rrb-", "generate", "21m", "visible", "shade", "sample", "overflow", "16m", "sample", "texture", "we", "currently", "use", "-lrb-", "cf.", "Fig.", "10", "-rrb-", "Shadow", "geometry", "scale", "scene", "complexity", "main", "scalability", "limitation", "practice", "use", "micropolygon", "instead", "source", "primitive", "design", "decision", "avoid", "re-implementing", "every", "primitive", "support", "prman", "we", "control", "shadow-geometry", "level", "detail", "alter", "shade", "rate", "shadow", "bake", "pass", "additional", "mesh", "decimation", "pass", "could", "useful", "aside", "from", "shadow", "we", "system", "effectively", "scale", "image", "complexity", "indirect", "framebuffer", "cache", "compression", "dramatically", "reduce", "memory", "cost", "transparency", "main", "difference", "from", "previous", "technique", "because", "add", "unbounded", "number", "sample", "we", "create", "complex", "scene", "test", "scalability", "-lrb-", "fig.", "15", "-rrb-", "430k", "transparent", "hair", "fiber", "-lrb-", "0.1", "opacity", "threshold", "0.996", "-rrb-", "result", "55m", "prman", "micropolygon", "20m", "visible", "Lightspeed", "shade", "sample", "render", "720x389", "64x", "supersampling", "overflow", "we", "shade", "sample", "texture", "because", "GPU?s", "4kx4k", "-lrb-", "16m", "-rrb-", "texture", "limit", "however", "reduce", "0.6", "same", "scene", "only", "require", "11m", "shade", "sample", "-lrb-", "vs.", "43m", "prman", "-rrb-", "work", "12", "hz", "-lrb-", "33", "sec", "full", "refinement", "because", "full", "cache", "2gb", "need", "page", "-rrb-", "transparency", "Lightspeed", "shade", "just", "4m", "sample", "-lrb-", "vs.", "25m", "prman", "-rrb-", "22", "hz", "-lrb-", "5.5", "sec", "full", "refinement", "-rrb-", "16m", "limit", "can", "trivially", "increase", "use", "multiple", "texture", "8k", "texture", "DirectX", "10", "we", "production", "scene", "however", "we", "have", "encounter", "extreme", "case", "we", "artist", "avoid", "transparent", "hair", "favor", "smaller", "sub-pixel", "hair", "because", "same", "scalability", "problem", "apply", "prman", "fact", "though", "unbounded", "transparency", "consistently", "contribute", "much", "less", "total", "frame", "complexity", "than", "-lrb-", "bound", "-rrb-", "multisample", "we", "scene", "while", "worst", "case", "scale", "supersampled", "image", "complexity", "-lrb-", "time", "depth", "complexity", "transparency", "-rrb-", "key", "goal", "we", "design?visibility", "compression", "linearization", "visibility", "indirect", "framebuffer?is", "provide", "real-world", "scaling", "much", "closer", "pixel-complexity", "even", "motion", "blur", "-lrb-", "fig.", "-rrb-", "subpixel", "microgeometry", "like", "hair", "-lrb-", "fig.", "15", "-rrb-", "modest", "average", "transparency", "depth", "overall", "conclusion", "we", "test", "ignore", "shadow", "we", "can", "handle", "lot", "fine", "geometry", "handle", "lot", "very", "transparent", "coarse", "geometry", "we", "current", "implementation", "handle", "lot", "very", "transparent", "fine", "geometry", "completely", "fill", "image", "antialiasing", "we", "can", "handle", "lot", "fine", "geometry", "semi-transparent", "even", "fill", "image", "high", "antialiasing", "where", "scene", "complexity", "can", "become", "issue", "indirect", "framebuffer", "during", "caching", "because", "simple", "method", "caching", "-lrb-", "bake3d", "-rrb-", "extract", "all", "shaded", "grid", "from", "prman", "initial", "cache", "size", "can", "very", "large", "compression", "become", "disk", "i/o", "bind", "we", "address", "push", "compression", "in-memory", "renderer", "-lrb-", "dso", "-rrb-", "which", "greatly", "accelerate", "caching", "culling", "number", "unique", "shader", "can", "also", "issue", "however", "give", "surface", "shader", "use", "multiple", "surface", "different", "parameter", "we", "only", "need", "specialize", "once", "total", "number", "dynamic", "shader", "product", "number", "different", "light", "shader", "number", "surface", "shader", "-lrb-", "number", "instance", "-rrb-", "because", "we", "mostly", "use", "bershader", "problem", "we", "workload", "-lrb-", "10-100", "combination", "practice", "Fig.", "13", "-rrb-", "though", "would", "studio", "thousand", "unique", "shader", "shot", "might", "address", "established", "technique", "discuss", "Footnote", "practice", "we", "find", "we", "approach", "quite", "robust", "major", "challenge", "we", "have", "address", "include", "Dynamic", "call", "external", "routine", "largely", "eliminate", "during", "specialization", "where", "aren?t", "have", "be", "effectively", "emulate", "GPU", "make", "cache-required", "generate", "deep-framebuffer", "compress", "modest", "size", "even", "we", "more", "complicated", "scene", "shader", "GPU", "texture", "limit", "abstract", "through", "tiling", "complex", "visibility", "effectively", "compress", "even", "high", "multisampling", "rate", "interactivity", "maintain", "face", "complexity", "progressive", "refinement", "automatically", "specialize", "shader", "fit", "within", "current", "GPU", "limit", "future", "shader", "surpass", "limit", "we", "current", "hardware", "newer", "gpus", "have", "already", "elevated", "relevant", "program", "register", "size", "limit", "least", "order", "magnitude", "we", "key", "limitation", "same", "face", "any", "GPU", "shade", "system?namely", "operation", "easily", "express", "native", "GPU", "instruction", "require", "special", "handling", "most", "importantly", "nonlocal", "shade", "must", "handle", "explicitly", "use", "multipass", "algorithm", "we", "have", "achieve", "shadow", "translucency", "additional", "implementation", "require", "other", "effect", "still", "number", "feature", "can", "translate", "would", "result", "error", "message", "deem", "dynamic", "fortunately", "feature", "usually", "use", "dynamic", "part", "shader", "we", "studio", "may", "true", "all", "studio", "Ray", "Tracing", "we", "do", "perform", "ray", "casting", "note", "specular", "ray", "trace", "could", "preview", "deep-framebuffer", "use", "indirect", "buffer", "-lrb-", "ray", "intersection", "do", "change", "unless", "index", "refraction", "edit", "transmitted", "ray", "-rrb-", "future", "work", "main", "limitation", "concern", "ray-cast", "shadow", "inter-reflection", "ambient", "occlusion", "Lightspeed", "would", "require", "re-caching", "occlusion", "object-object", "shadow", "assignment", "change", "we", "artist", "only", "edit", "occlusion", "gain", "during", "lighting", "design", "interobject", "occlusion", "itself", "can", "cache", "shadow", "we", "system", "currently", "do", "implement", "deep", "shadow", "serious", "limitation", "scene", "hair", "brickmap", "pointcloud", "memory", "management", "would", "present", "challenge", "implement", "brickmap", "we", "do", "support", "they", "dynamic", "code", "particular", "problem", "brickmap", "use", "light", "shader", "we", "subsurface", "scattering", "implementation", "example", "where", "point", "cloud", "statically", "sample", "cache", "time", "return", "value", "dynamic", "non-linear", "light", "non-linear", "contribution", "easily", "cache", "Dynamic", "loop", "Dynamic", "loop", "contain", "cache", "expression", "limitation", "we", "support", "they", "special", "case", "where", "bound", "since", "we", "statically", "allocate", "space", "deep", "framebuffer", "Figure", "12", "use", "bound", "dynamic", "loop", "layered", "material", "Shadow", "geometry", "scale", "scene", "complexity", "main", "scalability", "limitation", "practice", "use", "micropolygon", "instead", "source", "primitive", "design", "decision", "avoid", "re-implementing", "every", "primitive", "support", "prman", "we", "control", "shadow-geometry", "level", "detail", "alter", "shade", "rate", "shadow", "bake", "pass", "additional", "mesh", "decimation", "pass", "could", "useful", "aside", "from", "shadow", "we", "system", "effectively", "scale", "image", "complexity", "indirect", "framebuffer", "cache", "compression", "dramatically", "reduce", "memory", "cost", "transparency", "main", "difference", "from", "previous", "technique", "because", "add", "unbounded", "number", "sample", "we", "create", "complex", "scene", "test", "scalability", "-lrb-", "fig.", "15", "-rrb-", "430k", "transparent", "hair", "fiber", "-lrb-", "0.1", "opacity", "threshold", "0.996", "-rrb-", "result", "55m", "prman", "micropolygon", "20m", "visible", "Lightspeed", "shade", "sample", "render", "720x389", "64x", "supersampling", "overflow", "we", "shade", "sample", "texture", "because", "GPU?s", "4kx4k", "-lrb-", "16m", "-rrb-", "texture", "limit", "however", "reduce", "0.6", "same", "scene", "only", "require", "11m", "shade", "sample", "-lrb-", "vs.", "43m", "prman", "-rrb-", "work", "12", "hz", "-lrb-", "33", "sec", "full", "refinement", "because", "full", "cache", "2gb", "need", "page", "-rrb-", "transparency", "Lightspeed", "shade", "just", "4m", "sample", "-lrb-", "vs.", "25m", "prman", "-rrb-", "22", "hz", "-lrb-", "5.5", "sec", "full", "refinement", "-rrb-", "16m", "limit", "can", "trivially", "increase", "use", "multiple", "texture", "8k", "texture", "DirectX", "10", "we", "production", "scene", "however", "we", "have", "encounter", "extreme", "case", "we", "artist", "avoid", "transparent", "hair", "favor", "smaller", "sub-pixel", "hair", "because", "same", "scalability", "problem", "apply", "prman", "fact", "though", "unbounded", "transparency", "consistently", "contribute", "much", "less", "total", "frame", "complexity", "than", "-lrb-", "bound", "-rrb-", "multisample", "we", "scene", "while", "worst", "case", "scale", "supersampled", "image", "complexity", "-lrb-", "time", "depth", "complexity", "transparency", "-rrb-", "key", "goal", "we", "design?visibility", "compression", "linearization", "visibility", "indirect", "framebuffer?is", "provide", "real-world", "scaling", "much", "closer", "pixel-complexity", "even", "motion", "blur", "-lrb-", "fig.", "-rrb-", "subpixel", "microgeometry", "like", "hair", "-lrb-", "fig.", "15", "-rrb-", "modest", "average", "transparency", "depth", "overall", "conclusion", "we", "test", "ignore", "shadow", "we", "can", "handle", "lot", "fine", "geometry", "handle", "lot", "very", "transparent", "coarse", "geometry", "we", "current", "implementation", "handle", "lot", "very", "transparent", "fine", "geometry", "completely", "fill", "image", "antialiasing", "we", "can", "handle", "lot", "fine", "geometry", "semi-transparent", "even", "fill", "image", "high", "antialiasing", "where", "scene", "complexity", "can", "become", "issue", "indirect", "framebuffer", "during", "caching", "because", "simple", "method", "caching", "-lrb-", "bake3d", "-rrb-", "extract", "all", "shaded", "grid", "from", "prman", "initial", "cache", "size", "can", "very", "large", "compression", "become", "disk", "i/o", "bind", "we", "address", "push", "compression", "in-memory", "renderer", "-lrb-", "dso", "-rrb-", "which", "greatly", "accelerate", "caching", "culling", "number", "unique", "shader", "can", "also", "issue", "however", "give", "surface", "shader", "use", "multiple", "surface", "different", "parameter", "we", "only", "need", "specialize", "once", "total", "number", "dynamic", "shader", "product", "number", "different", "light", "shader", "number", "surface", "shader", "-lrb-", "number", "instance", "-rrb-", "because", "we", "mostly", "use", "bershader", "problem", "we", "workload", "-lrb-", "10-100", "combination", "practice", "Fig.", "13", "-rrb-", "though", "would", "studio", "thousand", "unique", "shader", "shot", "might", "address", "established", "technique", "discuss", "Footnote", "practice", "we", "find", "we", "approach", "quite", "robust", "major", "challenge", "we", "have", "address", "include", "Dynamic", "call", "external", "routine", "largely", "eliminate", "during", "specialization", "where", "aren?t", "have", "be", "effectively", "emulate", "GPU", "make", "cache-required", "generate", "deep-framebuffer", "compress", "modest", "size", "even", "we", "more", "complicated", "scene", "shader", "GPU", "texture", "limit", "abstract", "through", "tiling", "complex", "visibility", "effectively", "compress", "even", "high", "multisampling", "rate", "interactivity", "maintain", "face", "complexity", "progressive", "refinement", "automatically", "specialize", "shader", "fit", "within", "current", "GPU", "limit", "future", "shader", "surpass", "limit", "we", "current", "hardware", "newer", "gpus", "have", "already", "elevated", "relevant", "program", "register", "size", "limit", "least", "order", "magnitude", "we", "key", "limitation", "same", "face", "any", "GPU", "shade", "system?namely", "operation", "easily", "express", "native", "GPU", "instruction", "require", "special", "handling", "most", "importantly", "nonlocal", "shade", "must", "handle", "explicitly", "use", "multipass", "algorithm", "we", "have", "achieve", "shadow", "translucency", "additional", "implementation", "require", "other", "effect", "still", "number", "feature", "can", "translate", "would", "result", "error", "message", "deem", "dynamic", "fortunately", "feature", "usually", "use", "dynamic", "part", "shader", "we", "studio", "may", "true", "all", "studio", "Ray", "Tracing", "we", "do", "perform", "ray", "casting", "note", "specular", "ray", "trace", "could", "preview", "deep-framebuffer", "use", "indirect", "buffer", "-lrb-", "ray", "intersection", "do", "change", "unless", "index", "refraction", "edit", "transmitted", "ray", "-rrb-", "future", "work", "main", "limitation", "concern", "ray-cast", "shadow", "inter-reflection", "ambient", "occlusion", "Lightspeed", "would", "require", "re-caching", "occlusion", "object-object", "shadow", "assignment", "change", "we", "artist", "only", "edit", "occlusion", "gain", "during", "lighting", "design", "interobject", "occlusion", "itself", "can", "cache", "shadow", "we", "system", "currently", "do", "implement", "deep", "shadow", "serious", "limitation", "scene", "hair", "brickmap", "pointcloud", "memory", "management", "would", "present", "challenge", "implement", "brickmap", "we", "do", "support", "they", "dynamic", "code", "particular", "problem", "brickmap", "use", "light", "shader", "we", "subsurface", "scattering", "implementation", "example", "where", "point", "cloud", "statically", "sample", "cache", "time", "return", "value", "dynamic", "non-linear", "light", "non-linear", "contribution", "easily", "cache", "Dynamic", "loop", "Dynamic", "loop", "contain", "cache", "expression", "limitation", "we", "support", "they", "special", "case", "where", "bound", "since", "we", "statically", "allocate", "space", "deep", "framebuffer", "Figure", "12", "use", "bound", "dynamic", "loop", "layered", "material", "we", "have", "introduce", "system", "real-time", "preview", "RenderMan", "scene", "during", "lighting", "design", "we", "method", "automatically", "specialize", "shader", "static", "RenderMan", "pass", "generate", "deepframebuffer", "dynamic", "cg", "pass", "use", "deep-framebuffer", "enable", "real-time", "preview", "GPU", "cache", "compression", "enable", "automatically", "generate", "deep-framebuffer", "fit", "modest", "GPU", "memory", "complex", "production", "shot", "we", "have", "introduce", "indirect", "framebuffer", "which", "efficiently", "encode", "multisample", "high-quality", "render", "transparency", "motion", "blur", "we", "computation", "graph-based", "system", "architecture", "flexible", "amenable", "multipass", "render", "algorithm", "which", "we", "demonstrate", "shadow", "mapping", "subsurface", "scattering", "we", "be", "surprise", "effectiveness", "cache", "compression", "initially", "we", "assume", "we", "would", "build", "complex", "compiler", "analysis", "control", "cache", "size", "however", "due", "data-parallel", "nature", "shade", "redundancy", "abound", "simple", "post-process", "easily", "uncover", "savings", "which", "static", "analysis", "could", "recognize", "whole", "we", "system", "bring", "level", "automation", "greatly", "simplify", "interactive", "lighting", "preview", "alleviate", "need", "write", "maintain", "different", "shader", "final", "rendering", "preprocessing", "preview", "however", "do", "close", "debate", "between", "manual", "instrumentation", "automatic", "specialization", "manual", "programming", "preview", "shader", "can", "bring", "extra", "level", "flexibility", "particular", "adapt", "level", "detail", "further", "accelerate", "preview", "illustrate", "lpic", "-lsb-", "Pellacini", "et", "al.", "2005", "-rsb-", "though", "Pellacini", "separately", "show", "automatic", "level-of-detail", "can", "help", "-lsb-", "2005", "-rsb-", "long", "run", "we", "believe", "lighting", "preview", "should", "address", "way", "similar", "traditional", "programming", "automatic", "tool", "provide", "compilation", "optimization", "programmer", "can", "provide", "hint", "manually", "optimize", "simplify", "critical", "portion", "code", "base", "profiling", "tool", "still", "greatest", "limitation", "deep-framebuffer", "rendering", "its", "basis", "local", "shading", "global", "illumination", "become", "prevalent", "production", "rendering", "ability", "integrate", "global", "effect", "system", "determine", "its", "future", "success", "fortunately", "we", "technique", "specific", "gpus", "rather", "generally", "useful", "reduce", "complex", "shade", "efficient", "data-parallel", "execution", "include", "future", "manycore", "cpus", "may", "ultimately", "avenue", "through", "which", "global", "effect", "most", "efficiently", "achieve", "Acknowledgments", "numerous", "people", "have", "contribute", "project", "its", "many", "year", "exploration", "implementation", "work", "start", "under", "advise", "Pat", "Hanrahan", "initially", "collaboration", "ujval", "kapasus", "Alex", "Aiken", "John", "Kodumal", "propose", "dependence", "analysis", "graph", "reachability", "provide", "first", "analysis", "library", "we", "use", "Matt", "Pharr", "John", "Owens", "Aaron", "Lefohn", "Eric", "Chan", "many", "member", "Stanford", "MIT", "Graphics", "Labs", "provide", "year", "essential", "advice", "feedback", "Tippett", "Studio", "take", "great", "risk", "actively", "support", "early", "research", "Dan", "Goldman", "introduce", "work", "ILM", "where", "Alan", "Trombla", "Ed", "Hanway", "Steve", "Sullivan", "have", "oversee", "many", "developer", "have", "contribute", "code", "include", "Sebastian", "Fernandez", "Peter", "Murphy", "Simon", "Premo", "ze", "Aaron", "Luk", "Hilmar", "Koch", "Paul", "Churchill", "Tom", "Martinek", "Charles", "Rose", "provide", "critical", "artist?s", "perspective", "early", "design", "Dan", "Wexler", "Larry", "Gritz", "Reid", "Gershbein", "provide", "useful", "explanation", "commercial", "lighting", "technology", "we", "thank", "Michael", "Bay", "graciously", "share", "unreleased", "image", "from", "he", "movie", "Dan", "Piponi", "generate", "we", "hair", "datum", "anonymous", "reviewer", "insightful", "discussion", "criticism", "Sylvain", "Paris", "Ravi", "Ramamoorthi", "Kevin", "Egan", "Aner", "Ben-Artzi", "Kayvon", "Fatahalian", "provide", "critical", "write", "feedback", "work", "support", "NSF", "CAREER", "award", "0447561", "NSF", "Graduate", "Research", "Fellowship", "NVIDIA", "Graduate", "Fellowship", "Ford", "Foundation", "Graduate", "Fellowship", "Microsoft", "Research", "New", "Faculty", "Fellowship", "Sloan", "fellowship" ],
  "content" : "Figure 13 summarizes our system?s fully-automatic performance on two of our shots (Figs. 1, 12). Cache sizes fit within current GPU resources, though our system scales to support out-of-core shots at much higher resolutions or with even more complex shaders. We report all results for our current, deployed artist workstations, with dual 2.6GHz AMD Opteron 2218 processors, 8GB RAM, and NVIDIA Quadro FX 5500 (G71) graphics. We are generally at the limit of the capability/performance curve for our current hardware, but preliminary results suggest major performance improvements on next-generation hardware. Pirate (12) Robot (1) resolution 640x376 914x389 supersampling 4x4 13x13 lights 3 42 RenderMan (total) 409 sec 3406 sec irradiance shading 111 sec material shaders 1 2 material instances 4 44 light shaders 1 5 light instances 3 42 Caching (total) 1425 sec 931 sec initialization 8 sec 18 sec shader specialization 24 sec 63 sec deep-framebuffer caching 627 sec 499 sec shadow geometry caching 105 sec 164 sec cache compression 60 sec 187 sec octree compression 600 sec Preview irradiance shading (1 light) 7 sec interaction (irradiance cached) 0.5 sec coarse refinement, 4x4 blocks 0.1 sec full refinement (1 light changed) 10 sec 2.7 sec full refinement (n lights) 29 sec (3 lights) 31.7 (42 lights) deep-framebuffer 104 MB 256 MB indirect framebuffer 33 MB 29 MB irradiance deep-framebuffer 83 MB scattering index buffer 436 MB System performance compared to our RenderManbased offline pipeline for two production shots (Figs. 1 & 12). In both, initial feedback is accelerated several orders of magnitude, to interactive rates. Caching time for Robot is significantly less than even a single offline render (common for most complex shots), because we cache with lights turned off. Caching time for the Pirate example is dominated by unoptimized octree caching and compression processes which (unnecessarily) read and write multiple GB of octree data on disk several times during caching. Our system has been integrated into the pipelines of two special effects studios. It is currently in initial release with a number of artists in production for both lighting and look-design. We have focused our efforts on ironing out the major, previously-unsolved technical challenges with such a system. As such, some technically straightforward but significant aspects of our implementation, such as shadow map rendering, currently lack extensive optimization, while significant effort has been paid to ensure the fidelity and scalability of the core compiler, preprocessing, and real-time shading components on complex scenes. Subsurface scattering is only proof-of-concept and requires further optimization. Nevertheless, initial feedback has been extremely positive. For example, artists love the freedom to experiment with complex features such as noise: ?[we] usually shy away from noise because it takes so long to edit... this interactivity makes it much more useful. ? In general, there was a strong feeling that interactive feedback not only accelerated the adjustment of key parameters (?getting that level right [previously] took me an hour! ? [after just tuning a light to match the background in under 10 seconds]), but left users more willing to experiment aggressively. GPU vs. specialization speedup We have estimated the gain due to specialization vs. GPU execution. Since we do not have a software preview runtime, we can only perform back of the envelope calculations comparing the GPU shaders to RenderMan shaders, and prman timing with real vs. trivial shaders. For the included scenes, we estimate that specialization and caching provide a 100x speedup while execution on the GPU brings another 20x. The coarsest level of refinement provides an extra 10-100x. The upper-right half of the image is rendered with our approach while the lower left is the final RenderMan frame. Initial refinement renders at over 20 Hz with our full 4k instruction specialized surface shader and spot light, including shadows. Error is in percentage of max pixel value. Figure 15: 430k transparent hairs (? = 0.6, opacity threshold: 0.96) rendered at 720x389 with 8x8 sampling. This generates 43M micropolygons and 58M pixel samples in RenderMan, and condenses to 11M visible shading samples and 17M unique visibility samples through lossless visibility compression, rendering at 12 Hz and fully refining in 33 secs. Compression and performance are even better at ? = 1.0, but ? = 0.1 (threshold: 0.996) generates 21M visible shading samples, overflowing the 16M sample textures we currently use (cf. Fig. 10 ). Shadow geometry scales with scene complexity and is the main scalability limitation, in practice. Using micropolygons instead of source primitives was a design decision to avoid re-implementing every primitive supported by prman. We control shadow-geometry level of detail by altering the shading rate of the shadow bake pass. Additional mesh decimation passes could be useful. Aside from shadowing, our system effectively scales with image complexity. The indirect framebuffer and cache compression dramatically reduce memory costs. Transparency is the main difference from previous techniques because it adds an unbounded number of samples. We created a complex scene to test scalability (Fig. 15): 430k transparent hair fibers (? = 0.1, opacity threshold= 0.996), resulting in 55M prman micropolygons and 20M visible Lightspeed shading samples rendered at 720x389 with 64x supersampling. This overflows our shade sample texture because of the GPU?s 4kx4k (16M) texture limit. However, with ? reduced to 0.6, the same scene only requires 11M shade samples (vs. 43M in prman) and works at 12 Hz (33 secs for full refinement because the full cache is 2GB and needs to be paged). With no transparency, Lightspeed shades just 4M samples (vs. 25M for prman) at 22 Hz (5.5 secs for full refinement). The 16M limit can trivially be increased by using multiple textures or 8k textures in DirectX 10. For our production scenes, however, we have not encountered such extreme cases. Our artists avoid transparent hair in favor of smaller sub-pixel hair because these same scalability problems apply in prman. In fact, though unbounded, transparency consistently contributes much less to total frame complexity than (bounded) multisampling in our scenes. While the worst case scales with supersampled image complexity (times depth complexity for transparency), the key goal of our design?visibility compression and the linearization of visibility into the indirect framebuffer?is to provide real-world scaling much closer to pixel-complexity, even with motion blur ( Fig. 8 ), subpixel microgeometry like hair (Fig. 15), and a modest average transparency depth. The overall conclusion of our tests, ignoring shadowing, is: ? We can handle a lot of fine geometry, or handle a lot of very transparent coarse geometry, but our current implementation will not handle a lot of very transparent and fine geometry that completely fills the image, with antialiasing. ? We can handle a lot of fine geometry that is semi-transparent even if it fills the image, with high antialiasing. Where scene complexity can become an issue for the indirect framebuffer is during caching. Because simple methods of caching (bake3d) extract all shaded grids from prman, initial cache sizes can be very large, and compression becomes disk i/o bound. We addressed this by pushing compression in-memory with the renderer (as a DSO), which greatly accelerates caching and culling. The number of unique shaders can also be an issue. However, if a given surface shader is used for multiple surfaces with different parameters, we only need to specialize it once. The total number of dynamic shaders is the product of the number of different light shaders and the number of surface shaders (not the number of instances). Because we mostly use ?bershaders, this is not a problem for our workloads (?10-100 combinations in practice, Fig. 13 ), though it would be for studios with thousands of unique shaders in a shot. This might be addressed with established techniques, as discussed in Footnote 1. In practice we find our approach quite robust. Major challenges we have addressed include: ? Dynamic calls to external C routines are largely eliminated during specialization, and, where they aren?t, they have been effectively emulated on the GPU or made cache-required. ? Generated deep-framebuffers are compressed to modest sizes, even for our more complicated scenes and shaders. ? GPU texture limits are abstracted through tiling. ? Complex visibility is effectively compressed, even at high multisampling rates. ? Interactivity is maintained in the face of complexity by progressive refinement. ? Automatically specialized shaders fit within current GPU limits. Future shaders will surpass the limits of our current hardware, but newer GPUs have already elevated the relevant program and register size limits by at least an order of magnitude. Our key limitations are the same faced by any GPU shading system?namely, that operations not easily expressed as native GPU instructions require special handling. Most importantly, nonlocal shading must be handled explicitly using multipass algorithms. We have achieved this for shadows and translucency, but additional implementation is required for other effects. Still, a number of features cannot be translated and would result in an error message if deemed dynamic. Fortunately, such features are usually not used in the dynamic parts of shaders in our studio. This may not be true in all studios. Ray Tracing We do not perform ray casting. Note that specular ray tracing could be previewed in a deep-framebuffer using indirect buffers (ray intersections do not change unless the index of refraction is edited for transmitted rays). This is future work. The main limitation concerns ray-casting for shadows and inter-reflections. Ambient occlusion Lightspeed would require re-caching of occlusion if object-object shadowing assignments changed. Our artists only edit occlusion gain during lighting design, and interobject occlusion, itself, can be cached. Shadows Our system currently does not implement deep shadows and this is a serious limitation for scenes with hair. Brickmaps and pointclouds Memory management would present challenges for implementing brickmaps. We do not support them in dynamic code. This is a particular problem if brickmaps are used in a light shader. Our subsurface scattering implementation is an example where a point cloud is statically sampled at cache time, but the returned values are dynamic. Non-linear lights Non-linear contributions are not easily cached. Dynamic loops Dynamic loops containing cached expressions are a limitation. We support them in the special case where they are bounded, since we statically allocate space in the deep framebuffer. Figure 12 uses bounded dynamic loops for layered materials. Shadow geometry scales with scene complexity and is the main scalability limitation, in practice. Using micropolygons instead of source primitives was a design decision to avoid re-implementing every primitive supported by prman. We control shadow-geometry level of detail by altering the shading rate of the shadow bake pass. Additional mesh decimation passes could be useful. Aside from shadowing, our system effectively scales with image complexity. The indirect framebuffer and cache compression dramatically reduce memory costs. Transparency is the main difference from previous techniques because it adds an unbounded number of samples. We created a complex scene to test scalability (Fig. 15): 430k transparent hair fibers (? = 0.1, opacity threshold= 0.996), resulting in 55M prman micropolygons and 20M visible Lightspeed shading samples rendered at 720x389 with 64x supersampling. This overflows our shade sample texture because of the GPU?s 4kx4k (16M) texture limit. However, with ? reduced to 0.6, the same scene only requires 11M shade samples (vs. 43M in prman) and works at 12 Hz (33 secs for full refinement because the full cache is 2GB and needs to be paged). With no transparency, Lightspeed shades just 4M samples (vs. 25M for prman) at 22 Hz (5.5 secs for full refinement). The 16M limit can trivially be increased by using multiple textures or 8k textures in DirectX 10. For our production scenes, however, we have not encountered such extreme cases. Our artists avoid transparent hair in favor of smaller sub-pixel hair because these same scalability problems apply in prman. In fact, though unbounded, transparency consistently contributes much less to total frame complexity than (bounded) multisampling in our scenes. While the worst case scales with supersampled image complexity (times depth complexity for transparency), the key goal of our design?visibility compression and the linearization of visibility into the indirect framebuffer?is to provide real-world scaling much closer to pixel-complexity, even with motion blur ( Fig. 8 ), subpixel microgeometry like hair (Fig. 15), and a modest average transparency depth. The overall conclusion of our tests, ignoring shadowing, is: ? We can handle a lot of fine geometry, or handle a lot of very transparent coarse geometry, but our current implementation will not handle a lot of very transparent and fine geometry that completely fills the image, with antialiasing. ? We can handle a lot of fine geometry that is semi-transparent even if it fills the image, with high antialiasing. Where scene complexity can become an issue for the indirect framebuffer is during caching. Because simple methods of caching (bake3d) extract all shaded grids from prman, initial cache sizes can be very large, and compression becomes disk i/o bound. We addressed this by pushing compression in-memory with the renderer (as a DSO), which greatly accelerates caching and culling. The number of unique shaders can also be an issue. However, if a given surface shader is used for multiple surfaces with different parameters, we only need to specialize it once. The total number of dynamic shaders is the product of the number of different light shaders and the number of surface shaders (not the number of instances). Because we mostly use ?bershaders, this is not a problem for our workloads (?10-100 combinations in practice, Fig. 13 ), though it would be for studios with thousands of unique shaders in a shot. This might be addressed with established techniques, as discussed in Footnote 1. In practice we find our approach quite robust. Major challenges we have addressed include: ? Dynamic calls to external C routines are largely eliminated during specialization, and, where they aren?t, they have been effectively emulated on the GPU or made cache-required. ? Generated deep-framebuffers are compressed to modest sizes, even for our more complicated scenes and shaders. ? GPU texture limits are abstracted through tiling. ? Complex visibility is effectively compressed, even at high multisampling rates. ? Interactivity is maintained in the face of complexity by progressive refinement. ? Automatically specialized shaders fit within current GPU limits. Future shaders will surpass the limits of our current hardware, but newer GPUs have already elevated the relevant program and register size limits by at least an order of magnitude. Our key limitations are the same faced by any GPU shading system?namely, that operations not easily expressed as native GPU instructions require special handling. Most importantly, nonlocal shading must be handled explicitly using multipass algorithms. We have achieved this for shadows and translucency, but additional implementation is required for other effects. Still, a number of features cannot be translated and would result in an error message if deemed dynamic. Fortunately, such features are usually not used in the dynamic parts of shaders in our studio. This may not be true in all studios. Ray Tracing We do not perform ray casting. Note that specular ray tracing could be previewed in a deep-framebuffer using indirect buffers (ray intersections do not change unless the index of refraction is edited for transmitted rays). This is future work. The main limitation concerns ray-casting for shadows and inter-reflections. Ambient occlusion Lightspeed would require re-caching of occlusion if object-object shadowing assignments changed. Our artists only edit occlusion gain during lighting design, and interobject occlusion, itself, can be cached. Shadows Our system currently does not implement deep shadows and this is a serious limitation for scenes with hair. Brickmaps and pointclouds Memory management would present challenges for implementing brickmaps. We do not support them in dynamic code. This is a particular problem if brickmaps are used in a light shader. Our subsurface scattering implementation is an example where a point cloud is statically sampled at cache time, but the returned values are dynamic. Non-linear lights Non-linear contributions are not easily cached. Dynamic loops Dynamic loops containing cached expressions are a limitation. We support them in the special case where they are bounded, since we statically allocate space in the deep framebuffer. Figure 12 uses bounded dynamic loops for layered materials. We have introduced a system for the real-time preview of RenderMan scenes during lighting design. Our method automatically specializes shaders into a static RenderMan pass that generates a deepframebuffer, and a dynamic Cg pass that uses the deep-framebuffer to enable real-time preview on a GPU. Cache compression enables automatically generated deep-framebuffers to fit in modest GPU memory for complex production shots. We have introduced the indirect framebuffer which efficiently encodes multisampling for high-quality rendering with transparency and motion blur. Our computation graph-based system architecture is flexible and is amenable to multipass rendering algorithms, which we demonstrate with shadow mapping and subsurface scattering. We were surprised by the effectiveness of cache compression. Initially, we assumed we would build complex compiler analyses to control cache size. However, due to the data-parallel nature of shading, redundancy abounds, and simple post-processes easily uncover savings which static analysis could not recognize. As a whole, our system brings a level of automation that greatly simplifies interactive lighting preview and alleviates the need to write and maintain different shaders for final rendering, preprocessing, and preview. However, it does not close the debate between manual instrumentation and automatic specialization. The manual programming of preview shaders can bring an extra level of flexibility, in particular to adapt the level of detail to further accelerate preview, as illustrated in lpics [Pellacini et al. 2005], though Pellacini separately showed that automatic level-of-detail can help [2005]. In the long run, we believe that lighting preview should be addressed in a way similar to traditional programming: automatic tools are provided for compilation and optimization, and the programmer can provide hints or manually optimize and simplify critical portions of the code based on profiling tools. Still, the greatest limitation to deep-framebuffer rendering is its basis in local shading. As global illumination becomes prevalent in production rendering, the ability to integrate global effects into this system will determine its future success. Fortunately, our techniques are not specific to GPUs. Rather, they are generally useful for reducing complex shading to efficient data-parallel execution, including on future manycore CPUs, and this may ultimately be the avenue through which global effects are most efficiently achieved. Acknowledgments Numerous people have contributed to this project in its many years of exploration and implementation. This work started under the advising of Pat Hanrahan, initially in collaboration with Ujval Kapasi. Alex Aiken and John Kodumal proposed dependence analysis by graph reachability and provided the first analysis library we used. Matt Pharr, John Owens, Aaron Lefohn, Eric Chan, and many members of the Stanford and MIT Graphics Labs provided years of essential advice and feedback. Tippett Studio took great risk in actively supporting early research. Dan Goldman introduced the work to ILM, where Alan Trombla, Ed Hanway, and Steve Sullivan have overseen it. Many developers have contributed code, including Sebastian Fernandez, Peter Murphy, Simon Premo ze, and Aaron Luk. Hilmar Koch, Paul Churchill, Tom Martinek, and Charles Rose provided a critical artist?s perspective early in design. Dan Wexler, Larry Gritz, and Reid Gershbein provided useful explanations of commercial lighting technologies. We thank Michael Bay for graciously sharing unreleased images from his movie, Dan Piponi for generating our hair data, and the anonymous reviewers for their insightful discussion and criticism. Sylvain Paris, Ravi Ramamoorthi, Kevin Egan, Aner Ben-Artzi, and Kayvon Fatahalian provided critical writing feedback. This work was supported by NSF CAREER award 0447561, an NSF Graduate Research Fellowship, NVIDIA Graduate Fellowship, Ford Foundation Graduate Fellowship, Microsoft Research New Faculty Fellowship and a Sloan fellowship.",
  "resources" : [ ]
}