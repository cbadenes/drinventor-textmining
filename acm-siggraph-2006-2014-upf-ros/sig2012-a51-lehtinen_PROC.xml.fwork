{
  "uri" : "sig2012-a51-lehtinen_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2012/a51-lehtinen_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Reconstructing the Indirect Light Field for Global Illumination",
    "published" : "2012",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Jaakko-Lehtinen",
      "name" : "Jaakko",
      "surname" : "Lehtinen"
    }, {
      "uri" : "http://drinventor/Timo-Aila",
      "name" : "Timo",
      "surname" : "Aila"
    }, {
      "uri" : "http://drinventor/Samuli-Laine",
      "name" : "Samuli",
      "surname" : "Laine"
    }, {
      "uri" : "http://drinventor/Fr?do-Durand",
      "name" : "Fr?do",
      "surname" : "Durand"
    } ]
  },
  "bagOfWords" : [ "evaluate", "indirect", "illumination", "entail", "sampling", "radiance", "over", "hemisphere", "each", "visible", "point", "notoriously", "prone", "noise", "due", "high", "variance", "integrand", "cause", "visibility", "texture", "illumination", "reconstructed", "light", "field", "use", "standard", "brdf", "sampling", "step", "generate", "final", "image", "we", "build", "recent", "work", "have", "provide", "solid", "understanding", "local", "anisotropy", "exhibit", "temporal", "light", "field", "-lsb-", "Durand", "et", "al.", "2005", "Ramamoorthi", "et", "al.", "2007", "Egan", "et", "al.", "2009", "Soler", "et", "al.", "2009", "Egan", "et", "al.", "2011b", "-rsb-", "contrast", "large", "body", "previous", "work", "aim", "reduce", "noise", "global", "illumination", "we", "do", "utilize", "scene", "geometry", "reconstruction", "pass", "body", "recent", "work", "concentrate", "anisotropy", "i.e.", "fact", "signal", "often", "vary", "slowly", "along", "certain", "non-axis-aligned", "subspace", "fourier", "analysis", "elegantly", "reveal", "signal", "locally", "effectively", "lower", "dimension", "case", "-lsb-", "Durand", "et", "al.", "2005", "Egan", "et", "al.", "2009", "-rsb-", "recent", "trend", "anisotropic", "reconstruction", "can", "trace", "back", "multidimensional", "adaptive", "sampling", "reconstruction", "-lrb-", "mda", "-rrb-", "algorithm", "Hachisuka", "et", "al.", "-lsb-", "2008", "-rsb-", "while", "numerous", "earlier", "technique", "have", "address", "generation", "sample", "accord", "expect", "variance", "integrand", "-lrb-", "importance", "sampling", "adaptive", "sampling", "method", "-rrb-", "Hachisuka", "et", "al.", "concentrate", "example", "4d", "integrand", "over", "image", "lens", "correspond", "diffuse", "fronto-parallel", "planar", "object", "out", "focus", "actually", "only", "two-dimensional", "author", "measure", "local", "anisotropy", "from", "sample", "use", "structure", "tensor", "use", "locally", "warp", "distance", "metric", "use", "reconstruct", "integrand", "use", "highdimensional", "k-nearest-neighbor", "search", "-lrb-", "k-nn", "-rrb-", "can", "yield", "significant", "benefit", "unfortunately", "noise", "texture", "may", "confuse", "anisotropy", "estimator", "Egan", "et", "al.", "-lsb-", "2009", "-rsb-", "analyze", "anisotropy", "spacetime", "integrand", "motion", "blur", "from", "first", "principle", "through", "fourier", "analysis", "use", "prediction", "local", "spectrum", "drive", "adaptive", "sampling", "sheared", "filter", "allow", "sharing", "sample", "between", "pixel", "adapt", "predict", "spectrum", "similar", "analysis", "algorithm", "be", "present", "soft", "shadow", "directional", "occlusion", "same", "author", "-lsb-", "Egan", "et", "al.", "2011b", "Egan", "et", "al.", "2011a", "-rsb-", "while", "analysis", "successful", "drive", "adaptive", "sampling", "sheared", "reconstruction", "filter", "less", "efficient", "when", "direction", "anisotropy", "change", "either", "continuously", "discontinuously", "across", "image", "goal", "present", "work", "extend", "approach", "more", "challenging", "unstructured", "case", "indirect", "illumination", "sample-based", "algorithm", "several", "technique", "e.g.", "anisotropic", "diffusion", "-lsb-", "McCool", "1999", "-rsb-", "-lrb-", "cascade", "-rrb-", "cross-bilateral", "filter", "-lrb-", "-rrb-", "-lsb-", "Dammertz", "et", "al.", "2010", "-rsb-", "post-process", "sample", "pixel", "generate", "initial", "render", "pass", "reduce", "noise", "Sen", "Darabi", "-lsb-", "2012", "-rsb-", "improve", "quality", "cross-bilateral", "filter", "compute", "weight", "adaptively", "each", "pixel", "base", "apparent", "dependency", "between", "domain", "variable", "scene", "feature", "sample", "color", "while", "method", "can", "example", "detect", "sample", "some", "pixel", "heavily", "affect", "time", "do", "know", "magnitude", "direction", "motion", "Overbeck", "et", "al.", "-lsb-", "2009", "-rsb-", "Rousselle", "et", "al.", "-lsb-", "2011", "-rsb-", "describe", "method", "maintain", "basis-representation", "image", "adaptively", "request", "more", "sample", "from", "renderer", "area", "exhibit", "high", "variance", "shade", "reuse", "several", "algorithm", "reuse", "shade", "result", "radiance", "irradiance", "while", "determine", "visibility", "actual", "scene", "-lsb-", "Ward", "et", "al.", "1988", "Bala", "et", "al.", "1999", "Bekaert", "et", "al.", "2002", "Gassenbauer", "et", "al.", "2009", "-rsb-", "sampling", "often", "adaptive", "drive", "error", "heuristic", "algorithm", "convert", "scene", "point-based", "representation", "preprocess", "compute", "solution", "use", "representation", "contrast", "we", "obtain", "sparse", "set", "path", "segment", "from", "renderer", "-lrb-", "which", "use", "whatever", "representation", "internally", "-rrb-", "treat", "segment", "sample", "indirect", "light", "field", "upsample", "solution", "accounting", "angular", "effect", "gloss", "photon", "vpl", "some", "method", "generate", "cloud", "point", "light", "-lrb-", "call", "photon", "virtual", "point", "light", "vpl", "-rrb-", "represent", "entire", "indirect", "light", "field", "-lsb-", "Wann", "Jensen", "1996", "Keller", "1997", "Walter", "et", "al.", "2005", "-rsb-", "we", "seek", "render", "high-quality", "global", "illumination", "while", "only", "trace", "small", "number", "ray", "across", "hemisphere", "each", "visible", "point", "we", "reuse", "ray", "across", "many", "pixel", "reconstruct", "each", "visible", "point", "upsampled", "version", "incoming", "light", "field", "we", "store", "ray", "cast", "from", "visible", "point", "spatial", "hierarchy", "index", "hit", "point", "-lrb-", "section", "2.1", "-rrb-", "each", "ray", "sample", "indirect", "light", "field", "handle", "two", "dimension", "light", "field", "each", "input", "sample", "correspond", "secondary", "ray", "consist", "tuple", "where", "radiance", "origin", "hit", "point", "secondary", "ray", "corresponding", "normal", "motion", "vector", "number", "-lcb-", "-rcb-", "image", "lens", "time", "coordinate", "incident", "direction", "which", "-lrb-", "-rrb-", "sample", "store", "its", "concentration", "parameter", "total", "number", "reconstruction", "ray", "per", "pixel", "thus", "where", "number", "primary", "hit", "per", "pixel", "guarantee", "distribution", "ray", "generate", "during", "final", "image", "reconstruction", "similar", "input", "we", "discuss", "possible", "noise", "radiance", "value", "section", "we", "employ", "standard", "light", "field", "parameterization", "where", "ray", "encode", "intersection", "two", "plane", "st", "plane", "uv", "plane", "unit", "distance", "from", "former", "spatial", "angular", "distribution", "input", "sample", "determine", "scene", "geometry", "reflectance", "function", "primary", "hit", "input", "renderer", "perform", "importance", "sampling", "accord", "they", "we", "input", "carry", "information", "about", "angular", "variation", "form", "bandwidth", "estimate", "remain", "balance", "known", "angular", "support", "spatial", "support", "specifically", "diffuse", "surface", "where", "outgoing", "radiance", "do", "vary", "over", "angle", "radiance", "input", "sample", "can", "reuse", "any", "reconstruction", "ray", "pass", "near", "sample", "space", "matter", "how", "far", "angle", "provide", "visibility", "account", "treat", "splat", "simple", "opaque", "occluder", "lead", "unacceptable", "result", "more", "sophisticated", "technique", "require", "determine", "which", "splat", "part", "same", "surface", "-lsb-", "Zwicker", "et", "al.", "2001", "-rsb-", "allow", "filter", "between", "sample", "detect", "visibility", "conflict", "we", "generalize", "heuristic", "Lehtinen", "et", "al.", "-lsb-", "2011", "-rsb-", "detect", "crossing", "trajectory", "light", "field", "defocus", "motion", "blur", "geometric", "interpretation", "test", "two", "sample", "belong", "different", "surface", "event", "line", "define", "line", "go", "through", "scene", "point", "correspond", "sample", "intersect", "lens", "visibility", "conflict", "detect", "compute", "intersection", "st", "plane", "event", "line", "form", "connect", "two", "endpoint", "effect", "curvature", "anisotropy", "incident", "light", "field", "-lrb-", "instance", "near-field", "illumination", "-rrb-", "sample", "point", "play", "role", "how", "space", "angle", "interact", "outgoing", "light", "field", "potentially", "cause", "additional", "shears", "-lsb-", "Durand", "et", "al.", "2005", "-rsb-" ],
  "content" : "Evaluating the indirect illumination entails sampling the radiance over the hemisphere at each visible point, and is notoriously prone to noise due to the high variance of the integrand caused by visibility, texture, and illumination. The reconstructed light field is then used in a standard BRDF sampling step to generate the final image. We build on recent work that has provided a solid understanding of the local anisotropies exhibited by the temporal light field [Durand et al. 2005; Ramamoorthi et al. 2007; Egan et al. 2009; Soler et al. 2009; Egan et al. 2011b]. In contrast to a large body of previous work aiming to reduce noise in global illumination, we do not utilize the scene geometry in the reconstruction pass. A body of recent work concentrates on anisotropy, i.e., the fact that the signal often varies slowly along certain non-axis-aligned subspaces. Fourier analysis elegantly reveals that the signal is locally effectively of a lower dimension 1 in these cases [Durand et al. 2005; Egan et al. 2009]. The recent trend in anisotropic reconstruction can be traced back to the Multidimensional Adaptive Sampling and Reconstruction (MDAS) algorithm of Hachisuka et al. [2008]. While numerous earlier techniques had addressed the generation of samples according to the expected variance in the integrand (importance sampling and adaptive sampling methods), Hachisuka et al. concentrated on\n      1 For example, the 4D integrand over the image and the lens that corresponds to a diffuse fronto-parallel planar object that is out of focus is actually only two-dimensional. The authors measure the local anisotropy from the samples using a structure tensor, and use it for locally warping the distance metric used for reconstructing the integrand using a highdimensional k-nearest-neighbor search (k-NN). This can yield significant benefits, but unfortunately, noise and texture may confuse the anisotropy estimator. Egan et al. [2009] analyzed the anisotropy in the spacetime integrand of motion blur from first principles through Fourier analysis, and used predictions of the local spectra for driving adaptive sampling. A sheared filter that allows sharing of samples between pixels was then adapted to the predicted spectra. Similar analysis and algorithms were presented for soft shadows and directional occlusion by the same authors [Egan et al. 2011b; Egan et al. 2011a]. While the analysis is successful in driving adaptive sampling, the sheared reconstruction filter is less efficient when the direction of anisotropy changes, either continuously or discontinuously, across the image. The goal of the present work is to extend this approach to the more challenging and unstructured case of indirect illumination. Sample-based algorithms Several techniques, e.g., anisotropic diffusion [McCool 1999] or a (cascade of) cross-bilateral filter(s) [Dammertz et al. 2010], post-process the samples or pixels generated in an initial rendering pass to reduce noise. Sen and Darabi [2012] improve the quality of cross-bilateral filters by computing the weights adaptively for each pixel based on apparent dependencies between domain variables, scene features, and sample colors. While their method can, for example, detect that samples in some pixels are heavily affected by time, it does not know the magnitude or direction of the motion. Overbeck et al. [2009] and Rousselle et al. [2011] describe methods that maintain a basis-representation of the image and adaptively request more samples from the renderer to the areas that exhibit high variance. Shading reuse Several algorithms reuse shading results, radiance or irradiance, while determining visibility with the actual scene [Ward et al. 1988; Bala et al. 1999; Bekaert et al. 2002; Gassenbauer et al. 2009]. Sampling is often adaptive and driven by an error heuristic. These algorithms convert the scene to a point-based representation as a preprocess, and then compute the solution using that representation. In contrast, we obtain a sparse set of path segments from a renderer (which uses whatever representation internally), treat the segments as samples of the indirect light field, and upsample the solution accounting for angular effects of gloss. Photons and VPLs Some methods generate a cloud of point lights (called photons or virtual point lights or VPLs) that represents the entire indirect light field [Wann Jensen 1996; Keller 1997; Walter et al. 2005]. We seek to render high-quality global illumination while only tracing a small number of rays across the hemisphere at each visible point. We reuse these rays across many pixels to reconstruct, at each visible point, an upsampled version of the incoming light field. We store the rays cast from the visible points into a spatial hierarchy, indexed by their hit point (Section 2.1). Each ray is a sample of the indirect light field. This handles two dimensions of the light field. Each input sample s i corresponds to a secondary ray, and consists of the tuple  where L is radiance, o and h are the origin and hit point of the secondary ray, n o,h and v o,h are their corresponding normals and motion vectors. The numbers {x, y, u, v, t, ?} are the image, lens, and time coordinates, and the incident direction in which L(o ? ?) was sampled. and store ?, its concentration parameter. The total number of reconstruction rays per pixel is thus N ? n, where n is the number of primary hits per pixel. This guarantees that the distribution of rays generated during the final image reconstruction is similar to that in the input. We discuss possible noise in the radiance values L in Section 4. We employ a standard light field parameterization, where rays are encoded by their intersections with two planes: an st plane, and an uv plane at unit distance from the former. The spatial and angular distribution of the input samples is determined by the scene geometry and the reflectance functions of the primary hits, as the input renderer performs importance sampling according to them. As our input carries information about the angular variation in form of the bandwidth estimate, it remains to balance the known angular support with the spatial support. Specifically, for diffuse surfaces, where outgoing radiance does not vary over angle, the radiance of the input sample can be reused for any reconstruction ray that passes near the sample in space, no matter how far in angle, provided visibility is accounted for. Treating the splats as simple opaque occluders leads to unacceptable results, and more sophisticated techniques are required for determining which splats are part of the same surface [Zwicker et al. 2001] to allow filtering between samples. To detect visibility conflicts, we generalize the heuristic of Lehtinen et al. [2011] that detects crossings of trajectories in the light field for defocus and motion blur. A geometric interpretation of their test is that two samples belong to different surfaces if an event  line, defined as the line that goes through the scene points corresponding to the samples, intersects the lens. Visibility conflicts are detected by computing the intersection of the st plane and the event line formed by connecting the two endpoints h i and h j . Effects such as curvature and the anisotropy of the incident light field (for instance, near-field illumination) at the sample points play a role in how space and angle interact in the outgoing light field, potentially causing additional shears [Durand et al. 2005].",
  "resources" : [ ]
}