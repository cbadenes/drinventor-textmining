{
  "uri" : "sig2011a-a130-dale_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2011a/a130-dale_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Video Face Replacement",
    "published" : "2011",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Mahmoud-Afifi",
      "name" : "Mahmoud",
      "surname" : "Afifi"
    }, {
      "uri" : "http://drinventor/Khaled F.-Hussain",
      "name" : "Khaled F.",
      "surname" : "Hussain"
    }, {
      "uri" : "http://drinventor/Hosny M.-Ibrahim",
      "name" : "Hosny M.",
      "surname" : "Ibrahim"
    }, {
      "uri" : "http://drinventor/Nagwa M.-Omar",
      "name" : "Nagwa M.",
      "surname" : "Omar"
    } ]
  },
  "bagOfWords" : [ "technique", "manipulate", "replace", "face", "photograph", "have", "mature", "point", "realistic", "result", "can", "obtain", "minimal", "user", "input", "-lrb-", "e.g.", "-lsb-", "Agarwala", "et", "al.", "2004", "Bitouk", "et", "al.", "2008", "Sunkavalli", "et", "al.", "2010", "-rsb-", "-rrb-", "Face", "replacement", "video", "however", "pose", "significant", "challenge", "due", "complex", "facial", "geometry", "well", "we", "perceptual", "sensitivity", "both", "static", "dynamic", "element", "face", "result", "current", "system", "require", "complex", "hardware", "significant", "user", "intervention", "achieve", "sufficient", "level", "realism", "-lrb-", "e.g.", "-lsb-", "Alexander", "et", "al.", "2009", "-rsb-", "-rrb-", "paper", "present", "method", "face", "replacement", "video", "achieve", "high-quality", "result", "use", "simple", "acquisition", "process", "unlike", "previous", "work", "we", "approach", "assume", "inexpensive", "hardware", "require", "minimal", "user", "intervention", "use", "single", "camera", "simple", "illumination", "we", "capture", "source", "video", "insert", "target", "video", "-lrb-", "fig.", "-rrb-", "we", "track", "face", "both", "source", "target", "video", "use", "3d", "multilinear", "model", "we", "warp", "source", "video", "both", "space", "time", "align", "target", "finally", "we", "blend", "video", "compute", "optimal", "spatio-temporal", "seam", "novel", "mesh-centric", "gradient", "domain", "blend", "technique", "we", "system", "replace", "all", "part", "face", "target", "video", "from", "source", "video", "source", "target", "can", "have", "same", "person", "two", "different", "subject", "can", "contain", "similar", "performance", "two", "very", "different", "performance", "either", "source", "target", "can", "exist", "-lrb-", "i.e.", "uncontrolled", "-rrb-", "footage", "long", "face", "pose", "-lrb-", "i.e.", "rotation", "translation", "-rrb-", "approximately", "same", "lead", "handful", "unique", "useful", "scenario", "film", "video", "editing", "where", "video", "face", "replacement", "can", "apply", "example", "common", "multiple", "take", "same", "scene", "shoot", "close", "succession", "during", "television", "movie", "shoot", "while", "timing", "performance", "across", "take", "very", "similar", "subtle", "variation", "actor?s", "inflection", "expression", "distinguish", "one", "take", "from", "other", "instead", "choose", "single", "best", "take", "final", "cut", "we", "system", "can", "combine", "e.g.", "mouth", "performance", "from", "one", "take", "eye", "brow", "expression", "from", "another", "produce", "video", "montage", "related", "scenario", "dub", "where", "source", "target", "subject", "same", "source", "video", "depict", "actor", "studio", "record", "foreign", "language", "track", "target", "footage", "shot", "location", "result", "video", "face", "replacement", "can", "far", "superior", "common", "approach", "replace", "audio", "track", "only", "contrast", "multi-take", "video", "montage", "timing", "dub", "source", "completely", "different", "target", "face", "typically", "fully", "replace", "although", "partial", "replacement", "just", "mouth", "performance", "possible", "too", "another", "useful", "scenario", "involve", "retargeting", "exist", "footage", "produce", "sequence", "combine", "exist", "backdrop", "new", "face", "place", "exist", "actor?s", "facial", "performance", "new", "footage", "here", "new", "footage", "shoot", "use", "old", "footage", "audiovisual", "guide", "timing", "performance", "roughly", "match", "we", "video-based", "method", "particularly", "suitable", "case", "because", "we", "have", "control", "over", "capture", "exist", "footage", "final", "scenario", "replacement", "where", "target", "facial", "performance", "replace", "arbitrary", "source", "performance", "different", "subject", "useful", "example", "when", "replace", "stunt", "actor?s", "face", "capture", "dangerous", "environment", "star", "actor?s", "face", "record", "safe", "studio", "setting", "contrast", "retargeting", "where", "source", "footage", "shoot", "use", "target", "audiovisual", "guide", "roughly", "match", "timing", "performance", "source", "target", "can", "very", "different", "similar", "dub", "different", "subject", "furthermore", "entertaining", "amateur", "put", "face", "friend", "family", "popular", "movie", "music", "video", "indeed", "active", "community", "user", "YouTube", "have", "form", "share", "video", "despite", "current", "manual", "process", "create", "they", "-lrb-", "e.g.", "search", "Obama", "Dance", "off", "-rrb-", "we", "video", "face", "replacement", "system", "would", "certainly", "benefit", "user", "dramatically", "simplify", "currently", "labor-intensive", "process", "make", "video", "Video", "face", "replacement", "have", "advantage", "over", "replace", "entire", "body", "head", "video", "full", "body", "replacement", "typically", "require", "chroma", "key", "compositing", "-lrb-", "i.e.", "green", "screening", "-rrb-", "rotoscoping", "separate", "body", "from", "video", "head", "replacement", "difficult", "due", "complexity", "determine", "appropriate", "matte", "region", "contain", "hair", "exist", "method", "both", "body", "head", "replacement", "require", "expensive", "equipment", "significant", "manual", "work", "both", "-lsb-", "Alexander", "et", "al.", "2009", "-rsb-", "method", "practical", "amateur", "setting", "also", "time", "consuming", "challenging", "professional", "we", "system", "do", "rely", "few", "assumption", "about", "input", "video", "work", "best", "when", "illumination", "source", "target", "video", "similar", "however", "we", "mitigate", "limitation", "find", "coherent", "spatio-temporal", "seam", "blend", "minimize", "difference", "between", "source", "target", "video", "-lrb-", "sec", "second", "we", "assume", "pose", "face", "source", "target", "video", "45", "from", "frontal", "otherwise", "automatic", "tracking", "alignment", "face", "fail", "-lrb-", "Sec", "assumption", "could", "waive", "employ", "user", "assistance", "during", "tracking", "main", "contribution", "paper", "new", "system", "video", "face", "replacement", "do", "require", "expensive", "equipment", "significant", "user", "intervention", "we", "develop", "novel", "spatio-temporal", "seam", "finding", "technique", "work", "mesh", "optimal", "coherent", "blending", "result", "we", "demonstrate", "applicability", "we", "approach", "number", "example", "four", "scenario", "video", "montage", "-lrb-", "fig.", "-rrb-", "dubbing", "-lrb-", "fig.", "-rrb-", "retargeting", "-lrb-", "fig.", "10", "-rrb-", "replacement", "-lrb-", "fig.", "-rrb-", "we", "present", "result", "user", "study", "mechanical", "Turk", "demonstrate", "we", "system", "sufficient", "plausible", "face", "replacement", "difficult", "distinguish", "from", "real", "footage", "-lrb-", "sec", "Face", "replacement", "image", "video", "have", "be", "consider", "variety", "scenario", "include", "animation", "expression", "transfer", "online", "privacy", "however", "direct", "video-to-video", "face", "transfer", "present", "paper", "have", "be", "relatively", "unexplored", "we", "briefly", "describe", "previous", "work", "face", "replacement", "compare", "approach", "we", "system", "edit", "face", "image", "Face", "editing", "replacement", "image", "have", "be", "subject", "extensive", "research", "example", "method", "Blanz", "et", "al.", "-lsb-", "2004", "-rsb-", "fit", "morphable", "model", "face", "both", "source", "target", "image", "render", "source", "face", "parameter", "estimate", "from", "target", "image", "wellknown", "photomontage", "-lsb-", "Agarwala", "et", "al.", "2004", "-rsb-", "instant", "cloning", "system", "-lsb-", "Farbman", "et", "al.", "2009", "-rsb-", "allow", "replace", "face", "photograph", "use", "seamless", "blending", "-lsb-", "p?rez", "et", "al.", "2003", "-rsb-", "Bitouk", "et", "al.", "-lsb-", "2008", "-rsb-", "describe", "system", "automatic", "face", "swap", "use", "large", "database", "face", "use", "system", "conceal", "identity", "face", "target", "image", "Face", "image", "have", "be", "also", "use", "prior", "enhance", "face", "attractiveness", "use", "global", "face", "warping", "-lsb-", "Leyvand", "et", "al.", "2008", "-rsb-", "adjust", "tone", "sharpness", "lighting", "face", "-lsb-", "Joshi", "et", "al.", "2010", "-rsb-", "system", "Sunkavalli", "et", "al.", "-lsb-", "2010", "-rsb-", "model", "texture", "noise", "contrast", "blur", "target", "face", "improve", "appearance", "composite", "more", "recently", "Yang", "et", "al.", "-lsb-", "2011", "-rsb-", "use", "optical", "flow", "replace", "face", "expression", "between", "two", "photograph", "flow", "derive", "from", "3d", "morphable", "model", "fit", "source", "target", "photo", "clear", "whether", "any", "method", "could", "achieve", "temporally", "coherent", "result", "when", "apply", "video", "sequence", "Face", "Replacement", "Video", "use", "3D", "model", "traditional", "way", "replace", "face", "video", "acquire", "3d", "face", "model", "actor", "animate", "face", "relight", "render", "composite", "animated", "model", "source", "footage", "3d", "face", "model", "actor", "can", "capture", "use", "marker-based", "-lsb-", "Williams", "1990", "Guenter", "et", "al.", "1998", "Bickel", "et", "al.", "2007", "-rsb-", "structured", "light", "-lsb-", "Zhang", "et", "al.", "2004", "Ma", "et", "al.", "2008", "Li", "et", "al.", "2009", "Weise", "et", "al.", "2009", "-rsb-", "passive", "multi-view", "stereo", "approach", "-lsb-", "Jones", "et", "al.", "2006", "Bradley", "et", "al.", "2010", "Beeler", "et", "al.", "2011", "-lrb-", "appear", "-rrb-", "-rsb-", "model-based", "face", "replacement", "can", "achieve", "remarkable", "realism", "notable", "example", "include", "recreation", "actor", "Matrix", "Reloaded", "-lsb-", "Borshukov", "et", "al.", "2003", "-rsb-", "curious", "case", "Benjamin", "Button", "-lsb-", "Robertson", "2009", "-rsb-", "Digital", "Emily", "project", "-lsb-", "Alexander", "et", "al.", "2009", "-rsb-", "however", "method", "expensive", "typically", "require", "complex", "hardware", "significant", "user", "intervention", "achieve", "sufficient", "level", "realism", "Video-to-Video", "Face", "Replacement", "purely", "image-based", "method", "do", "construct", "3d", "model", "actor", "Bregler", "et", "al.", "-lsb-", "1997", "-rsb-", "Ezzat", "et", "al.", "-lsb-", "2002", "-rsb-", "replace", "mouth", "region", "video", "match", "phoneme", "novel", "audio", "input", "use", "database", "training", "image", "same", "actor", "Flagg", "et", "al.", "-lsb-", "2009", "-rsb-", "use", "video-texture", "synthesize", "plausible", "articulated", "body", "motion", "Kemelmacher-Shlizerman", "et", "al.", "-lsb-", "2010", "-rsb-", "make", "use", "image", "collection", "video", "celebrity", "available", "online", "replace", "face", "photo", "real-time", "base", "expression", "pose", "similarity", "however", "none", "method", "able", "synthesize", "subtlety", "facial", "performance", "actor", "morphable-model", "Face", "synthesis", "closely", "related", "we", "work", "image-based", "face", "capture", "method", "-lsb-", "Essa", "et", "al.", "1996", "DeCarlo", "Metaxas", "1996", "Pighin", "et", "al.", "1999", "Blanz", "et", "al.", "2003", "Vlasic", "et", "al.", "2005", "-rsb-", "approach", "build", "morphable", "3d", "face", "model", "from", "source", "image", "without", "marker", "special", "face", "scanning", "equipment", "we", "use", "multilinear", "model", "Vlasic", "al.", "-lsb-", "2005", "-rsb-", "capture", "identity", "expression", "viseme", "source", "target", "video", "exist", "approach", "use", "estimate", "model", "parameter", "generate", "drive", "detailed", "3d", "textured", "face", "mesh", "target", "identity", "which", "can", "seamlessly", "render", "back", "target", "footage", "general", "system", "assume", "source", "actor?s", "performance", "face", "desire", "newly", "synthesize", "output", "video", "contrast", "we", "approach", "blend", "source", "actor?s", "complete", "face", "performance", "all", "its", "nuance", "intact", "target" ],
  "content" : "Techniques for manipulating and replacing faces in photographs have matured to the point that realistic results can be obtained with minimal user input (e.g., [Agarwala et al. 2004; Bitouk et al. 2008;  Sunkavalli et al. 2010]). Face replacement in video, however, poses significant challenges due to the complex facial geometry as well as our perceptual sensitivity to both the static and dynamic elements of faces. As a result, current systems require complex hardware and significant user intervention to achieve a sufficient level of realism (e.g., [Alexander et al. 2009]). This paper presents a method for face replacement in video that achieves high-quality results using a simple acquisition process. Unlike previous work, our approach assumes inexpensive hardware and requires minimal user intervention. Using a single camera and simple illumination, we capture source video that will be inserted into a target video ( Fig. 1 ). We track the face in both the source and target videos using a 3D multilinear model. Then we warp the source video in both space and time to align it to the target. Finally, we blend the videos by computing an optimal spatio-temporal seam and a novel mesh-centric gradient domain blending technique. Our system replaces all or part of the face in the target video with that from the source video. Source and target can have the same person or two different subjects. They can contain similar performances or two very different performances. And either the source or the target can be existing (i.e., uncontrolled) footage, as long as the face poses (i.e., rotation and translation) are approximately the same. This leads to a handful of unique and useful scenarios in film and video editing where video face replacement can be applied. For example, it is common for multiple takes of the same scene to be shot in close succession during a television or movie shoot. While the timing of performances across takes is very similar, subtle variations in the actor?s inflection or expression distinguish one take from the other. Instead of choosing the single best take for the final cut, our system can combine, e.g., the mouth performance from one take and the eyes, brow, and expressions from another to produce a video montage. A related scenario is dubbing, where the source and target subject are the same, and the source video depicts an actor in a studio recording a foreign language track for the target footage shot on location. The resulting video face replacement can be far superior to the common approach of replacing the audio track only. In contrast to multi-take video montage, the timing of the dubbing source is completely different and the target face is typically fully replaced, although partial replacement of just the mouth performance is possible, too. Another useful scenario involves retargeting existing footage to produce a sequence that combines an existing backdrop with a new face or places an existing actor?s facial performance into new footage. Here the new footage is shot using the old footage as an audiovisual guide such that the timing of the performances roughly matches. Our video-based method is particularly suitable in this case because we have no control over the capture of the existing footage. A final scenario is replacement, where the target facial performance is replaced with an arbitrary source performance by a different subject. This is useful, for example, when replacing a stunt actor?s face, captured in a dangerous environment, with the star actor?s face, recorded in a safe studio setting. In contrast to retargeting, where the source footage is shot using the target as an audiovisual guide to roughly match the timings, the performance of the source and target can be very different, similar to dubbing but with different subjects. Furthermore, it is entertaining for amateurs to put faces of friends and family into popular movies or music videos. Indeed, an active community of users on YouTube has formed to share such videos despite the current manual process of creating them (e.g., search for ?Obama Dance Off?). Our video face replacement system would certainly benefit these users by dramatically simplifying the currently labor-intensive process of making these videos. Video face replacement has advantages over replacing the entire body or the head in video. Full body replacement typically requires chroma key compositing (i.e., green screening) or rotoscoping to separate the body from the video. Head replacement is difficult due to the complexities of determining an appropriate matte in regions containing hair. Existing methods for both body and head replacement require expensive equipment, significant manual work, or both [Alexander et al. 2009]. Such methods are not practical in an amateur setting and are also time consuming and challenging for professionals. Our system does rely on a few assumptions about the input videos. It works best when the illumination in the source and target videos is similar. However, we mitigate this limitation by finding a coherent spatio-temporal seam for blending that minimizes the differences between the source and target videos (Sec. Second, we assume that the pose of faces in the source and target videos is ?45 o from frontal, otherwise automatic tracking and alignment of the faces will fail (Sec. This assumption could be waived by employing user assistance during tracking. The main contribution of this paper is a new system for video face replacement that does not require expensive equipment or significant user intervention. We developed a novel spatio-temporal seam finding technique that works on meshes for optimal coherent blending results. We demonstrate the applicability of our approach on a number of examples in four scenarios: video montage ( Fig. 6 ), dubbing ( Fig. 7 ), retargeting (Figs. 1 and 10), and replacement ( Fig. 9 ). We present results of a user study on Mechanical Turk that demonstrates that our system is sufficient for plausible face replacement and difficult to distinguish from real footage (Sec. Face replacement in images and video has been considered in a variety of scenarios, including animation, expression transfer, and online privacy. However, the direct video-to-video face transfer presented in this paper has been relatively unexplored. We briefly  describe previous work on face replacement and compare these approaches to our system. Editing Faces in Images Face editing and replacement in images has been a subject of an extensive research. For example, the method by Blanz et al. [2004] fits a morphable model to faces in both the source and target images and renders the source face with the parameters estimated from the target image. The wellknown photomontage [Agarwala et al. 2004] and instant cloning systems [Farbman et al. 2009] allow for replacing faces in photographs using seamless blending [P?rez et al. 2003]. Bitouk et al. [2008] describe a system for automatic face swapping using a large database of faces. They use this system to conceal the identity of the face in the target image. Face images have been also used as priors to enhance face attractiveness using global face warping [Leyvand et al. 2008] or to adjust tone, sharpness, and lighting of faces [Joshi et al. 2010]. The system of Sunkavalli et al. [2010] models the texture, noise, contrast and blur of the target face to improve the appearance of the composite. More recently, Yang et al. [2011] use optical flow to replace face expressions between two photographs. The flow is derived from 3D morphable models that are fit to the source and target photos. It is not clear whether any of these methods could achieve temporally coherent results when applied to a video sequence. Face Replacement in Video using 3D Models The traditional way to replace faces in video is to acquire a 3D face model of the actor, to animate the face, and to relight, render, and composite the animated model into the source footage. The 3D face model of the actor can be captured using marker-based [Williams 1990; Guenter et al. 1998; Bickel et al. 2007], structured light [Zhang et al. 2004; Ma et al. 2008; Li et al. 2009; Weise et al. 2009], or passive multi-view stereo approaches [Jones et al. 2006; Bradley et al. 2010; Beeler et al. 2011 (to appear)]. Model-based face replacement can achieve remarkable realism. Notable examples include the recreation of actors for The Matrix Reloaded [Borshukov et al. 2003], The Curious Case of Benjamin Button [Robertson 2009], and the Digital Emily project [Alexander et al. 2009]. However, these methods are expensive, and typically require complex hardware and significant user intervention to achieve a sufficient level of realism. Video-to-Video Face Replacement Purely image-based methods do not construct a 3D model of the actor. Bregler et al. [1997] and Ezzat et al. [2002] replace the mouth region in video to match phonemes of novel audio input using a database of training images of the same actor. Flagg et al. [2009] use video-textures to synthesize plausible articulated body motion. Kemelmacher-Shlizerman et al. [2010] make use of image collections and videos of celebrities available online and replace face photos in real-time based on expression and pose similarity. However, none of these methods are able to synthesize the subtleties of the facial performance of an actor. Morphable-Models for Face Synthesis Closely related to our work are image-based face capture methods [Essa et al. 1996; DeCarlo and Metaxas 1996; Pighin et al. 1999; Blanz et al. 2003; Vlasic et al. 2005]. These approaches build a morphable 3D face model from source images without markers or special face scanning equipment. We use the multilinear model by Vlasic at al. [2005] that captures identity, expression, and visemes in the source and target videos. Existing approaches use the estimated model parameters to generate and drive a detailed 3D textured face mesh for a target identity, which can be seamlessly rendered back into target footage. In general, these systems assume the source actor?s performance, but not their face, is desired in the newly synthesized output video. In contrast, our approach blends the source actor?s complete face and performance, with all of its nuances intact, into the target.",
  "resources" : [ ]
}