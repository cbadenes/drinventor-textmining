{
  "uri" : "sig2014-a37-su_PROC.xml",
  "url" : "/Users/cbadenes/Documents/OEG/Projects/DrInventor/datasets/acm-siggraph-2006-2014-upf/sig2014/a37-su_PROC.xml",
  "source" : {
    "name" : "SIGGRAPH",
    "uri" : "http://drinventor/SIGGRAPH",
    "url" : "http://drinventor/SIGGRAPH",
    "protocol" : "http"
  },
  "metainformation" : {
    "title" : "Estimating Image Depth Using Shape Collections",
    "published" : "2014",
    "format" : "pdf",
    "language" : "en",
    "rights" : "GPLv2",
    "description" : "",
    "creators" : [ {
      "uri" : "http://drinventor/Hao-Su",
      "name" : "Hao",
      "surname" : "Su"
    }, {
      "uri" : "http://drinventor/Qixing-Huang",
      "name" : "Qixing",
      "surname" : "Huang"
    }, {
      "uri" : "http://drinventor/Niloy J.-Mitra",
      "name" : "Niloy J.",
      "surname" : "Mitra"
    }, {
      "uri" : "http://drinventor/Yangyan-Li",
      "name" : "Yangyan",
      "surname" : "Li"
    }, {
      "uri" : "http://drinventor/Leonidas J.-Guibas",
      "name" : "Leonidas J.",
      "surname" : "Guibas"
    } ]
  },
  "bagOfWords" : [ "point", "cloud", "optimization", "stage", "take", "25", "average", "camera", "initialization", "stage", "take", "average", "0.3", "each", "input", "image", "most", "time", "spend", "extract", "image", "feature", "reconstruction", "stage", "proceeds", "three", "step", "where", "first", "two", "step", "provide", "initial", "solution", "-lrb-", "set", "similar", "shape", "initial", "point", "cloud", "-rrb-", "third", "step", "optimize", "point", "cloud", "minimize", "its", "distance", "deform", "similar", "shape", "give", "initial", "camera", "configuration", "we", "generate", "initial", "point", "cloud", "from", "do", "select", "set", "similar", "shape", "input", "image", "establish", "dense", "correspondence", "between", "similar", "shape", "transfer", "depth", "information", "algorithm", "consist", "preprocessing", "stage", "which", "align", "input", "shape", "each", "other", "learn", "deformation", "model", "each", "shape", "reconstruction", "stage", "which", "use", "continuous", "optimization", "recover", "image", "object", "pose", "reconstruct", "point", "cloud", "from", "image", "align", "relevant", "3d", "model", "extract", "from", "collection", "illustrate", "figure", "pipeline", "consist", "preprocessing", "stage", "reconstruction", "stage", "each", "image", "object", "point", "cloud", "initialization", "stage", "take", "7", "average", "1", "correspondence", "initialization", "6", "correspondence", "pruning", "infer", "point", "cloud", "only", "have", "point", "visible", "from", "camera", "view", "second", "success", "non-rigid", "alignment", "depend", "good", "initialization", "both", "camera", "pose", "point", "cloud", "objective", "function", "minimize", "distance", "between", "point", "cloud", "deform", "shape" ],
  "content" : "The point cloud optimization stage took ? 25s in average. The camera initialization stage takes on average 0.3s for each input image, and most of the time was spent on extracting image features. The reconstruction stage proceeds in three steps, where the first two steps provide an initial solution (a set of similar shapes and an initial point cloud) and the third step optimizes this point cloud to minimize its distance to the deformed similar shapes. Given the initial camera configuration we generate an initial point cloud P from I. This is done by selecting a set of similar shapes to the input image, and then establishing dense correspondences between I and the similar shapes for transferring depth information. The algorithm consists of a preprocessing stage, which aligns the input shapes to each other and learns a deformation model for each shape; and a reconstruction stage, which uses a continuous optimization to recover the image object pose and reconstruct a point cloud from the image that aligns with relevant 3D models extracted from the collection. As illustrated in Figure 2 , the pipeline consists of a preprocessing stage and a reconstruction stage. For each image object, the point cloud initialization stage took ?7s in average, with ?1s on correspondence initialization and ? 6s on correspondence pruning. The inferred point cloud only has points visible from the camera view. Second, the success of the non-rigid alignment depends on a good initialization for both the camera pose and the point cloud. The objective function minimizes the distance between the point cloud and the deformed shapes.",
  "resources" : [ ]
}